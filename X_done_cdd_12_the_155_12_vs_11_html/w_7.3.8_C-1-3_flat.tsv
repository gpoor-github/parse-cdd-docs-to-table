"Section"	"section_id"	"req_id"	"full_key"	"key_as_number"	"requirement"	"Test Availability"	"search_roots"	"search_terms"	"manual_search_terms"	"not_search_terms"	"not_files"	"max_matches"	"class_defs"	"methods"	"modules"	"protected"	"class_def"	"method"	"module"	"file_name"	"matched_files"	"methods_string"	"urls"	"method_text"	"matched_terms"	"qualified_method"	"Annotation?"	"New Req for S?"	"New CTS for S?"	"Comment(internal) e.g. why a test is not possible"	"CTS Bug Id"	"CDD Bug Id"	"Area"	"Shortened"	"Test Level"
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.TimestampClockSourceVerification"	"isDeviceSuspendTest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/TimestampClockSourceVerification.java"	""	"public void test/*
 *
 */

package android.hardware.cts.helpers.sensorverification;

import junit.framework.Assert;

import android.hardware.SensorEvent;
import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEvent;
import android.os.SystemClock;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;
import android.util.Log;

/**
 * A {@link ISensorVerification} which verifies that the timestamp of the {@link SensorEvent} is
 * synchronized with {@link SystemClock#elapsedRealtimeNanos()}, based on a given threshold.
 */
public class TimestampClockSourceVerification extends AbstractSensorVerification {
    public static final String TAG = ""TimestampClockSourceVerification"";
    public static final String PASSED_KEY = ""timestamp_verification_passed"";

    // number of indices to print in assertion message before truncating
    private static final int TRUNCATE_MESSAGE_LENGTH = 3;

    private static final long DEFAULT_THRESHOLD_NS = TimeUnit.MILLISECONDS.toNanos(1000);
    private static final float ALLOWED_LATENCY_ERROR = 0.1f; //10%

    private final ArrayList<TestSensorEvent> mCollectedEvents = new ArrayList<TestSensorEvent>();

    private long mMaximumLatencyNs;

    /**
     * Constructs an instance of {@link TimestampClockSourceVerification}.
     *
     * @param maxLatencyNs Maximum allowed timestamp delta between event timestamp and current time
     */
    public TimestampClockSourceVerification (
            long maxLatencyUs) {
        mMaximumLatencyNs = maxLatencyUs * 1000;
    }

    /**
     * Gets a default {@link TimestampClockSourceVerification}.
     *
     * @param environment The test environment
     * @return The verification or null if the verification is not supported in the given
     *         environment.
     */
    public static TimestampClockSourceVerification getDefault(
            TestSensorEnvironment environment) {
        long reportLatencyUs = environment.getMaxReportLatencyUs();
        long fifoMaxEventCount = environment.getSensor().getFifoMaxEventCount();
        int maximumExpectedSamplingPeriodUs = environment.getMaximumExpectedSamplingPeriodUs();
        if (fifoMaxEventCount > 0 && maximumExpectedSamplingPeriodUs != Integer.MAX_VALUE) {
            long fifoBasedReportLatencyUs = fifoMaxEventCount * maximumExpectedSamplingPeriodUs;
            // If the device goes into suspend mode and the sensor is a non wake-up sensor, the
            // FIFO will keep overwriting itself and the reportLatency will be equal to the time
            // it takes to fill up the FIFO.
            if (environment.isDeviceSuspendTest() && !environment.getSensor().isWakeUpSensor()) {
                reportLatencyUs = fifoBasedReportLatencyUs;
            } else {
                // In this case the sensor under test is either a wake-up sensor OR it
                // is a non wake-up sensor but the device does not go into suspend.
                // So the expected delay of a sensor_event is the minimum of the
                // fifoBasedReportLatencyUs and the requested latency by the application.
                reportLatencyUs = Math.min(reportLatencyUs, fifoBasedReportLatencyUs);
            }
        }
        // Add an additional filter delay which is a function of the samplingPeriod.
        long filterDelayUs = (long)(2.5 * maximumExpectedSamplingPeriodUs);

        long expectedSyncLatencyNs = TimeUnit.MICROSECONDS.toNanos(reportLatencyUs + filterDelayUs);

        return new TimestampClockSourceVerification(expectedSyncLatencyNs);
    }

    @Override
    public void verify(TestSensorEnvironment environment, SensorStats stats) {
        StringBuilder errorMessageBuilder =
                new StringBuilder("" Incorrect timestamp clock source failures: "");
        boolean success = false;
        int failuresCount = 0;
        List<IndexedEvent> failures;

        try {
            failures = verifyTimestampClockSource(errorMessageBuilder);
            failuresCount = failures.size();
            stats.addValue(SensorStats.EVENT_TIME_WRONG_CLOCKSOURCE_COUNT_KEY, failuresCount);
            stats.addValue(
                    SensorStats.EVENT_TIME_WRONG_CLOCKSOURCE_POSITIONS_KEY,
                    getIndexArray(failures));
            success = failures.isEmpty();
        } catch (Throwable e) {
            failuresCount++;
            stats.addValue(SensorStats.EVENT_TIME_WRONG_CLOCKSOURCE_COUNT_KEY, 0);
        }
        stats.addValue(PASSED_KEY, success);
        errorMessageBuilder.insert(0, failuresCount);
        Assert.assertTrue(errorMessageBuilder.toString(), success);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public TimestampClockSourceVerification clone() {
        return new TimestampClockSourceVerification(
                mMaximumLatencyNs);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    protected void addSensorEventInternal(TestSensorEvent event) {
        mCollectedEvents.add(event);
    }

    /**
     * Verifies timestamp clock source for each collected event
     *
     * @param builder A string builder to store error messaged found in the collected sensor events.
     * @return A list of events tha failed the verification.
     */
    private List<IndexedEvent> verifyTimestampClockSource(StringBuilder builder) throws Throwable {
        int collectedEventsCount = mCollectedEvents.size();
        ArrayList<IndexedEvent> failures = new ArrayList<IndexedEvent>();

        if (collectedEventsCount == 0) {
            if (failures.size() < TRUNCATE_MESSAGE_LENGTH) {
                builder.append(""No events received !"");
            }
            Assert.assertTrue(""No events received !"", false);
        }

        for (int i = 0; i < collectedEventsCount; ++i) {
            TestSensorEvent event = mCollectedEvents.get(i);
            long eventTimestampNs = event.timestamp;
            long receivedTimestampNs = event.receivedTimestamp;
            long upperThresholdNs = receivedTimestampNs;
            long lowerThresholdNs = receivedTimestampNs - mMaximumLatencyNs;

            if (eventTimestampNs < lowerThresholdNs || eventTimestampNs > upperThresholdNs) {
                if (failures.size() < TRUNCATE_MESSAGE_LENGTH) {
                    builder.append(""position="").append(i);
                    builder.append("", timestamp="").append(String.format(""%.2fms"",
                                nanosToMillis(eventTimestampNs)));
                    builder.append("", expected=["").append(String.format(""%.2fms"",
                                nanosToMillis(lowerThresholdNs)));
                    builder.append("", "").append(String.format(""%.2f]ms; "",
                                nanosToMillis(upperThresholdNs)));
                }
                failures.add(new IndexedEvent(i, event));
            }
        }
        if (failures.size() >= TRUNCATE_MESSAGE_LENGTH) {
            builder.append(""more; "");
        }
        return failures;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Renderer.BaseRenderer"	"doTestSpecificRendering"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Renderer/BaseRenderer.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Renderer;

import com.android.cts.verifier.sensors.sixdof.Renderer.RenderUtils.CameraStreamManager;
import com.android.cts.verifier.sensors.sixdof.Renderer.RenderUtils.DrawParameters;
import com.android.cts.verifier.sensors.sixdof.Renderer.Renderable.CameraPreviewRenderable;
import com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils;
import com.android.cts.verifier.sensors.sixdof.Utils.PoseProvider.PoseProvider;

import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.MATRIX_4X4;
import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.ORIENTATION_360_ANTI_CLOCKWISE;
import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.X;
import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.Y;
import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.Z;

import android.content.Context;
import android.content.res.Configuration;
import android.content.res.Resources;
import android.opengl.GLES20;
import android.opengl.GLSurfaceView;
import android.opengl.Matrix;
import android.util.Log;
import android.view.Display;
import android.view.Surface;
import android.view.WindowManager;

import javax.microedition.khronos.egl.EGLConfig;
import javax.microedition.khronos.opengles.GL10;

/**
 * Abstract class that connects to Android Camera to use as an OpenGL texture.
 */
public abstract class BaseRenderer implements GLSurfaceView.Renderer {
    private static final String TAG = ""BaseRenderer"";
    private static final int ORIENTATION_COUNT = 4;

    protected float[] mViewMatrix = new float[MATRIX_4X4];
    protected float[] mOrthogonalViewMatrix = new float[MATRIX_4X4];
    protected float[] mProjectionMatrix = new float[MATRIX_4X4];

    protected float[] mOrthogonalProjectionMatrix = new float[MATRIX_4X4];
    protected float[] mFrustrumProjectionMatrix = new float[MATRIX_4X4];

    protected DrawParameters mDrawParameters;

    protected float[] mCameraCoordinates;

    protected PoseProvider mPoseProvider;
    protected boolean mIsValid = false;

    protected CameraPreviewRenderable mCameraPreview;
    protected double mLastRGBFrameTimestamp = -1;

    private int mCameraPreviewRotation = 0;

    protected int mOpenGlRotation = 0;
    protected float[] mOpenGlUpVector;

    private Context mContext;

    public BaseRenderer(Context context) {
        mContext = context;
        mOpenGlRotation = getDeviceRotation(context);
        mOpenGlUpVector = getUpVector(mOpenGlRotation);
        mCameraPreviewRotation = CameraStreamManager.getRotation(context, mOpenGlRotation);
    }

    @Override
    public void onSurfaceCreated(GL10 glUnused, EGLConfig config) {
        // Set the background clear color to black.
        GLES20.glClearColor(0.0f, 0.0f, 0.0f, 0.0f);

        // Enable depth testing
        GLES20.glEnable(GLES20.GL_DEPTH_TEST);

        mCameraPreview = new CameraPreviewRenderable();

        resetViewMatrix();
    }

    protected void resetViewMatrix() {
        // Position the eye in front of the origin.
        final float eyeX = 0.0f;
        final float eyeY = 0.0f;
        final float eyeZ = 0.0f;

        // We are looking toward the distance
        final float lookX = 0.0f;
        final float lookY = 0.0f;
        final float lookZ = -5.0f;

        // Set our up vector. This is where our head would be pointing were we holding the camera.
        float[] upVector = getUpVector(mCameraPreviewRotation);

        // Set the view matrix.
        Matrix.setLookAtM(mViewMatrix, 0,
                eyeX, eyeY, eyeZ,
                lookX, lookY, lookZ,
                upVector[X], upVector[Y], upVector[Z]);
        Matrix.setLookAtM(mOrthogonalViewMatrix, 0,
                eyeX, eyeY, eyeZ,
                lookX, lookY, lookZ,
                upVector[X], upVector[Y], upVector[Z]);
    }

    @Override
    public void onSurfaceChanged(GL10 glUnused, int width, int height) {
        // Set the OpenGL viewport to the same size as the surface.
        GLES20.glViewport(0, 0, width, height);

        // Create a new perspective projection matrix. The height will stay the same
        // while the width will vary as per aspect ratio.
        // This project matrix does not take into account the camera intrinsics and should not be
        // used for AR purposes.
        final float ratio = (float) width / height;
        float left = -ratio;
        float right = ratio;
        float bottom = -1.0f;
        float top = 1.0f;
        final float near = 1.0f;
        final float far = 10.0f;

        boolean invertAxis = false;

        switch (mCameraPreviewRotation) {
            case MathsUtils.ORIENTATION_0:
            case MathsUtils.ORIENTATION_180_ANTI_CLOCKWISE:
            case MathsUtils.ORIENTATION_360_ANTI_CLOCKWISE:
                break;
            case MathsUtils.ORIENTATION_90_ANTI_CLOCKWISE:
            case MathsUtils.ORIENTATION_270_ANTI_CLOCKWISE:
                // Invert aspect ratio.
                invertAxis = true;
                bottom = -ratio;
                top = ratio;
                left = -1.0f;
                right = 1.0f;
                break;
            default:
                // Unexpected orientation, error out.
                throw new RuntimeException(""Unexpected orientation that cannot be dealt with!"");
        }

        mCameraCoordinates = getCameraCoordinates(left, right, bottom, top);

        // Give camera preview reference to the context so that it can connect to the camera.
        mCameraPreview.initialiseCameraPreview(mCameraCoordinates, invertAxis, mContext);

        Matrix.orthoM(mOrthogonalProjectionMatrix, 0, left, right, bottom, top, near, far);
        Matrix.frustumM(mFrustrumProjectionMatrix, 0, left, right, bottom, top, near, far);

        mProjectionMatrix = mOrthogonalProjectionMatrix;

        mDrawParameters = new DrawParameters();

        mIsValid = true;
    }

    @Override
    public void onDrawFrame(GL10 glUnused) {
        GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT | GLES20.GL_DEPTH_BUFFER_BIT);
        doPreRenderingSetup();
        doCoreRendering();
        doTestSpecificRendering();
    }

    private void doCoreRendering() {
        mDrawParameters.update(mViewMatrix, mProjectionMatrix);
        mCameraPreview.draw(mDrawParameters);
    }

    protected synchronized void updateCameraTexture() {
        mLastRGBFrameTimestamp = mCameraPreview.updateTexture();
    }

    /**
     * Setup up view and projecttion matrices to be the ones you want for this draw call.
     */
    protected abstract void doPreRenderingSetup();

    /**
     * Do rendering that is unique to each test.
     */
    protected abstract void doTestSpecificRendering();

    /**
     * Where to position the camera preview on the screen. Can be overridden by sub classes.
     */
    protected float[] getCameraCoordinates(float left, float right, float bottom, float top) {
        switch (mCameraPreviewRotation) {
            case MathsUtils.ORIENTATION_0:
            case MathsUtils.ORIENTATION_180_ANTI_CLOCKWISE:
            case MathsUtils.ORIENTATION_360_ANTI_CLOCKWISE:
                // Normal aspect ratio.
                return new float[]{
                        left, top, 0.0f,
                        left, bottom, 0.0f,
                        right, top, 0.0f,
                        left, bottom, 0.0f,
                        right, bottom, 0.0f,
                        right, top, 0.0f,
                };
            case MathsUtils.ORIENTATION_90_ANTI_CLOCKWISE:
            case MathsUtils.ORIENTATION_270_ANTI_CLOCKWISE:
                // Inverted aspect ratio.
                return new float[]{
                        bottom, right, 0.0f,
                        bottom, left, 0.0f,
                        top, right, 0.0f,
                        bottom, left, 0.0f,
                        top, left, 0.0f,
                        top, right, 0.0f,
                };
            default:
                // Unexpected orientation, error out.
                throw new RuntimeException(""Unexpected orientation that cannot be dealt with!"");
        }
    }


    /**
     * Saves PoseProvider object for later so we can connect to camera at appropriate time.
     */
    public void connectCamera(PoseProvider poseProvider, Context context) {
        // Save these for later so we can connect to camera after mCameraPreview has been
        // initialised. Also used to setup extrinsics in ComplexMovementRenderer.
        mPoseProvider = poseProvider;
        mContext = context;
    }

    public void disconnectCamera() {
        mCameraPreview.disconnectCamera();
    }

    public void onDestroy() {
        mPoseProvider = null;
        mContext = null;

        if (mCameraPreview != null) {
            mCameraPreview.destroy();
            mCameraPreview = null;
        }
    }

    private static float[] getUpVector(int rotation) {
        float [] upVector = new float[MathsUtils.VECTOR_3D];

        switch (rotation) {
            case MathsUtils.ORIENTATION_0:
            case ORIENTATION_360_ANTI_CLOCKWISE:
                upVector[X] = 0.0f;
                upVector[Y] = 1.0f;
                upVector[Z] = 0.0f;
                break;
            case MathsUtils.ORIENTATION_90_ANTI_CLOCKWISE:
                upVector[X] = -1.0f;
                upVector[Y] = 0.0f;
                upVector[Z] = 0.0f;
                break;
            case MathsUtils.ORIENTATION_180_ANTI_CLOCKWISE:
                upVector[X] = 0.0f;
                upVector[Y] = -1.0f;
                upVector[Z] = 0.0f;
                break;
            case MathsUtils.ORIENTATION_270_ANTI_CLOCKWISE:
                upVector[X] = 1.0f;
                upVector[Y] = 0.0f;
                upVector[Z] = 0.0f;
                break;
            default:
                // Unexpected orientation, error out.
                throw new RuntimeException(""Unexpected orientation that cannot be dealt with!"");
        }

        return upVector;
    }

    public static int getDeviceRotation(Context context) {
        WindowManager windowManager = (WindowManager)
                context.getSystemService(Context.WINDOW_SERVICE);
        final Display display = windowManager.getDefaultDisplay();
        int naturalOrientation = Configuration.ORIENTATION_LANDSCAPE;
        int configOrientation = context.getResources().getConfiguration().orientation;
        switch (display.getRotation()) {
            case Surface.ROTATION_0:
            case Surface.ROTATION_180:
                // We are currently in the same basic orientation as the natural orientation.
                naturalOrientation = configOrientation;
                break;
            case Surface.ROTATION_90:
            case Surface.ROTATION_270:
                // We are currently in the other basic orientation to the natural orientation.
                naturalOrientation = (configOrientation == Configuration.ORIENTATION_LANDSCAPE) ?
                        Configuration.ORIENTATION_PORTRAIT : Configuration.ORIENTATION_LANDSCAPE;
                break;
            default:
                // Unexpected orientation, error out.
                throw new RuntimeException(""Unexpected orientation that cannot be dealt with!"");
        }

        // Since the map starts at portrait, we need to offset if this device's natural orientation
        // is landscape.
        int indexOffset = 0;
        if (naturalOrientation == Configuration.ORIENTATION_LANDSCAPE) {
            indexOffset = 1;
        }

        // Get rotation as a clockwise rotation.
        int currentRotation = ORIENTATION_COUNT - display.getRotation();

        // Check for reverse rotation direction and currentRotation if required.
        try {
            if (context.getResources().getBoolean(context.getResources().getSystem().getIdentifier(
                    ""config_reverseDefaultRotation"", ""bool"", ""android""))) {
                currentRotation = display.getRotation();
            }
        } catch (Resources.NotFoundException e) {
            // If resource is not found, assume default rotation and continue.
            Log.d(TAG, ""Cannot determine device rotation direction, assuming default"");
        }

        int currentOrientation = (currentRotation + indexOffset);
        int defaultOrientation = indexOffset;

        int difference = (currentOrientation - defaultOrientation) % ORIENTATION_COUNT;
        difference = difference * 90;

        return difference;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.StepCounterTestActivity"	"StepCounterTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/StepCounterTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;

import junit.framework.Assert;

import android.content.Context;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.hardware.cts.helpers.MovementDetectorHelper;
import android.hardware.cts.helpers.SensorTestStateNotSupportedException;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEvent;
import android.os.SystemClock;
import android.view.MotionEvent;
import android.view.View;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;

public class StepCounterTestActivity
        extends SensorCtsVerifierTestActivity
        implements SensorEventListener {
    public StepCounterTestActivity() {
        super(StepCounterTestActivity.class);
    }

    private static final int TEST_DURATION_SECONDS = 20;
    private static final long TIMESTAMP_SYNCHRONIZATION_THRESHOLD_NANOS =
            TimeUnit.MILLISECONDS.toNanos(500);

    private static final int MIN_NUM_STEPS_PER_TEST = 10;
    private static final int MAX_STEP_DISCREPANCY = 5;
    private static final long MAX_TOLERANCE_STEP_TIME_NANOS = TimeUnit.SECONDS.toNanos(10);

    private static final long[] VIBRATE_PATTERN = {
            1000L, 500L, 1000L, 750L, 1000L, 500L, 1000L, 750L, 1000L, 1000L, 500L, 1000L,
            750L, 1000L, 500L, 1000L };

    private SensorManager mSensorManager;
    private Sensor mSensorStepCounter;
    private Sensor mSensorStepDetector;
    private MovementDetectorHelper mMovementDetectorHelper;

    private volatile boolean mMoveDetected;

    private final List<Long> mTimestampsUserReported = new ArrayList<Long>();
    private final List<TestSensorEvent> mStepCounterEvents = new ArrayList<TestSensorEvent>();
    private final List<TestSensorEvent> mStepDetectorEvents = new ArrayList<TestSensorEvent>();

    /**
     * A flag that indicates if the test is interested in registering steps reported by the
     * operator. The registration of events happens by tapping the screen throughout the test.
     */
    private volatile boolean mCheckForMotion;

    @Override
    protected void activitySetUp() {
        mSensorManager = (SensorManager) getSystemService(Context.SENSOR_SERVICE);
        mSensorStepCounter = mSensorManager.getDefaultSensor(Sensor.TYPE_STEP_COUNTER);
        mSensorStepDetector = mSensorManager.getDefaultSensor(Sensor.TYPE_STEP_DETECTOR);

        if (mSensorStepCounter == null && mSensorStepDetector == null) {
            throw new SensorTestStateNotSupportedException(
                    ""Sensors Step Counter/Detector are not supported."");
        }

        setLogScrollViewListener(new View.OnTouchListener() {
            @Override
            public boolean onTouch(View v, MotionEvent event) {
                // during movement of the device, the ScrollView will detect user taps as attempts
                // to scroll, when in reality they are taps in the layout
                // to overcome the fact that a ScrollView cannot be disabled from scrolling, we
                // listen for ACTION_UP events instead of click events in the child layout
                long elapsedTime = SystemClock.elapsedRealtimeNanos();
                if (event.getAction() != MotionEvent.ACTION_UP) {
                    return false;
                }

                try {
                    logUserReportedStep(elapsedTime);
                } catch (InterruptedException e) {
                    // we cannot propagate the exception in the main thread, so we just catch and
                    // restore the status, we don't need to log as we are terminating anyways
                    Thread.currentThread().interrupt();
                }
                return false;
            }
        });
    }

    @Override
    protected void activityCleanUp() {
        setLogScrollViewListener(null /* listener */);
    }

    public String testWalking() throws Throwable {
        return runTest(
                R.string.snsr_step_counter_test_walking,
                MIN_NUM_STEPS_PER_TEST,
                false /* vibrate */);
    }

    public String testStill() throws Throwable {
        return runTest(
                R.string.snsr_step_counter_test_still,
                0 /* expectedSteps */,
                true /* vibrate */);
    }

    /**
     * @param instructionsResId Resource ID containing instruction to be shown to testers
     * @param expectedSteps Number of steps expected in this test
     * @param vibrate If TRUE, vibration will be concurrent with the test
     */
    private String runTest(int instructionsResId, int expectedSteps, boolean vibrate)
            throws Throwable {
        mTimestampsUserReported.clear();
        mStepCounterEvents.clear();
        mStepDetectorEvents.clear();

        mMoveDetected = false;
        mCheckForMotion = false;

        getTestLogger().logInstructions(instructionsResId);
        waitForUserToBegin();

        mCheckForMotion = (expectedSteps > 0);
        if (vibrate) {
            vibrate(VIBRATE_PATTERN);
        }
        startMeasurements();
        getTestLogger().logWaitForSound();

        Thread.sleep(TimeUnit.SECONDS.toMillis(TEST_DURATION_SECONDS));
        mCheckForMotion = false;
        playSound();

        return verifyMeasurements(expectedSteps);
    }

    private void startMeasurements() {
        if (mSensorStepCounter != null) {
            mSensorManager.registerListener(this, mSensorStepCounter,
                    SensorManager.SENSOR_DELAY_NORMAL);
        }

        if (mSensorStepDetector != null) {
            mSensorManager.registerListener(this, mSensorStepDetector,
                    SensorManager.SENSOR_DELAY_NORMAL);
        }

        mMovementDetectorHelper = new MovementDetectorHelper(getApplicationContext()) {
            @Override
            protected void onMovementDetected() {
                mMoveDetected = true;
            }
        };
        mMovementDetectorHelper.start();
    }

    private String verifyMeasurements(int stepsExpected) {
        mSensorManager.unregisterListener(this);
        mMovementDetectorHelper.stop();

        if (mCheckForMotion) {
            Assert.assertTrue(
                    getString(R.string.snsr_movement_expected, mMoveDetected),
                    mMoveDetected);
        }

        final int userReportedSteps = mTimestampsUserReported.size();
        String stepsReportedMessage = getString(
                R.string.snsr_step_counter_expected_steps,
                stepsExpected,
                userReportedSteps);
        Assert.assertFalse(stepsReportedMessage, userReportedSteps < stepsExpected);

        // TODO: split test cases for step detector and counter
        verifyStepDetectorMeasurements();
        verifyStepCounterMeasurements();
        return null;
    }

    private void verifyStepCounterMeasurements() {
        if (mSensorStepCounter == null) {
            // sensor not supported, so no-op
            return;
        }

        final int userReportedSteps = mTimestampsUserReported.size();
        int totalStepsCounted = 0;
        int initialStepCount = -1;
        for (TestSensorEvent counterEvent : mStepCounterEvents) {
            String sensorName = counterEvent.sensor.getName();
            float[] values = counterEvent.values;

            final int expectedLength = 1;
            int valuesLength = values.length;
            String eventLengthMessage = getString(
                    R.string.snsr_event_length,
                    expectedLength,
                    valuesLength,
                    sensorName);
            Assert.assertEquals(eventLengthMessage, expectedLength, valuesLength);

            int stepValue = (int) values[0];
            if (initialStepCount == -1) {
                initialStepCount = stepValue;
            } else {
                int stepsCounted = stepValue - initialStepCount;
                int countDelta = stepsCounted - totalStepsCounted;

                String eventTriggered = getString(
                        R.string.snsr_step_counter_event_changed,
                        countDelta,
                        counterEvent.timestamp);
                Assert.assertTrue(eventTriggered, countDelta > 0);

                // TODO: abstract this into an ISensorVerification

                long deltaThreshold = TIMESTAMP_SYNCHRONIZATION_THRESHOLD_NANOS
                        + TestSensorEnvironment.getSensorMaxDetectionLatencyNs(counterEvent.sensor);
                assertTimestampSynchronization(
                        counterEvent.timestamp,
                        counterEvent.receivedTimestamp,
                        deltaThreshold,
                        counterEvent.sensor.getName());

                totalStepsCounted = stepsCounted;
            }
        }

        int stepsCountedDelta = Math.abs(totalStepsCounted - userReportedSteps);
        String stepsDeltaMessage = getString(
                R.string.snsr_step_counter_detected_reported,
                userReportedSteps,
                totalStepsCounted,
                stepsCountedDelta,
                MAX_STEP_DISCREPANCY);
        Assert.assertFalse(stepsDeltaMessage, stepsCountedDelta > MAX_STEP_DISCREPANCY);

        int stepCounterLength = mStepCounterEvents.size();
        for (int i = 0; i < userReportedSteps && i < stepCounterLength; ++i) {
            long userReportedTimestamp = mTimestampsUserReported.get(i);
            TestSensorEvent counterEvent = mStepCounterEvents.get(i);

            assertTimestampSynchronization(
                    counterEvent.timestamp,
                    userReportedTimestamp,
                    MAX_TOLERANCE_STEP_TIME_NANOS,
                    counterEvent.sensor.getName());
        }
    }

    private void verifyStepDetectorMeasurements() {
        if (mSensorStepDetector == null) {
            // sensor not supported, so no-op
            return;
        }

        final int userReportedSteps = mTimestampsUserReported.size();
        int stepsDetected = mStepDetectorEvents.size();
        int stepsDetectedDelta = Math.abs(stepsDetected - userReportedSteps);
        String stepsDetectedMessage = getString(
                R.string.snsr_step_detector_detected_reported,
                userReportedSteps,
                stepsDetected,
                stepsDetectedDelta,
                MAX_STEP_DISCREPANCY);
        Assert.assertFalse(stepsDetectedMessage, stepsDetectedDelta > MAX_STEP_DISCREPANCY);

        for (TestSensorEvent detectorEvent : mStepDetectorEvents) {
            String sensorName = detectorEvent.sensor.getName();
            float[] values = detectorEvent.values;

            final int expectedLength = 1;
            int valuesLength = values.length;
            String eventLengthMessage = getString(
                    R.string.snsr_event_length,
                    expectedLength,
                    valuesLength,
                    sensorName);
            Assert.assertEquals(eventLengthMessage, expectedLength, valuesLength);

            final float expectedValue = 1.0f;
            float value0 = values[0];
            String eventValueMessage =
                    getString(R.string.snsr_event_value, expectedValue, value0, sensorName);
            Assert.assertEquals(eventValueMessage, expectedValue, value0);
        }

        // TODO: verify correlation of events with steps from user
    }

    @Override
    public final void onAccuracyChanged(Sensor sensor, int accuracy) {
    }

    public final void onSensorChanged(SensorEvent event) {
        long elapsedRealtimeNanos = SystemClock.elapsedRealtimeNanos();
        int type = event.sensor.getType();
        if (type == Sensor.TYPE_STEP_COUNTER) {
            mStepCounterEvents.add(new TestSensorEvent(event, elapsedRealtimeNanos));
            getTestLogger().logMessage(
                    R.string.snsr_step_counter_event,
                    elapsedRealtimeNanos,
                    (int) event.values[0]);
        } else if (type == Sensor.TYPE_STEP_DETECTOR) {
            mStepDetectorEvents.add(new TestSensorEvent(event, elapsedRealtimeNanos));
            getTestLogger().logMessage(R.string.snsr_step_detector_event, elapsedRealtimeNanos);

        }
        // TODO: with delayed assertions check events of other types are tracked
    }

    private void logUserReportedStep(long timestamp) throws InterruptedException {
        if (!mCheckForMotion) {
            return;
        }
        playSound();
        mTimestampsUserReported.add(timestamp);
        getTestLogger().logMessage(R.string.snsr_step_reported, timestamp);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.RobustnessTest"	"testMandatoryMaximumResolutionOutputCombinations"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/RobustnessTest.java"	""	"public void testMandatoryMaximumResolutionOutputCombinations() throws Exception {
        testMandatoryOutputCombinations(/*maxResolution*/ true);
    }

    private void testMandatoryStreamCombination(String cameraId, StaticMetadata staticInfo,
            String physicalCameraId, MandatoryStreamCombination combination) throws Exception {
        // Check whether substituting YUV_888 format with Y8 format
        boolean substituteY8 = false;
        if (staticInfo.isMonochromeWithY8()) {
            List<MandatoryStreamInformation> streamsInfo = combination.getStreamsInformation();
            for (MandatoryStreamInformation streamInfo : streamsInfo) {
                if (streamInfo.getFormat() == ImageFormat.YUV_420_888) {
                    substituteY8 = true;
                    break;
                }
            }
        }

        // Check whether substituting JPEG format with HEIC format
        boolean substituteHeic = false;
        if (staticInfo.isHeicSupported()) {
            List<MandatoryStreamInformation> streamsInfo = combination.getStreamsInformation();
            for (MandatoryStreamInformation streamInfo : streamsInfo) {
                if (streamInfo.getFormat() == ImageFormat.JPEG) {
                    substituteHeic = true;
                    break;
                }
            }
        }

        // Test camera output combination
        String log = ""Testing mandatory stream combination: "" + combination.getDescription() +
                "" on camera: "" + cameraId;
        if (physicalCameraId != null) {
            log += "", physical sub-camera: "" + physicalCameraId;
        }
        Log.i(TAG, log);
        testMandatoryStreamCombination(cameraId, staticInfo, physicalCameraId, combination,
                /*substituteY8*/false, /*substituteHeic*/false, /*maxResolution*/false);

        if (substituteY8) {
            Log.i(TAG, log + "" with Y8"");
            testMandatoryStreamCombination(cameraId, staticInfo, physicalCameraId, combination,
                    /*substituteY8*/true, /*substituteHeic*/false, /*maxResolution*/false);
        }

        if (substituteHeic) {
            Log.i(TAG, log + "" with HEIC"");
            testMandatoryStreamCombination(cameraId, staticInfo, physicalCameraId, combination,
                    /*substituteY8*/false, /*substituteHeic*/true, /**maxResolution*/ false);
        }
    }

    private void testMandatoryStreamCombination(String cameraId,
            StaticMetadata staticInfo, String physicalCameraId,
            MandatoryStreamCombination combination,
            boolean substituteY8, boolean substituteHeic, boolean ultraHighResolution)
            throws Exception {

        // Timeout is relaxed by 1 second for LEGACY devices to reduce false positive rate in CTS
        // TODO: This needs to be adjusted based on feedback
        final int TIMEOUT_MULTIPLIER = ultraHighResolution ? 2 : 1;
        final int TIMEOUT_FOR_RESULT_MS =
                ((staticInfo.isHardwareLevelLegacy()) ? 2000 : 1000) * TIMEOUT_MULTIPLIER;
        final int MIN_RESULT_COUNT = 3;

        // Set up outputs
        List<OutputConfiguration> outputConfigs = new ArrayList<>();
        List<Surface> outputSurfaces = new ArrayList<Surface>();
        List<Surface> uhOutputSurfaces = new ArrayList<Surface>();
        StreamCombinationTargets targets = new StreamCombinationTargets();

        CameraTestUtils.setupConfigurationTargets(combination.getStreamsInformation(),
                targets, outputConfigs, outputSurfaces, uhOutputSurfaces, MIN_RESULT_COUNT,
                substituteY8, substituteHeic, physicalCameraId, /*multiResStreamConfig*/null,
                mHandler);

        boolean haveSession = false;
        try {
            CaptureRequest.Builder requestBuilder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
            CaptureRequest.Builder uhRequestBuilder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);

            for (Surface s : outputSurfaces) {
                requestBuilder.addTarget(s);
            }

            for (Surface s : uhOutputSurfaces) {
                uhRequestBuilder.addTarget(s);
            }
            // We need to explicitly set the sensor pixel mode to default since we're mixing default
            // and max resolution requests in the same capture session.
            requestBuilder.set(CaptureRequest.SENSOR_PIXEL_MODE,
                    CameraMetadata.SENSOR_PIXEL_MODE_DEFAULT);
            if (ultraHighResolution) {
                uhRequestBuilder.set(CaptureRequest.SENSOR_PIXEL_MODE,
                        CameraMetadata.SENSOR_PIXEL_MODE_MAXIMUM_RESOLUTION);
            }
            CameraCaptureSession.CaptureCallback mockCaptureCallback =
                    mock(CameraCaptureSession.CaptureCallback.class);

            if (physicalCameraId == null) {
                checkSessionConfigurationSupported(mCamera, mHandler, outputConfigs,
                        /*inputConfig*/ null, SessionConfiguration.SESSION_REGULAR,
                        true/*defaultSupport*/, String.format(
                        ""Session configuration query from combination: %s failed"",
                        combination.getDescription()));
            } else {
                SessionConfigSupport sessionConfigSupport = isSessionConfigSupported(
                        mCamera, mHandler, outputConfigs, /*inputConfig*/ null,
                        SessionConfiguration.SESSION_REGULAR, false/*defaultSupport*/);
                assertTrue(
                        String.format(""Session configuration query from combination: %s failed"",
                        combination.getDescription()), !sessionConfigSupport.error);
                if (!sessionConfigSupport.callSupported) {
                    return;
                }
                assertTrue(
                        String.format(""Session configuration must be supported for combination: "" +
                        ""%s"", combination.getDescription()), sessionConfigSupport.configSupported);
            }

            createSessionByConfigs(outputConfigs);
            haveSession = true;
            CaptureRequest request = requestBuilder.build();
            CaptureRequest uhRequest = uhRequestBuilder.build();
            mCameraSession.setRepeatingRequest(request, mockCaptureCallback, mHandler);
            if (ultraHighResolution) {
                mCameraSession.capture(uhRequest, mockCaptureCallback, mHandler);
            }
            verify(mockCaptureCallback,
                    timeout(TIMEOUT_FOR_RESULT_MS * MIN_RESULT_COUNT).atLeast(MIN_RESULT_COUNT))
                    .onCaptureCompleted(
                        eq(mCameraSession),
                        eq(request),
                        isA(TotalCaptureResult.class));
           if (ultraHighResolution) {
                verify(mockCaptureCallback,
                        timeout(TIMEOUT_FOR_RESULT_MS).atLeast(1))
                        .onCaptureCompleted(
                            eq(mCameraSession),
                            eq(uhRequest),
                            isA(TotalCaptureResult.class));
            }

            verify(mockCaptureCallback, never()).
                    onCaptureFailed(
                        eq(mCameraSession),
                        eq(request),
                        isA(CaptureFailure.class));

        } catch (Throwable e) {
            mCollector.addMessage(String.format(""Mandatory stream combination: %s failed due: %s"",
                    combination.getDescription(), e.getMessage()));
        }
        if (haveSession) {
            try {
                Log.i(TAG, String.format(""Done with camera %s, combination: %s, closing session"",
                                cameraId, combination.getDescription()));
                stopCapture(/*fast*/false);
            } catch (Throwable e) {
                mCollector.addMessage(
                    String.format(""Closing down for combination: %s failed due to: %s"",
                            combination.getDescription(), e.getMessage()));
            }
        }

        targets.close();
    }

    /**
     * Test for making sure the required reprocess input/output combinations for each hardware
     * level and capability work as expected.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.RobustnessTest"	"testMandatoryMaximumResolutionReprocessConfigurations"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/RobustnessTest.java"	""	"public void testMandatoryMaximumResolutionReprocessConfigurations() throws Exception {
        testMandatoryReprocessConfigurations(/*maxResolution*/true);
    }

    /**
     * Test for making sure the required reprocess input/output combinations for each hardware
     * level and capability work as expected.
     */
    public void testMandatoryReprocessConfigurations(boolean maxResolution) throws Exception {
        for (String id : mCameraIdsUnderTest) {
            openDevice(id);
            CameraCharacteristics chars = mStaticInfo.getCharacteristics();
            if (maxResolution && !CameraTestUtils.hasCapability(
                  chars, CameraMetadata.REQUEST_AVAILABLE_CAPABILITIES_REMOSAIC_REPROCESSING)) {
                Log.i(TAG, ""Camera id "" + id + ""doesn't support REMOSAIC_REPROCESSING, skip test"");
                closeDevice(id);
                continue;
            }
            CameraCharacteristics.Key<MandatoryStreamCombination []> ck =
                    CameraCharacteristics.SCALER_MANDATORY_STREAM_COMBINATIONS;

            if (maxResolution) {
                ck = CameraCharacteristics.SCALER_MANDATORY_MAXIMUM_RESOLUTION_STREAM_COMBINATIONS;
            }

            MandatoryStreamCombination[] combinations = chars.get(ck);
            if (combinations == null) {
                Log.i(TAG, ""No mandatory stream combinations for camera: "" + id + "" skip test"");
                closeDevice(id);
                continue;
            }

            try {
                for (MandatoryStreamCombination combination : combinations) {
                    if (combination.isReprocessable()) {
                        Log.i(TAG, ""Testing mandatory reprocessable stream combination: "" +
                                combination.getDescription() + "" on camera: "" + id);
                        testMandatoryReprocessableStreamCombination(id, combination, maxResolution);
                    }
                }
            } finally {
                closeDevice(id);
            }
        }
    }

    private void testMandatoryReprocessableStreamCombination(String cameraId,
            MandatoryStreamCombination combination, boolean maxResolution)  throws Exception {
        // Test reprocess stream combination
        testMandatoryReprocessableStreamCombination(cameraId, combination,
                /*substituteY8*/false, /*substituteHeic*/false, maxResolution/*maxResolution*/);
        if (maxResolution) {
            // Maximum resolution mode doesn't guarantee HEIC and Y8 streams.
            return;
        }

        // Test substituting YUV_888 format with Y8 format in reprocess stream combination.
        if (mStaticInfo.isMonochromeWithY8()) {
            List<MandatoryStreamInformation> streamsInfo = combination.getStreamsInformation();
            boolean substituteY8 = false;
            for (MandatoryStreamInformation streamInfo : streamsInfo) {
                if (streamInfo.getFormat() == ImageFormat.YUV_420_888) {
                    substituteY8 = true;
                }
            }
            if (substituteY8) {
                testMandatoryReprocessableStreamCombination(cameraId, combination,
                        /*substituteY8*/true, /*substituteHeic*/false, false/*maxResolution*/);
            }
        }

        if (mStaticInfo.isHeicSupported()) {
            List<MandatoryStreamInformation> streamsInfo = combination.getStreamsInformation();
            boolean substituteHeic = false;
            for (MandatoryStreamInformation streamInfo : streamsInfo) {
                if (streamInfo.getFormat() == ImageFormat.JPEG) {
                    substituteHeic = true;
                }
            }
            if (substituteHeic) {
                testMandatoryReprocessableStreamCombination(cameraId, combination,
                        /*substituteY8*/false, /*substituteHeic*/true, false/*maxResolution*/);
            }
        }
    }

    private void testMandatoryReprocessableStreamCombination(String cameraId,
            MandatoryStreamCombination combination, boolean substituteY8,
            boolean substituteHeic, boolean maxResolution) throws Exception {

        final int TIMEOUT_MULTIPLIER = maxResolution ? 2 : 1;
        final int TIMEOUT_FOR_RESULT_MS = 5000 * TIMEOUT_MULTIPLIER;
        final int NUM_REPROCESS_CAPTURES_PER_CONFIG = 3;

        StreamCombinationTargets targets = new StreamCombinationTargets();
        ArrayList<Surface> defaultOutputSurfaces = new ArrayList<>();
        ArrayList<Surface> allOutputSurfaces = new ArrayList<>();
        List<OutputConfiguration> outputConfigs = new ArrayList<>();
        List<Surface> uhOutputSurfaces = new ArrayList<Surface>();
        ImageReader inputReader = null;
        ImageWriter inputWriter = null;
        SimpleImageReaderListener inputReaderListener = new SimpleImageReaderListener();
        SimpleCaptureCallback inputCaptureListener = new SimpleCaptureCallback();
        SimpleCaptureCallback reprocessOutputCaptureListener = new SimpleCaptureCallback();

        List<MandatoryStreamInformation> streamInfo = combination.getStreamsInformation();
        assertTrue(""Reprocessable stream combinations should have at least 3 or more streams"",
                (streamInfo != null) && (streamInfo.size() >= 3));

        assertTrue(""The first mandatory stream information in a reprocessable combination must "" +
                ""always be input"", streamInfo.get(0).isInput());

        List<Size> inputSizes = streamInfo.get(0).getAvailableSizes();
        int inputFormat = streamInfo.get(0).getFormat();
        if (substituteY8 && (inputFormat == ImageFormat.YUV_420_888)) {
            inputFormat = ImageFormat.Y8;
        }

        Log.i(TAG, ""testMandatoryReprocessableStreamCombination: "" +
                combination.getDescription() + "", substituteY8 = "" + substituteY8 +
                "", substituteHeic = "" + substituteHeic);
        try {
            // The second stream information entry is the ZSL stream, which is configured
            // separately.
            List<MandatoryStreamInformation> mandatoryStreamInfos = null;
            mandatoryStreamInfos = new ArrayList<MandatoryStreamInformation>();
            mandatoryStreamInfos = streamInfo.subList(2, streamInfo.size());
            CameraTestUtils.setupConfigurationTargets(mandatoryStreamInfos, targets,
                    outputConfigs, defaultOutputSurfaces, uhOutputSurfaces,
                    NUM_REPROCESS_CAPTURES_PER_CONFIG,
                    substituteY8, substituteHeic, null/*overridePhysicalCameraId*/,
                    /*multiResStreamConfig*/null, mHandler);
            allOutputSurfaces.addAll(defaultOutputSurfaces);
            allOutputSurfaces.addAll(uhOutputSurfaces);
            InputConfiguration inputConfig = new InputConfiguration(inputSizes.get(0).getWidth(),
                    inputSizes.get(0).getHeight(), inputFormat);

            // For each config, YUV and JPEG outputs will be tested. (For YUV/Y8 reprocessing,
            // the YUV/Y8 ImageReader for input is also used for output.)
            final boolean inputIsYuv = inputConfig.getFormat() == ImageFormat.YUV_420_888;
            final boolean inputIsY8 = inputConfig.getFormat() == ImageFormat.Y8;
            final boolean useYuv = inputIsYuv || targets.mYuvTargets.size() > 0;
            final boolean useY8 = inputIsY8 || targets.mY8Targets.size() > 0;
            final int totalNumReprocessCaptures =  NUM_REPROCESS_CAPTURES_PER_CONFIG *
                    (maxResolution ? 1 : (((inputIsYuv || inputIsY8) ? 1 : 0) +
                    (substituteHeic ? targets.mHeicTargets.size() : targets.mJpegTargets.size()) +
                    (useYuv ? targets.mYuvTargets.size() : targets.mY8Targets.size())));

            // It needs 1 input buffer for each reprocess capture + the number of buffers
            // that will be used as outputs.
            inputReader = ImageReader.newInstance(inputConfig.getWidth(), inputConfig.getHeight(),
                    inputConfig.getFormat(),
                    totalNumReprocessCaptures + NUM_REPROCESS_CAPTURES_PER_CONFIG);
            inputReader.setOnImageAvailableListener(inputReaderListener, mHandler);
            allOutputSurfaces.add(inputReader.getSurface());

            checkSessionConfigurationWithSurfaces(mCamera, mHandler, allOutputSurfaces,
                    inputConfig, SessionConfiguration.SESSION_REGULAR, /*defaultSupport*/ true,
                    String.format(""Session configuration query %s failed"",
                    combination.getDescription()));

            // Verify we can create a reprocessable session with the input and all outputs.
            BlockingSessionCallback sessionListener = new BlockingSessionCallback();
            CameraCaptureSession session = configureReprocessableCameraSession(mCamera,
                    inputConfig, allOutputSurfaces, sessionListener, mHandler);
            inputWriter = ImageWriter.newInstance(session.getInputSurface(),
                    totalNumReprocessCaptures);

            // Prepare a request for reprocess input
            CaptureRequest.Builder builder = mCamera.createCaptureRequest(
                    CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG);
            builder.addTarget(inputReader.getSurface());
            if (maxResolution) {
                builder.set(CaptureRequest.SENSOR_PIXEL_MODE,
                        CameraMetadata.SENSOR_PIXEL_MODE_MAXIMUM_RESOLUTION);
            }

            for (int i = 0; i < totalNumReprocessCaptures; i++) {
                session.capture(builder.build(), inputCaptureListener, mHandler);
            }

            List<CaptureRequest> reprocessRequests = new ArrayList<>();
            List<Surface> reprocessOutputs = new ArrayList<>();

            if (maxResolution) {
                if (uhOutputSurfaces.size() == 0) { // RAW -> RAW reprocessing
                    reprocessOutputs.add(inputReader.getSurface());
                } else {
                    for (Surface surface : uhOutputSurfaces) {
                        reprocessOutputs.add(surface);
                    }
                }
            } else {
                if (inputIsYuv || inputIsY8) {
                    reprocessOutputs.add(inputReader.getSurface());
                }

                for (ImageReader reader : targets.mJpegTargets) {
                    reprocessOutputs.add(reader.getSurface());
                }

                for (ImageReader reader : targets.mHeicTargets) {
                    reprocessOutputs.add(reader.getSurface());
                }

                for (ImageReader reader : targets.mYuvTargets) {
                    reprocessOutputs.add(reader.getSurface());
                }

                for (ImageReader reader : targets.mY8Targets) {
                    reprocessOutputs.add(reader.getSurface());
                }
            }

            for (int i = 0; i < NUM_REPROCESS_CAPTURES_PER_CONFIG; i++) {
                for (Surface output : reprocessOutputs) {
                    TotalCaptureResult result = inputCaptureListener.getTotalCaptureResult(
                            TIMEOUT_FOR_RESULT_MS);
                    builder =  mCamera.createReprocessCaptureRequest(result);
                    inputWriter.queueInputImage(
                            inputReaderListener.getImage(TIMEOUT_FOR_RESULT_MS));
                    builder.addTarget(output);
                    reprocessRequests.add(builder.build());
                }
            }

            session.captureBurst(reprocessRequests, reprocessOutputCaptureListener, mHandler);

            for (int i = 0; i < reprocessOutputs.size() * NUM_REPROCESS_CAPTURES_PER_CONFIG; i++) {
                TotalCaptureResult result = reprocessOutputCaptureListener.getTotalCaptureResult(
                        TIMEOUT_FOR_RESULT_MS);
            }
        } catch (Throwable e) {
            mCollector.addMessage(String.format(""Reprocess stream combination %s failed due to: %s"",
                    combination.getDescription(), e.getMessage()));
        } finally {
            inputReaderListener.drain();
            reprocessOutputCaptureListener.drain();
            targets.close();

            if (inputReader != null) {
                inputReader.close();
            }

            if (inputWriter != null) {
                inputWriter.close();
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.RobustnessTest"	"testConfigureInvalidSensorPixelModes"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/RobustnessTest.java"	""	"public void testConfigureInvalidSensorPixelModes() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            // Go through given, stream configuration map, add the incorrect sensor pixel mode
            // to an OutputConfiguration, make sure the session configuration fails.
            CameraCharacteristics chars = mCameraManager.getCameraCharacteristics(id);
            StreamConfigurationMap defaultStreamConfigMap =
                    chars.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
            StreamConfigurationMap maxStreamConfigMap =
                    chars.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP_MAXIMUM_RESOLUTION);
            openDevice(id);
            try {
                verifyBasicSensorPixelModes(id, defaultStreamConfigMap, /*maxResolution*/ false);
                verifyBasicSensorPixelModes(id, maxStreamConfigMap, /*maxResolution*/ true);
            } finally {
                closeDevice(id);
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.RobustnessTest"	"testOisDataMode"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/RobustnessTest.java"	""	"public void testOisDataMode() throws Exception {
        final int NUM_FRAMES_VERIFIED = 3;

        for (String id : mCameraIdsUnderTest) {
            Log.i(TAG, String.format(""Testing Camera %s for OIS mode"", id));

            StaticMetadata staticInfo =
                    new StaticMetadata(mCameraManager.getCameraCharacteristics(id));
            if (!staticInfo.isOisDataModeSupported()) {
                continue;
            }

            openDevice(id);

            try {
                SurfaceTexture preview = new SurfaceTexture(/*random int*/ 1);
                Surface previewSurface = new Surface(preview);

                CaptureRequest.Builder previewRequest = preparePreviewTestSession(preview);
                SimpleCaptureCallback previewListener = new CameraTestUtils.SimpleCaptureCallback();

                int[] availableOisDataModes = staticInfo.getCharacteristics().get(
                        CameraCharacteristics.STATISTICS_INFO_AVAILABLE_OIS_DATA_MODES);

                // Test each OIS data mode
                for (int oisMode : availableOisDataModes) {
                    previewRequest.set(CaptureRequest.STATISTICS_OIS_DATA_MODE, oisMode);

                    int sequenceId = mCameraSession.setRepeatingRequest(previewRequest.build(),
                            previewListener, mHandler);

                    // Check OIS data in each mode.
                    for (int i = 0; i < NUM_FRAMES_VERIFIED; i++) {
                        TotalCaptureResult result =
                            previewListener.getTotalCaptureResult(CAPTURE_TIMEOUT);

                        OisSample[] oisSamples = result.get(CaptureResult.STATISTICS_OIS_SAMPLES);

                        if (oisMode == CameraCharacteristics.STATISTICS_OIS_DATA_MODE_OFF) {
                            mCollector.expectKeyValueEquals(result,
                                    CaptureResult.STATISTICS_OIS_DATA_MODE,
                                    CaptureResult.STATISTICS_OIS_DATA_MODE_OFF);
                            mCollector.expectTrue(""OIS samples reported in OIS_DATA_MODE_OFF"",
                                    oisSamples == null || oisSamples.length == 0);

                        } else if (oisMode == CameraCharacteristics.STATISTICS_OIS_DATA_MODE_ON) {
                            mCollector.expectKeyValueEquals(result,
                                    CaptureResult.STATISTICS_OIS_DATA_MODE,
                                    CaptureResult.STATISTICS_OIS_DATA_MODE_ON);
                            mCollector.expectTrue(""OIS samples not reported in OIS_DATA_MODE_ON"",
                                    oisSamples != null && oisSamples.length != 0);
                        } else {
                            mCollector.addMessage(String.format(""Invalid OIS mode: %d"", oisMode));
                        }
                    }

                    mCameraSession.stopRepeating();
                    previewListener.getCaptureSequenceLastFrameNumber(sequenceId, CAPTURE_TIMEOUT);
                    previewListener.drain();
                }
            } finally {
                closeDevice(id);
            }
        }
    }

    private CaptureRequest.Builder preparePreviewTestSession(SurfaceTexture preview)
            throws Exception {
        Surface previewSurface = new Surface(preview);

        preview.setDefaultBufferSize(640, 480);

        ArrayList<Surface> sessionOutputs = new ArrayList<>();
        sessionOutputs.add(previewSurface);

        createSession(sessionOutputs);

        CaptureRequest.Builder previewRequest =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);

        previewRequest.addTarget(previewSurface);

        return previewRequest;
    }

    private CaptureRequest.Builder prepareTriggerTestSession(
            SurfaceTexture preview, int aeMode, int afMode) throws Exception {
        Log.i(TAG, String.format(""Testing AE mode %s, AF mode %s"",
                        StaticMetadata.getAeModeName(aeMode),
                        StaticMetadata.getAfModeName(afMode)));

        CaptureRequest.Builder previewRequest = preparePreviewTestSession(preview);
        previewRequest.set(CaptureRequest.CONTROL_AE_MODE, aeMode);
        previewRequest.set(CaptureRequest.CONTROL_AF_MODE, afMode);

        return previewRequest;
    }

    private void cancelTriggersAndWait(CaptureRequest.Builder previewRequest,
            SimpleCaptureCallback captureListener, int afMode) throws Exception {
        previewRequest.set(CaptureRequest.CONTROL_AF_TRIGGER,
                CaptureRequest.CONTROL_AF_TRIGGER_CANCEL);
        previewRequest.set(CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER,
                CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_CANCEL);

        CaptureRequest triggerRequest = previewRequest.build();
        mCameraSession.capture(triggerRequest, captureListener, mHandler);

        // Wait for a few frames to initialize 3A

        CaptureResult previewResult = null;
        int afState;
        int aeState;

        for (int i = 0; i < PREVIEW_WARMUP_FRAMES; i++) {
            previewResult = captureListener.getCaptureResult(
                    CameraTestUtils.CAPTURE_RESULT_TIMEOUT_MS);
            if (VERBOSE) {
                afState = previewResult.get(CaptureResult.CONTROL_AF_STATE);
                aeState = previewResult.get(CaptureResult.CONTROL_AE_STATE);
                Log.v(TAG, String.format(""AF state: %s, AE state: %s"",
                                StaticMetadata.AF_STATE_NAMES[afState],
                                StaticMetadata.AE_STATE_NAMES[aeState]));
            }
        }

        // Verify starting states

        afState = previewResult.get(CaptureResult.CONTROL_AF_STATE);
        aeState = previewResult.get(CaptureResult.CONTROL_AE_STATE);

        verifyStartingAfState(afMode, afState);

        // After several frames, AE must no longer be in INACTIVE state
        assertTrue(String.format(""AE state must be SEARCHING, CONVERGED, "" +
                        ""or FLASH_REQUIRED, is %s"", StaticMetadata.AE_STATE_NAMES[aeState]),
                aeState == CaptureResult.CONTROL_AE_STATE_SEARCHING ||
                aeState == CaptureResult.CONTROL_AE_STATE_CONVERGED ||
                aeState == CaptureResult.CONTROL_AE_STATE_FLASH_REQUIRED);
    }

    private void verifyBasicSensorPixelModes(String id, StreamConfigurationMap configs,
            boolean maxResolution) throws Exception {
        // Go through StreamConfiguration map, set up OutputConfiguration and add the opposite
        // sensorPixelMode.
        final int MIN_RESULT_COUNT = 3;
        if (!maxResolution) {
            assertTrue(""Default stream config map must be present for id: "" + id, configs != null);
        }
        if (configs == null) {
            Log.i(TAG, ""camera id "" + id + "" has no StreamConfigurationMap for max resolution "" +
                "", skipping verifyBasicSensorPixelModes"");
            return;
        }
        OutputConfiguration outputConfig = null;
        for (int format : configs.getOutputFormats()) {
            Size targetSize = CameraTestUtils.getMaxSize(configs.getOutputSizes(format));
            // Create outputConfiguration with this size and format
            SimpleImageReaderListener imageListener = new SimpleImageReaderListener();
            SurfaceTexture textureTarget = null;
            ImageReader readerTarget = null;
            if (format == ImageFormat.PRIVATE) {
                textureTarget = new SurfaceTexture(1);
                textureTarget.setDefaultBufferSize(targetSize.getWidth(), targetSize.getHeight());
                outputConfig = new OutputConfiguration(new Surface(textureTarget));
            } else {
                readerTarget = ImageReader.newInstance(targetSize.getWidth(),
                        targetSize.getHeight(), format, MIN_RESULT_COUNT);
                readerTarget.setOnImageAvailableListener(imageListener, mHandler);
                outputConfig = new OutputConfiguration(readerTarget.getSurface());
            }
            try {
                int invalidSensorPixelMode =
                        maxResolution ? CameraMetadata.SENSOR_PIXEL_MODE_DEFAULT :
                                CameraMetadata.SENSOR_PIXEL_MODE_MAXIMUM_RESOLUTION;

                outputConfig.addSensorPixelModeUsed(invalidSensorPixelMode);
                CameraCaptureSession.StateCallback sessionListener =
                        mock(CameraCaptureSession.StateCallback.class);
                List<OutputConfiguration> outputs = new ArrayList<>();
                outputs.add(outputConfig);
                CameraCaptureSession session =
                        CameraTestUtils.configureCameraSessionWithConfig(mCamera, outputs,
                                sessionListener, mHandler);

                verify(sessionListener, timeout(CONFIGURE_TIMEOUT).atLeastOnce()).
                        onConfigureFailed(any(CameraCaptureSession.class));
                verify(sessionListener, never()).onConfigured(any(CameraCaptureSession.class));

                // Remove the invalid sensor pixel mode, session configuration should succeed
                sessionListener = mock(CameraCaptureSession.StateCallback.class);
                outputConfig.removeSensorPixelModeUsed(invalidSensorPixelMode);
                CameraTestUtils.configureCameraSessionWithConfig(mCamera, outputs,
                        sessionListener, mHandler);
                verify(sessionListener, timeout(CONFIGURE_TIMEOUT).atLeastOnce()).
                        onConfigured(any(CameraCaptureSession.class));
                verify(sessionListener, never()).onConfigureFailed(any(CameraCaptureSession.class));
            } finally {
                if (textureTarget != null) {
                    textureTarget.release();
                }

                if (readerTarget != null) {
                    readerTarget.close();
                }
            }
        }
    }

    private void verifyStartingAfState(int afMode, int afState) {
        switch (afMode) {
            case CaptureResult.CONTROL_AF_MODE_AUTO:
            case CaptureResult.CONTROL_AF_MODE_MACRO:
                assertTrue(String.format(""AF state not INACTIVE, is %s"",
                                StaticMetadata.AF_STATE_NAMES[afState]),
                        afState == CaptureResult.CONTROL_AF_STATE_INACTIVE);
                break;
            case CaptureResult.CONTROL_AF_MODE_CONTINUOUS_PICTURE:
            case CaptureResult.CONTROL_AF_MODE_CONTINUOUS_VIDEO:
                // After several frames, AF must no longer be in INACTIVE state
                assertTrue(String.format(""In AF mode %s, AF state not PASSIVE_SCAN"" +
                                "", PASSIVE_FOCUSED, or PASSIVE_UNFOCUSED, is %s"",
                                StaticMetadata.getAfModeName(afMode),
                                StaticMetadata.AF_STATE_NAMES[afState]),
                        afState == CaptureResult.CONTROL_AF_STATE_PASSIVE_SCAN ||
                        afState == CaptureResult.CONTROL_AF_STATE_PASSIVE_FOCUSED ||
                        afState == CaptureResult.CONTROL_AF_STATE_PASSIVE_UNFOCUSED);
                break;
            default:
                fail(""unexpected af mode"");
        }
    }

    private boolean verifyAfSequence(int afMode, int afState, boolean focusComplete) {
        if (focusComplete) {
            assertTrue(String.format(""AF Mode %s: Focus lock lost after convergence: AF state: %s"",
                            StaticMetadata.getAfModeName(afMode),
                            StaticMetadata.AF_STATE_NAMES[afState]),
                    afState == CaptureResult.CONTROL_AF_STATE_FOCUSED_LOCKED ||
                    afState ==CaptureResult.CONTROL_AF_STATE_NOT_FOCUSED_LOCKED);
            return focusComplete;
        }
        if (VERBOSE) {
            Log.v(TAG, String.format(""AF mode: %s, AF state: %s"",
                            StaticMetadata.getAfModeName(afMode),
                            StaticMetadata.AF_STATE_NAMES[afState]));
        }
        switch (afMode) {
            case CaptureResult.CONTROL_AF_MODE_AUTO:
            case CaptureResult.CONTROL_AF_MODE_MACRO:
                assertTrue(String.format(""AF mode %s: Unexpected AF state %s"",
                                StaticMetadata.getAfModeName(afMode),
                                StaticMetadata.AF_STATE_NAMES[afState]),
                        afState == CaptureResult.CONTROL_AF_STATE_ACTIVE_SCAN ||
                        afState == CaptureResult.CONTROL_AF_STATE_FOCUSED_LOCKED ||
                        afState == CaptureResult.CONTROL_AF_STATE_NOT_FOCUSED_LOCKED);
                focusComplete =
                        (afState != CaptureResult.CONTROL_AF_STATE_ACTIVE_SCAN);
                break;
            case CaptureResult.CONTROL_AF_MODE_CONTINUOUS_PICTURE:
                assertTrue(String.format(""AF mode %s: Unexpected AF state %s"",
                                StaticMetadata.getAfModeName(afMode),
                                StaticMetadata.AF_STATE_NAMES[afState]),
                        afState == CaptureResult.CONTROL_AF_STATE_PASSIVE_SCAN ||
                        afState == CaptureResult.CONTROL_AF_STATE_FOCUSED_LOCKED ||
                        afState == CaptureResult.CONTROL_AF_STATE_NOT_FOCUSED_LOCKED);
                focusComplete =
                        (afState != CaptureResult.CONTROL_AF_STATE_PASSIVE_SCAN);
                break;
            case CaptureResult.CONTROL_AF_MODE_CONTINUOUS_VIDEO:
                assertTrue(String.format(""AF mode %s: Unexpected AF state %s"",
                                StaticMetadata.getAfModeName(afMode),
                                StaticMetadata.AF_STATE_NAMES[afState]),
                        afState == CaptureResult.CONTROL_AF_STATE_FOCUSED_LOCKED ||
                        afState == CaptureResult.CONTROL_AF_STATE_NOT_FOCUSED_LOCKED);
                focusComplete = true;
                break;
            default:
                fail(""Unexpected AF mode: "" + StaticMetadata.getAfModeName(afMode));
        }
        return focusComplete;
    }

    private boolean verifyAeSequence(int aeState, boolean precaptureComplete) {
        if (precaptureComplete) {
            assertTrue(""Precapture state seen after convergence"",
                    aeState != CaptureResult.CONTROL_AE_STATE_PRECAPTURE);
            return precaptureComplete;
        }
        if (VERBOSE) {
            Log.v(TAG, String.format(""AE state: %s"", StaticMetadata.AE_STATE_NAMES[aeState]));
        }
        switch (aeState) {
            case CaptureResult.CONTROL_AE_STATE_PRECAPTURE:
                // scan still continuing
                break;
            case CaptureResult.CONTROL_AE_STATE_CONVERGED:
            case CaptureResult.CONTROL_AE_STATE_FLASH_REQUIRED:
                // completed
                precaptureComplete = true;
                break;
            default:
                fail(String.format(""Precapture sequence transitioned to ""
                                + ""state %s incorrectly!"", StaticMetadata.AE_STATE_NAMES[aeState]));
                break;
        }
        return precaptureComplete;
    }

    /**
     * Test for making sure that all expected mandatory stream combinations are present and
     * advertised accordingly.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.RobustnessTest"	"testVerifyReprocessMandatoryOutputCombinationTables"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/RobustnessTest.java"	""	"public void testVerifyReprocessMandatoryOutputCombinationTables() throws Exception {
        final int[][] LIMITED_COMBINATIONS = {
            // Input           Outputs
            {PRIV, MAXIMUM,    JPEG, MAXIMUM},
            {YUV , MAXIMUM,    JPEG, MAXIMUM},
            {PRIV, MAXIMUM,    PRIV, PREVIEW, JPEG, MAXIMUM},
            {YUV , MAXIMUM,    PRIV, PREVIEW, JPEG, MAXIMUM},
            {PRIV, MAXIMUM,    YUV , PREVIEW, JPEG, MAXIMUM},
            {YUV , MAXIMUM,    YUV , PREVIEW, JPEG, MAXIMUM},
            {PRIV, MAXIMUM,    YUV , PREVIEW, YUV , PREVIEW, JPEG, MAXIMUM},
            {YUV,  MAXIMUM,    YUV , PREVIEW, YUV , PREVIEW, JPEG, MAXIMUM},
        };

        final int[][] FULL_COMBINATIONS = {
            // Input           Outputs
            {YUV , MAXIMUM,    PRIV, PREVIEW},
            {YUV , MAXIMUM,    YUV , PREVIEW},
            {PRIV, MAXIMUM,    PRIV, PREVIEW, YUV , RECORD},
            {YUV , MAXIMUM,    PRIV, PREVIEW, YUV , RECORD},
            {PRIV, MAXIMUM,    PRIV, PREVIEW, YUV , MAXIMUM},
            {PRIV, MAXIMUM,    YUV , PREVIEW, YUV , MAXIMUM},
            {PRIV, MAXIMUM,    PRIV, PREVIEW, YUV , PREVIEW, JPEG, MAXIMUM},
            {YUV , MAXIMUM,    PRIV, PREVIEW, YUV , PREVIEW, JPEG, MAXIMUM},
        };

        final int[][] RAW_COMBINATIONS = {
            // Input           Outputs
            {PRIV, MAXIMUM,    YUV , PREVIEW, RAW , MAXIMUM},
            {YUV , MAXIMUM,    YUV , PREVIEW, RAW , MAXIMUM},
            {PRIV, MAXIMUM,    PRIV, PREVIEW, YUV , PREVIEW, RAW , MAXIMUM},
            {YUV , MAXIMUM,    PRIV, PREVIEW, YUV , PREVIEW, RAW , MAXIMUM},
            {PRIV, MAXIMUM,    YUV , PREVIEW, YUV , PREVIEW, RAW , MAXIMUM},
            {YUV , MAXIMUM,    YUV , PREVIEW, YUV , PREVIEW, RAW , MAXIMUM},
            {PRIV, MAXIMUM,    PRIV, PREVIEW, JPEG, MAXIMUM, RAW , MAXIMUM},
            {YUV , MAXIMUM,    PRIV, PREVIEW, JPEG, MAXIMUM, RAW , MAXIMUM},
            {PRIV, MAXIMUM,    YUV , PREVIEW, JPEG, MAXIMUM, RAW , MAXIMUM},
            {YUV , MAXIMUM,    YUV , PREVIEW, JPEG, MAXIMUM, RAW , MAXIMUM},
        };

        final int[][] LEVEL_3_COMBINATIONS = {
            // Input          Outputs
            // In-app viewfinder analysis with YUV->YUV ZSL and RAW
            {YUV , MAXIMUM,   PRIV, PREVIEW, PRIV, VGA, RAW, MAXIMUM},
            // In-app viewfinder analysis with PRIV->JPEG ZSL and RAW
            {PRIV, MAXIMUM,   PRIV, PREVIEW, PRIV, VGA, RAW, MAXIMUM, JPEG, MAXIMUM},
            // In-app viewfinder analysis with YUV->JPEG ZSL and RAW
            {YUV , MAXIMUM,   PRIV, PREVIEW, PRIV, VGA, RAW, MAXIMUM, JPEG, MAXIMUM},
        };

        final int[][][] TABLES =
                { LIMITED_COMBINATIONS, FULL_COMBINATIONS, RAW_COMBINATIONS, LEVEL_3_COMBINATIONS };

        validityCheckConfigurationTables(TABLES);

        for (String id : mCameraIdsUnderTest) {
            openDevice(id);
            MandatoryStreamCombination[] cs = mStaticInfo.getCharacteristics().get(
                    CameraCharacteristics.SCALER_MANDATORY_STREAM_COMBINATIONS);
            if ((cs == null) || (cs.length == 0)) {
                Log.i(TAG, ""No mandatory stream combinations for camera: "" + id + "" skip test"");
                closeDevice(id);
                continue;
            }

            boolean supportYuvReprocess = mStaticInfo.isCapabilitySupported(
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_YUV_REPROCESSING);
            boolean supportOpaqueReprocess = mStaticInfo.isCapabilitySupported(
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING);
            if (!supportYuvReprocess && !supportOpaqueReprocess) {
                Log.i(TAG, ""No reprocess support for camera: "" + id + "" skip test"");
                closeDevice(id);
                continue;
            }

            MaxStreamSizes maxSizes = new MaxStreamSizes(mStaticInfo, id, mContext);
            try {
                for (int[] c : LIMITED_COMBINATIONS) {
                    assertTrue(String.format(""Expected static reprocessable stream combination:"" +
                                ""%s not found among the available mandatory combinations"",
                                maxSizes.reprocessCombinationToString(c)),
                            isMandatoryCombinationAvailable(c, maxSizes, /*isInput*/ true, cs));
                }

                if (mStaticInfo.isHardwareLevelAtLeastFull()) {
                    for (int[] c : FULL_COMBINATIONS) {
                        assertTrue(String.format(
                                    ""Expected static reprocessable stream combination:"" +
                                    ""%s not found among the available mandatory combinations"",
                                    maxSizes.reprocessCombinationToString(c)),
                                isMandatoryCombinationAvailable(c, maxSizes, /*isInput*/ true, cs));
                    }
                }

                if (mStaticInfo.isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_RAW)) {
                    for (int[] c : RAW_COMBINATIONS) {
                        assertTrue(String.format(
                                    ""Expected static reprocessable stream combination:"" +
                                    ""%s not found among the available mandatory combinations"",
                                    maxSizes.reprocessCombinationToString(c)),
                                isMandatoryCombinationAvailable(c, maxSizes, /*isInput*/ true, cs));
                    }
                }

                if (mStaticInfo.isHardwareLevelAtLeast(
                            CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_3)) {
                    for (int[] c : LEVEL_3_COMBINATIONS) {
                        assertTrue(String.format(
                                    ""Expected static reprocessable stream combination:"" +
                                    ""%s not found among the available mandatory combinations"",
                                    maxSizes.reprocessCombinationToString(c)),
                                isMandatoryCombinationAvailable(c, maxSizes, /*isInput*/ true, cs));
                    }
                }
            } finally {
                closeDevice(id);
            }
        }
    }

    private boolean isMandatoryCombinationAvailable(final int[] combination,
            final MaxStreamSizes maxSizes,
            final MandatoryStreamCombination[] availableCombinations) {
        return isMandatoryCombinationAvailable(combination, maxSizes, /*isInput*/ false,
                availableCombinations);
    }

    private boolean isMandatoryCombinationAvailable(final int[] combination,
            final MaxStreamSizes maxSizes, boolean isInput,
            final MandatoryStreamCombination[] availableCombinations) {
        boolean supportYuvReprocess = mStaticInfo.isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_YUV_REPROCESSING);
        boolean supportOpaqueReprocess = mStaticInfo.isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING);
        // Static combinations to be verified can be composed of multiple entries
        // that have the following layout (format, size). In case ""isInput"" is set,
        // the first stream configuration entry will contain the input format and size
        // as well as the first matching output.
        int streamCount = combination.length / 2;

        List<Pair<Pair<Integer, Boolean>, Size>> currentCombination =
                new ArrayList<Pair<Pair<Integer, Boolean>, Size>>(streamCount);
        for (int i = 0; i < combination.length; i += 2) {
            if (isInput && (i == 0)) {
                // Skip the combination if the format is not supported for reprocessing.
                if ((combination[i] == YUV && !supportYuvReprocess) ||
                        (combination[i] == PRIV && !supportOpaqueReprocess)) {
                    return true;
                }
                Size sz = maxSizes.getMaxInputSizeForFormat(combination[i]);
                currentCombination.add(Pair.create(Pair.create(new Integer(combination[i]),
                            new Boolean(true)), sz));
                currentCombination.add(Pair.create(Pair.create(new Integer(combination[i]),
                            new Boolean(false)), sz));
            } else {
                Size sz = maxSizes.getOutputSizeForFormat(combination[i], combination[i+1]);
                currentCombination.add(Pair.create(Pair.create(new Integer(combination[i]),
                            new Boolean(false)), sz));
            }
        }

        for (MandatoryStreamCombination c : availableCombinations) {
            List<MandatoryStreamInformation> streamInfoList = c.getStreamsInformation();
            if ((streamInfoList.size() == currentCombination.size()) &&
                    (isInput == c.isReprocessable())) {
                ArrayList<Pair<Pair<Integer, Boolean>, Size>> expected =
                        new ArrayList<Pair<Pair<Integer, Boolean>, Size>>(currentCombination);

                for (MandatoryStreamInformation streamInfo : streamInfoList) {
                    Size maxSize = CameraTestUtils.getMaxSize(
                            streamInfo.getAvailableSizes().toArray(new Size[0]));
                    Pair p = Pair.create(Pair.create(new Integer(streamInfo.getFormat()),
                            new Boolean(streamInfo.isInput())), maxSize);
                    if (expected.contains(p)) {
                        expected.remove(p);
                    }
                }

                if (expected.isEmpty()) {
                    return true;
                }
            }
        }

        return false;
    }

    /**
     * Verify correctness of the configuration tables.
     */
    private void validityCheckConfigurationTables(final int[][][] tables) throws Exception {
        int tableIdx = 0;
        for (int[][] table : tables) {
            int rowIdx = 0;
            for (int[] row : table) {
                assertTrue(String.format(""Odd number of entries for table %d row %d: %s "",
                                tableIdx, rowIdx, Arrays.toString(row)),
                        (row.length % 2) == 0);
                for (int i = 0; i < row.length; i += 2) {
                    int format = row[i];
                    int maxSize = row[i + 1];
                    assertTrue(String.format(""table %d row %d index %d format not valid: %d"",
                                    tableIdx, rowIdx, i, format),
                            format == PRIV || format == JPEG || format == YUV || format == RAW);
                    assertTrue(String.format(""table %d row %d index %d max size not valid: %d"",
                                    tableIdx, rowIdx, i + 1, maxSize),
                            maxSize == PREVIEW || maxSize == RECORD ||
                            maxSize == MAXIMUM || maxSize == VGA);
                }
                rowIdx++;
            }
            tableIdx++;
        }
    }

    /**
     * Simple holder for resolutions to use for different camera outputs and size limits.
     */
    static class MaxStreamSizes {
        // Format shorthands
        static final int PRIV = ImageFormat.PRIVATE;
        static final int JPEG = ImageFormat.JPEG;
        static final int YUV  = ImageFormat.YUV_420_888;
        static final int RAW  = ImageFormat.RAW_SENSOR;
        static final int Y8   = ImageFormat.Y8;
        static final int HEIC = ImageFormat.HEIC;

        // Max resolution indices
        static final int PREVIEW = 0;
        static final int RECORD  = 1;
        static final int MAXIMUM = 2;
        static final int VGA = 3;
        static final int VGA_FULL_FOV = 4;
        static final int MAX_30FPS = 5;
        static final int RESOLUTION_COUNT = 6;

        static final long FRAME_DURATION_30FPS_NSEC = (long) 1e9 / 30;

        public MaxStreamSizes(StaticMetadata sm, String cameraId, Context context) {
            Size[] privSizes = sm.getAvailableSizesForFormatChecked(ImageFormat.PRIVATE,
                    StaticMetadata.StreamDirection.Output, /*fastSizes*/true, /*slowSizes*/false);
            Size[] yuvSizes = sm.getAvailableSizesForFormatChecked(ImageFormat.YUV_420_888,
                    StaticMetadata.StreamDirection.Output, /*fastSizes*/true, /*slowSizes*/false);

            Size[] y8Sizes = sm.getAvailableSizesForFormatChecked(ImageFormat.Y8,
                    StaticMetadata.StreamDirection.Output, /*fastSizes*/true, /*slowSizes*/false);
            Size[] jpegSizes = sm.getAvailableSizesForFormatChecked(ImageFormat.JPEG,
                    StaticMetadata.StreamDirection.Output, /*fastSizes*/true, /*slowSizes*/false);
            Size[] rawSizes = sm.getAvailableSizesForFormatChecked(ImageFormat.RAW_SENSOR,
                    StaticMetadata.StreamDirection.Output, /*fastSizes*/true, /*slowSizes*/false);
            Size[] heicSizes = sm.getAvailableSizesForFormatChecked(ImageFormat.HEIC,
                    StaticMetadata.StreamDirection.Output, /*fastSizes*/true, /*slowSizes*/false);

            Size maxPreviewSize = getMaxPreviewSize(context, cameraId);

            maxRawSize = (rawSizes.length != 0) ? CameraTestUtils.getMaxSize(rawSizes) : null;

            StreamConfigurationMap configs = sm.getCharacteristics().get(
                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
            if (sm.isColorOutputSupported()) {
                maxPrivSizes[PREVIEW] = getMaxSize(privSizes, maxPreviewSize);
                maxYuvSizes[PREVIEW]  = getMaxSize(yuvSizes, maxPreviewSize);
                maxJpegSizes[PREVIEW] = getMaxSize(jpegSizes, maxPreviewSize);

                if (sm.isExternalCamera()) {
                    maxPrivSizes[RECORD] = getMaxExternalRecordingSize(cameraId, configs);
                    maxYuvSizes[RECORD]  = getMaxExternalRecordingSize(cameraId, configs);
                    maxJpegSizes[RECORD] = getMaxExternalRecordingSize(cameraId, configs);
                } else {
                    maxPrivSizes[RECORD] = getMaxRecordingSize(cameraId);
                    maxYuvSizes[RECORD]  = getMaxRecordingSize(cameraId);
                    maxJpegSizes[RECORD] = getMaxRecordingSize(cameraId);
                }

                maxPrivSizes[MAXIMUM] = CameraTestUtils.getMaxSize(privSizes);
                maxYuvSizes[MAXIMUM] = CameraTestUtils.getMaxSize(yuvSizes);
                maxJpegSizes[MAXIMUM] = CameraTestUtils.getMaxSize(jpegSizes);

                // Must always be supported, add unconditionally
                final Size vgaSize = new Size(640, 480);
                maxPrivSizes[VGA] = vgaSize;
                maxYuvSizes[VGA] = vgaSize;
                maxJpegSizes[VGA] = vgaSize;

                if (sm.isMonochromeWithY8()) {
                    maxY8Sizes[PREVIEW]  = getMaxSize(y8Sizes, maxPreviewSize);
                    if (sm.isExternalCamera()) {
                        maxY8Sizes[RECORD]  = getMaxExternalRecordingSize(cameraId, configs);
                    } else {
                        maxY8Sizes[RECORD]  = getMaxRecordingSize(cameraId);
                    }
                    maxY8Sizes[MAXIMUM] = CameraTestUtils.getMaxSize(y8Sizes);
                    maxY8Sizes[VGA] = vgaSize;
                }

                if (sm.isHeicSupported()) {
                    maxHeicSizes[PREVIEW] = getMaxSize(heicSizes, maxPreviewSize);
                    maxHeicSizes[RECORD] = getMaxRecordingSize(cameraId);
                    maxHeicSizes[MAXIMUM] = CameraTestUtils.getMaxSize(heicSizes);
                    maxHeicSizes[VGA] = vgaSize;
                }
            }
            if (sm.isColorOutputSupported() && !sm.isHardwareLevelLegacy()) {
                // VGA resolution, but with aspect ratio matching full res FOV
                float fullFovAspect = maxYuvSizes[MAXIMUM].getWidth() /
                    (float) maxYuvSizes[MAXIMUM].getHeight();
                Size vgaFullFovSize = new Size(640, (int) (640 / fullFovAspect));

                maxPrivSizes[VGA_FULL_FOV] = vgaFullFovSize;
                maxYuvSizes[VGA_FULL_FOV] = vgaFullFovSize;
                maxJpegSizes[VGA_FULL_FOV] = vgaFullFovSize;
                if (sm.isMonochromeWithY8()) {
                    maxY8Sizes[VGA_FULL_FOV] = vgaFullFovSize;
                }

                // Max resolution that runs at 30fps

                Size maxPriv30fpsSize = null;
                Size maxYuv30fpsSize = null;
                Size maxY830fpsSize = null;
                Size maxJpeg30fpsSize = null;
                Comparator<Size> comparator = new SizeComparator();
                for (Map.Entry<Size, Long> e :
                             sm.getAvailableMinFrameDurationsForFormatChecked(ImageFormat.PRIVATE).
                             entrySet()) {
                    Size s = e.getKey();
                    Long minDuration = e.getValue();
                    Log.d(TAG, String.format(""Priv Size: %s, duration %d limit %d"", s, minDuration,
                                FRAME_DURATION_30FPS_NSEC));
                    if (minDuration <= FRAME_DURATION_30FPS_NSEC) {
                        if (maxPriv30fpsSize == null ||
                                comparator.compare(maxPriv30fpsSize, s) < 0) {
                            maxPriv30fpsSize = s;
                        }
                    }
                }
                assertTrue(""No PRIVATE resolution available at 30fps!"", maxPriv30fpsSize != null);

                for (Map.Entry<Size, Long> e :
                             sm.getAvailableMinFrameDurationsForFormatChecked(
                                     ImageFormat.YUV_420_888).
                             entrySet()) {
                    Size s = e.getKey();
                    Long minDuration = e.getValue();
                    Log.d(TAG, String.format(""YUV Size: %s, duration %d limit %d"", s, minDuration,
                                FRAME_DURATION_30FPS_NSEC));
                    if (minDuration <= FRAME_DURATION_30FPS_NSEC) {
                        if (maxYuv30fpsSize == null ||
                                comparator.compare(maxYuv30fpsSize, s) < 0) {
                            maxYuv30fpsSize = s;
                        }
                    }
                }
                assertTrue(""No YUV_420_888 resolution available at 30fps!"",
                        maxYuv30fpsSize != null);

                if (sm.isMonochromeWithY8()) {
                    for (Map.Entry<Size, Long> e :
                                 sm.getAvailableMinFrameDurationsForFormatChecked(
                                         ImageFormat.Y8).
                                 entrySet()) {
                        Size s = e.getKey();
                        Long minDuration = e.getValue();
                        Log.d(TAG, String.format(""Y8 Size: %s, duration %d limit %d"",
                                s, minDuration, FRAME_DURATION_30FPS_NSEC));
                        if (minDuration <= FRAME_DURATION_30FPS_NSEC) {
                            if (maxY830fpsSize == null ||
                                    comparator.compare(maxY830fpsSize, s) < 0) {
                                maxY830fpsSize = s;
                            }
                        }
                    }
                    assertTrue(""No Y8 resolution available at 30fps!"", maxY830fpsSize != null);
                }

                for (Map.Entry<Size, Long> e :
                             sm.getAvailableMinFrameDurationsForFormatChecked(ImageFormat.JPEG).
                             entrySet()) {
                    Size s = e.getKey();
                    Long minDuration = e.getValue();
                    Log.d(TAG, String.format(""JPEG Size: %s, duration %d limit %d"", s, minDuration,
                                FRAME_DURATION_30FPS_NSEC));
                    if (minDuration <= FRAME_DURATION_30FPS_NSEC) {
                        if (maxJpeg30fpsSize == null ||
                                comparator.compare(maxJpeg30fpsSize, s) < 0) {
                            maxJpeg30fpsSize = s;
                        }
                    }
                }
                assertTrue(""No JPEG resolution available at 30fps!"", maxJpeg30fpsSize != null);

                maxPrivSizes[MAX_30FPS] = maxPriv30fpsSize;
                maxYuvSizes[MAX_30FPS] = maxYuv30fpsSize;
                maxY8Sizes[MAX_30FPS] = maxY830fpsSize;
                maxJpegSizes[MAX_30FPS] = maxJpeg30fpsSize;
            }

            Size[] privInputSizes = configs.getInputSizes(ImageFormat.PRIVATE);
            maxInputPrivSize = privInputSizes != null ?
                    CameraTestUtils.getMaxSize(privInputSizes) : null;
            Size[] yuvInputSizes = configs.getInputSizes(ImageFormat.YUV_420_888);
            maxInputYuvSize = yuvInputSizes != null ?
                    CameraTestUtils.getMaxSize(yuvInputSizes) : null;
            Size[] y8InputSizes = configs.getInputSizes(ImageFormat.Y8);
            maxInputY8Size = y8InputSizes != null ?
                    CameraTestUtils.getMaxSize(y8InputSizes) : null;
        }

        private final Size[] maxPrivSizes = new Size[RESOLUTION_COUNT];
        private final Size[] maxJpegSizes = new Size[RESOLUTION_COUNT];
        private final Size[] maxYuvSizes = new Size[RESOLUTION_COUNT];
        private final Size[] maxY8Sizes = new Size[RESOLUTION_COUNT];
        private final Size[] maxHeicSizes = new Size[RESOLUTION_COUNT];
        private final Size maxRawSize;
        // TODO: support non maximum reprocess input.
        private final Size maxInputPrivSize;
        private final Size maxInputYuvSize;
        private final Size maxInputY8Size;

        public final Size getOutputSizeForFormat(int format, int resolutionIndex) {
            if (resolutionIndex >= RESOLUTION_COUNT) {
                return new Size(0, 0);
            }

            switch (format) {
                case PRIV:
                    return maxPrivSizes[resolutionIndex];
                case YUV:
                    return maxYuvSizes[resolutionIndex];
                case JPEG:
                    return maxJpegSizes[resolutionIndex];
                case Y8:
                    return maxY8Sizes[resolutionIndex];
                case HEIC:
                    return maxHeicSizes[resolutionIndex];
                case RAW:
                    return maxRawSize;
                default:
                    return new Size(0, 0);
            }
        }

        public final Size getMaxInputSizeForFormat(int format) {
            switch (format) {
                case PRIV:
                    return maxInputPrivSize;
                case YUV:
                    return maxInputYuvSize;
                case Y8:
                    return maxInputY8Size;
                default:
                    return new Size(0, 0);
            }
        }

        static public String combinationToString(int[] combination) {
            StringBuilder b = new StringBuilder(""{ "");
            for (int i = 0; i < combination.length; i += 2) {
                int format = combination[i];
                int sizeLimit = combination[i + 1];

                appendFormatSize(b, format, sizeLimit);
                b.append("" "");
            }
            b.append(""}"");
            return b.toString();
        }

        static public String reprocessCombinationToString(int[] reprocessCombination) {
            // reprocessConfig[0..1] is the input configuration
            StringBuilder b = new StringBuilder(""Input: "");
            appendFormatSize(b, reprocessCombination[0], reprocessCombination[1]);

            // reprocessCombnation[0..1] is also output combination to be captured as reprocess
            // input.
            b.append("", Outputs: { "");
            for (int i = 0; i < reprocessCombination.length; i += 2) {
                int format = reprocessCombination[i];
                int sizeLimit = reprocessCombination[i + 1];

                appendFormatSize(b, format, sizeLimit);
                b.append("" "");
            }
            b.append(""}"");
            return b.toString();
        }

        static private void appendFormatSize(StringBuilder b, int format, int Size) {
            switch (format) {
                case PRIV:
                    b.append(""[PRIV, "");
                    break;
                case JPEG:
                    b.append(""[JPEG, "");
                    break;
                case YUV:
                    b.append(""[YUV, "");
                    break;
                case Y8:
                    b.append(""[Y8, "");
                    break;
                case RAW:
                    b.append(""[RAW, "");
                    break;
                default:
                    b.append(""[UNK, "");
                    break;
            }

            switch (Size) {
                case PREVIEW:
                    b.append(""PREVIEW]"");
                    break;
                case RECORD:
                    b.append(""RECORD]"");
                    break;
                case MAXIMUM:
                    b.append(""MAXIMUM]"");
                    break;
                case VGA:
                    b.append(""VGA]"");
                    break;
                case VGA_FULL_FOV:
                    b.append(""VGA_FULL_FOV]"");
                    break;
                case MAX_30FPS:
                    b.append(""MAX_30FPS]"");
                    break;
                default:
                    b.append(""UNK]"");
                    break;
            }
        }
    }

    private static Size getMaxRecordingSize(String cameraId) {
        int id = Integer.valueOf(cameraId);

        int quality =
                CamcorderProfile.hasProfile(id, CamcorderProfile.QUALITY_2160P) ?
                    CamcorderProfile.QUALITY_2160P :
                CamcorderProfile.hasProfile(id, CamcorderProfile.QUALITY_1080P) ?
                    CamcorderProfile.QUALITY_1080P :
                CamcorderProfile.hasProfile(id, CamcorderProfile.QUALITY_720P) ?
                    CamcorderProfile.QUALITY_720P :
                CamcorderProfile.hasProfile(id, CamcorderProfile.QUALITY_480P) ?
                    CamcorderProfile.QUALITY_480P :
                CamcorderProfile.hasProfile(id, CamcorderProfile.QUALITY_QVGA) ?
                    CamcorderProfile.QUALITY_QVGA :
                CamcorderProfile.hasProfile(id, CamcorderProfile.QUALITY_CIF) ?
                    CamcorderProfile.QUALITY_CIF :
                CamcorderProfile.hasProfile(id, CamcorderProfile.QUALITY_QCIF) ?
                    CamcorderProfile.QUALITY_QCIF :
                    -1;

        assertTrue(""No recording supported for camera id "" + cameraId, quality != -1);

        CamcorderProfile maxProfile = CamcorderProfile.get(id, quality);
        return new Size(maxProfile.videoFrameWidth, maxProfile.videoFrameHeight);
    }

    private static Size getMaxExternalRecordingSize(
            String cameraId, StreamConfigurationMap config) {
        final Size FULLHD = new Size(1920, 1080);

        Size[] videoSizeArr = config.getOutputSizes(android.media.MediaRecorder.class);
        List<Size> sizes = new ArrayList<Size>();
        for (Size sz: videoSizeArr) {
            if (sz.getWidth() <= FULLHD.getWidth() && sz.getHeight() <= FULLHD.getHeight()) {
                sizes.add(sz);
            }
        }
        List<Size> videoSizes = getAscendingOrderSizes(sizes, /*ascending*/false);
        for (Size sz : videoSizes) {
            long minFrameDuration = config.getOutputMinFrameDuration(
                    android.media.MediaRecorder.class, sz);
            // Give some margin for rounding error
            if (minFrameDuration > (1e9 / 30.1)) {
                Log.i(TAG, ""External camera "" + cameraId + "" has max video size:"" + sz);
                return sz;
            }
        }
        fail(""Camera "" + cameraId + "" does not support any 30fps video output"");
        return FULLHD; // doesn't matter what size is returned here
    }

    /**
     * Get maximum size in list that's equal or smaller to than the bound.
     * Returns null if no size is smaller than or equal to the bound.
     */
    private static Size getMaxSize(Size[] sizes, Size bound) {
        if (sizes == null || sizes.length == 0) {
            throw new IllegalArgumentException(""sizes was empty"");
        }

        Size sz = null;
        for (Size size : sizes) {
            if (size.getWidth() <= bound.getWidth() && size.getHeight() <= bound.getHeight()) {

                if (sz == null) {
                    sz = size;
                } else {
                    long curArea = sz.getWidth() * (long) sz.getHeight();
                    long newArea = size.getWidth() * (long) size.getHeight();
                    if ( newArea > curArea ) {
                        sz = size;
                    }
                }
            }
        }

        assertTrue(""No size under bound found: "" + Arrays.toString(sizes) + "" bound "" + bound,
                sz != null);

        return sz;
    }

    private static Size getMaxPreviewSize(Context context, String cameraId) {
        try {
            WindowManager windowManager =
                (WindowManager) context.getSystemService(Context.WINDOW_SERVICE);
            Display display = windowManager.getDefaultDisplay();

            int width = display.getWidth();
            int height = display.getHeight();

            if (height > width) {
                height = width;
                width = display.getHeight();
            }

            CameraManager camMgr =
                (CameraManager) context.getSystemService(Context.CAMERA_SERVICE);
            List<Size> orderedPreviewSizes = CameraTestUtils.getSupportedPreviewSizes(
                cameraId, camMgr, PREVIEW_SIZE_BOUND);

            if (orderedPreviewSizes != null) {
                for (Size size : orderedPreviewSizes) {
                    if (width >= size.getWidth() &&
                        height >= size.getHeight())
                        return size;
                }
            }
        } catch (Exception e) {
            Log.e(TAG, ""getMaxPreviewSize Failed. ""+e.toString());
        }
        return PREVIEW_SIZE_BOUND;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.fingerprint.FingerprintServiceTest"	"adoptShellPermissionIdentity"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/fingerprint/FingerprintServiceTest.java"	""	"/*
 *.
 */

package android.server.biometrics.fingerprint;

import static android.server.biometrics.SensorStates.SensorState;
import static android.server.biometrics.SensorStates.UserState;
import static android.server.biometrics.fingerprint.Components.AUTH_ON_CREATE_ACTIVITY;

import static androidx.test.platform.app.InstrumentationRegistry.getInstrumentation;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;
import static org.junit.Assume.assumeTrue;

import android.app.Instrumentation;
import android.hardware.biometrics.BiometricTestSession;
import android.hardware.biometrics.SensorProperties;
import android.hardware.fingerprint.FingerprintManager;
import android.os.Bundle;
import android.platform.test.annotations.Presubmit;
import android.server.biometrics.BiometricServiceState;
import android.server.biometrics.SensorStates;
import android.server.biometrics.Utils;
import android.server.wm.ActivityManagerTestBase;
import android.server.wm.TestJournalProvider.TestJournal;
import android.server.wm.TestJournalProvider.TestJournalContainer;
import android.server.wm.UiDeviceUtils;
import android.server.wm.WindowManagerState;
import android.util.Log;

import androidx.annotation.NonNull;
import androidx.annotation.Nullable;

import com.android.server.biometrics.nano.SensorServiceStateProto;
import com.android.server.biometrics.nano.SensorStateProto;

import org.junit.After;
import org.junit.Before;
import org.junit.Test;

import java.util.ArrayList;
import java.util.List;
import java.util.Map;

@SuppressWarnings(""deprecation"")
@Presubmit
public class FingerprintServiceTest extends ActivityManagerTestBase {
    private static final String TAG = ""FingerprintServiceTest"";

    private static final String DUMPSYS_FINGERPRINT = ""dumpsys fingerprint --proto --state"";

    private SensorStates getSensorStates() throws Exception {
        final byte[] dump = Utils.executeShellCommand(DUMPSYS_FINGERPRINT);
        SensorServiceStateProto proto = SensorServiceStateProto.parseFrom(dump);
        return SensorStates.parseFrom(proto);
    }

    @Nullable
    private static FingerprintCallbackHelper.State getCallbackState(@NonNull TestJournal journal) {
        Utils.waitFor(""Waiting for authentication callback"",
                () -> journal.extras.containsKey(FingerprintCallbackHelper.KEY));

        final Bundle bundle = journal.extras.getBundle(FingerprintCallbackHelper.KEY);
        if (bundle == null) {
            return null;
        }

        final FingerprintCallbackHelper.State state =
                FingerprintCallbackHelper.State.fromBundle(bundle);

        // Clear the extras since we want to wait for the journal to sync any new info the next
        // time it's read
        journal.extras.clear();

        return state;
    }

    @NonNull private Instrumentation mInstrumentation;
    @Nullable private FingerprintManager mFingerprintManager;
    @NonNull private List<SensorProperties> mSensorProperties;

    @Before
    public void setUp() throws Exception {
        mInstrumentation = getInstrumentation();
        mFingerprintManager = mInstrumentation.getContext()
                .getSystemService(FingerprintManager.class);

        // Tests can be skipped on devices without FingerprintManager
        assumeTrue(mFingerprintManager != null);

        mInstrumentation.getUiAutomation().adoptShellPermissionIdentity();

        mSensorProperties = mFingerprintManager.getSensorProperties();

        // Tests can be skipped on devices without fingerprint sensors
        assumeTrue(!mSensorProperties.isEmpty());
    }

    @After
    public void cleanup() throws Exception {
        if (mFingerprintManager == null || mSensorProperties.isEmpty()) {
            // The tests were skipped anyway, nothing to clean up. Maybe we can use JUnit test
            // annotations in the future.
            return;
        }


        mInstrumentation.waitForIdleSync();
        Utils.waitForIdleService(this::getSensorStates);

        final SensorStates sensorStates = getSensorStates();
        for (Map.Entry<Integer, SensorState> sensorEntry : sensorStates.sensorStates.entrySet()) {
            for (Map.Entry<Integer, UserState> userEntry
                    : sensorEntry.getValue().getUserStates().entrySet()) {
                if (userEntry.getValue().numEnrolled != 0) {
                    Log.w(TAG, ""Cleaning up for sensor: "" + sensorEntry.getKey()
                            + "", user: "" + userEntry.getKey());
                    BiometricTestSession session =
                            mFingerprintManager.createTestSession(sensorEntry.getKey());
                    session.cleanupInternalState(userEntry.getKey());
                    session.close();
                }
            }
        }

        mInstrumentation.getUiAutomation().dropShellPermissionIdentity();
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.fingerprint.FingerprintServiceTest"	"testEnroll"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/fingerprint/FingerprintServiceTest.java"	""	"public void testEnroll() throws Exception {
        for (SensorProperties prop : mSensorProperties) {
            try (BiometricTestSession session
                         = mFingerprintManager.createTestSession(prop.getSensorId())){
                testEnrollForSensor(session, prop.getSensorId());
            }
        }
    }

    private void testEnrollForSensor(BiometricTestSession session, int sensorId) throws Exception {
        final int userId = 0;

        session.startEnroll(userId);
        mInstrumentation.waitForIdleSync();
        Utils.waitForIdleService(this::getSensorStates);

        session.finishEnroll(userId);
        mInstrumentation.waitForIdleSync();
        Utils.waitForIdleService(this::getSensorStates);

        final SensorStates sensorStates = getSensorStates();

        // The (sensorId, userId) has one finger enrolled.
        assertEquals(1, sensorStates.sensorStates
                .get(sensorId).getUserStates().get(userId).numEnrolled);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.fingerprint.FingerprintServiceTest"	"testAuthenticateFromForegroundActivity"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/fingerprint/FingerprintServiceTest.java"	""	"public void testAuthenticateFromForegroundActivity() throws Exception {
        // Turn screen on and dismiss keyguard
        UiDeviceUtils.pressWakeupButton();
        UiDeviceUtils.pressUnlockButton();

        // Manually keep track and close the sessions, since we want to enroll all sensors before
        // requesting auth.
        final List<BiometricTestSession> testSessions = new ArrayList<>();

        final int userId = 0;
        for (SensorProperties prop : mSensorProperties) {
            BiometricTestSession session =
                    mFingerprintManager.createTestSession(prop.getSensorId());
            testSessions.add(session);

            session.startEnroll(userId);
            mInstrumentation.waitForIdleSync();
            Utils.waitForIdleService(this::getSensorStates);

            session.finishEnroll(userId);
            mInstrumentation.waitForIdleSync();
            Utils.waitForIdleService(this::getSensorStates);
        }

        final TestJournal journal = TestJournalContainer.get(AUTH_ON_CREATE_ACTIVITY);

        // Launch test activity
        launchActivity(AUTH_ON_CREATE_ACTIVITY);
        mWmState.waitForActivityState(AUTH_ON_CREATE_ACTIVITY, WindowManagerState.STATE_RESUMED);
        mInstrumentation.waitForIdleSync();

        // At least one sensor should be authenticating
        assertFalse(getSensorStates().areAllSensorsIdle());

        // Nothing happened yet
        FingerprintCallbackHelper.State callbackState = getCallbackState(journal);
        assertNotNull(callbackState);
        assertEquals(0, callbackState.mNumAuthRejected);
        assertEquals(0, callbackState.mNumAuthAccepted);
        assertEquals(0, callbackState.mAcquiredReceived.size());
        assertEquals(0, callbackState.mErrorsReceived.size());

        // Auth and check again now
        testSessions.get(0).acceptAuthentication(userId);
        mInstrumentation.waitForIdleSync();
        callbackState = getCallbackState(journal);
        assertNotNull(callbackState);
        assertTrue(callbackState.mErrorsReceived.isEmpty());
        assertTrue(callbackState.mAcquiredReceived.isEmpty());
        assertEquals(1, callbackState.mNumAuthAccepted);
        assertEquals(0, callbackState.mNumAuthRejected);

        // Cleanup
        for (BiometricTestSession session : testSessions) {
            session.close();
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.fingerprint.FingerprintServiceTest"	"testRejectThenErrorFromForegroundActivity"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/fingerprint/FingerprintServiceTest.java"	""	"public void testRejectThenErrorFromForegroundActivity() throws Exception {
        // Turn screen on and dismiss keyguard
        UiDeviceUtils.pressWakeupButton();
        UiDeviceUtils.pressUnlockButton();

        // Manually keep track and close the sessions, since we want to enroll all sensors before
        // requesting auth.
        final List<BiometricTestSession> testSessions = new ArrayList<>();

        final int userId = 0;
        for (SensorProperties prop : mSensorProperties) {
            BiometricTestSession session =
                    mFingerprintManager.createTestSession(prop.getSensorId());
            testSessions.add(session);

            session.startEnroll(userId);
            mInstrumentation.waitForIdleSync();
            Utils.waitForIdleService(this::getSensorStates);

            session.finishEnroll(userId);
            mInstrumentation.waitForIdleSync();
            Utils.waitForIdleService(this::getSensorStates);
        }

        final TestJournal journal = TestJournalContainer.get(AUTH_ON_CREATE_ACTIVITY);

        // Launch test activity
        launchActivity(AUTH_ON_CREATE_ACTIVITY);
        mWmState.waitForActivityState(AUTH_ON_CREATE_ACTIVITY, WindowManagerState.STATE_RESUMED);
        mInstrumentation.waitForIdleSync();
        FingerprintCallbackHelper.State callbackState = getCallbackState(journal);
        assertNotNull(callbackState);

        // Fingerprint rejected
        testSessions.get(0).rejectAuthentication(userId);
        mInstrumentation.waitForIdleSync();
        callbackState = getCallbackState(journal);
        assertNotNull(callbackState);
        assertEquals(1, callbackState.mNumAuthRejected);
        assertEquals(0, callbackState.mNumAuthAccepted);
        assertEquals(0, callbackState.mAcquiredReceived.size());
        assertEquals(0, callbackState.mErrorsReceived.size());

        // Send an acquire message
        // skip this check on devices with UDFPS because they prompt to try again
        // and do not dispatch an acquired event via BiometricPrompt
        final boolean verifyPartial = !hasUdfps();
        if (verifyPartial) {
            testSessions.get(0).notifyAcquired(userId,
                    FingerprintManager.FINGERPRINT_ACQUIRED_PARTIAL);
            mInstrumentation.waitForIdleSync();
            callbackState = getCallbackState(journal);
            assertNotNull(callbackState);
            assertEquals(1, callbackState.mNumAuthRejected);
            assertEquals(0, callbackState.mNumAuthAccepted);
            assertEquals(1, callbackState.mAcquiredReceived.size());
            assertEquals(FingerprintManager.FINGERPRINT_ACQUIRED_PARTIAL,
                    (int) callbackState.mAcquiredReceived.get(0));
            assertEquals(0, callbackState.mErrorsReceived.size());
        }

        // Send an error
        testSessions.get(0).notifyError(userId,
                FingerprintManager.FINGERPRINT_ERROR_CANCELED);
        mInstrumentation.waitForIdleSync();
        callbackState = getCallbackState(journal);
        assertNotNull(callbackState);
        assertEquals(1, callbackState.mNumAuthRejected);
        assertEquals(0, callbackState.mNumAuthAccepted);
        if (verifyPartial) {
            assertEquals(1, callbackState.mAcquiredReceived.size());
            assertEquals(FingerprintManager.FINGERPRINT_ACQUIRED_PARTIAL,
                    (int) callbackState.mAcquiredReceived.get(0));
        } else {
            assertEquals(0, callbackState.mAcquiredReceived.size());
        }
        assertEquals(1, callbackState.mErrorsReceived.size());
        assertEquals(FingerprintManager.FINGERPRINT_ERROR_CANCELED,
                (int) callbackState.mErrorsReceived.get(0));

        // Authentication lifecycle is done
        assertTrue(getSensorStates().areAllSensorsIdle());

        // Cleanup
        for (BiometricTestSession session : testSessions) {
            session.close();
        }
    }

    private boolean hasUdfps() throws Exception {
        final BiometricServiceState state = Utils.getBiometricServiceCurrentState();
        return state.mSensorStates.containsModalityFlag(SensorStateProto.FINGERPRINT_UDFPS);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.SignificantMotionTestActivity"	"SignificantMotionTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/SignificantMotionTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import java.util.Timer;
import java.util.TimerTask;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;
import com.android.cts.verifier.sensors.helpers.SensorTestScreenManipulator;

import android.app.AlarmManager;
import android.app.PendingIntent;
import android.content.BroadcastReceiver;
import android.content.Context;
import android.content.Intent;
import android.content.IntentFilter;
import android.hardware.cts.helpers.SensorNotSupportedException;
import android.hardware.cts.helpers.SuspendStateMonitor;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.Sensor;
import android.hardware.SensorManager;
import android.hardware.TriggerEvent;
import android.hardware.TriggerEventListener;
import android.os.Handler;
import android.os.Looper;
import android.os.PowerManager;
import android.os.PowerManager.WakeLock;
import android.os.SystemClock;
import androidx.localbroadcastmanager.content.LocalBroadcastManager;
import android.util.Log;

import junit.framework.Assert;

/**
 * Test cases for Significant Motion sensor.
 * They use walking motion to change the location and trigger Significant Motion.
 */
public class SignificantMotionTestActivity extends SensorCtsVerifierTestActivity {
    public SignificantMotionTestActivity() {
        super(SignificantMotionTestActivity.class, true);
    }

    // acceptable time difference between event time and system time
    private static final long MAX_ACCEPTABLE_EVENT_TIME_DELAY_NANOS =
            TimeUnit.MILLISECONDS.toNanos(500);

    // acceptable time difference between event time and AP wake up time.
    private static final long MAX_ACCEPTABLE_DELAY_EVENT_AP_WAKE_UP_NS =
            TimeUnit.MILLISECONDS.toNanos(2000);

    // time to wait for SMD after the device has gone into suspend. Even after
    // 45 secs if SMD does not trigger, the test will fail.
    private static final long ALARM_WAKE_TIME_DELAY_MS = TimeUnit.SECONDS.toMillis(45);

    // time for the test to wait for a trigger
    private static final int TRIGGER_MAX_DELAY_SECONDS = 30;
    private static final int VIBRATE_DURATION_MILLIS = 10000;

    private static final int EVENT_VALUES_LENGTH = 1;
    private static final float EXPECTED_EVENT_VALUE = 1.0f;
    private static String ACTION_ALARM = ""SignificantMotionTestActivity.ACTION_ALARM"";

    private SensorManager mSensorManager;
    private Sensor mSensorSignificantMotion;
    private TriggerVerifier mVerifier;
    private SensorTestScreenManipulator mScreenManipulator;
    private WakeLock mPartialWakeLock;

    /**
     * Test cases.
     */
    @SuppressWarnings(""unused"")
    public String testTrigger() throws Throwable {
        return runTest(
                R.string.snsr_significant_motion_test_trigger,
                true /* isMotionExpected */,
                false /* cancelEventNotification */,
                false /* vibrate */);
    }

    @SuppressWarnings(""unused"")
    public String testNotTriggerAfterCancel() throws Throwable {
        return runTest(
                R.string.snsr_significant_motion_test_cancel,
                false /* isMotionExpected */,
                true /* cancelEventNotification */,
                false /* vibrate */);
    }

    /**
     * Verifies that Significant Motion is not trigger by the vibrator motion.
     */
    @SuppressWarnings(""unused"")
    public String testVibratorDoesNotTrigger() throws Throwable {
     return runTest(
             R.string.snsr_significant_motion_test_vibration,
             false /* isMotionExpected */,
             false /* cancelEventNotification */,
             true /* vibrate */);
    }

    /**
     * Verifies that the natural motion of keeping the device in hand does not change the location.
     * It ensures that Significant Motion will not trigger in that scenario.
     */
    @SuppressWarnings(""unused"")
    public String testInHandDoesNotTrigger() throws Throwable {
        return runTest(
                R.string.snsr_significant_motion_test_in_hand,
                false /* isMotionExpected */,
                false /* cancelEventNotification */,
                false /* vibrate */);
    }

    @SuppressWarnings(""unused"")
    public String testSittingDoesNotTrigger() throws Throwable {
        return runTest(
                R.string.snsr_significant_motion_test_sitting,
                false /* isMotionExpected */,
                false /* cancelEventNotification */,
                false /* vibrate */);
    }

    @SuppressWarnings(""unused"")
    public String testTriggerDeactivation() throws Throwable {

        setFirstExecutionInstruction(R.string.snsr_significant_motion_test_deactivation);

        TriggerVerifier verifier = new TriggerVerifier();
        mSensorManager.requestTriggerSensor(verifier, mSensorSignificantMotion);
        getTestLogger().logWaitForSound();

        String result;
        try {
            mPartialWakeLock.acquire();

            // wait for the first event to trigger
            verifier.verifyEventTriggered();

            // wait for a second event not to trigger
            result = verifier.verifyEventNotTriggered();
        } finally {
            playSound();
            mScreenManipulator.turnScreenOn();
            mPartialWakeLock.release();
        }
        return result;
    }

    public static class AlarmReceiver extends BroadcastReceiver {
        @Override
        public void onReceive(Context context, Intent intent) {
            Intent alarm_intent = new Intent(context, SignificantMotionTestActivity.class);
            alarm_intent.setAction(SignificantMotionTestActivity.ACTION_ALARM);
            LocalBroadcastManager.getInstance(context).sendBroadcastSync(alarm_intent);
        }
    }

    public BroadcastReceiver myBroadCastReceiver = new BroadcastReceiver() {
        @Override
        public void onReceive(Context context, Intent intent) {
            mVerifier.releaseLatch();
            mScreenManipulator.turnScreenOn();
            try {
                playSound();
            } catch (InterruptedException e) {
                // Ignore ...
            }
        }
    };

    @SuppressWarnings(""unused"")
    public String testAPWakeUpOnSMDTrigger() throws Throwable {

        setFirstExecutionInstruction(R.string.snsr_significant_motion_ap_suspend);

        mVerifier = new TriggerVerifier();
        mSensorManager.requestTriggerSensor(mVerifier, mSensorSignificantMotion);
        long testStartTimeNs = SystemClock.elapsedRealtimeNanos();
        Handler handler = new Handler(Looper.getMainLooper());
        SuspendStateMonitor suspendStateMonitor = new SuspendStateMonitor();

        Intent intent = new Intent(this, AlarmReceiver.class);
        PendingIntent pendingIntent = PendingIntent.getBroadcast(this, 0, intent, PendingIntent.FLAG_MUTABLE_UNAUDITED);

        AlarmManager am = (AlarmManager) getSystemService(ALARM_SERVICE);
        am.setExact(AlarmManager.ELAPSED_REALTIME_WAKEUP,
                     SystemClock.elapsedRealtime() + ALARM_WAKE_TIME_DELAY_MS, pendingIntent);
        try {
            // Wait for the first event to trigger. Device is expected to go into suspend here.
            mVerifier.verifyEventTriggered();
            long eventTimeStampNs = mVerifier.getTimeStampForTriggerEvent();
            long endTimeNs = SystemClock.elapsedRealtimeNanos();
            long lastWakeupTimeNs = TimeUnit.MILLISECONDS.toNanos(
                    suspendStateMonitor.getLastWakeUpTime());
            Assert.assertTrue(getString(R.string.snsr_device_did_not_go_into_suspend),
                              testStartTimeNs < lastWakeupTimeNs && lastWakeupTimeNs < endTimeNs);
            long timestampDelta = Math.abs(lastWakeupTimeNs - eventTimeStampNs);
            Assert.assertTrue(
                    String.format(getString(R.string.snsr_device_did_not_wake_up_at_trigger),
                              TimeUnit.NANOSECONDS.toMillis(lastWakeupTimeNs),
                              TimeUnit.NANOSECONDS.toMillis(eventTimeStampNs)),
                              timestampDelta < MAX_ACCEPTABLE_DELAY_EVENT_AP_WAKE_UP_NS);
        } finally {
            am.cancel(pendingIntent);
            suspendStateMonitor.cancel();
            mScreenManipulator.turnScreenOn();
            playSound();
        }
        return null;
    }

    /**
     * @param instructionsResId Instruction to be shown to testers
     * @param isMotionExpected Should the device detect significant motion event
     *            for this test?
     * @param cancelEventNotification If TRUE, motion notifications will be
     *            requested first and request will be cancelled
     * @param vibrate If TRUE, vibration will be concurrent with the test
     * @throws Throwable
     */
    private String runTest(
            int instructionsResId,
            boolean isMotionExpected,
            boolean cancelEventNotification,
            boolean vibrate) throws Throwable {

        setFirstExecutionInstruction(instructionsResId);

        if (vibrate) {
            vibrate(VIBRATE_DURATION_MILLIS);
        }

        TriggerVerifier verifier = new TriggerVerifier();
        boolean success = mSensorManager.requestTriggerSensor(verifier, mSensorSignificantMotion);
        Assert.assertTrue(
                getString(R.string.snsr_significant_motion_registration, success),
                success);
        if (cancelEventNotification) {
            Assert.assertTrue(
                    getString(R.string.snsr_significant_motion_cancelation),
                    mSensorManager.cancelTriggerSensor(verifier, mSensorSignificantMotion));
        }
        getTestLogger().logWaitForSound();

        String result;
        try {
            mPartialWakeLock.acquire();

            if (isMotionExpected) {
                result = verifier.verifyEventTriggered();
            } else {
                result = verifier.verifyEventNotTriggered();
            }
        } finally {
            mSensorManager.cancelTriggerSensor(verifier, mSensorSignificantMotion);

            // notify user test finished
            playSound();
            mScreenManipulator.turnScreenOn();
            mPartialWakeLock.release();
        }
        return result;
    }

    @Override
    protected void activitySetUp() {
        mSensorManager = (SensorManager) getApplicationContext()
                .getSystemService(Context.SENSOR_SERVICE);
        mSensorSignificantMotion = mSensorManager.getDefaultSensor(Sensor.TYPE_SIGNIFICANT_MOTION);
        if (mSensorSignificantMotion == null) {
            throw new SensorNotSupportedException(Sensor.TYPE_SIGNIFICANT_MOTION);
        }

        mScreenManipulator = new SensorTestScreenManipulator(this);
        try {
            mScreenManipulator.initialize(this);
        } catch (InterruptedException e) {
        }
        PowerManager pm = (PowerManager)getSystemService(Context.POWER_SERVICE);
        mPartialWakeLock = pm.newWakeLock(PowerManager.PARTIAL_WAKE_LOCK, ""SignificantMotionTestActivity"");
        LocalBroadcastManager.getInstance(this).registerReceiver(myBroadCastReceiver,
                                            new IntentFilter(ACTION_ALARM));
    }

    @Override
    protected void activityCleanUp() {
        if (mScreenManipulator != null) {
            // after this screen does not have to be on constantly
            mScreenManipulator.releaseScreenOn();
        }
        if (mPartialWakeLock != null && mPartialWakeLock.isHeld()) {
            mPartialWakeLock.release();
        }
        LocalBroadcastManager.getInstance(this).unregisterReceiver(myBroadCastReceiver);
    }

    @Override
    protected void onDestroy() {
        super.onDestroy();
        if (mScreenManipulator != null){
            mScreenManipulator.close();
        }
    }

    /**
     * Helper Trigger listener for testing.
     * It cannot be reused.
     */
    private class TriggerVerifier extends TriggerEventListener {
        private volatile CountDownLatch mCountDownLatch;
        private volatile TriggerEventRegistry mEventRegistry;
        private volatile long mTimestampForTriggeredEvent = 0;

        // TODO: refactor out if needed
        private class TriggerEventRegistry {
            public final TriggerEvent triggerEvent;
            public final long realtimeTimestampNanos;

            public TriggerEventRegistry(TriggerEvent event, long realtimeTimestampNanos) {
                this.triggerEvent = event;
                this.realtimeTimestampNanos = realtimeTimestampNanos;
            }
        }

        public void onTrigger(TriggerEvent event) {
            long elapsedRealtimeNanos = SystemClock.elapsedRealtimeNanos();
            mEventRegistry = new TriggerEventRegistry(event, elapsedRealtimeNanos);
            mCountDownLatch.countDown();
        }

        public void releaseLatch() {
            if (mCountDownLatch != null) {
                mCountDownLatch.countDown();
            }
        }

        public long getTimeStampForTriggerEvent() {
            return mTimestampForTriggeredEvent;
        }

        public String verifyEventTriggered() throws Throwable {
            TriggerEventRegistry registry = awaitForEvent();

            // verify an event arrived, and it is indeed a Significant Motion event
            TriggerEvent event = registry.triggerEvent;
            String eventArrivalMessage =
                    getString(R.string.snsr_significant_motion_event_arrival, event != null);
            Assert.assertNotNull(eventArrivalMessage, event);

            int eventType = event.sensor.getType();
            String eventTypeMessage = getString(
                    R.string.snsr_significant_motion_event_type,
                    Sensor.TYPE_SIGNIFICANT_MOTION,
                    eventType);
            Assert.assertEquals(eventTypeMessage, Sensor.TYPE_SIGNIFICANT_MOTION, eventType);

            String sensorName = event.sensor.getName();
            int valuesLength = event.values.length;
            String valuesLengthMessage = getString(
                    R.string.snsr_event_length,
                    EVENT_VALUES_LENGTH,
                    valuesLength,
                    sensorName);
            Assert.assertEquals(valuesLengthMessage, EVENT_VALUES_LENGTH, valuesLength);

            float value = event.values[0];
            String valuesMessage = getString(
                    R.string.snsr_event_value,
                    EXPECTED_EVENT_VALUE,
                    value,
                    sensorName);
            Assert.assertEquals(valuesMessage, EXPECTED_EVENT_VALUE, value);

            long deltaThreshold = MAX_ACCEPTABLE_EVENT_TIME_DELAY_NANOS
                    + TestSensorEnvironment.getSensorMaxDetectionLatencyNs(event.sensor);
            return assertTimestampSynchronization(
                    event.timestamp,
                    registry.realtimeTimestampNanos,
                    deltaThreshold,
                    sensorName);
        }

        public String verifyEventNotTriggered() throws Throwable {
            TriggerEventRegistry registry = awaitForEvent();

            TriggerEvent event = registry.triggerEvent;
            String eventMessage =
                    getString(R.string.snsr_significant_motion_event_unexpected, event != null);
            Assert.assertNull(eventMessage, event);
            return eventMessage;
        }

        private TriggerEventRegistry awaitForEvent() throws InterruptedException {
            mCountDownLatch = new CountDownLatch(1);
            mCountDownLatch.await(TRIGGER_MAX_DELAY_SECONDS, TimeUnit.SECONDS);
            TriggerEventRegistry registry = mEventRegistry;

            // Save the last timestamp when the event triggered.
            if (mEventRegistry != null && mEventRegistry.triggerEvent != null) {
                mTimestampForTriggeredEvent = mEventRegistry.triggerEvent.timestamp;
            }

            mEventRegistry = null;
            return registry != null ? registry : new TriggerEventRegistry(null, 0);
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.deviceandprofileowner.PermissionsTest"	"PermissionBroadcastReceiver"	""	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/app/DeviceAndProfileOwner/src/com/android/cts/deviceandprofileowner/PermissionsTest.java"	""	"public void test/*
 *.
 */
package com.android.cts.deviceandprofileowner;

import static android.Manifest.permission.READ_CONTACTS;
import static android.Manifest.permission.WRITE_CONTACTS;
import static android.app.admin.DevicePolicyManager.PERMISSION_GRANT_STATE_DEFAULT;
import static android.app.admin.DevicePolicyManager.PERMISSION_GRANT_STATE_DENIED;
import static android.app.admin.DevicePolicyManager.PERMISSION_GRANT_STATE_GRANTED;
import static android.app.admin.DevicePolicyManager.PERMISSION_POLICY_AUTO_DENY;
import static android.app.admin.DevicePolicyManager.PERMISSION_POLICY_AUTO_GRANT;
import static android.app.admin.DevicePolicyManager.PERMISSION_POLICY_PROMPT;
import static android.content.pm.PackageManager.PERMISSION_DENIED;
import static android.content.pm.PackageManager.PERMISSION_GRANTED;

import android.Manifest.permission;
import android.app.UiAutomation;
import android.app.admin.DevicePolicyManager;
import android.content.IntentFilter;
import android.content.pm.PackageManager;
import android.support.test.uiautomator.By;
import android.support.test.uiautomator.BySelector;
import android.support.test.uiautomator.UiDevice;
import android.support.test.uiautomator.UiObject2;
import android.util.Log;

import com.android.cts.devicepolicy.PermissionBroadcastReceiver;
import com.android.cts.devicepolicy.PermissionUtils;

import com.google.android.collect.Sets;

import java.util.Set;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

/**
 * Test Runtime Permissions APIs in DevicePolicyManager.
 */
public class PermissionsTest extends BaseDeviceAdminTest {

    private static final String TAG = ""PermissionsTest"";

    private static final String PERMISSION_APP_PACKAGE_NAME = ""com.android.cts.permissionapp"";
    private static final String PRE_M_APP_PACKAGE_NAME
            = ""com.android.cts.launcherapps.simplepremapp"";
    private static final String PERMISSIONS_ACTIVITY_NAME
            = PERMISSION_APP_PACKAGE_NAME + "".PermissionActivity"";
    private static final String CUSTOM_PERM_A_NAME = ""com.android.cts.permissionapp.permA"";
    private static final String CUSTOM_PERM_B_NAME = ""com.android.cts.permissionapp.permB"";
    private static final String DEVELOPMENT_PERMISSION = ""android.permission.INTERACT_ACROSS_USERS"";

    private static final String ACTION_PERMISSION_RESULT
            = ""com.android.cts.permission.action.PERMISSION_RESULT"";

    private static final BySelector CRASH_POPUP_BUTTON_SELECTOR = By
            .clazz(android.widget.Button.class.getName())
            .text(""OK"")
            .pkg(""android"");
    private static final BySelector CRASH_POPUP_TEXT_SELECTOR = By
            .clazz(android.widget.TextView.class.getName())
            .pkg(""android"");
    private static final String CRASH_WATCHER_ID = ""CRASH"";
    private static final String AUTO_GRANTED_PERMISSIONS_CHANNEL_ID =
            ""alerting auto granted permissions"";

    private static final Set<String> LOCATION_PERMISSIONS = Sets.newHashSet(
            permission.ACCESS_FINE_LOCATION,
            permission.ACCESS_BACKGROUND_LOCATION,
            permission.ACCESS_COARSE_LOCATION);

    private static final Set<String> SENSORS_PERMISSIONS = Sets.newHashSet(
            permission.ACCESS_FINE_LOCATION,
            permission.ACCESS_COARSE_LOCATION,
            permission.CAMERA,
            permission.ACTIVITY_RECOGNITION,
            permission.BODY_SENSORS);


    private PermissionBroadcastReceiver mReceiver;
    private UiDevice mDevice;
    private UiAutomation mUiAutomation;

    @Override
    protected void setUp() throws Exception {
        super.setUp();
        mReceiver = new PermissionBroadcastReceiver();
        mContext.registerReceiver(mReceiver, new IntentFilter(ACTION_PERMISSION_RESULT));
        mDevice = UiDevice.getInstance(getInstrumentation());
        mUiAutomation = getInstrumentation().getUiAutomation();
    }

    @Override
    protected void tearDown() throws Exception {
        mContext.unregisterReceiver(mReceiver);
        mDevice.removeWatcher(CRASH_WATCHER_ID);
        super.tearDown();
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.deviceandprofileowner.PermissionsTest"	"testSensorsRelatedPermissionsCannotBeGranted"	""	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/app/DeviceAndProfileOwner/src/com/android/cts/deviceandprofileowner/PermissionsTest.java"	""	"public void testSensorsRelatedPermissionsCannotBeGranted() throws Exception {
        for (String sensorPermission : SENSORS_PERMISSIONS) {
            try {
                // The permission cannot be granted.
                assertFailedToSetPermissionGrantState(
                        sensorPermission, DevicePolicyManager.PERMISSION_GRANT_STATE_GRANTED);

                // But the user can grant it.
                PermissionUtils.launchActivityAndRequestPermission(mReceiver, mDevice,
                        sensorPermission, PERMISSION_GRANTED, PERMISSION_APP_PACKAGE_NAME,
                        PERMISSIONS_ACTIVITY_NAME);

                // And the package manager should show it as granted.
                PermissionUtils.checkPermission(sensorPermission, PERMISSION_GRANTED,
                        PERMISSION_APP_PACKAGE_NAME);
            } finally {
                revokePermission(sensorPermission);
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.deviceandprofileowner.PermissionsTest"	"testSensorsRelatedPermissionsCanBeDenied"	""	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/app/DeviceAndProfileOwner/src/com/android/cts/deviceandprofileowner/PermissionsTest.java"	""	"public void testSensorsRelatedPermissionsCanBeDenied() throws Exception {
        for (String sensorPermission : SENSORS_PERMISSIONS) {
            // The permission can be denied
            setPermissionGrantState(sensorPermission, PERMISSION_GRANT_STATE_DENIED);

            assertPermissionGrantState(sensorPermission, PERMISSION_GRANT_STATE_DENIED);
            assertCannotRequestPermissionFromActivity(sensorPermission);
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.deviceandprofileowner.PermissionsTest"	"testSensorsRelatedPermissionsNotGrantedViaPolicy"	""	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/app/DeviceAndProfileOwner/src/com/android/cts/deviceandprofileowner/PermissionsTest.java"	""	"public void testSensorsRelatedPermissionsNotGrantedViaPolicy() throws Exception {
        setPermissionPolicy(PERMISSION_POLICY_AUTO_GRANT);
        for (String sensorPermission : SENSORS_PERMISSIONS) {
            try {
                // The permission is not granted by default.
                PermissionUtils.checkPermission(sensorPermission, PERMISSION_DENIED,
                        PERMISSION_APP_PACKAGE_NAME);
                // But the user can grant it.
                PermissionUtils.launchActivityAndRequestPermission(mReceiver, mDevice,
                        sensorPermission,
                        PERMISSION_GRANTED, PERMISSION_APP_PACKAGE_NAME, PERMISSIONS_ACTIVITY_NAME);

                // And the package manager should show it as granted.
                PermissionUtils.checkPermission(sensorPermission, PERMISSION_GRANTED,
                        PERMISSION_APP_PACKAGE_NAME);
            } finally {
                revokePermission(sensorPermission);
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.deviceandprofileowner.PermissionsTest"	"testStateOfSensorsRelatedPermissionsCannotBeRead"	""	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/app/DeviceAndProfileOwner/src/com/android/cts/deviceandprofileowner/PermissionsTest.java"	""	"public void testStateOfSensorsRelatedPermissionsCannotBeRead() throws Exception {
        for (String sensorPermission : SENSORS_PERMISSIONS) {
            try {
                // The admin tries to grant the permission.
                setPermissionGrantState(sensorPermission, PERMISSION_GRANT_STATE_GRANTED);

                // But the user denies it.
                PermissionUtils.launchActivityAndRequestPermission(mReceiver, mDevice,
                        sensorPermission, PERMISSION_DENIED, PERMISSION_APP_PACKAGE_NAME,
                        PERMISSIONS_ACTIVITY_NAME);

                // And the admin cannot learn of it.
                assertPermissionGrantState(sensorPermission, PERMISSION_GRANT_STATE_DEFAULT);
            } finally {
                revokePermission(sensorPermission);
            }
        }
    }

    private void revokePermission(String sensorPermission) {
        if (LOCATION_PERMISSIONS.contains(sensorPermission)) {
            mUiAutomation.revokeRuntimePermission(PERMISSION_APP_PACKAGE_NAME,
                    permission.ACCESS_FINE_LOCATION);
            mUiAutomation.revokeRuntimePermission(PERMISSION_APP_PACKAGE_NAME,
                    permission.ACCESS_COARSE_LOCATION);
        } else {
            mUiAutomation.revokeRuntimePermission(PERMISSION_APP_PACKAGE_NAME, sensorPermission);
        }
    }

    private void assertFailedToSetPermissionGrantState(String permission, int value) {
        assertTrue(mDevicePolicyManager.setPermissionGrantState(ADMIN_RECEIVER_COMPONENT,
                PERMISSION_APP_PACKAGE_NAME, permission, value));
        assertEquals(mDevicePolicyManager.getPermissionGrantState(ADMIN_RECEIVER_COMPONENT,
                PERMISSION_APP_PACKAGE_NAME, permission),
                DevicePolicyManager.PERMISSION_GRANT_STATE_DEFAULT);
        assertEquals(mContext.getPackageManager().checkPermission(permission,
                PERMISSION_APP_PACKAGE_NAME),
                PackageManager.PERMISSION_DENIED);
    }

    private CountDownLatch initPermissionNotificationLatch() {
        CountDownLatch notificationCounterLatch = new CountDownLatch(1);
        NotificationListener.getInstance().addListener((notification) -> {
            if (notification.getPackageName().equals(
                    mContext.getPackageManager().getPermissionControllerPackageName()) &&
                    notification.getNotification().getChannelId().equals(
                            AUTO_GRANTED_PERMISSIONS_CHANNEL_ID)) {
                notificationCounterLatch.countDown();
            }
        });
        return notificationCounterLatch;
    }

    private void setPermissionPolicy(int permissionPolicy) {
        mDevicePolicyManager.setPermissionPolicy(ADMIN_RECEIVER_COMPONENT, permissionPolicy);
    }

    private boolean setPermissionGrantState(String permission, int grantState) {
        return mDevicePolicyManager.setPermissionGrantState(ADMIN_RECEIVER_COMPONENT,
                PERMISSION_APP_PACKAGE_NAME, permission, grantState);
    }

    private void unableToSetPermissionGrantState(String permission, int grantState) {
        assertFalse(setPermissionGrantState(permission, grantState));
    }

    private void assertPermissionGrantState(String permission, int grantState) {
        assertEquals(mDevicePolicyManager.getPermissionGrantState(ADMIN_RECEIVER_COMPONENT,
                PERMISSION_APP_PACKAGE_NAME, permission), grantState);
    }

    private void assertPermissionPolicy(int permissionPolicy) {
        assertEquals(mDevicePolicyManager.getPermissionPolicy(ADMIN_RECEIVER_COMPONENT),
                permissionPolicy);
    }

    private void assertCanRequestPermissionFromActivity(String permission) throws Exception {
        PermissionUtils.launchActivityAndRequestPermission(
                mReceiver, permission, PERMISSION_GRANTED,
                PERMISSION_APP_PACKAGE_NAME, PERMISSIONS_ACTIVITY_NAME);
    }

    private void assertCannotRequestPermissionFromActivity(String permission) throws Exception {
        PermissionUtils.launchActivityAndRequestPermission(
                mReceiver, permission, PERMISSION_DENIED,
                PERMISSION_APP_PACKAGE_NAME, PERMISSIONS_ACTIVITY_NAME);
    }

    private void assertHasPermissionFromActivity(String permission) throws Exception {
        PermissionUtils.launchActivityAndCheckPermission(
                mReceiver, permission, PERMISSION_GRANTED,
                PERMISSION_APP_PACKAGE_NAME, PERMISSIONS_ACTIVITY_NAME);
    }

    private void assertNoPermissionFromActivity(String permission) throws Exception {
        PermissionUtils.launchActivityAndCheckPermission(
                mReceiver, permission, PERMISSION_DENIED,
                PERMISSION_APP_PACKAGE_NAME, PERMISSIONS_ACTIVITY_NAME);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.input.InputDeviceSensorManagerTest"	"assertNoDisconnection"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/input/InputDeviceSensorManagerTest.java"	""	"/*
 *.
 */

package android.view.cts;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;

import android.app.Instrumentation;
import android.hardware.Sensor;
import android.hardware.SensorDirectChannel;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.hardware.input.InputManager;
import android.os.Handler;
import android.os.HandlerThread;
import android.os.MemoryFile;
import android.os.SystemClock;
import android.util.Log;
import android.view.InputDevice;

import androidx.annotation.NonNull;
import androidx.test.ext.junit.runners.AndroidJUnit4;
import androidx.test.filters.SmallTest;
import androidx.test.platform.app.InstrumentationRegistry;

import com.android.cts.input.InputJsonParser;
import com.android.cts.input.UinputDevice;

import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import org.junit.runner.RunWith;

import java.io.IOException;
import java.util.Arrays;
import java.util.List;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.TimeUnit;

/**
 * Test {@link android.view.InputDevice} sensor functionality.
 */
@SmallTest
@RunWith(AndroidJUnit4.class)
public class InputDeviceSensorManagerTest {
    private static final String TAG = ""InputDeviceSensorManagerTest"";
    private static final int SENSOR_VEC_LENGTH = 3;
    private static final int EV_SYN = 0;
    private static final int EV_ABS = 3;
    private static final int EV_MSC = 4;
    private static final int ABS_X = 0;
    private static final int ABS_Y = 1;
    private static final int ABS_Z = 2;
    private static final int ABS_RX = 3;
    private static final int ABS_RY = 4;
    private static final int ABS_RZ = 5;
    private static final int MSC_TIMESTAMP = 5;
    // The time interval for between sensor time events, in unit of micro seconds.
    private static final int TIME_INTERVAL_US = 10000;
    // Requested sensor listening interval, to pass to registerListener API,
    // in unit of milli seconds.
    private static final int SAMPLING_INTERVAL_US = 20000;
    // The Gyroscope sensor hardware resolution of 1 unit, degree/second.
    private static final float GYRO_RESOLUTION = 1024.0f;
    // The Accelerometer sensor hardware resolution of 1 unit, per g.
    private static final float ACCEL_RESOLUTION = 8192.0f;
    // Numbers of sensor samples to run.
    private static final int RUNNING_SAMPLES = 100;
    // Sensor raw value increment step for each sensor event.
    private static final int SAMPLE_STEP = 925;
    // Tolerance of sensor event values.
    private static final float TOLERANCE = 0.01f;
    // Linux accelerometer unit is per g,  Android unit is m/s^2
    private static final float GRAVITY_MS2_UNIT = 9.80665f;
    // Linux gyroscope unit is degree/second, Android unit is radians/second
    private static final float DEGREE_RADIAN_UNIT = 0.0174533f;
    // Share memory size
    private static final int SHARED_MEMORY_SIZE = 8192;

    private static final int CONNECTION_TIMEOUT_SEC = 3;

    private InputManager mInputManager;
    private UinputDevice mUinputDevice;
    private InputJsonParser mParser;
    private Instrumentation mInstrumentation;
    private SensorManager mSensorManager;
    private HandlerThread mSensorThread = null;
    private Handler mSensorHandler = null;
    private int mDeviceId;
    private final Object mLock = new Object();

    private class Callback extends SensorManager.DynamicSensorCallback {
        private Sensor mSensor;
        private CountDownLatch mConnectLatch = new CountDownLatch(1);
        private CountDownLatch mDisconnectLatch = new CountDownLatch(1);

        Callback(@NonNull Sensor sensor) {
            mSensor = sensor;
        }

        @Override
        public void onDynamicSensorConnected(Sensor sensor) {
            synchronized (mSensor) {
                if (mSensor.getId() == sensor.getId()) {
                    mConnectLatch.countDown();
                }
            }
        }

        @Override
        public void onDynamicSensorDisconnected(Sensor sensor) {
            synchronized (mSensor) {
                if (mSensor.getId() == sensor.getId()) {
                    mDisconnectLatch.countDown();
                }
            }
        }

        public boolean waitForConnection() {
            try {
                return mConnectLatch.await(CONNECTION_TIMEOUT_SEC, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
            return false;
        }

        public void assertNoDisconnection() {
            assertEquals(1, mDisconnectLatch.getCount());
        }
    }

    private class InputTestSensorEventListener implements SensorEventListener {
        private CountDownLatch mAccuracyLatch;
        private int mAccuracy = SensorManager.SENSOR_STATUS_NO_CONTACT;
        private final BlockingQueue<SensorEvent> mEvents = new LinkedBlockingQueue<>();
        InputTestSensorEventListener() {
            super();
            mAccuracyLatch = new CountDownLatch(1);
        }

        public SensorEvent waitForSensorEvent() {
            try {
                return mEvents.poll(5, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                fail(""unexpectedly interrupted while waiting for SensorEvent"");
                return null;
            }
        }

        public int waitForAccuracyChanged() {
            boolean ret;
            try {
                ret = mAccuracyLatch.await(5, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                ret = false;
                Thread.currentThread().interrupt();
            }

            synchronized (mLock) {
                return mAccuracy;
            }
        }

        @Override
        public void onSensorChanged(SensorEvent event) {
            synchronized (mLock) {
                try {
                    mEvents.put(event);
                } catch (InterruptedException ex) {
                    fail(""interrupted while adding a SensorEvent to the queue"");
                }
            }
        }

        @Override
        public void onAccuracyChanged(Sensor sensor, int accuracy) {
            synchronized (mLock) {
                mAccuracy = accuracy;
            }
            if (mAccuracyLatch != null) {
                mAccuracyLatch.countDown();
            }
        }
    }

    /**
     * Get a SensorManager object from input device with specified Vendor Id and Product Id.
     * @param vid Vendor Id
     * @param pid Product Id
     * @return SensorManager object in specified InputDevice
     */
    private SensorManager getSensorManager(int vid, int pid) {
        final int[] inputDeviceIds = mInputManager.getInputDeviceIds();
        for (int inputDeviceId : inputDeviceIds) {
            final InputDevice inputDevice = mInputManager.getInputDevice(inputDeviceId);
            if (inputDevice.getVendorId() == vid && inputDevice.getProductId() == pid) {
                SensorManager sensorManager = inputDevice.getSensorManager();
                assertNotNull(""getSensorManager returns null"", sensorManager);
                Log.i(TAG, ""Input device: "" + inputDeviceId + "" VendorId: ""
                        + inputDevice.getVendorId() + "" ProductId: "" + inputDevice.getProductId());
                return sensorManager;
            }
        }
        return null;
    }

    private void bumpSensorsData(int[] sensorVector) {
        final int step = SAMPLE_STEP;
        for (int i = 0; i < sensorVector.length; i++) {
            sensorVector[i] = sensorVector[i] + step;
        }
    }

    private float[] getExpectedSensorValue(Sensor sensor, int[] dataVector) {
        float[] sensorValues = new float[dataVector.length];
        for (int i = 0; i < dataVector.length; i++) {
            switch (sensor.getType()) {
                case Sensor.TYPE_ACCELEROMETER:
                    sensorValues[i] = ((float) dataVector[i]) / ACCEL_RESOLUTION
                            * GRAVITY_MS2_UNIT;
                    break;
                case Sensor.TYPE_GYROSCOPE:
                    sensorValues[i] = ((float) dataVector[i]) / GYRO_RESOLUTION
                            * DEGREE_RADIAN_UNIT;
                    break;
                default:
                    break;
            }
        }
        return sensorValues;
    }

    private void assertSensorDataEquals(float[] expected, float[] received) {
        assertEquals(""expected sensor data length is not same as received sensor data length"",
                expected.length, received.length);
        for (int i = 0; i < expected.length; i++) {
            assertEquals(""Data index["" + i + ""] not match"", expected[i], received[i], TOLERANCE);
        }
    }

    /**
     * Simulate a sensor data sample from device.
     * @param sensor sensor object for data to be injected
     * @param dataVec sensor data vector
     * @param timestamp sensor data timestamp and sync to be injected, 0 for no timestamp and sync
     */
    private void injectSensorSample(Sensor sensor, int[] dataVec, int timestamp) {
        assertEquals(""Sensor sample size is wrong"", dataVec.length, SENSOR_VEC_LENGTH);

        switch (sensor.getType()) {
            case Sensor.TYPE_ACCELEROMETER: {
                int[] evSensorSample = new int[] {
                    EV_ABS, ABS_X, dataVec[0],
                    EV_ABS, ABS_Y, dataVec[1],
                    EV_ABS, ABS_Z, dataVec[2],
                };
                mUinputDevice.injectEvents(Arrays.toString(evSensorSample));
                break;
            }
            case Sensor.TYPE_GYROSCOPE: {
                int[] evSensorSample = new int[] {
                    EV_ABS, ABS_RX, dataVec[0],
                    EV_ABS, ABS_RY, dataVec[1],
                    EV_ABS, ABS_RZ, dataVec[2],
                };
                mUinputDevice.injectEvents(Arrays.toString(evSensorSample));
                break;
            }
            default:
                return;
        }
        if (timestamp > 0) {
            int[] evTimestamp = new int[] {
                    EV_MSC, MSC_TIMESTAMP, timestamp,
                    EV_SYN, 0, 0 };
            mUinputDevice.injectEvents(Arrays.toString(evTimestamp));
        }
    }

    private void testSensorManagerListenerForSensors(Sensor[] sensors) {
        final InputTestSensorEventListener[] listeners =
                new InputTestSensorEventListener[sensors.length];
        int[] dataVector = new int[]{2535, -2398, 31345};
        long[] lastTimestamp = new long[sensors.length];

        for (int i = 0; i < sensors.length; i++) {
            listeners[i] = new InputTestSensorEventListener();
            assertTrue(mSensorManager.registerListener(listeners[i], sensors[i],
                    SensorManager.SENSOR_DELAY_GAME, mSensorHandler));
        }

        long startTimestamp = SystemClock.elapsedRealtimeNanos();
        for (int count = 0; count < RUNNING_SAMPLES; count++) {
            bumpSensorsData(dataVector);
            // when the listener's sampling interval is longer than sensor native sample interval,
            // the listener get report for multiple sensor samples, inject multiple samples so
            // sensor listener can get an event callback.
            for (int hwTimestamp = 100000;
                    hwTimestamp - 100000 < SAMPLING_INTERVAL_US;
                    hwTimestamp += TIME_INTERVAL_US) {
                // Inject sensor samples
                for (int i = 0; i < sensors.length; i++) {
                    if (i == sensors.length - 1) {
                        injectSensorSample(sensors[i], dataVector, hwTimestamp);
                    } else {
                        injectSensorSample(sensors[i], dataVector, 0 /* timestamp */);
                    }
                }
                SystemClock.sleep(TIME_INTERVAL_US / 1000);
            }
            // Check the sensor listener events for each sensor
            for (int i = 0; i < sensors.length; i++) {
                SensorEvent e = listeners[i].waitForSensorEvent();
                assertNotNull(""Sensor event for count "" + count + "" is null"", e);
                // Verify timestamp monotonically increasing
                if (lastTimestamp[i] != 0) {
                    final long diff = e.timestamp - lastTimestamp[i];
                    assertTrue(""Sensor timestamp "" + e.timestamp + "" not monotonically increasing!""
                            + ""last "" + lastTimestamp[i], diff > TIME_INTERVAL_US);
                }
                lastTimestamp[i] = e.timestamp;
                // Verify sensor timestamp greater than start Android time
                assertTrue(""Sensor timestamp smaller than starting elapsedRealtimeNanos"",
                        startTimestamp < e.timestamp);
                assertSensorDataEquals(getExpectedSensorValue(sensors[i], dataVector),
                        e.values);
            }
            // Check sensor onAccuracyChanged events are called
            for (int i = 0; i < sensors.length; i++) {
                assertEquals(SensorManager.SENSOR_STATUS_ACCURACY_HIGH,
                        listeners[i].waitForAccuracyChanged());
            }
        }

        for (int i = 0; i < sensors.length; i++) {
            mSensorManager.unregisterListener(listeners[i]);
        }
    }

    private Sensor getDefaultSensor(int sensorType) {
        Sensor sensor = mSensorManager.getDefaultSensor(sensorType);
        assertNotNull(sensor);
        assertEquals(sensor.getType(), sensorType);
        return sensor;
    }

    @Before
    public void setup() {
        final int resourceId = R.raw.gamepad_sensors_register;
        mInstrumentation = InstrumentationRegistry.getInstrumentation();
        mInputManager = mInstrumentation.getTargetContext().getSystemService(InputManager.class);
        assertNotNull(mInputManager);

        mParser = new InputJsonParser(mInstrumentation.getTargetContext());
        mDeviceId = mParser.readDeviceId(resourceId);
        String registerCommand = mParser.readRegisterCommand(resourceId);
        final int vendorId = mParser.readVendorId(resourceId);
        final int productId = mParser.readProductId(resourceId);
        mUinputDevice = new UinputDevice(mInstrumentation, mDeviceId,
            vendorId, productId, InputDevice.SOURCE_KEYBOARD, registerCommand);
        mSensorManager = getSensorManager(vendorId, productId);
        assertNotNull(mSensorManager);

        mSensorThread = new HandlerThread(""SensorThread"");
        mSensorThread.start();
        mSensorHandler = new Handler(mSensorThread.getLooper());
    }

    @After
    public void tearDown() {
        mUinputDevice.close();
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.input.InputDeviceSensorManagerTest"	"testAccelerometerSensorListener"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/input/InputDeviceSensorManagerTest.java"	""	"public void testAccelerometerSensorListener() {
        // Test Accelerometer sensor
        final Sensor[] sensors = new Sensor[]{
            getDefaultSensor(Sensor.TYPE_ACCELEROMETER)
        };
        testSensorManagerListenerForSensors(sensors);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.input.InputDeviceSensorManagerTest"	"testGyroscopeSensorListener"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/input/InputDeviceSensorManagerTest.java"	""	"public void testGyroscopeSensorListener() {
        // Test Gyroscope sensor
        final Sensor[] sensors = new Sensor[]{
            getDefaultSensor(Sensor.TYPE_GYROSCOPE)
        };
        testSensorManagerListenerForSensors(sensors);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.input.InputDeviceSensorManagerTest"	"testAllSensorsListeners"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/input/InputDeviceSensorManagerTest.java"	""	"public void testAllSensorsListeners() {
        final Sensor[] sensors = new Sensor[]{
            getDefaultSensor(Sensor.TYPE_ACCELEROMETER),
            getDefaultSensor(Sensor.TYPE_GYROSCOPE)
        };
        testSensorManagerListenerForSensors(sensors);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.input.InputDeviceSensorManagerTest"	"testSupportedSensorTypes"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/input/InputDeviceSensorManagerTest.java"	""	"public void testSupportedSensorTypes() {
        final List<Integer> types = Arrays.asList(Sensor.TYPE_ACCELEROMETER,
                Sensor.TYPE_GYROSCOPE);
        for (int i = 0; i < types.size(); i++) {
            List<Sensor> sensors = mSensorManager.getSensorList(types.get(i));
            assertEquals(""Sensor type "" + types.get(i), 1L, sensors.size());
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.input.InputDeviceSensorManagerTest"	"testUnsupportedSensorTypes"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/input/InputDeviceSensorManagerTest.java"	""	"public void testUnsupportedSensorTypes() {
        final List<Integer> supportedTypes = Arrays.asList(Sensor.TYPE_ACCELEROMETER,
                Sensor.TYPE_GYROSCOPE);

        for (int type = Sensor.TYPE_ACCELEROMETER; type <= Sensor.TYPE_HINGE_ANGLE; type++) {
            if (!supportedTypes.contains(type)) {
                List<Sensor> sensors = mSensorManager.getSensorList(type);
                assertEquals(0L, sensors.size());
                assertNull(mSensorManager.getDefaultSensor(type));
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.input.InputDeviceSensorManagerTest"	"testDirectChannelAPIs"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/input/InputDeviceSensorManagerTest.java"	""	"public void testDirectChannelAPIs() {
        // Direct channel is not supported by input device sensor manager.
        try {
            final MemoryFile memFile = new MemoryFile(""Sensor Channel"", SHARED_MEMORY_SIZE);
            SensorDirectChannel channel = mSensorManager.createDirectChannel(memFile);
            // Expect returning a null channel when calling the API
            assertNull(channel);
        } catch (IOException e) {
            fail(""IOException when allocating MemoryFile"");
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.input.InputDeviceSensorManagerTest"	"testDynamicSensorAPIs"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/input/InputDeviceSensorManagerTest.java"	""	"public void testDynamicSensorAPIs() {
        final List<Sensor> dynamicAccelerometers =
                mSensorManager.getDynamicSensorList(Sensor.TYPE_ACCELEROMETER);
        // Input device sensor manager doesn't expose any dynamic sensor
        assertEquals(0, dynamicAccelerometers.size());

        // Attempt to register regular sensor as dynamic sensor
        final Sensor accelerometer = mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER);
        final Callback callback = new Callback(accelerometer);
        mSensorManager.registerDynamicSensorCallback(callback);
        // Dynamic call back is not supported, not connection or disconnection should happen.
        assertFalse(callback.waitForConnection());
        callback.assertNoDisconnection();
        // Unregister the dynamic sensor callback shouldn't throw any exception.
        mSensorManager.unregisterDynamicSensorCallback(callback);
        // The isDynamicSensorDiscoverySupported API should returns false.
        assertFalse(mSensorManager.isDynamicSensorDiscoverySupported());

    }

}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricServiceTests"	"testAuthenticatorIdsInvalidated"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricServiceTests.java"	""	"public void testAuthenticatorIdsInvalidated() throws Exception {
        // On devices with multiple strong sensors, adding enrollments to one strong sensor
        // must cause authenticatorIds for all other strong sensors to be invalidated, if they
        // (the other strong sensors) have enrollments.
        final List<Integer> strongSensors = new ArrayList<>();
        for (SensorProperties prop : mSensorProperties) {
            if (prop.getSensorStrength() == SensorProperties.STRENGTH_STRONG) {
                strongSensors.add(prop.getSensorId());
            }
        }
        assumeTrue(""numStrongSensors: "" + strongSensors.size(), strongSensors.size() >= 2);

        Log.d(TAG, ""testAuthenticatorIdsInvalidated, numStrongSensors: "" + strongSensors.size());

        for (Integer sensorId : strongSensors) {
            testAuthenticatorIdsInvalidated_forSensor(sensorId, strongSensors);
        }
    }

    /**
     * Tests that the specified sensorId's authenticatorId when any other strong sensor adds
     * an enrollment.
     */
    private void testAuthenticatorIdsInvalidated_forSensor(int sensorId,
            @NonNull List<Integer> strongSensors) throws Exception {
        Log.d(TAG, ""testAuthenticatorIdsInvalidated_forSensor: "" + sensorId);
        final List<BiometricTestSession> biometricSessions = new ArrayList<>();

        final BiometricTestSession targetSensorTestSession =
                mBiometricManager.createTestSession(sensorId);

        // Get the state once. This intentionally clears the scheduler's recent operations dump.
        BiometricServiceState state = getCurrentStateAndClearSchedulerLog();

        waitForAllUnenrolled();
        Log.d(TAG, ""Enrolling for: "" + sensorId);
        enrollForSensor(targetSensorTestSession, sensorId);
        biometricSessions.add(targetSensorTestSession);
        state = getCurrentStateAndClearSchedulerLog();

        // Target sensorId has never been requested to invalidate authenticatorId yet.
        assertEquals(0, Utils.numberOfSpecifiedOperations(state, sensorId,
                BiometricsProto.CM_INVALIDATE));

        // Add enrollments for all other sensors. Upon each enrollment, the authenticatorId for
        // the above sensor should be invalidated.
        for (Integer id : strongSensors) {
            if (id != sensorId) {
                final BiometricTestSession session = mBiometricManager.createTestSession(id);
                biometricSessions.add(session);
                Log.d(TAG, ""Sensor "" + id + "" should request invalidation"");
                enrollForSensor(session, id);
                state = getCurrentStateAndClearSchedulerLog();
                assertEquals(1, Utils.numberOfSpecifiedOperations(state, sensorId,
                        BiometricsProto.CM_INVALIDATE));

                // In addition, the sensor that should have enrolled should have been the one that
                // requested invalidation.
                assertEquals(1, Utils.numberOfSpecifiedOperations(state, id,
                        BiometricsProto.CM_INVALIDATION_REQUESTER));
            }
        }

        // Cleanup
        for (BiometricTestSession session : biometricSessions) {
            session.close();
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricServiceTests"	"testLockoutResetRequestedAfterCredentialUnlock"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricServiceTests.java"	""	"public void testLockoutResetRequestedAfterCredentialUnlock() throws Exception {
        // ResetLockout only really needs to be applied when enrollments exist. Furthermore, some
        // interfaces may take this a step further and ignore resetLockout requests when no
        // enrollments exist.
        List<BiometricTestSession> biometricSessions = new ArrayList<>();
        for (SensorProperties prop : mSensorProperties) {
            BiometricTestSession session = mBiometricManager.createTestSession(prop.getSensorId());
            enrollForSensor(session, prop.getSensorId());
            biometricSessions.add(session);
        }

        try (CredentialSession credentialSession = new CredentialSession()) {
            credentialSession.setCredential();

            // Explicitly clear the state so we can check exact number below
            final BiometricServiceState clearState = getCurrentStateAndClearSchedulerLog();
            credentialSession.verifyCredential();

            Utils.waitFor(""Waiting for password verification and resetLockout completion"", () -> {
                try {
                    BiometricServiceState state = getCurrentState();
                    // All sensors have processed exactly one resetLockout request. Use a boolean
                    // to track this so we have better logging
                    boolean allResetOnce = true;
                    for (SensorProperties prop : mSensorProperties) {
                        final int numResetLockouts = Utils.numberOfSpecifiedOperations(state,
                                prop.getSensorId(), BiometricsProto.CM_RESET_LOCKOUT);
                        Log.d(TAG, ""Sensor: "" + prop.getSensorId()
                                + "", numResetLockouts: "" + numResetLockouts);
                        if (numResetLockouts != 1) {
                            allResetOnce = false;
                        }
                    }
                    return allResetOnce;
                } catch (Exception e) {
                    return false;
                }
            }, unused -> fail(""All sensors must receive and process exactly one resetLockout""));
        }

        for (BiometricTestSession session : biometricSessions) {
            session.close();
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricServiceTests"	"testLockoutResetRequestedAfterBiometricUnlock_whenStrong"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricServiceTests.java"	""	"public void testLockoutResetRequestedAfterBiometricUnlock_whenStrong() throws Exception {
        assumeTrue(mSensorProperties.size() > 1);

        // ResetLockout only really needs to be applied when enrollments exist. Furthermore, some
        // interfaces may take this a step further and ignore resetLockout requests when no
        // enrollments exist.
        Map<Integer, BiometricTestSession> biometricSessions = new HashMap<>();
        for (SensorProperties prop : mSensorProperties) {
            BiometricTestSession session = mBiometricManager.createTestSession(prop.getSensorId());
            enrollForSensor(session, prop.getSensorId());
            biometricSessions.put(prop.getSensorId(), session);
        }

        // When a strong biometric sensor authenticates, all other biometric sensors that:
        //  1) Do not require HATs for resetLockout (e.g. IBiometricsFingerprint@2.1) or
        //  2) Require HATs but do not require challenges (e.g. IFingerprint@1.0, IFace@1.0)
        // schedule and complete a resetLockout operation.
        //
        // To be more explicit, sensors that require HATs AND challenges (IBiometricsFace@1.0)
        // do not schedule resetLockout, since the interface has no way of generating multiple
        // HATs with a single authentication (e.g. if the user requested to unlock an auth-bound
        // key, the only HAT returned would have the keystore operationId within).
        for (SensorProperties prop : mSensorProperties) {
            if (prop.getSensorStrength() != SensorProperties.STRENGTH_STRONG) {
                Log.d(TAG, ""Skipping sensor: "" + prop.getSensorId()
                        + "", strength: "" + prop.getSensorStrength());
                continue;
            }
            testLockoutResetRequestedAfterBiometricUnlock_whenStrong_forSensor(
                    prop.getSensorId(), biometricSessions.get(prop.getSensorId()));
        }

        for (BiometricTestSession session : biometricSessions.values()) {
            session.close();
        }
    }

    private void testLockoutResetRequestedAfterBiometricUnlock_whenStrong_forSensor(int sensorId,
            @NonNull BiometricTestSession session)
            throws Exception {
        Log.d(TAG, ""testLockoutResetRequestedAfterBiometricUnlock_whenStrong_forSensor: ""
                + sensorId);
        final int userId = 0;

        BiometricServiceState state = getCurrentState();
        final List<Integer> eligibleSensorsToReset = new ArrayList<>();
        final List<Integer> ineligibleSensorsToReset = new ArrayList<>();
        for (SensorProperties prop : mSensorProperties) {
            if (prop.getSensorId() == sensorId) {
                // Do not need to resetLockout for self
                continue;
            }

            SensorStates.SensorState sensorState = state.mSensorStates.sensorStates
                    .get(prop.getSensorId());
            final boolean supportsChallengelessHat =
                    sensorState.isResetLockoutRequiresHardwareAuthToken()
                            && !sensorState.isResetLockoutRequiresChallenge();
            final boolean doesNotRequireHat =
                    !sensorState.isResetLockoutRequiresHardwareAuthToken();
            Log.d(TAG, ""SensorId: "" + prop.getSensorId()
                    + "", supportsChallengelessHat: "" + supportsChallengelessHat
                    + "", doesNotRequireHat: "" + doesNotRequireHat);
            if (supportsChallengelessHat || doesNotRequireHat) {
                Log.d(TAG, ""Adding eligible sensor: "" + prop.getSensorId());
                eligibleSensorsToReset.add(prop.getSensorId());
            } else {
                Log.d(TAG, ""Adding ineligible sensor: "" + prop.getSensorId());
                ineligibleSensorsToReset.add(prop.getSensorId());
            }
        }

        // Explicitly clear the log so that we can check the exact number of resetLockout operations
        // below.
        state = getCurrentStateAndClearSchedulerLog();

        // Request authentication with the specified sensorId that was passed in
        showDefaultBiometricPromptAndAuth(session, sensorId, userId);

        // Check that all eligible sensors have resetLockout in their scheduler history
        state = getCurrentState();
        for (Integer id : eligibleSensorsToReset) {
            assertEquals(""Sensor: "" + id + "" should have exactly one resetLockout"", 1,
                    Utils.numberOfSpecifiedOperations(state, id, BiometricsProto.CM_RESET_LOCKOUT));
        }

        // Check that all ineligible sensors do not have resetLockout in their scheduler history
        for (Integer id : ineligibleSensorsToReset) {
            assertEquals(""Sensor: "" + id + "" should have no resetLockout"", 0,
                    Utils.numberOfSpecifiedOperations(state, id, BiometricsProto.CM_RESET_LOCKOUT));
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricServiceTests"	"testLockoutResetNotRequestedAfterBiometricUnlock_whenNotStrong"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricServiceTests.java"	""	"public void testLockoutResetNotRequestedAfterBiometricUnlock_whenNotStrong() throws Exception {
        assumeTrue(mSensorProperties.size() > 1);

        // ResetLockout only really needs to be applied when enrollments exist. Furthermore, some
        // interfaces may take this a step further and ignore resetLockout requests when no
        // enrollments exist.
        Map<Integer, BiometricTestSession> biometricSessions = new HashMap<>();
        for (SensorProperties prop : mSensorProperties) {
            BiometricTestSession session = mBiometricManager.createTestSession(prop.getSensorId());
            enrollForSensor(session, prop.getSensorId());
            biometricSessions.put(prop.getSensorId(), session);
        }

        // Sensors that do not meet BIOMETRIC_STRONG are not allowed to resetLockout for other
        // sensors.
        // TODO: Note that we are only testing STRENGTH_WEAK for now, since STRENGTH_CONVENIENCE is
        //  not exposed to BiometricPrompt. In other words, we currently do not have a way to
        //  request and finish authentication for STRENGTH_CONVENIENCE sensors.
        for (SensorProperties prop : mSensorProperties) {
            if (prop.getSensorStrength() != SensorProperties.STRENGTH_WEAK) {
                Log.d(TAG, ""Skipping sensor: "" + prop.getSensorId()
                        + "", strength: "" + prop.getSensorStrength());
                continue;
            }

            testLockoutResetNotRequestedAfterBiometricUnlock_whenNotStrong_forSensor(
                    prop.getSensorId(), biometricSessions.get(prop.getSensorId()));
        }

        // Cleanup
        for (BiometricTestSession s : biometricSessions.values()) {
            s.close();
        }
    }

    private void testLockoutResetNotRequestedAfterBiometricUnlock_whenNotStrong_forSensor(
            int sensorId, @NonNull BiometricTestSession session) throws Exception {
        Log.d(TAG, ""testLockoutResetNotRequestedAfterBiometricUnlock_whenNotStrong_forSensor: ""
                + sensorId);
        final int userId = 0;

        // Explicitly clear the log so that we can check the exact number of resetLockout operations
        // below.
        BiometricServiceState state = getCurrentStateAndClearSchedulerLog();

        // Request authentication with the specified sensorId that was passed in
        showDefaultBiometricPromptAndAuth(session, sensorId, userId);

        // Check that no other sensors have resetLockout in their queue
        for (SensorProperties prop : mSensorProperties) {
            if (prop.getSensorId() == sensorId) {
                continue;
            }
            state = getCurrentState();
            assertEquals(""Sensor: "" + prop.getSensorId() + "" should have no resetLockout"", 0,
                    Utils.numberOfSpecifiedOperations(state, prop.getSensorId(),
                            BiometricsProto.CM_RESET_LOCKOUT));
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricServiceTests"	"testBiometricsRemovedWhenCredentialRemoved"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricServiceTests.java"	""	"public void testBiometricsRemovedWhenCredentialRemoved() throws Exception {
        // Manually keep track of sessions and do not use autocloseable, since we do not want the
        // test session to automatically cleanup and remove enrollments once we leave scope.
        final List<BiometricTestSession> biometricSessions = new ArrayList<>();

        try (CredentialSession session = new CredentialSession()) {
            session.setCredential();
            for (SensorProperties prop : mSensorProperties) {
                BiometricTestSession biometricSession =
                        mBiometricManager.createTestSession(prop.getSensorId());
                biometricSessions.add(biometricSession);
                enrollForSensor(biometricSession, prop.getSensorId());
            }
        }

        // All biometrics should now be removed, since CredentialSession removes device credential
        // after losing scope.
        waitForAllUnenrolled();
        // In case any additional cleanup needs to be done in the future, aside from un-enrollment
        for (BiometricTestSession session : biometricSessions) {
            session.close();
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.SensorRatePermissionEventConnectionTestHelper"	"toList"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/SensorRatePermissionEventConnectionTestHelper.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers;

import android.hardware.Sensor;
import android.hardware.SensorPrivacyManager;
import android.os.Handler;

import com.android.compatibility.common.util.ShellUtils;
import com.android.compatibility.common.util.SystemUtil;

import com.google.common.collect.ImmutableSet;

import org.junit.Assert;

import java.util.List;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

/**
 * A helper class to test sensor APIs related to sampling rates of SensorEventConnections.
 */
public class SensorRatePermissionEventConnectionTestHelper {
    public static final int CAPPED_SAMPLE_RATE_HZ = 220; // Capped rate 200 Hz + 10% headroom
    // Set of sensors that are throttled
    public static final ImmutableSet<Integer> CAPPED_SENSOR_TYPE_SET = ImmutableSet.of(
            Sensor.TYPE_ACCELEROMETER,
            Sensor.TYPE_ACCELEROMETER_UNCALIBRATED,
            Sensor.TYPE_GYROSCOPE,
            Sensor.TYPE_GYROSCOPE_UNCALIBRATED,
            Sensor.TYPE_MAGNETIC_FIELD,
            Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED
    );

    private final TestSensorEnvironment mTestSensorEnvironment;
    private final TestSensorManager mTestSensorManager;

    public SensorRatePermissionEventConnectionTestHelper(TestSensorEnvironment environment) {
        mTestSensorEnvironment = environment;
        mTestSensorManager = new TestSensorManager(mTestSensorEnvironment);
    }

    public static double computeAvgRate(List<TestSensorEvent> events,
            long startTimestamp, long endTimestamp) {

        List<TestSensorEvent> filteredEvents = events.stream()
                .filter(event -> event.timestamp > startTimestamp && event.timestamp < endTimestamp)
                .collect(Collectors.toList());

        double rate = Double.MIN_VALUE;
        int numOfEvents = filteredEvents.size();
        if (numOfEvents >= 2) {
            long lastTimestamp = filteredEvents.get(numOfEvents - 1).timestamp;
            long firstTimestamp = filteredEvents.get(0).timestamp;
            rate = SensorCtsHelper.getFrequency(
                    (lastTimestamp - firstTimestamp) / (numOfEvents - 1),
                    TimeUnit.NANOSECONDS);
        }
        return rate;
    }

    /**
     * Error message being shown in Assert statements of unit tests when the sampling rate exceeds
     * the allowed capped rate.
     */
    public String errorWhenExceedCappedRate() {
        Sensor sensor = mTestSensorEnvironment.getSensor();
        return String.format(
                ""%s: Sampling rate is expected to be less than or equal to %d (Hz)"",
                sensor.getName(),
                CAPPED_SAMPLE_RATE_HZ);
    }

    /**
     * Error message being shown in Assert statements of unit tests when the sampling rate is below
     * its expected rate.
     */
    public String errorWhenBelowExpectedRate() {
        Sensor sensor = mTestSensorEnvironment.getSensor();
        return String.format(
                ""%s: Sampling rate is expected to larger than to %d (Hz)"",
                sensor.getName(),
                CAPPED_SAMPLE_RATE_HZ);
    }

    /**
     * Flip the microphone toggle to off and assert that it is indeed off.
     */
    public void flipAndAssertMicToggleOff(int userID, SensorPrivacyManager spm) {
        ShellUtils.runShellCommand(""cmd sensor_privacy disable "" + userID + "" microphone"");
        SystemUtil.runWithShellPermissionIdentity(() -> {
            Assert.assertTrue(""Failed to switch the mic toggle off!"",
                    !spm.isSensorPrivacyEnabled(SensorPrivacyManager.Sensors.MICROPHONE));
        });
    }

    /**
     * Flip the microphone toggle to off and assert that it is indeed on.
     */
    public void flipAndAssertMicToggleOn(int userID, SensorPrivacyManager spm) {
        ShellUtils.runShellCommand(""cmd sensor_privacy enable "" + userID + "" microphone"");
        SystemUtil.runWithShellPermissionIdentity(() -> {
            Assert.assertTrue(""Failed to switch the mic toggle on!"",
                    spm.isSensorPrivacyEnabled(SensorPrivacyManager.Sensors.MICROPHONE));
        });
    }

    /**
     * Register a listener and waits until there are numOfEvents events
     *
     * @param specifyHandler true if a {@link Handler} is associated with the instance.
     */
    public List<TestSensorEvent> getSensorEvents(boolean specifyHandler, int numOfEvents)
            throws InterruptedException {
        TestSensorEventListener listener = new TestSensorEventListener(mTestSensorEnvironment);
        CountDownLatch eventLatch = mTestSensorManager.registerListener(
                listener,
                numOfEvents,
                specifyHandler);
        listener.waitForEvents(eventLatch, numOfEvents, false);
        List<TestSensorEvent> testSensorEventList = listener.getCollectedEvents();
        listener.clearEvents();
        mTestSensorManager.unregisterListener();
        return testSensorEventList;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.SensorStatsTest"	"testFlatten"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/SensorStatsTest.java"	""	"public void testFlatten() {
        SensorStats stats = new SensorStats();
        stats.addValue(""value0"", 0);
        stats.addValue(""value1"", 1);

        SensorStats subStats = new SensorStats();
        subStats.addValue(""value2"", 2);
        subStats.addValue(""value3"", 3);

        SensorStats subSubStats = new SensorStats();
        subSubStats.addValue(""value4"", 4);
        subSubStats.addValue(""value5"", 5);

        subStats.addSensorStats(""stats1"", subSubStats);
        stats.addSensorStats(""stats0"", subStats);

        // Add empty stats, expect no value in flattened map
        stats.addSensorStats(""stats2"", new SensorStats());

        // Add null values, expect no value in flattened map
        stats.addSensorStats(""stats3"", null);
        stats.addValue(""value6"", null);

        Map<String, Object> flattened = stats.flatten();

        assertEquals(6, flattened.size());
        assertEquals(0, (int) (Integer) flattened.get(""value0""));
        assertEquals(1, (int) (Integer) flattened.get(""value1""));
        assertEquals(2, (int) (Integer) flattened.get(""stats0__value2""));
        assertEquals(3, (int) (Integer) flattened.get(""stats0__value3""));
        assertEquals(4, (int) (Integer) flattened.get(""stats0__stats1__value4""));
        assertEquals(5, (int) (Integer) flattened.get(""stats0__stats1__value5""));
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.Camera_SizeTest"	"testConstructor"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/cts/Camera_SizeTest.java"	""	"public void testConstructor() {
        if (Camera.getNumberOfCameras() < 1) {
            return;
        }

        Camera camera = Camera.open(0);
        Parameters parameters = camera.getParameters();

        checkSize(parameters, WIDTH1, HEIGHT1);
        checkSize(parameters, WIDTH2, HEIGHT2);
        checkSize(parameters, WIDTH3, HEIGHT3);

        camera.release();
    }

    /**
     * Check that the largest available preview and jpeg outputs have the same aspect ratio.  This
     * aspect ratio must be the same as the physical camera sensor, and the FOV for these outputs
     * must not be cropped.
     *
     * This is only required for backward compatibility of the Camera2 API when running in LEGACY
     * mode.
     *
     * @see {@link android.hardware.camera2.CameraCharacteristics#INFO_SUPPORTED_HARDWARE_LEVEL}
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.base.SensorCtsTestSuite"	"countTestCases"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/base/SensorCtsTestSuite.java"	""	"public void test/*
 *
 */

package com.android.cts.verifier.sensors.base;

import junit.framework.Test;
import junit.framework.TestResult;
import junit.framework.TestSuite;

import android.content.Context;

import java.util.Enumeration;

/**
 * A wrapper class for a {@link TestSuite}.
 *
 * It provides a way to inject a {@link SensorCtsTestResult} during execution.
 */
class SensorCtsTestSuite extends TestSuite {
    private final Context mContext;
    private final TestSuite mWrappedTestSuite;

    public SensorCtsTestSuite(Context context, TestSuite testSuite) {
        mContext = context;
        mWrappedTestSuite = testSuite;
    }

    @Override
    public void run(TestResult testResult) {
        mWrappedTestSuite.run(new SensorCtsTestResult(mContext, testResult));
    }

    @Override
    public void addTest(Test test) {
        mWrappedTestSuite.addTest(test);
    }

    @Override
    public int countTestCases() {
        return mWrappedTestSuite.countTestCases();
    }

    @Override
    public String getName() {
        return mWrappedTestSuite.getName();
    }

    @Override
    public void runTest(Test test, TestResult testResult) {
        mWrappedTestSuite.runTest(test, testResult);
    }

    @Override
    public void setName(String name) {
        mWrappedTestSuite.setName(name);
    }

    @Override
    public Test testAt(int index) {
        return mWrappedTestSuite.testAt(index);
    }

    @Override
    public int testCount() {
        return mWrappedTestSuite.testCount();
    }

    @Override
    public Enumeration<Test> tests() {
        return mWrappedTestSuite.tests();
    }

    @Override
    public String toString() {
        return mWrappedTestSuite.toString();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.ManifestTestListAdapter"	"isEmpty"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/ManifestTestListAdapter.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier;

import static com.android.cts.verifier.TestListActivity.sCurrentDisplayMode;
import static com.android.cts.verifier.TestListActivity.sInitialLaunch;

import android.content.Context;
import android.content.Intent;
import android.content.pm.ActivityInfo;
import android.content.pm.PackageManager;
import android.content.pm.ResolveInfo;
import android.content.res.Resources;
import android.os.Bundle;
import android.telephony.TelephonyManager;
import android.util.Log;
import android.widget.ListView;

import com.android.cts.verifier.TestListActivity.DisplayMode;

import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.Comparator;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;

/**
 * {@link TestListAdapter} that populates the {@link TestListActivity}'s {@link ListView} by
 * reading data from the CTS Verifier's AndroidManifest.xml.
 * <p>
 * Making a new test activity to appear in the list requires the following steps:
 *
 * <ol>
 *     <li>REQUIRED: Add an activity to the AndroidManifest.xml with an intent filter with a
 *         main action and the MANUAL_TEST category.
 *         <pre>
 *             <intent-filter>
 *                <action android:name=""android.intent.action.MAIN"" />
 *                <category android:name=""android.cts.intent.category.MANUAL_TEST"" />
 *             </intent-filter>
 *         </pre>
 *     </li>
 *     <li>REQUIRED: Add a meta data attribute to indicate which display modes of tests the activity
 *         should belong to. ""single_display_mode"" indicates a test is only needed to run on the
 *         main display mode (i.e. unfolded), and ""multi_display_mode"" indicates a test is required
 *         to run under both modes (i.e. both folded and unfolded).If you don't add this attribute,
 *         your test will show up in both unfolded and folded modes.
 *         <pre>
 *             <meta-data android:name=""display_mode"" android:value=""multi_display_mode"" />
 *         </pre>
 *     </li>
 *     <li>OPTIONAL: Add a meta data attribute to indicate what category of tests the activity
 *         should belong to. If you don't add this attribute, your test will show up in the
 *         ""Other"" tests category.
 *         <pre>
 *             <meta-data android:name=""test_category"" android:value=""@string/test_category_security"" />
 *         </pre>
 *     </li>
 *     <li>OPTIONAL: Add a meta data attribute to indicate whether this test has a parent test.
 *         <pre>
 *             <meta-data android:name=""test_parent"" android:value=""com.android.cts.verifier.bluetooth.BluetoothTestActivity"" />
 *         </pre>
 *     </li>
 *     <li>OPTIONAL: Add a meta data attribute to indicate what features are required to run the
 *         test. If the device does not have all of the required features then it will not appear
 *         in the test list. Use a colon (:) to specify multiple required features.
 *         <pre>
 *             <meta-data android:name=""test_required_features"" android:value=""android.hardware.sensor.accelerometer"" />
 *         </pre>
 *     </li>
 *     <li>OPTIONAL: Add a meta data attribute to indicate features such that, if any present, the
 *         test gets excluded from being shown. If the device has any of the excluded features then
 *         the test will not appear in the test list. Use a colon (:) to specify multiple features
 *         to exclude for the test. Note that the colon means ""or"" in this case.
 *         <pre>
 *             <meta-data android:name=""test_excluded_features"" android:value=""android.hardware.type.television"" />
 *         </pre>
 *     </li>
 *     <li>OPTIONAL: Add a meta data attribute to indicate features such that, if any present,
 *         the test is applicable to run. If the device has any of the applicable features then
 *         the test will appear in the test list. Use a colon (:) to specify multiple features
 *         <pre>
 *             <meta-data android:name=""test_applicable_features"" android:value=""android.hardware.sensor.compass"" />
 *         </pre>
 *     </li>
 *     <li>OPTIONAL: Add a meta data attribute to indicate which intent actions are required to run
 *         the test. If the device does not have activities that handle all those actions, then it
 *         will not appear in the test list. Use a colon (:) to specify multiple required intent actions.
 *         <pre>
 *             <meta-data android:name=""test_required_actions"" android:value=""android.app.action.ADD_DEVICE_ADMIN"" />
 *         </pre>
 *     </li>
 *
 * </ol>
 */
public class ManifestTestListAdapter extends TestListAdapter {
    private static final String LOG_TAG = ""ManifestTestListAdapter"";

    private static final String TEST_CATEGORY_META_DATA = ""test_category"";

    private static final String TEST_PARENT_META_DATA = ""test_parent"";

    private static final String TEST_REQUIRED_FEATURES_META_DATA = ""test_required_features"";

    private static final String TEST_EXCLUDED_FEATURES_META_DATA = ""test_excluded_features"";

    private static final String TEST_APPLICABLE_FEATURES_META_DATA = ""test_applicable_features"";

    private static final String TEST_REQUIRED_CONFIG_META_DATA = ""test_required_configs"";

    private static final String TEST_REQUIRED_ACTIONS_META_DATA = ""test_required_actions"";

    private static final String TEST_DISPLAY_MODE_META_DATA = ""display_mode"";

    private static final String CONFIG_NO_EMULATOR = ""config_no_emulator"";

    private static final String CONFIG_VOICE_CAPABLE = ""config_voice_capable"";

    private static final String CONFIG_HAS_RECENTS = ""config_has_recents"";

    private static final String CONFIG_HDMI_SOURCE = ""config_hdmi_source"";

    private static final String CONFIG_QUICK_SETTINGS_SUPPORTED = ""config_quick_settings_supported"";

    /** The config to represent that a test is only needed to run in the main display mode
     * (i.e. unfolded) */
    private static final String SINGLE_DISPLAY_MODE = ""single_display_mode"";

    /** The config to represent that a test is needed to run in the multiple display modes
     * (i.e. both unfolded and folded) */
    private static final String MULTIPLE_DISPLAY_MODE = ""multi_display_mode"";

    private final HashSet<String> mDisabledTests;

    private Context mContext;

    private String mTestParent;

    public ManifestTestListAdapter(Context context, String testParent, String[] disabledTestArray) {
        super(context);
        mContext = context;
        mTestParent = testParent;
        mDisabledTests = new HashSet<>(disabledTestArray.length);
        for (int i = 0; i < disabledTestArray.length; i++) {
            mDisabledTests.add(disabledTestArray[i]);
        }

        // Configs to distinct that the adapter is for top-level tests or subtests.
        if (testParent == null) {
            // For top-level tests.
            hasTestParentInManifestAdapter = false;
        } else {
            hasTestParentInManifestAdapter = true;
        }
        adapterFromManifest = true;
    }

    public ManifestTestListAdapter(Context context, String testParent) {
        this(context, testParent, context.getResources().getStringArray(R.array.disabled_tests));
    }

    @Override
    protected List<TestListItem> getRows() {
        List<TestListItem> allRows = new ArrayList<TestListItem>();

        // When launching at the first time or after killing the process, needs to fetch the
        // test items of all display modes as the bases for switching.
        if (mDisplayModesTests.isEmpty()) {
            for (DisplayMode mode : DisplayMode.values()) {
                allRows = getRowsWithDisplayMode(mode.toString());
                mDisplayModesTests.put(mode.toString(), allRows);
            }
        }

        if (!sInitialLaunch) {
            return getRowsWithDisplayMode(sCurrentDisplayMode);
        }
        return allRows;
    }

    /**
     * Gets all rows based on the specific display mode.
     *
     * @param mode Given display mode.
     * @return A list containing all test itmes in the given display mode.
     */
    private List<TestListItem> getRowsWithDisplayMode (String mode) {
        /*
         * 1. Get all the tests belonging to the test parent.
         * 2. Get all the tests keyed by their category.
         * 3. Flatten the tests and categories into one giant list for the list view.
         */
        List<TestListItem> allRows = new ArrayList<TestListItem>();
        List<ResolveInfo> infos = getResolveInfosForParent();
        Map<String, List<TestListItem>> testsByCategory = getTestsByCategory(infos);

        List<String> testCategories = new ArrayList<String>(testsByCategory.keySet());
        Collections.sort(testCategories);
        for (String testCategory : testCategories) {
            List<TestListItem> tests = filterTests(testsByCategory.get(testCategory), mode);
            if (!tests.isEmpty()) {
                allRows.add(TestListItem.newCategory(testCategory));
                Collections.sort(tests, Comparator.comparing(item -> item.title));
                allRows.addAll(tests);
            }
        }
        return allRows;
    }

    List<ResolveInfo> getResolveInfosForParent() {
        Intent mainIntent = new Intent(Intent.ACTION_MAIN);
        mainIntent.addCategory(CATEGORY_MANUAL_TEST);
        mainIntent.setPackage(mContext.getPackageName());

        PackageManager packageManager = mContext.getPackageManager();
        List<ResolveInfo> list = packageManager.queryIntentActivities(mainIntent,
                PackageManager.GET_ACTIVITIES | PackageManager.GET_META_DATA);
        int size = list.size();

        List<ResolveInfo> matchingList = new ArrayList<>();
        for (int i = 0; i < size; i++) {
            ResolveInfo info = list.get(i);
            String parent = getTestParent(info.activityInfo.metaData);
            if ((mTestParent == null && parent == null)
                    || (mTestParent != null && mTestParent.equals(parent))) {
                matchingList.add(info);
            }
        }
        return matchingList;
    }

    Map<String, List<TestListItem>> getTestsByCategory(List<ResolveInfo> list) {
        Map<String, List<TestListItem>> testsByCategory = new HashMap<>();

        int size = list.size();
        for (int i = 0; i < size; i++) {
            ResolveInfo info = list.get(i);
            if (info.activityInfo == null || mDisabledTests.contains(info.activityInfo.name)) {
                Log.w(LOG_TAG, ""ignoring disabled test: "" + info.activityInfo.name);
                continue;
            }
            String title = getTitle(mContext, info.activityInfo);
            String testName = info.activityInfo.name;
            Intent intent = getActivityIntent(info.activityInfo);
            String[] requiredFeatures = getRequiredFeatures(info.activityInfo.metaData);
            String[] requiredConfigs = getRequiredConfigs(info.activityInfo.metaData);
            String[] requiredActions = getRequiredActions(info.activityInfo.metaData);
            String[] excludedFeatures = getExcludedFeatures(info.activityInfo.metaData);
            String[] applicableFeatures = getApplicableFeatures(info.activityInfo.metaData);
            String displayMode = getDisplayMode(info.activityInfo.metaData);

            TestListItem item = TestListItem.newTest(title, testName, intent, requiredFeatures,
                     requiredConfigs, requiredActions, excludedFeatures, applicableFeatures,
                     displayMode);

            String testCategory = getTestCategory(mContext, info.activityInfo.metaData);
            addTestToCategory(testsByCategory, testCategory, item);
        }

        return testsByCategory;
    }

    static String getTestCategory(Context context, Bundle metaData) {
        String testCategory = null;
        if (metaData != null) {
            testCategory = metaData.getString(TEST_CATEGORY_META_DATA);
        }
        if (testCategory != null) {
            return testCategory;
        } else {
            return context.getString(R.string.test_category_other);
        }
    }

    static String getTestParent(Bundle metaData) {
        return metaData != null ? metaData.getString(TEST_PARENT_META_DATA) : null;
    }

    static String[] getRequiredFeatures(Bundle metaData) {
        if (metaData == null) {
            return null;
        } else {
            String value = metaData.getString(TEST_REQUIRED_FEATURES_META_DATA);
            if (value == null) {
                return null;
            } else {
                return value.split("":"");
            }
        }
    }

    static String[] getRequiredActions(Bundle metaData) {
        if (metaData == null) {
            return null;
        } else {
            String value = metaData.getString(TEST_REQUIRED_ACTIONS_META_DATA);
            if (value == null) {
                return null;
            } else {
                return value.split("":"");
            }
        }
    }

    static String[] getRequiredConfigs(Bundle metaData) {
        if (metaData == null) {
            return null;
        } else {
            String value = metaData.getString(TEST_REQUIRED_CONFIG_META_DATA);
            if (value == null) {
                return null;
            } else {
                return value.split("":"");
            }
        }
    }

    static String[] getExcludedFeatures(Bundle metaData) {
        if (metaData == null) {
            return null;
        } else {
            String value = metaData.getString(TEST_EXCLUDED_FEATURES_META_DATA);
            if (value == null) {
                return null;
            } else {
                return value.split("":"");
            }
        }
    }

    static String[] getApplicableFeatures(Bundle metaData) {
        if (metaData == null) {
            return null;
        } else {
            String value = metaData.getString(TEST_APPLICABLE_FEATURES_META_DATA);
            if (value == null) {
                return null;
            } else {
                return value.split("":"");
            }
        }
    }

    /**
     * Gets the configuration of the display mode per test. The default value is multi_display_mode.
     *
     * @param metaData Given metadata of the display mode.
     * @return A string representing the display mode of the test.
     */
    static String getDisplayMode(Bundle metaData) {
        if (metaData == null) {
            return MULTIPLE_DISPLAY_MODE;
        }
        String displayMode = metaData.getString(TEST_DISPLAY_MODE_META_DATA);
        return displayMode == null ? MULTIPLE_DISPLAY_MODE : displayMode;
    }

    static String getTitle(Context context, ActivityInfo activityInfo) {
        if (activityInfo.labelRes != 0) {
            return context.getString(activityInfo.labelRes);
        } else {
            return activityInfo.name;
        }
    }

    static Intent getActivityIntent(ActivityInfo activityInfo) {
        Intent intent = new Intent();
        intent.setClassName(activityInfo.packageName, activityInfo.name);
        return intent;
    }

    static void addTestToCategory(Map<String, List<TestListItem>> testsByCategory,
            String testCategory, TestListItem item) {
        List<TestListItem> tests;
        if (testsByCategory.containsKey(testCategory)) {
            tests = testsByCategory.get(testCategory);
        } else {
            tests = new ArrayList<TestListItem>();
        }
        testsByCategory.put(testCategory, tests);
        tests.add(item);
    }

    private boolean hasAnyFeature(String[] features) {
        if (features != null) {
            PackageManager packageManager = mContext.getPackageManager();
            for (String feature : features) {
                if (packageManager.hasSystemFeature(feature)) {
                    return true;
                }
            }
            Log.v(LOG_TAG, ""Missing features "" + Arrays.toString(features));
        }
        return false;
    }

    private boolean hasAllFeatures(String[] features) {
        if (features != null) {
            PackageManager packageManager = mContext.getPackageManager();
            for (String feature : features) {
                if (!packageManager.hasSystemFeature(feature)) {
                    Log.v(LOG_TAG, ""Missing feature "" + feature);
                    return false;
                }
            }
        }
        return true;
    }

    private boolean hasAllActions(String[] actions) {
        if (actions != null) {
            PackageManager packageManager = mContext.getPackageManager();
            for (String action : actions) {
                Intent intent = new Intent(action);
                if (packageManager.queryIntentActivities(intent, /* flags= */ 0).isEmpty()) {
                    Log.v(LOG_TAG, ""Missing action "" + action);
                    return false;
                }
            }
        }
        return true;
    }

    private boolean matchAllConfigs(String[] configs) {
        if (configs != null) {
            for (String config : configs) {
                switch (config) {
                    case CONFIG_NO_EMULATOR:
                        try {
                            Method getStringMethod = ClassLoader.getSystemClassLoader()
                                .loadClass(""android.os.SystemProperties"")
                                .getMethod(""get"", String.class);
                            String emulatorKernel = (String) getStringMethod.invoke(""0"",
                                    ""ro.boot.qemu"");
                            if (emulatorKernel.equals(""1"")) {
                                return false;
                            }
                        } catch (Exception e) {
                            Log.e(LOG_TAG, ""Exception while checking for emulator support."", e);
                        }
                        break;
                    case CONFIG_VOICE_CAPABLE:
                        TelephonyManager telephonyManager = mContext.getSystemService(
                                TelephonyManager.class);
                        if (!telephonyManager.isVoiceCapable()) {
                            return false;
                        }
                        break;
                    case CONFIG_HAS_RECENTS:
                        if (!getSystemResourceFlag(""config_hasRecents"")) {
                            return false;
                        }
                        break;
                    case CONFIG_HDMI_SOURCE:
                        final int DEVICE_TYPE_HDMI_SOURCE = 4;
                        try {
                            if (!getHdmiDeviceType().contains(DEVICE_TYPE_HDMI_SOURCE)) {
                                return false;
                            }
                        } catch (Exception exception) {
                            Log.e(
                                    LOG_TAG,
                                    ""Exception while looking up HDMI device type."",
                                    exception);
                        }
                        break;
                    case CONFIG_QUICK_SETTINGS_SUPPORTED:
                        if (!getSystemResourceFlag(""config_quickSettingsSupported"")) {
                            return false;
                        }
                        break;
                    default:
                        break;
                }
            }
        }
        return true;
    }

    /**
     * Check if the test should be ran by the given display mode.
     *
     * @param mode Configs of the display mode.
     * @param currentMode Given display mode.
     * @return True if the given display mode matches the configs, otherwise, return false;
     */
    private boolean matchDisplayMode(String mode, String currentMode) {
        if (mode == null) {
            return false;
        }
        switch (mode) {
            case SINGLE_DISPLAY_MODE:
                return currentMode.equals(DisplayMode.UNFOLDED.toString());
            case MULTIPLE_DISPLAY_MODE:
                return true;
            default:
                return false;
        }
    }

    private boolean getSystemResourceFlag(String key) {
        final Resources systemRes = mContext.getResources().getSystem();
        final int id = systemRes.getIdentifier(key, ""bool"", ""android"");
        if (id == Resources.ID_NULL) {
            // The flag being queried should exist in
            // frameworks/base/core/res/res/values/config.xml.
            throw new RuntimeException(""System resource flag "" + key + "" not found"");
        }
        return systemRes.getBoolean(id);
    }

    private static List<Integer> getHdmiDeviceType()
            throws InvocationTargetException, IllegalAccessException, ClassNotFoundException,
                    NoSuchMethodException {
        Method getStringMethod =
                ClassLoader.getSystemClassLoader()
                        .loadClass(""android.os.SystemProperties"")
                        .getMethod(""get"", String.class);
        String deviceTypesStr = (String) getStringMethod.invoke(null, ""ro.hdmi.device_type"");
        if (deviceTypesStr.equals("""")) {
            return new ArrayList<>();
        }
        return Arrays.stream(deviceTypesStr.split("",""))
                .map(Integer::parseInt)
                .collect(Collectors.toList());
    }

    List<TestListItem> filterTests(List<TestListItem> tests, String mode) {
        List<TestListItem> filteredTests = new ArrayList<>();
        for (TestListItem test : tests) {
            if (!hasAnyFeature(test.excludedFeatures) && hasAllFeatures(test.requiredFeatures)
                    && hasAllActions(test.requiredActions)
                    && matchAllConfigs(test.requiredConfigs)
                    && matchDisplayMode(test.displayMode, mode)) {
                if (test.applicableFeatures == null || hasAnyFeature(test.applicableFeatures)) {
                    // Add suffix in test name if the test is in the folded mode.
                    test.testName = setTestNameSuffix(mode, test.testName);
                    filteredTests.add(test);
                } else {
                    Log.d(LOG_TAG, ""Skipping "" + test.testName + "" due to metadata filtering"");
                }
            } else {
                Log.d(LOG_TAG, ""Skipping "" + test.testName + "" due to metadata filtering"");
            }
        }
        return filteredTests;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.CaptureResultTest"	"testResultTimestamps"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/CaptureResultTest.java"	""	"public void testResultTimestamps() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            ImageReader previewReader = null;
            ImageReader jpegReader = null;

            CaptureResult resultForNdk = null;

            SimpleImageReaderListener jpegListener = new SimpleImageReaderListener();
            SimpleImageReaderListener prevListener = new SimpleImageReaderListener();
            try {
                if (!mAllStaticInfo.get(id).isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + id + "" does not support color outputs, skipping"");
                    continue;
                }

                openDevice(id);
                CaptureRequest.Builder previewBuilder =
                        mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
                CaptureRequest.Builder multiBuilder =
                        mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);

                // Create image reader and surface.
                Size previewSize = mOrderedPreviewSizes.get(0);
                Size jpegSize = mOrderedStillSizes.get(0);

                // Create ImageReaders.
                previewReader = makeImageReader(previewSize, ImageFormat.YUV_420_888,
                        MAX_NUM_IMAGES, prevListener, mHandler);
                jpegReader = makeImageReader(jpegSize, ImageFormat.JPEG,
                        MAX_NUM_IMAGES, jpegListener, mHandler);

                // Configure output streams with preview and jpeg streams.
                List<Surface> outputSurfaces = new ArrayList<>(Arrays.asList(
                        previewReader.getSurface(), jpegReader.getSurface()));

                SessionListener mockSessionListener = getMockSessionListener();

                CameraCaptureSession session = configureAndVerifySession(mockSessionListener,
                        mCamera, outputSurfaces, mHandler);

                // Configure the requests.
                previewBuilder.addTarget(previewReader.getSurface());
                multiBuilder.addTarget(previewReader.getSurface());
                multiBuilder.addTarget(jpegReader.getSurface());

                if (mStaticInfo.isEnableZslSupported()) {
                    // Turn off ZSL to ensure timestamps are increasing
                    previewBuilder.set(CaptureRequest.CONTROL_ENABLE_ZSL, false);
                    multiBuilder.set(CaptureRequest.CONTROL_ENABLE_ZSL, false);
                }

                CaptureCallback mockCaptureCallback = getMockCaptureListener();

                // Capture targeting only preview
                Pair<TotalCaptureResult, Long> result = captureAndVerifyResult(mockCaptureCallback,
                        session, previewBuilder.build(), mHandler);

                // Check if all timestamps are the same
                Image prevImage = prevListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
                validateTimestamps(""Result 1"", result.first,
                        prevImage, result.second);
                prevImage.close();

                // Capture targeting both jpeg and preview
                Pair<TotalCaptureResult, Long> result2 = captureAndVerifyResult(mockCaptureCallback,
                        session, multiBuilder.build(), mHandler);

                // Check if all timestamps are the same
                prevImage = prevListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
                Image jpegImage = jpegListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
                validateTimestamps(""Result 2 Preview"", result2.first,
                        prevImage, result2.second);
                validateTimestamps(""Result 2 Jpeg"", result2.first,
                        jpegImage, result2.second);
                prevImage.close();
                jpegImage.close();

                // Check if timestamps are increasing
                mCollector.expectGreater(""Timestamps must be increasing."", result.second,
                        result2.second);

                // Capture two preview frames
                long startTime = SystemClock.elapsedRealtimeNanos();
                Pair<TotalCaptureResult, Long> result3 = captureAndVerifyResult(mockCaptureCallback,
                        session, previewBuilder.build(), mHandler);
                Pair<TotalCaptureResult, Long> result4 = captureAndVerifyResult(mockCaptureCallback,
                        session, previewBuilder.build(), mHandler);
                long clockDiff = SystemClock.elapsedRealtimeNanos() - startTime;
                long resultDiff = result4.second - result3.second;

                // Check if all timestamps are the same
                prevImage = prevListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
                validateTimestamps(""Result 3"", result3.first,
                        prevImage, result3.second);
                prevImage.close();
                prevImage = prevListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
                validateTimestamps(""Result 4"", result4.first,
                        prevImage, result4.second);
                prevImage.close();

                // Check that the timestamps monotonically increase at a reasonable rate
                mCollector.expectGreaterOrEqual(""Timestamps increase faster than system clock."",
                        resultDiff, clockDiff);
                mCollector.expectGreater(""Timestamps must be increasing."", result3.second,
                        result4.second);

                resultForNdk = result.first;
            } finally {
                closeDevice(id);
                closeImageReader(previewReader);
                closeImageReader(jpegReader);
            }

            mCollector.expectTrue(
                ""validateACameraMetadataFromCameraMetadataCriticalTagsNative failed"",
                validateACameraMetadataFromCameraMetadataCriticalTagsNative(resultForNdk,
                        resultForNdk.get(CaptureResult.SENSOR_TIMESTAMP)));

            long timestamp = resultForNdk.get(CaptureResult.SENSOR_TIMESTAMP);
            mCollector.expectTrue(
                ""stashACameraMetadataFromCameraMetadataNative failed"",
                stashACameraMetadataFromCameraMetadataNative(resultForNdk));

            // Try to drop the Java side object here
            resultForNdk = null;
            int[] block = null;
            final int count = 9;
            for (int i = 0; i < count + 1; i++) {
                block = new int[1000000];
                block[1000 + i] = i;

                Runtime.getRuntime().gc();
                Runtime.getRuntime().runFinalization();

                mCollector.expectTrue(""This should never fail"", block[1000 + i] == i);
            }
            mCollector.expectTrue(
                ""validateStashedACameraMetadataFromCameraMetadataNative failed"",
                validateStashedACameraMetadataFromCameraMetadataNative(timestamp));
            mCollector.expectTrue(""This should never fail"", block[1000 + count] == count);
        }
    }

    private void validateTimestamps(String msg, TotalCaptureResult result, Image resultImage,
                                    long captureTime) {
        mCollector.expectKeyValueEquals(result, CaptureResult.SENSOR_TIMESTAMP, captureTime);
        mCollector.expectEquals(msg + "": Capture timestamp must be same as resultImage timestamp"",
                resultImage.getTimestamp(), captureTime);
    }

    public static void validateCaptureResult(CameraErrorCollector errorCollector,
            SimpleCaptureCallback captureListener, StaticMetadata staticInfo,
            Map<String, StaticMetadata> allStaticInfo, List<String> requestedPhysicalIds,
            CaptureRequest.Builder requestBuilder, int numFramesVerified) throws Exception {
        // List that includes all public keys from CaptureResult
        List<CaptureResult.Key<?>> allKeys = getAllCaptureResultKeys();
        // Get the waived keys for current camera device
        List<CaptureResult.Key<?>> waiverKeys = getWaiverKeysForCamera(staticInfo);
        if (requestedPhysicalIds == null) {
            requestedPhysicalIds = new ArrayList<String>();
        }

        HashMap<String, List<CaptureResult.Key<?>>> physicalWaiverKeys = new HashMap<>();
        for (String physicalId : requestedPhysicalIds) {
            StaticMetadata physicalStaticInfo = allStaticInfo.get(physicalId);
            physicalWaiverKeys.put(physicalId, getWaiverKeysForCamera(physicalStaticInfo));
        }

        TotalCaptureResult result = null;
        // List of (frameNumber, physical camera Id) pairs
        ArrayList<Pair<Long, String>> droppedPhysicalResults = new ArrayList<>();
        for (int i = 0; i < numFramesVerified; i++) {
            result = captureListener.getTotalCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);

            Map<String, CaptureResult> physicalCaptureResults = result.getPhysicalCameraResults();
            ArrayList<String> droppedIds = new ArrayList<String>(requestedPhysicalIds);
            droppedIds.removeAll(physicalCaptureResults.keySet());
            for (String droppedId : droppedIds) {
                droppedPhysicalResults.add(
                        new Pair<Long, String>(result.getFrameNumber(), droppedId));
            }

            validateOneCaptureResult(errorCollector, staticInfo, waiverKeys, allKeys,
                    requestBuilder, result, null/*cameraId*/, i);
            for (String physicalId : physicalCaptureResults.keySet()) {
                StaticMetadata physicalStaticInfo = allStaticInfo.get(physicalId);
                validateOneCaptureResult(errorCollector, physicalStaticInfo,
                        physicalWaiverKeys.get(physicalId),
                        allKeys, null/*requestBuilder*/, physicalCaptureResults.get(physicalId),
                        physicalId, i);
            }
        }

        // Verify that all dropped physical camera results are notified via capture failure.
        while (captureListener.hasMoreFailures()) {
            ArrayList<CaptureFailure> failures =
                    captureListener.getCaptureFailures(/*maxNumFailures*/ 1);
            for (CaptureFailure failure : failures) {
                String failedPhysicalId = failure.getPhysicalCameraId();
                Long failedFrameNumber = failure.getFrameNumber();
                if (failedPhysicalId != null) {
                    droppedPhysicalResults.removeIf(
                            n -> n.equals(
                            new Pair<Long, String>(failedFrameNumber, failedPhysicalId)));
                }
            }
        }
        errorCollector.expectTrue(""Not all dropped results for physical cameras are notified"",
                droppedPhysicalResults.isEmpty());
    }

    private static void validateOneCaptureResult(CameraErrorCollector errorCollector,
            StaticMetadata staticInfo, List<CaptureResult.Key<?>> skippedKeys,
            List<CaptureResult.Key<?>> allKeys,
            CaptureRequest.Builder requestBuilder, CaptureResult result, String cameraId,
            int resultCount) throws Exception {
        String failMsg = ""Failed capture result "" + resultCount + "" test"";
        String cameraIdString = "" "";
        if (cameraId != null) {
            cameraIdString += ""for physical camera "" + cameraId;
        }
        boolean verifyMatchRequest = (requestBuilder != null);
        for (CaptureResult.Key<?> key : allKeys) {
            if (!skippedKeys.contains(key)) {
                /**
                 * Check the critical tags here.
                 * TODO: Can use the same key for request and result when request/result
                 * becomes symmetric (b/14059883). Then below check can be wrapped into
                 * a generic function.
                 */
                String msg = failMsg + cameraIdString + ""for key "" + key.getName();
                if (verifyMatchRequest) {
                    if (key.equals(CaptureResult.CONTROL_AE_MODE)) {
                        errorCollector.expectEquals(msg,
                                requestBuilder.get(CaptureRequest.CONTROL_AE_MODE),
                                result.get(CaptureResult.CONTROL_AE_MODE));
                    } else if (key.equals(CaptureResult.CONTROL_AF_MODE)) {
                        errorCollector.expectEquals(msg,
                                requestBuilder.get(CaptureRequest.CONTROL_AF_MODE),
                                result.get(CaptureResult.CONTROL_AF_MODE));
                    } else if (key.equals(CaptureResult.CONTROL_AWB_MODE)) {
                        errorCollector.expectEquals(msg,
                                requestBuilder.get(CaptureRequest.CONTROL_AWB_MODE),
                                result.get(CaptureResult.CONTROL_AWB_MODE));
                    } else if (key.equals(CaptureResult.CONTROL_MODE)) {
                        errorCollector.expectEquals(msg,
                                requestBuilder.get(CaptureRequest.CONTROL_MODE),
                                result.get(CaptureResult.CONTROL_MODE));
                    } else if (key.equals(CaptureResult.STATISTICS_FACE_DETECT_MODE)) {
                        errorCollector.expectEquals(msg,
                                requestBuilder.get(CaptureRequest.STATISTICS_FACE_DETECT_MODE),
                                result.get(CaptureResult.STATISTICS_FACE_DETECT_MODE));
                    } else if (key.equals(CaptureResult.NOISE_REDUCTION_MODE)) {
                        errorCollector.expectEquals(msg,
                                requestBuilder.get(CaptureRequest.NOISE_REDUCTION_MODE),
                                result.get(CaptureResult.NOISE_REDUCTION_MODE));
                    } else if (key.equals(CaptureResult.NOISE_REDUCTION_MODE)) {
                        errorCollector.expectEquals(msg,
                                requestBuilder.get(CaptureRequest.NOISE_REDUCTION_MODE),
                                result.get(CaptureResult.NOISE_REDUCTION_MODE));
                    } else if (key.equals(CaptureResult.REQUEST_PIPELINE_DEPTH)) {

                    } else if (key.equals(CaptureResult.STATISTICS_OIS_DATA_MODE)) {
                        errorCollector.expectEquals(msg,
                                requestBuilder.get(CaptureRequest.STATISTICS_OIS_DATA_MODE),
                                result.get(CaptureResult.STATISTICS_OIS_DATA_MODE));
                    } else if (key.equals(CaptureResult.DISTORTION_CORRECTION_MODE)) {
                        errorCollector.expectEquals(msg,
                                requestBuilder.get(CaptureRequest.DISTORTION_CORRECTION_MODE),
                                result.get(CaptureResult.DISTORTION_CORRECTION_MODE));
                    } else if (key.equals(CaptureResult.SENSOR_DYNAMIC_BLACK_LEVEL)) {
                        float[] blackLevel = errorCollector.expectKeyValueNotNull(
                                result, CaptureResult.SENSOR_DYNAMIC_BLACK_LEVEL);
                        if (blackLevel != null && staticInfo.isMonochromeCamera()) {
                            errorCollector.expectEquals(
                                    ""Monochrome camera dynamic blacklevel must be 2x2"",
                                    blackLevel.length, 4);
                            for (int index = 1; index < blackLevel.length; index++) {
                                errorCollector.expectEquals(
                                    ""Monochrome camera 2x2 channels blacklevel value must be the same."",
                                    blackLevel[index], blackLevel[0]);
                            }
                        }
                    } else {
                        // Only do non-null check for the rest of keys.
                        errorCollector.expectKeyValueNotNull(failMsg, result, key);
                    }
                } else {
                    // Only do non-null check for the rest of keys.
                    errorCollector.expectKeyValueNotNull(failMsg, result, key);
                }
            } else {
                // These keys should always be null
                if (key.equals(CaptureResult.CONTROL_AE_REGIONS)) {
                    errorCollector.expectNull(
                            ""Capture result contains AE regions but aeMaxRegions is 0""
                            + cameraIdString,
                            result.get(CaptureResult.CONTROL_AE_REGIONS));
                } else if (key.equals(CaptureResult.CONTROL_AWB_REGIONS)) {
                    errorCollector.expectNull(
                            ""Capture result contains AWB regions but awbMaxRegions is 0""
                            + cameraIdString,
                            result.get(CaptureResult.CONTROL_AWB_REGIONS));
                } else if (key.equals(CaptureResult.CONTROL_AF_REGIONS)) {
                    errorCollector.expectNull(
                            ""Capture result contains AF regions but afMaxRegions is 0""
                            + cameraIdString,
                            result.get(CaptureResult.CONTROL_AF_REGIONS));
                }
            }
        }
    }

    /*
     * Add waiver keys per camera device hardware level and capability.
     *
     * Must be called after camera device is opened.
     */
    private static List<CaptureResult.Key<?>> getWaiverKeysForCamera(StaticMetadata staticInfo) {
        List<CaptureResult.Key<?>> waiverKeys = new ArrayList<>();

        // Global waiver keys
        waiverKeys.add(CaptureResult.JPEG_GPS_LOCATION);
        waiverKeys.add(CaptureResult.JPEG_ORIENTATION);
        waiverKeys.add(CaptureResult.JPEG_QUALITY);
        waiverKeys.add(CaptureResult.JPEG_THUMBNAIL_QUALITY);
        waiverKeys.add(CaptureResult.JPEG_THUMBNAIL_SIZE);

        if (!staticInfo.isUltraHighResolutionSensor()) {
            waiverKeys.add(CaptureResult.SENSOR_PIXEL_MODE);
            waiverKeys.add(CaptureResult.SENSOR_RAW_BINNING_FACTOR_USED);
        }

        // Keys only present when corresponding control is on are being
        // verified in its own functional test
        // Only present in certain tonemap mode. Test in CaptureRequestTest.
        waiverKeys.add(CaptureResult.TONEMAP_CURVE);
        waiverKeys.add(CaptureResult.TONEMAP_GAMMA);
        waiverKeys.add(CaptureResult.TONEMAP_PRESET_CURVE);
        // Only present when test pattern mode is SOLID_COLOR.
        // TODO: verify this key in test pattern test later
        waiverKeys.add(CaptureResult.SENSOR_TEST_PATTERN_DATA);
        // Only present when STATISTICS_LENS_SHADING_MAP_MODE is ON
        waiverKeys.add(CaptureResult.STATISTICS_LENS_SHADING_CORRECTION_MAP);
        // Only present when STATISTICS_INFO_AVAILABLE_HOT_PIXEL_MAP_MODES is ON
        waiverKeys.add(CaptureResult.STATISTICS_HOT_PIXEL_MAP);
        // Only present when face detection is on
        waiverKeys.add(CaptureResult.STATISTICS_FACES);
        // Only present in reprocessing capture result.
        waiverKeys.add(CaptureResult.REPROCESS_EFFECTIVE_EXPOSURE_FACTOR);

        // LOGICAL_MULTI_CAMERA_ACTIVE_PHYSICAL_ID not required if key is not supported.
        if (!staticInfo.isLogicalMultiCamera() ||
                !staticInfo.isActivePhysicalCameraIdSupported()) {
            waiverKeys.add(CaptureResult.LOGICAL_MULTI_CAMERA_ACTIVE_PHYSICAL_ID);
        }

        //Keys not required if RAW is not supported
        if (!staticInfo.isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_RAW)) {
            waiverKeys.add(CaptureResult.SENSOR_NEUTRAL_COLOR_POINT);
            waiverKeys.add(CaptureResult.SENSOR_GREEN_SPLIT);
            waiverKeys.add(CaptureResult.SENSOR_NOISE_PROFILE);
        } else if (staticInfo.isMonochromeCamera()) {
            waiverKeys.add(CaptureResult.SENSOR_NEUTRAL_COLOR_POINT);
            waiverKeys.add(CaptureResult.SENSOR_GREEN_SPLIT);
        }

        boolean calibrationReported = staticInfo.areKeysAvailable(
                CameraCharacteristics.LENS_POSE_ROTATION,
                CameraCharacteristics.LENS_POSE_TRANSLATION,
                CameraCharacteristics.LENS_INTRINSIC_CALIBRATION);

        // If any of distortion coefficients is reported in CameraCharacteristics, HAL must
        // also report (one of) them in CaptureResult
        boolean distortionReported = 
                staticInfo.areKeysAvailable(
                        CameraCharacteristics.LENS_RADIAL_DISTORTION) || 
                staticInfo.areKeysAvailable(
                        CameraCharacteristics.LENS_DISTORTION);

        //Keys for lens distortion correction
        boolean distortionCorrectionSupported = staticInfo.isDistortionCorrectionSupported();
        if (!distortionCorrectionSupported) {
            waiverKeys.add(CaptureResult.DISTORTION_CORRECTION_MODE);
        }

        boolean mustReportDistortion = true;
        // These keys must present on either DEPTH or distortion correction devices
        if (!staticInfo.isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_DEPTH_OUTPUT) &&
                !distortionCorrectionSupported &&
                !distortionReported) {
            mustReportDistortion = false;
            waiverKeys.add(CaptureResult.LENS_RADIAL_DISTORTION);
            waiverKeys.add(CaptureResult.LENS_DISTORTION);
        } else {
            // Radial distortion doesn't need to be present for new devices, or old devices that
            // opt in the new lens distortion tag.
            CameraCharacteristics c = staticInfo.getCharacteristics();
            if (Build.VERSION.DEVICE_INITIAL_SDK_INT > Build.VERSION_CODES.O_MR1 ||
                    c.get(CameraCharacteristics.LENS_DISTORTION) != null) {
                waiverKeys.add(CaptureResult.LENS_RADIAL_DISTORTION);
            }
        }

        // Calibration keys must exist for
        //   - DEPTH capable devices
        //   - Devices that reports calibration keys in static metadata
        //   - Devices that reports lens distortion keys in static metadata
        if (!staticInfo.isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_DEPTH_OUTPUT) &&
                !calibrationReported && !mustReportDistortion) {
            waiverKeys.add(CaptureResult.LENS_POSE_ROTATION);
            waiverKeys.add(CaptureResult.LENS_POSE_TRANSLATION);
            waiverKeys.add(CaptureResult.LENS_INTRINSIC_CALIBRATION);
        }

        // Waived if RAW output is not supported
        int[] outputFormats = staticInfo.getAvailableFormats(
                StaticMetadata.StreamDirection.Output);
        boolean supportRaw = false;
        for (int format : outputFormats) {
            if (format == ImageFormat.RAW_SENSOR || format == ImageFormat.RAW10 ||
                    format == ImageFormat.RAW12 || format == ImageFormat.RAW_PRIVATE) {
                supportRaw = true;
                break;
            }
        }
        if (!supportRaw) {
            waiverKeys.add(CaptureResult.CONTROL_POST_RAW_SENSITIVITY_BOOST);
        }

        // Waived if MONOCHROME capability
        if (staticInfo.isMonochromeCamera()) {
            waiverKeys.add(CaptureResult.COLOR_CORRECTION_MODE);
            waiverKeys.add(CaptureResult.COLOR_CORRECTION_TRANSFORM);
            waiverKeys.add(CaptureResult.COLOR_CORRECTION_GAINS);
        }

        if (staticInfo.getAeMaxRegionsChecked() == 0) {
            waiverKeys.add(CaptureResult.CONTROL_AE_REGIONS);
        }
        if (staticInfo.getAwbMaxRegionsChecked() == 0) {
            waiverKeys.add(CaptureResult.CONTROL_AWB_REGIONS);
        }
        if (staticInfo.getAfMaxRegionsChecked() == 0) {
            waiverKeys.add(CaptureResult.CONTROL_AF_REGIONS);
        }

        // Keys for dynamic black/white levels
        if (!staticInfo.isOpticalBlackRegionSupported()) {
            waiverKeys.add(CaptureResult.SENSOR_DYNAMIC_BLACK_LEVEL);
            waiverKeys.add(CaptureResult.SENSOR_DYNAMIC_WHITE_LEVEL);
        }

        if (!staticInfo.isEnableZslSupported()) {
            waiverKeys.add(CaptureResult.CONTROL_ENABLE_ZSL);
        }

        if (!staticInfo.isAfSceneChangeSupported()) {
            waiverKeys.add(CaptureResult.CONTROL_AF_SCENE_CHANGE);
        }

        if (!staticInfo.isOisDataModeSupported()) {
            waiverKeys.add(CaptureResult.STATISTICS_OIS_DATA_MODE);
            waiverKeys.add(CaptureResult.STATISTICS_OIS_SAMPLES);
        }

        if (staticInfo.getAvailableExtendedSceneModeCapsChecked().length == 0) {
            waiverKeys.add(CaptureResult.CONTROL_EXTENDED_SCENE_MODE);
        }

        if (!staticInfo.isRotateAndCropSupported()) {
            waiverKeys.add(CaptureResult.SCALER_ROTATE_AND_CROP);
        }

        if (staticInfo.isHardwareLevelAtLeastFull()) {
            return waiverKeys;
        }

        /*
         * Hardware Level = LIMITED or LEGACY
         */
        // Key not present if certain control is not supported
        if (!staticInfo.isColorCorrectionSupported()) {
            waiverKeys.add(CaptureResult.COLOR_CORRECTION_GAINS);
            waiverKeys.add(CaptureResult.COLOR_CORRECTION_MODE);
            waiverKeys.add(CaptureResult.COLOR_CORRECTION_TRANSFORM);
        }

        if (!staticInfo.isManualColorAberrationControlSupported()) {
            waiverKeys.add(CaptureResult.COLOR_CORRECTION_ABERRATION_MODE);
        }

        if (!staticInfo.isManualToneMapSupported()) {
            waiverKeys.add(CaptureResult.TONEMAP_MODE);
        }

        if (!staticInfo.isEdgeModeControlSupported()) {
            waiverKeys.add(CaptureResult.EDGE_MODE);
        }

        if (!staticInfo.isHotPixelMapModeControlSupported()) {
            waiverKeys.add(CaptureResult.HOT_PIXEL_MODE);
        }

        if (!staticInfo.isNoiseReductionModeControlSupported()) {
            waiverKeys.add(CaptureResult.NOISE_REDUCTION_MODE);
        }

        if (!staticInfo.isManualLensShadingMapSupported()) {
            waiverKeys.add(CaptureResult.SHADING_MODE);
        }

        //Keys not required if neither MANUAL_SENSOR nor READ_SENSOR_SETTINGS is supported
        if (!staticInfo.isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR) &&
            !staticInfo.isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_READ_SENSOR_SETTINGS)) {
            waiverKeys.add(CaptureResult.SENSOR_EXPOSURE_TIME);
            waiverKeys.add(CaptureResult.SENSOR_SENSITIVITY);
            waiverKeys.add(CaptureResult.LENS_FOCUS_DISTANCE);
            waiverKeys.add(CaptureResult.LENS_APERTURE);
        }

        if (!staticInfo.isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
            waiverKeys.add(CaptureResult.SENSOR_FRAME_DURATION);
            waiverKeys.add(CaptureResult.BLACK_LEVEL_LOCK);
            waiverKeys.add(CaptureResult.LENS_FOCUS_RANGE);
            waiverKeys.add(CaptureResult.LENS_STATE);
            waiverKeys.add(CaptureResult.LENS_FILTER_DENSITY);
        }

        if (staticInfo.isHardwareLevelLimited() && staticInfo.isColorOutputSupported()) {
            return waiverKeys;
        }

        /*
         * Hardware Level = EXTERNAL
         */
        if (staticInfo.isExternalCamera()) {
            waiverKeys.add(CaptureResult.LENS_FOCAL_LENGTH);
            waiverKeys.add(CaptureResult.SENSOR_TEST_PATTERN_MODE);
            waiverKeys.add(CaptureResult.SENSOR_ROLLING_SHUTTER_SKEW);
        }

        if (staticInfo.isExternalCamera() && staticInfo.isColorOutputSupported()) {
            return waiverKeys;
        }

        /*
         * Hardware Level = LEGACY or no regular output is supported
         */
        waiverKeys.add(CaptureResult.CONTROL_AE_PRECAPTURE_TRIGGER);
        waiverKeys.add(CaptureResult.CONTROL_AE_STATE);
        waiverKeys.add(CaptureResult.CONTROL_AWB_STATE);
        waiverKeys.add(CaptureResult.FLASH_STATE);
        waiverKeys.add(CaptureResult.LENS_OPTICAL_STABILIZATION_MODE);
        waiverKeys.add(CaptureResult.SENSOR_ROLLING_SHUTTER_SKEW);
        waiverKeys.add(CaptureResult.STATISTICS_LENS_SHADING_MAP_MODE);
        waiverKeys.add(CaptureResult.STATISTICS_SCENE_FLICKER);
        waiverKeys.add(CaptureResult.STATISTICS_HOT_PIXEL_MAP_MODE);
        waiverKeys.add(CaptureResult.CONTROL_AE_TARGET_FPS_RANGE);
        waiverKeys.add(CaptureResult.CONTROL_AF_TRIGGER);

        if (staticInfo.isHardwareLevelLegacy()) {
            return waiverKeys;
        }

        /*
         * Regular output not supported, only depth, waive color-output-related keys
         */
        waiverKeys.add(CaptureResult.CONTROL_SCENE_MODE);
        waiverKeys.add(CaptureResult.CONTROL_EFFECT_MODE);
        waiverKeys.add(CaptureResult.CONTROL_VIDEO_STABILIZATION_MODE);
        waiverKeys.add(CaptureResult.SENSOR_TEST_PATTERN_MODE);
        waiverKeys.add(CaptureResult.NOISE_REDUCTION_MODE);
        waiverKeys.add(CaptureResult.COLOR_CORRECTION_ABERRATION_MODE);
        waiverKeys.add(CaptureResult.CONTROL_AE_ANTIBANDING_MODE);
        waiverKeys.add(CaptureResult.CONTROL_AE_EXPOSURE_COMPENSATION);
        waiverKeys.add(CaptureResult.CONTROL_AE_LOCK);
        waiverKeys.add(CaptureResult.CONTROL_AE_MODE);
        waiverKeys.add(CaptureResult.CONTROL_AF_MODE);
        waiverKeys.add(CaptureResult.CONTROL_AWB_MODE);
        waiverKeys.add(CaptureResult.CONTROL_AWB_LOCK);
        waiverKeys.add(CaptureResult.CONTROL_ZOOM_RATIO);
        waiverKeys.add(CaptureResult.STATISTICS_FACE_DETECT_MODE);
        waiverKeys.add(CaptureResult.FLASH_MODE);
        waiverKeys.add(CaptureResult.SCALER_CROP_REGION);
        waiverKeys.add(CaptureResult.SCALER_ROTATE_AND_CROP);

        return waiverKeys;
    }

    /**
     * A capture listener implementation for collecting both partial and total results.
     *
     * <p> This is not a full-blown class and has some implicit assumptions. The class groups
     * capture results by capture request, so the user must guarantee each request this listener
     * is listening is unique. This class is not thread safe, so don't attach an instance object
     * with multiple handlers.</p>
     * */
    private static class TotalAndPartialResultListener
            extends CameraCaptureSession.CaptureCallback {
        static final int ERROR_DUPLICATED_REQUEST = 1 << 0;
        static final int ERROR_WRONG_CALLBACK_ORDER = 1 << 1;

        private final LinkedBlockingQueue<Pair<TotalCaptureResult, List<CaptureResult>> > mQueue =
                new LinkedBlockingQueue<>();
        private final HashMap<CaptureRequest, List<CaptureResult>> mPartialResultsMap =
                new HashMap<CaptureRequest, List<CaptureResult>>();
        private final HashSet<CaptureRequest> completedRequests = new HashSet<>();
        private int errorCode = 0;

        @Override
        public void onCaptureStarted(
            CameraCaptureSession session, CaptureRequest request, long timestamp, long frameNumber)
        {
            checkCallbackOrder(request);
            createMapEntryIfNecessary(request);
        }

        @Override
        public void onCaptureCompleted(CameraCaptureSession session, CaptureRequest request,
                TotalCaptureResult result) {
            try {
                List<CaptureResult> partialResultsList = mPartialResultsMap.get(request);
                if (partialResultsList == null) {
                    Log.w(TAG, ""onCaptureCompleted: unknown request"");
                }
                mQueue.put(new Pair<TotalCaptureResult, List<CaptureResult>>(
                        result, partialResultsList));
                mPartialResultsMap.remove(request);
                boolean newEntryAdded = completedRequests.add(request);
                if (!newEntryAdded) {
                    Integer frame = (Integer) request.getTag();
                    Log.e(TAG, ""Frame "" + frame + ""ERROR_DUPLICATED_REQUEST"");
                    errorCode |= ERROR_DUPLICATED_REQUEST;
                }
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(
                        ""Can't handle InterruptedException in onCaptureCompleted"");
            }
        }

        @Override
        public void onCaptureProgressed(CameraCaptureSession session, CaptureRequest request,
                CaptureResult partialResult) {
            createMapEntryIfNecessary(request);
            List<CaptureResult> partialResultsList = mPartialResultsMap.get(request);
            partialResultsList.add(partialResult);
        }

        private void createMapEntryIfNecessary(CaptureRequest request) {
            if (!mPartialResultsMap.containsKey(request)) {
                // create a new entry in the map
                mPartialResultsMap.put(request, new ArrayList<CaptureResult>());
            }
        }

        private void checkCallbackOrder(CaptureRequest request) {
            if (completedRequests.contains(request)) {
                Integer frame = (Integer) request.getTag();
                Log.e(TAG, ""Frame "" + frame + ""ERROR_WRONG_CALLBACK_ORDER"");
                errorCode |= ERROR_WRONG_CALLBACK_ORDER;
            }
        }

        public Pair<TotalCaptureResult, List<CaptureResult>> getCaptureResultPairs(long timeout) {
            try {
                Pair<TotalCaptureResult, List<CaptureResult>> result =
                        mQueue.poll(timeout, TimeUnit.MILLISECONDS);
                assertNotNull(""Wait for a capture result timed out in "" + timeout + ""ms"", result);
                return result;
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(""Unhandled interrupted exception"", e);
            }
        }

        public int getErrorCode() {
            return errorCode;
        }
    }

    // Returns true if `result` has timestamp `sensorTimestamp` when queried from the NDK via
    // ACameraMetadata_fromCameraMetadata().
    private static native boolean validateACameraMetadataFromCameraMetadataCriticalTagsNative(
        CaptureResult result, long sensorTimestamp);

    // First stash a native ACameraMetadata created from a capture result, then compare the stored value
    // to the passed-in timestamp.
    private static native boolean stashACameraMetadataFromCameraMetadataNative(CaptureResult result);
    private static native boolean validateStashedACameraMetadataFromCameraMetadataNative(long timestamp);

    /**
     * TODO: Use CameraCharacteristics.getAvailableCaptureResultKeys() once we can filter out
     * @hide keys.
     *
     */

    /*@O~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~
     * The key entries below this point are generated from metadata
     * definitions in /system/media/camera/docs. Do not modify by hand or
     * modify the comment blocks at the start or end.
     *~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~*/

    private static List<CaptureResult.Key<?>> getAllCaptureResultKeys() {
        ArrayList<CaptureResult.Key<?>> resultKeys = new ArrayList<CaptureResult.Key<?>>();
        resultKeys.add(CaptureResult.COLOR_CORRECTION_MODE);
        resultKeys.add(CaptureResult.COLOR_CORRECTION_TRANSFORM);
        resultKeys.add(CaptureResult.COLOR_CORRECTION_GAINS);
        resultKeys.add(CaptureResult.COLOR_CORRECTION_ABERRATION_MODE);
        resultKeys.add(CaptureResult.CONTROL_AE_ANTIBANDING_MODE);
        resultKeys.add(CaptureResult.CONTROL_AE_EXPOSURE_COMPENSATION);
        resultKeys.add(CaptureResult.CONTROL_AE_LOCK);
        resultKeys.add(CaptureResult.CONTROL_AE_MODE);
        resultKeys.add(CaptureResult.CONTROL_AE_REGIONS);
        resultKeys.add(CaptureResult.CONTROL_AE_TARGET_FPS_RANGE);
        resultKeys.add(CaptureResult.CONTROL_AE_PRECAPTURE_TRIGGER);
        resultKeys.add(CaptureResult.CONTROL_AF_MODE);
        resultKeys.add(CaptureResult.CONTROL_AF_REGIONS);
        resultKeys.add(CaptureResult.CONTROL_AF_TRIGGER);
        resultKeys.add(CaptureResult.CONTROL_AWB_LOCK);
        resultKeys.add(CaptureResult.CONTROL_AWB_MODE);
        resultKeys.add(CaptureResult.CONTROL_AWB_REGIONS);
        resultKeys.add(CaptureResult.CONTROL_CAPTURE_INTENT);
        resultKeys.add(CaptureResult.CONTROL_EFFECT_MODE);
        resultKeys.add(CaptureResult.CONTROL_MODE);
        resultKeys.add(CaptureResult.CONTROL_SCENE_MODE);
        resultKeys.add(CaptureResult.CONTROL_VIDEO_STABILIZATION_MODE);
        resultKeys.add(CaptureResult.CONTROL_AE_STATE);
        resultKeys.add(CaptureResult.CONTROL_AF_STATE);
        resultKeys.add(CaptureResult.CONTROL_AWB_STATE);
        resultKeys.add(CaptureResult.CONTROL_POST_RAW_SENSITIVITY_BOOST);
        resultKeys.add(CaptureResult.CONTROL_ENABLE_ZSL);
        resultKeys.add(CaptureResult.CONTROL_AF_SCENE_CHANGE);
        resultKeys.add(CaptureResult.CONTROL_EXTENDED_SCENE_MODE);
        resultKeys.add(CaptureResult.CONTROL_ZOOM_RATIO);
        resultKeys.add(CaptureResult.EDGE_MODE);
        resultKeys.add(CaptureResult.FLASH_MODE);
        resultKeys.add(CaptureResult.FLASH_STATE);
        resultKeys.add(CaptureResult.HOT_PIXEL_MODE);
        resultKeys.add(CaptureResult.JPEG_GPS_LOCATION);
        resultKeys.add(CaptureResult.JPEG_ORIENTATION);
        resultKeys.add(CaptureResult.JPEG_QUALITY);
        resultKeys.add(CaptureResult.JPEG_THUMBNAIL_QUALITY);
        resultKeys.add(CaptureResult.JPEG_THUMBNAIL_SIZE);
        resultKeys.add(CaptureResult.LENS_APERTURE);
        resultKeys.add(CaptureResult.LENS_FILTER_DENSITY);
        resultKeys.add(CaptureResult.LENS_FOCAL_LENGTH);
        resultKeys.add(CaptureResult.LENS_FOCUS_DISTANCE);
        resultKeys.add(CaptureResult.LENS_OPTICAL_STABILIZATION_MODE);
        resultKeys.add(CaptureResult.LENS_POSE_ROTATION);
        resultKeys.add(CaptureResult.LENS_POSE_TRANSLATION);
        resultKeys.add(CaptureResult.LENS_FOCUS_RANGE);
        resultKeys.add(CaptureResult.LENS_STATE);
        resultKeys.add(CaptureResult.LENS_INTRINSIC_CALIBRATION);
        resultKeys.add(CaptureResult.LENS_RADIAL_DISTORTION);
        resultKeys.add(CaptureResult.LENS_DISTORTION);
        resultKeys.add(CaptureResult.NOISE_REDUCTION_MODE);
        resultKeys.add(CaptureResult.REQUEST_PIPELINE_DEPTH);
        resultKeys.add(CaptureResult.SCALER_CROP_REGION);
        resultKeys.add(CaptureResult.SCALER_ROTATE_AND_CROP);
        resultKeys.add(CaptureResult.SENSOR_EXPOSURE_TIME);
        resultKeys.add(CaptureResult.SENSOR_FRAME_DURATION);
        resultKeys.add(CaptureResult.SENSOR_SENSITIVITY);
        resultKeys.add(CaptureResult.SENSOR_TIMESTAMP);
        resultKeys.add(CaptureResult.SENSOR_NEUTRAL_COLOR_POINT);
        resultKeys.add(CaptureResult.SENSOR_NOISE_PROFILE);
        resultKeys.add(CaptureResult.SENSOR_GREEN_SPLIT);
        resultKeys.add(CaptureResult.SENSOR_TEST_PATTERN_DATA);
        resultKeys.add(CaptureResult.SENSOR_TEST_PATTERN_MODE);
        resultKeys.add(CaptureResult.SENSOR_ROLLING_SHUTTER_SKEW);
        resultKeys.add(CaptureResult.SENSOR_DYNAMIC_BLACK_LEVEL);
        resultKeys.add(CaptureResult.SENSOR_DYNAMIC_WHITE_LEVEL);
        resultKeys.add(CaptureResult.SENSOR_PIXEL_MODE);
        resultKeys.add(CaptureResult.SENSOR_RAW_BINNING_FACTOR_USED);
        resultKeys.add(CaptureResult.SHADING_MODE);
        resultKeys.add(CaptureResult.STATISTICS_FACE_DETECT_MODE);
        resultKeys.add(CaptureResult.STATISTICS_HOT_PIXEL_MAP_MODE);
        resultKeys.add(CaptureResult.STATISTICS_FACES);
        resultKeys.add(CaptureResult.STATISTICS_LENS_SHADING_CORRECTION_MAP);
        resultKeys.add(CaptureResult.STATISTICS_SCENE_FLICKER);
        resultKeys.add(CaptureResult.STATISTICS_HOT_PIXEL_MAP);
        resultKeys.add(CaptureResult.STATISTICS_LENS_SHADING_MAP_MODE);
        resultKeys.add(CaptureResult.STATISTICS_OIS_DATA_MODE);
        resultKeys.add(CaptureResult.STATISTICS_OIS_SAMPLES);
        resultKeys.add(CaptureResult.TONEMAP_CURVE);
        resultKeys.add(CaptureResult.TONEMAP_MODE);
        resultKeys.add(CaptureResult.TONEMAP_GAMMA);
        resultKeys.add(CaptureResult.TONEMAP_PRESET_CURVE);
        resultKeys.add(CaptureResult.BLACK_LEVEL_LOCK);
        resultKeys.add(CaptureResult.REPROCESS_EFFECTIVE_EXPOSURE_FACTOR);
        resultKeys.add(CaptureResult.LOGICAL_MULTI_CAMERA_ACTIVE_PHYSICAL_ID);
        resultKeys.add(CaptureResult.DISTORTION_CORRECTION_MODE);

        return resultKeys;
    }

    /*~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~
     * End generated code
     *~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~O@*/
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Fragments.PhaseStartFragment"	"OnClickListener"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Fragments/PhaseStartFragment.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Fragments;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.sixdof.Activities.TestActivity;

import android.os.Bundle;
import android.app.Fragment;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.widget.Button;
import android.widget.TextView;

/**
 * Provides the instructions for a particular phase before it starts.
 */
public class PhaseStartFragment extends Fragment {
    // Identifier for setting and retrieving the phase this Fragment was designed for.
    private static final String ARG_PHASE = ""ArgPhase"";

    Button mBtnStart;
    TextView mTvDesc;

    TestActivity.CTSTest mPhase;
    TestActivity mActivity;

    public static PhaseStartFragment newInstance(TestActivity.CTSTest phase) {
        PhaseStartFragment fragment = new PhaseStartFragment();
        Bundle arguments = new Bundle();
        arguments.putSerializable(ARG_PHASE, phase);
        fragment.setArguments(arguments);

        return fragment;
    }

    @Override
    public View onCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) {
        View rootView = inflater.inflate(R.layout.fragment_start_phase, container, false);
        mBtnStart = (Button) rootView.findViewById(R.id.btnStart);
        mTvDesc = (TextView) rootView.findViewById(R.id.tvDesc);
        mActivity = (TestActivity) getActivity();

        mPhase = (TestActivity.CTSTest) getArguments().getSerializable(ARG_PHASE);

        switch (mPhase) {
            case ACCURACY:
                mTvDesc.setText(getString(R.string.phase1_description));
                getActivity().setTitle(getResources().getStringArray(R.array.phase)[TestActivity.CTSTest.ACCURACY.ordinal()]);
                break;
            case ROBUSTNESS:
                mTvDesc.setText(getString(R.string.phase2_description));
                getActivity().setTitle(getResources().getStringArray(R.array.phase)[TestActivity.CTSTest.ROBUSTNESS.ordinal()]);
                break;
            case COMPLEX_MOVEMENT:
                mTvDesc.setText(getString(R.string.phase3_description));
                getActivity().setTitle(getResources().getStringArray(R.array.phase)[TestActivity.CTSTest.COMPLEX_MOVEMENT.ordinal()]);
                break;
            default:
                throw new AssertionError(""Trying to start a test that doesn't exist"");
        }

        mBtnStart.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View view) {
                mActivity.switchToTestFragment(mPhase);
            }
        });

        return rootView;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.CtsUtilsTest"	"testCopyPad3to5"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/CtsUtilsTest.java"	""	"public void testCopyPad3to5() {
        final int w = 21;
        final int h = 9;
        final FakeImage src = FakeImage.createRaw(w, h, 24);
        final FakeImage dst = FakeImage.createRaw(w, h, 26);

        drawGradient(src.planes[0], w, h);
        CameraTestUtils.imageCopy(src, dst);

        checkPlane(""RAW"", w, h, src.planes[0], dst.planes[0]);
    }

    private static void checkPlane(String planeName, int w, int h, FakePlane src, FakePlane dst) {
        final byte[] srcRow = new byte[w];
        final byte[] dstRow = new byte[w];
        src.buffer.rewind();
        dst.buffer.rewind();
        for (int y=0; y < h; ++y) {
            src.buffer.position(y * src.rowStride);
            dst.buffer.position(y * dst.rowStride);
            src.buffer.get(srcRow, 0, srcRow.length);
            dst.buffer.get(dstRow, 0, dstRow.length);
            for (int x=0; x < w; ++x) {
                if (srcRow[x] != dstRow[x]) {
                    fail(""plane "" + planeName + "" differs on row "" + y + "", col "" + x + "": "" +
                            ""src="" + srcRow[x] + "" dst="" + dstRow[x]);
                }
            }
            String failmsg = planeName + "" plane copied incorrectly"";
            assertTrue(failmsg, Arrays.equals(srcRow, dstRow));
        }
        assertEquals(""src plane "" + planeName + "" not exhausted"", 0, src.buffer.remaining());
        assertEquals(""dst plane "" + planeName + "" not exhausted"", 0, dst.buffer.remaining());
    }

    private static void drawGradient(FakePlane plane, int w, int h) {
        final int diagonal = (w-1)*(w-1) + (h-1)*(h-1);
        final int rowStride = plane.rowStride;
        final ByteBuffer buffer = plane.buffer;
        buffer.rewind();
        for (int y=0; y<h; ++y) {
            int x = 0;
            // fill the image area...
            for (; x < w; ++x) {
                final byte val;
                if (x == w/2) {
                    val = 0; // a vertical black line down the middle
                } else {
                    val = (byte)(255 * (x*x + y*y) / diagonal); // radial gradient
                }
                buffer.put(val);
            }
            // ...and pad the rest of the row stride.
            if (y < h-1) {
                for (; x < rowStride; ++x) {
                    buffer.put(PADBYTE);
                }
            }
        }
    }

}

class FakeImage extends Image {
    public final int format;
    public final int width;
    public final int height;
    public final long timestamp = System.nanoTime();
    public final FakePlane[] planes;

    public FakeImage(int format, int w, int h, FakePlane[] planes) {
        this.format = format;
        this.width = w;
        this.height = h;
        this.planes = planes;
    }

    public static FakeImage createYuv420(int w, int h, int yStride, int uStride, int vStride) {
        return new FakeImage(
                ImageFormat.YUV_420_888,
                w, h,
                new FakePlane[] {
                        FakePlane.createStrict(w,   h,   yStride),
                        FakePlane.createStrict(w/2, h/2, uStride),
                        FakePlane.createStrict(w/2, h/2, vStride),
                }
        );
    }

    public static FakeImage createRaw(int w, int h, int rowStride) {
        return new FakeImage(
                ImageFormat.RAW_SENSOR, w, h,
                new FakePlane[] { FakePlane.createStrict(w, h, rowStride) }
        );
    }

    @Override public int getFormat() { return format; }
    @Override public int getWidth() { return width; }
    @Override public int getHeight() { return height; }
    @Override public long getTimestamp() { return timestamp; }
    @Override public Plane[] getPlanes() { return planes; }
    @Override public void close() { /* no-op */ }
}

class FakePlane extends Image.Plane {
    public final int rowStride;
    public final ByteBuffer buffer;

    public FakePlane(int nbytes, int rowStride) {
        buffer = ByteBuffer.allocateDirect(nbytes);
        this.rowStride = rowStride;
    }

    public static FakePlane createStrict(int w, int h, int rowStride) {
        int nbytes = rowStride * (h - 1) + w; // strictest possible size
        return new FakePlane(nbytes, rowStride);
    }

    @Override public int getRowStride() { return rowStride; }
    @Override public int getPixelStride() { return 1; }
    @Override public ByteBuffer getBuffer() { return buffer; }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.car.cts.utils.VehiclePropertyVerifier"	"isNotNull"	"CtsCarTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/car/src/android/car/cts/utils/VehiclePropertyVerifier.java"	""	"public void test/*
 *.
 */

package android.car.cts.utils;

import static com.google.common.truth.Truth.assertWithMessage;

import static org.junit.Assume.assumeNotNull;

import android.car.VehicleAreaType;
import android.car.VehiclePropertyIds;
import android.car.hardware.CarPropertyConfig;
import android.car.hardware.CarPropertyValue;
import android.car.hardware.property.CarPropertyManager;
import android.os.SystemClock;

import com.google.common.collect.ImmutableSet;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Optional;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

public class VehiclePropertyVerifier<T> {
    private final static String CAR_PROPERTY_VALUE_SOURCE_GETTER = ""Getter"";
    private final static String CAR_PROPERTY_VALUE_SOURCE_CALLBACK = ""Callback"";

    private final int mPropertyId;
    private final String mPropertyName;
    private final int mAccess;
    private final int mAreaType;
    private final int mChangeMode;
    private final Class<T> mPropertyType;
    private final boolean mRequiredProperty;
    private final Optional<ConfigArrayVerifier> mConfigArrayVerifier;
    private final Optional<CarPropertyValueVerifier> mCarPropertyValueVerifier;
    private final Optional<AreaIdsVerifier> mAreaIdsVerifier;
    private final ImmutableSet<Integer> mPossibleConfigArrayValues;
    private final boolean mRequirePropertyValueToBeInConfigArray;

    private VehiclePropertyVerifier(int propertyId, int access, int areaType, int changeMode,
            Class<T> propertyType, boolean requiredProperty,
            Optional<ConfigArrayVerifier> configArrayVerifier,
            Optional<CarPropertyValueVerifier> carPropertyValueVerifier,
            Optional<AreaIdsVerifier> areaIdsVerifier,
            ImmutableSet<Integer> possibleConfigArrayValues,
            boolean requirePropertyValueToBeInConfigArray) {
        mPropertyId = propertyId;
        mPropertyName = VehiclePropertyIds.toString(propertyId);
        mAccess = access;
        mAreaType = areaType;
        mChangeMode = changeMode;
        mPropertyType = propertyType;
        mRequiredProperty = requiredProperty;
        mConfigArrayVerifier = configArrayVerifier;
        mCarPropertyValueVerifier = carPropertyValueVerifier;
        mAreaIdsVerifier = areaIdsVerifier;
        mPossibleConfigArrayValues = possibleConfigArrayValues;
        mRequirePropertyValueToBeInConfigArray = requirePropertyValueToBeInConfigArray;
    }

    public static <T> Builder<T> newBuilder(int propertyId, int access, int areaType,
            int changeMode,
            Class<T> propertyType) {
        return new Builder<>(propertyId, access, areaType, changeMode, propertyType);
    }

    private static String accessToString(int access) {
        switch (access) {
            case CarPropertyConfig.VEHICLE_PROPERTY_ACCESS_NONE:
                return ""VEHICLE_PROPERTY_ACCESS_NONE"";
            case CarPropertyConfig.VEHICLE_PROPERTY_ACCESS_READ:
                return ""VEHICLE_PROPERTY_ACCESS_READ"";
            case CarPropertyConfig.VEHICLE_PROPERTY_ACCESS_WRITE:
                return ""VEHICLE_PROPERTY_ACCESS_WRITE"";
            case CarPropertyConfig.VEHICLE_PROPERTY_ACCESS_READ_WRITE:
                return ""VEHICLE_PROPERTY_ACCESS_READ_WRITE"";
            default:
                return Integer.toString(access);
        }
    }

    private static String areaTypeToString(int areaType) {
        switch (areaType) {
            case VehicleAreaType.VEHICLE_AREA_TYPE_GLOBAL:
                return ""VEHICLE_AREA_TYPE_GLOBAL"";
            case VehicleAreaType.VEHICLE_AREA_TYPE_WINDOW:
                return ""VEHICLE_AREA_TYPE_WINDOW"";
            case VehicleAreaType.VEHICLE_AREA_TYPE_DOOR:
                return ""VEHICLE_AREA_TYPE_DOOR"";
            case VehicleAreaType.VEHICLE_AREA_TYPE_MIRROR:
                return ""VEHICLE_AREA_TYPE_MIRROR"";
            case VehicleAreaType.VEHICLE_AREA_TYPE_SEAT:
                return ""VEHICLE_AREA_TYPE_SEAT"";
            case VehicleAreaType.VEHICLE_AREA_TYPE_WHEEL:
                return ""VEHICLE_AREA_TYPE_WHEEL"";
            default:
                return Integer.toString(areaType);
        }
    }

    private static String changeModeToString(int changeMode) {
        switch (changeMode) {
            case CarPropertyConfig.VEHICLE_PROPERTY_CHANGE_MODE_STATIC:
                return ""VEHICLE_PROPERTY_CHANGE_MODE_STATIC"";
            case CarPropertyConfig.VEHICLE_PROPERTY_CHANGE_MODE_ONCHANGE:
                return ""VEHICLE_PROPERTY_CHANGE_MODE_ONCHANGE"";
            case CarPropertyConfig.VEHICLE_PROPERTY_CHANGE_MODE_CONTINUOUS:
                return ""VEHICLE_PROPERTY_CHANGE_MODE_CONTINUOUS"";
            default:
                return Integer.toString(changeMode);
        }
    }

    public void verify(CarPropertyManager carPropertyManager) {
        CarPropertyConfig<?> carPropertyConfig = carPropertyManager.getCarPropertyConfig(
                mPropertyId);
        if (mRequiredProperty) {
            assertWithMessage(""Must support "" + mPropertyName).that(carPropertyConfig)
                    .isNotNull();
        } else {
            assumeNotNull(carPropertyConfig);
        }

        verifyCarPropertyConfig(carPropertyConfig);
        verifyCarPropertyValueGetter(carPropertyConfig, carPropertyManager);
        verifyCarPropertyValueCallback(carPropertyConfig, carPropertyManager);
    }

    private void verifyCarPropertyValueCallback(CarPropertyConfig<?> carPropertyConfig,
            CarPropertyManager carPropertyManager) {
        if (mChangeMode == CarPropertyConfig.VEHICLE_PROPERTY_CHANGE_MODE_STATIC
                || mChangeMode == CarPropertyConfig.VEHICLE_PROPERTY_CHANGE_MODE_ONCHANGE) {
            CarPropertyValueCallback carPropertyValueCallback =
                    new CarPropertyValueCallback(mPropertyName,
                            carPropertyConfig.getAreaIds().length);
            assertWithMessage(""Failed to register callback for "" + mPropertyName).that(
                    carPropertyManager.registerCallback(carPropertyValueCallback, mPropertyId,
                            CarPropertyManager.SENSOR_RATE_ONCHANGE)).isTrue();
            List<CarPropertyValue<?>> carPropertyValues =
                    carPropertyValueCallback.getCarPropertyValues();
            carPropertyManager.unregisterCallback(carPropertyValueCallback, mPropertyId);

            for (CarPropertyValue<?> carPropertyValue : carPropertyValues) {
                verifyCarPropertyValue(carPropertyConfig, carPropertyValue,
                        carPropertyValue.getAreaId(), CAR_PROPERTY_VALUE_SOURCE_CALLBACK);
            }
            assertWithMessage(mPropertyName
                    + "" callback values did not cover all the property's area IDs"").that(
                    carPropertyValues.stream().map(CarPropertyValue::getAreaId).collect(
                            Collectors.toList())
            ).containsExactlyElementsIn(
                    Arrays.stream(carPropertyConfig.getAreaIds()).boxed().collect(
                            Collectors.toList()));

        } else if (mChangeMode == CarPropertyConfig.VEHICLE_PROPERTY_CHANGE_MODE_CONTINUOUS) {
            CarPropertyValueCallback carPropertyValueCallback =
                    new CarPropertyValueCallback(mPropertyName, 1);
            assertWithMessage(""Failed to register callback for "" + mPropertyName).that(
                    carPropertyManager.registerCallback(carPropertyValueCallback, mPropertyId,
                            CarPropertyManager.SENSOR_RATE_FASTEST)).isTrue();
            List<CarPropertyValue<?>> carPropertyValues =
                    carPropertyValueCallback.getCarPropertyValues();
            carPropertyManager.unregisterCallback(carPropertyValueCallback, mPropertyId);

            for (CarPropertyValue<?> carPropertyValue : carPropertyValues) {
                verifyCarPropertyValue(carPropertyConfig, carPropertyValue,
                        carPropertyValue.getAreaId(), CAR_PROPERTY_VALUE_SOURCE_CALLBACK);
            }
        }
    }

    private void verifyCarPropertyConfig(CarPropertyConfig<?> carPropertyConfig) {
        assertWithMessage(mPropertyName + "" CarPropertyConfig must have correct property ID"")
                .that(carPropertyConfig.getPropertyId())
                .isEqualTo(mPropertyId);
        if (mAccess == CarPropertyConfig.VEHICLE_PROPERTY_ACCESS_READ_WRITE) {
            assertWithMessage(mPropertyName + "" must be "" + accessToString(
                    CarPropertyConfig.VEHICLE_PROPERTY_ACCESS_READ) + "", "" + accessToString(
                    CarPropertyConfig.VEHICLE_PROPERTY_ACCESS_WRITE) + "", or "" + accessToString(
                    CarPropertyConfig.VEHICLE_PROPERTY_ACCESS_READ_WRITE))
                    .that(carPropertyConfig.getAccess())
                    .isIn(ImmutableSet.of(CarPropertyConfig.VEHICLE_PROPERTY_ACCESS_READ,
                            CarPropertyConfig.VEHICLE_PROPERTY_ACCESS_WRITE,
                            CarPropertyConfig.VEHICLE_PROPERTY_ACCESS_READ_WRITE));
        } else {
            assertWithMessage(mPropertyName + "" must be "" + accessToString(mAccess))
                    .that(carPropertyConfig.getAccess()).isEqualTo(mAccess);
        }
        assertWithMessage(mPropertyName + "" must be "" + areaTypeToString(mAreaType))
                .that(carPropertyConfig.getAreaType())
                .isEqualTo(mAreaType);
        assertWithMessage(mPropertyName + "" must be "" + changeModeToString(mChangeMode))
                .that(carPropertyConfig.getChangeMode())
                .isEqualTo(mChangeMode);
        assertWithMessage(mPropertyName + "" must be "" + mPropertyType + "" type property"")
                .that(carPropertyConfig.getPropertyType()).isEqualTo(mPropertyType);

        if (mAreaIdsVerifier.isPresent()) {
            mAreaIdsVerifier.get().verify(carPropertyConfig.getAreaIds());
        } else if (mAreaType == VehicleAreaType.VEHICLE_AREA_TYPE_GLOBAL) {
            assertWithMessage(
                    mPropertyName + ""'s AreaIds must contain a single 0 since it is ""
                            + areaTypeToString(mAreaType))
                    .that(carPropertyConfig.getAreaIds()).isEqualTo(new int[]{0});
        }

        if (mChangeMode == CarPropertyConfig.VEHICLE_PROPERTY_CHANGE_MODE_CONTINUOUS) {
            verifyContinuousCarPropertyConfig(carPropertyConfig);
        } else {
            verifyNonContinuousCarPropertyConfig(carPropertyConfig);
        }

        if (!mPossibleConfigArrayValues.isEmpty()) {
            assertWithMessage(
                    mPropertyName + "" configArray must specify supported values"")
                    .that(carPropertyConfig.getConfigArray().size())
                    .isGreaterThan(0);
            for (Integer supportedValue : carPropertyConfig.getConfigArray()) {
                assertWithMessage(
                        mPropertyName + "" configArray value must be a defined ""
                                + ""value: ""
                                + supportedValue).that(
                        supportedValue).isIn(mPossibleConfigArrayValues);
            }
        }

        mConfigArrayVerifier.ifPresent(configArrayVerifier -> configArrayVerifier.verify(
                carPropertyConfig.getConfigArray()));

        if (mPossibleConfigArrayValues.isEmpty() && !mConfigArrayVerifier.isPresent()) {
            assertWithMessage(mPropertyName + "" configArray is undefined, so it must be empty"")
                    .that(carPropertyConfig.getConfigArray().size()).isEqualTo(0);
        }
    }

    private void verifyContinuousCarPropertyConfig(CarPropertyConfig<?> carPropertyConfig) {
        assertWithMessage(
                mPropertyName + "" must define max sample rate since change mode is ""
                        + changeModeToString(mChangeMode))
                .that(carPropertyConfig.getMaxSampleRate()).isGreaterThan(0);
        assertWithMessage(
                mPropertyName + "" must define min sample rate since change mode is ""
                        + changeModeToString(mChangeMode))
                .that(carPropertyConfig.getMinSampleRate()).isGreaterThan(0);
        assertWithMessage(mPropertyName + "" max sample rate must be >= min sample rate"")
                .that(carPropertyConfig.getMaxSampleRate() >=
                        carPropertyConfig.getMinSampleRate())
                .isTrue();
    }

    private void verifyNonContinuousCarPropertyConfig(CarPropertyConfig<?> carPropertyConfig) {
        assertWithMessage(mPropertyName + "" must define max sample rate as 0 since change mode is ""
                + changeModeToString(mChangeMode))
                .that(carPropertyConfig.getMaxSampleRate()).isEqualTo(0);
        assertWithMessage(mPropertyName + "" must define min sample rate as 0 since change mode is ""
                + changeModeToString(mChangeMode))
                .that(carPropertyConfig.getMinSampleRate()).isEqualTo(0);
    }

    private void verifyCarPropertyValueGetter(CarPropertyConfig<?> carPropertyConfig,
            CarPropertyManager carPropertyManager) {
        for (int areaId : carPropertyConfig.getAreaIds()) {
            CarPropertyValue<?> carPropertyValue =
                    carPropertyManager.getProperty(
                            mPropertyId, areaId);

            verifyCarPropertyValue(carPropertyConfig, carPropertyValue, areaId,
                    CAR_PROPERTY_VALUE_SOURCE_GETTER);
        }
    }

    private void verifyCarPropertyValue(CarPropertyConfig<?> carPropertyConfig,
            CarPropertyValue<?> carPropertyValue, int areaId, String source) {
        assertWithMessage(
                mPropertyName + "" - areaId: "" + areaId + "" - source: "" + source
                        + "" value must have correct property ID"")
                .that(carPropertyValue.getPropertyId()).isEqualTo(mPropertyId);
        assertWithMessage(
                mPropertyName + "" - areaId: "" + areaId + "" - source: "" + source
                        + "" value must have correct area id: ""
                        + areaId)
                .that(carPropertyValue.getAreaId())
                .isEqualTo(areaId);
        assertWithMessage(
                mPropertyName + "" - areaId: "" + areaId + "" - source: "" + source
                        + "" value's status must be valid"")
                .that(carPropertyValue.getStatus()).isIn(
                ImmutableSet.of(CarPropertyValue.STATUS_AVAILABLE,
                        CarPropertyValue.STATUS_UNAVAILABLE, CarPropertyValue.STATUS_ERROR));
        assertWithMessage(mPropertyName + "" - areaId: "" + areaId +
                "" - source: "" + source
                + "" timestamp must use the SystemClock.elapsedRealtimeNanos() time base"")
                .that(carPropertyValue.getTimestamp()).isAtLeast(0);
        assertWithMessage(mPropertyName + "" - areaId: "" + areaId +
                "" - source: "" + source
                + "" timestamp must use the SystemClock.elapsedRealtimeNanos() time base"")
                .that(carPropertyValue.getTimestamp()).isLessThan(
                SystemClock.elapsedRealtimeNanos());
        assertWithMessage(
                mPropertyName + "" - areaId: "" + areaId + "" - source: "" + source + "" must return ""
                        + mPropertyType
                        + "" type value"")
                .that(carPropertyValue.getValue().getClass()).isEqualTo(mPropertyType);

        if (mRequirePropertyValueToBeInConfigArray) {
            assertWithMessage(mPropertyName + "" - areaId: "" + areaId + "" - source: "" + source +
                    "" value must be listed in configArray"")
                    .that(carPropertyConfig.getConfigArray().contains(
                            carPropertyValue.getValue())).isTrue();
        }

        mCarPropertyValueVerifier.ifPresent(
                propertyValueVerifier -> propertyValueVerifier.verify(carPropertyConfig,
                        carPropertyValue));
    }

    public interface ConfigArrayVerifier {
        void verify(List<Integer> configArray);
    }

    public interface CarPropertyValueVerifier {
        void verify(CarPropertyConfig<?> carPropertyConfig, CarPropertyValue<?> carPropertyValue);
    }

    public interface AreaIdsVerifier {
        void verify(int[] areaIds);
    }

    public static class Builder<T> {
        private final int mPropertyId;
        private final int mAccess;
        private final int mAreaType;
        private final int mChangeMode;
        private final Class<T> mPropertyType;
        private boolean mRequiredProperty = false;
        private Optional<ConfigArrayVerifier> mConfigArrayVerifier = Optional.empty();
        private Optional<CarPropertyValueVerifier> mCarPropertyValueVerifier = Optional.empty();
        private Optional<AreaIdsVerifier> mAreaIdsVerifier = Optional.empty();
        private ImmutableSet<Integer> mPossibleConfigArrayValues = ImmutableSet.of();
        private boolean mRequirePropertyValueToBeInConfigArray = false;


        private Builder(int propertyId, int access, int areaType, int changeMode,
                Class<T> propertyType) {
            mPropertyId = propertyId;
            mAccess = access;
            mAreaType = areaType;
            mChangeMode = changeMode;
            mPropertyType = propertyType;
        }

        public Builder<T> requireProperty() {
            mRequiredProperty = true;
            return this;
        }

        public Builder<T> setConfigArrayVerifier(ConfigArrayVerifier configArrayVerifier) {
            mConfigArrayVerifier = Optional.of(configArrayVerifier);
            return this;
        }

        public Builder<T> setCarPropertyValueVerifier(
                CarPropertyValueVerifier carPropertyValueVerifier) {
            mCarPropertyValueVerifier = Optional.of(carPropertyValueVerifier);
            return this;
        }

        public Builder<T> setAreaIdsVerifier(AreaIdsVerifier areaIdsVerifier) {
            mAreaIdsVerifier = Optional.of(areaIdsVerifier);
            return this;
        }

        public Builder<T> setPossibleConfigArrayValues(
                ImmutableSet<Integer> possibleConfigArrayValues) {
            mPossibleConfigArrayValues = possibleConfigArrayValues;
            return this;
        }

        public Builder<T> requirePropertyValueTobeInConfigArray() {
            mRequirePropertyValueToBeInConfigArray = true;
            return this;
        }

        public VehiclePropertyVerifier<T> build() {
            return new VehiclePropertyVerifier<>(mPropertyId, mAccess, mAreaType, mChangeMode,
                    mPropertyType, mRequiredProperty, mConfigArrayVerifier,
                    mCarPropertyValueVerifier, mAreaIdsVerifier, mPossibleConfigArrayValues,
                    mRequirePropertyValueToBeInConfigArray);
        }
    }

    private static class CarPropertyValueCallback implements
            CarPropertyManager.CarPropertyEventCallback {
        private final String mPropertyName;
        private final int mTotalOnChangeEvents;
        private final CountDownLatch mCountDownLatch;
        private final List<CarPropertyValue<?>> mCarPropertyValues = new ArrayList<>();

        public CarPropertyValueCallback(String propertyName, int totalOnChangeEvents) {
            mPropertyName = propertyName;
            mTotalOnChangeEvents = totalOnChangeEvents;
            mCountDownLatch = new CountDownLatch(totalOnChangeEvents);
        }

        public List<CarPropertyValue<?>> getCarPropertyValues() {
            try {
                assertWithMessage(
                        ""Never received "" + mTotalOnChangeEvents + ""  onChangeEvent(s) for ""
                                + mPropertyName + "" callback before 1500ms timeout"").that(
                        mCountDownLatch.await(1500, TimeUnit.MILLISECONDS)).isTrue();
            } catch (InterruptedException e) {
                assertWithMessage(""Waiting for onChangeEvent callback(s) for "" + mPropertyName
                        + "" threw an exception: "" + e).fail();
            }
            return mCarPropertyValues;
        }

        @Override
        public void onChangeEvent(CarPropertyValue value) {
            mCarPropertyValues.add(value);
            mCountDownLatch.countDown();
        }

        @Override
        public void onErrorEvent(int propId, int zone) {
        }

        @Override
        public void onErrorEvent(int propId, int areaId, int errorCode) {
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testValuesForAllSensors"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testValuesForAllSensors() {
        for (Sensor sensor : mSensorList) {
            assertSensorValues(sensor);
        }
        assertAllSensorsNameUniqueness();
    }

    private void hasOnlyOneWakeUpSensorOrEmpty(List<Sensor> sensors) {
        if (sensors == null || sensors.isEmpty()) return;
        if (sensors.size() > 1) {
            fail(""More than one "" + sensors.get(0).getName() + "" defined."");
            return;
        }
        assertTrue(sensors.get(0).getName() + "" defined as non-wake-up sensor"",
                sensors.get(0).isWakeUpSensor());
    }

    private void hasDefaultWakeupSensorOrEmpty(int sensorType, String sensorName) {
        Sensor sensor = mSensorManager.getDefaultSensor(sensorType);
        if (sensor == null) return;

        assertTrue(""Default "" + sensorName + "" sensor is not a wake-up sensor"", sensor.isWakeUpSensor());
    }

    // Some sensors like proximity, significant motion etc. are defined as wake-up sensors by
    // default. Check if the wake-up flag is set correctly.
    @Presubmit"	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testWakeUpFlags"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testWakeUpFlags() {
        final int TYPE_WAKE_GESTURE = 23;
        final int TYPE_GLANCE_GESTURE = 24;
        final int TYPE_PICK_UP_GESTURE = 25;

        hasOnlyOneWakeUpSensorOrEmpty(mSensorManager.getSensorList(Sensor.TYPE_SIGNIFICANT_MOTION));
        hasOnlyOneWakeUpSensorOrEmpty(mSensorManager.getSensorList(TYPE_WAKE_GESTURE));
        hasOnlyOneWakeUpSensorOrEmpty(mSensorManager.getSensorList(TYPE_GLANCE_GESTURE));
        hasOnlyOneWakeUpSensorOrEmpty(mSensorManager.getSensorList(TYPE_PICK_UP_GESTURE));

        hasDefaultWakeupSensorOrEmpty(Sensor.TYPE_PROXIMITY, ""proximity"");
        hasDefaultWakeupSensorOrEmpty(Sensor.TYPE_HINGE_ANGLE, ""hinge"");
    }"	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"NullTriggerEventListener"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void test/*
 *.
 */

package android.hardware.cts;

import android.content.Context;
import android.content.pm.PackageManager;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorEventListener2;
import android.hardware.SensorManager;
import android.hardware.TriggerEvent;
import android.hardware.TriggerEventListener;
import android.hardware.cts.helpers.SensorCtsHelper;
import android.hardware.cts.helpers.SensorNotSupportedException;
import android.hardware.cts.helpers.SensorTestStateNotSupportedException;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEventListener;
import android.hardware.cts.helpers.TestSensorManager;
import android.hardware.cts.helpers.sensoroperations.ParallelSensorOperation;
import android.hardware.cts.helpers.sensoroperations.TestSensorOperation;
import android.hardware.cts.helpers.sensorverification.ContinuousEventSanitizedVerification;
import android.hardware.cts.helpers.sensorverification.EventGapVerification;
import android.hardware.cts.helpers.sensorverification.EventOrderingVerification;
import android.hardware.cts.helpers.sensorverification.EventTimestampSynchronizationVerification;
import android.os.Build.VERSION_CODES;
import android.os.Handler;
import android.os.HandlerThread;
import android.os.PowerManager;
import android.os.SystemClock;
import android.platform.test.annotations.AppModeFull;
import android.platform.test.annotations.Presubmit;
import android.util.Log;
import com.google.common.collect.ArrayListMultimap;
import com.google.common.collect.Multimap;
import com.android.compatibility.common.util.PropertyUtil;

import junit.framework.Assert;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

public class SensorTest extends SensorTestCase {
    private static final String TAG = ""SensorTest"";

    // Test only SDK defined sensors. Any sensors with type > 100 are ignored.
    private static final int MAX_OFFICIAL_ANDROID_SENSOR_TYPE = 100;

    private PowerManager.WakeLock mWakeLock;
    private SensorManager mSensorManager;
    private TestSensorManager mTestSensorManager;
    private NullTriggerEventListener mNullTriggerEventListener;
    private NullSensorEventListener mNullSensorEventListener;
    private Sensor mTriggerSensor;
    private List<Sensor> mSensorList;
    private List<Sensor> mAndroidSensorList;

    @Override
    protected void setUp() throws Exception {
        Context context = getContext();
        PowerManager pm = (PowerManager) context.getSystemService(Context.POWER_SERVICE);
        mWakeLock = pm.newWakeLock(PowerManager.PARTIAL_WAKE_LOCK, TAG);

        mSensorManager = (SensorManager) context.getSystemService(Context.SENSOR_SERVICE);
        mNullTriggerEventListener = new NullTriggerEventListener();
        mNullSensorEventListener = new NullSensorEventListener();

        mSensorList = mSensorManager.getSensorList(Sensor.TYPE_ALL);
        assertNotNull(""SensorList was null."", mSensorList);
        if (mSensorList.isEmpty()) {
            // several devices will not have sensors, so we need to skip the tests in those cases
            throw new SensorTestStateNotSupportedException(
                    ""Sensors are not available in the system."");
        }

        mAndroidSensorList = new ArrayList<>();
        for (Sensor s : mSensorList) {
            if (s.getType() < Sensor.TYPE_DEVICE_PRIVATE_BASE &&
                    (!context.getPackageManager().isInstantApp() || s.getType() != Sensor.TYPE_HEART_RATE)) {
                mAndroidSensorList.add(s);
            }
        }

        mWakeLock.acquire();
    }

    @Override
    protected void tearDown() {
        if (mSensorManager != null) {
            // SensorManager will check listener and status, so just unregister listener
            mSensorManager.unregisterListener(mNullSensorEventListener);
            if (mTriggerSensor != null) {
                mSensorManager.cancelTriggerSensor(mNullTriggerEventListener, mTriggerSensor);
                mTriggerSensor = null;
            }
        }

        if (mTestSensorManager != null) {
            mTestSensorManager.unregisterListener();
            mTestSensorManager = null;
        }

        if (mWakeLock != null && mWakeLock.isHeld()) {
            mWakeLock.release();
        }
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testSensorOperations"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testSensorOperations() {
        // Because we can't know every sensors unit details, so we can't assert
        // get values with specified values.
        Sensor sensor = mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER);
        boolean hasAccelerometer = getContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_SENSOR_ACCELEROMETER);
        // accelerometer sensor is optional
        if (hasAccelerometer) {
            assertNotNull(sensor);
            assertEquals(Sensor.TYPE_ACCELEROMETER, sensor.getType());
            assertSensorValues(sensor);
        } else {
            assertNull(sensor);
        }

        sensor = mSensorManager.getDefaultSensor(Sensor.TYPE_STEP_COUNTER);
        boolean hasStepCounter = getContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_SENSOR_STEP_COUNTER);
        // stepcounter sensor is optional
        if (hasStepCounter) {
            assertNotNull(sensor);
            assertEquals(Sensor.TYPE_STEP_COUNTER, sensor.getType());
            assertSensorValues(sensor);
        } else {
            assertNull(sensor);
        }

        sensor = mSensorManager.getDefaultSensor(Sensor.TYPE_STEP_DETECTOR);
        boolean hasStepDetector = getContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_SENSOR_STEP_DETECTOR);
        // stepdetector sensor is optional
        if (hasStepDetector) {
            assertNotNull(sensor);
            assertEquals(Sensor.TYPE_STEP_DETECTOR, sensor.getType());
            assertSensorValues(sensor);
        } else {
            assertNull(sensor);
        }

        sensor = mSensorManager.getDefaultSensor(Sensor.TYPE_MAGNETIC_FIELD);
        boolean hasCompass = getContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_SENSOR_COMPASS);
        // compass sensor is optional
        if (hasCompass) {
            assertNotNull(sensor);
            assertEquals(Sensor.TYPE_MAGNETIC_FIELD, sensor.getType());
            assertSensorValues(sensor);
        } else {
            assertNull(sensor);
        }

        sensor = mSensorManager.getDefaultSensor(Sensor.TYPE_GYROSCOPE);
        boolean hasGyroscope = getContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_SENSOR_GYROSCOPE);
        // gyroscope sensor is optional
        if (hasGyroscope) {
            assertNotNull(sensor);
            assertEquals(Sensor.TYPE_GYROSCOPE, sensor.getType());
            assertSensorValues(sensor);
        } else {
            assertNull(sensor);
        }

        sensor = mSensorManager.getDefaultSensor(Sensor.TYPE_PRESSURE);
        boolean hasPressure = getContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_SENSOR_BAROMETER);
        // pressure sensor is optional
        if (hasPressure) {
            assertNotNull(sensor);
            assertEquals(Sensor.TYPE_PRESSURE, sensor.getType());
            assertSensorValues(sensor);
        } else {
            assertNull(sensor);
        }

        sensor = mSensorManager.getDefaultSensor(Sensor.TYPE_ORIENTATION);
        // Note: orientation sensor is deprecated.
        if (sensor != null) {
            assertEquals(Sensor.TYPE_ORIENTATION, sensor.getType());
            assertSensorValues(sensor);
        }

        sensor = mSensorManager.getDefaultSensor(Sensor.TYPE_TEMPERATURE);
        // temperature sensor is optional
        if (sensor != null) {
            assertEquals(Sensor.TYPE_TEMPERATURE, sensor.getType());
            assertSensorValues(sensor);
        }

        sensor = mSensorManager.getDefaultSensor(Sensor.TYPE_HINGE_ANGLE);
        boolean hasHingeAngle = getContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_SENSOR_HINGE_ANGLE);

        if (hasHingeAngle) {
            assertNotNull(sensor);
            assertEquals(Sensor.TYPE_HINGE_ANGLE, sensor.getType());
            assertSensorValues(sensor);
            assertTrue(""Max range must not be larger than 360. Range="" + sensor.getMaximumRange()
                + "" "" + sensor.getName(), sensor.getMaximumRange() <= 360);
        } else {
            assertNull(sensor);
        }
    }

    @AppModeFull(reason = ""Instant apps cannot access body sensors"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testBodySensorOperations"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testBodySensorOperations() {
        Sensor sensor = mSensorManager.getDefaultSensor(Sensor.TYPE_HEART_RATE);
        boolean hasHeartRate = getContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_SENSOR_HEART_RATE);
        // heartrate sensor is optional
        if (hasHeartRate) {
            assertEquals(Sensor.TYPE_HEART_RATE, sensor.getType());
            assertSensorValues(sensor);
        } else {
            assertNull(sensor);
        }
    }

    private void assertAllSensorsNameUniqueness() {
        Multimap<Integer, String> sensorTypeNameMap = ArrayListMultimap.create();

        for (Sensor sensor : mSensorList) {
            assertFalse(""Duplicate sensor name "" + sensor.getName() + "" for type "" + sensor.getType(),
                        sensorTypeNameMap.containsEntry(sensor.getType(), sensor.getName()));
            sensorTypeNameMap.put(sensor.getType(), sensor.getName());
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testGetDefaultSensorWithWakeUpFlag"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testGetDefaultSensorWithWakeUpFlag() {
        // With wake-up flags set to false, the sensor returned should be a non wake-up sensor.
        for (Sensor sensor : mSensorList) {
            Sensor curr_sensor = mSensorManager.getDefaultSensor(sensor.getType(), false);
            if (curr_sensor != null) {
                assertFalse(""getDefaultSensor wakeup=false returns a wake-up sensor"" +
                        curr_sensor.getName(),
                        curr_sensor.isWakeUpSensor());
            }

            curr_sensor = mSensorManager.getDefaultSensor(sensor.getType(), true);
            if (curr_sensor != null) {
                assertTrue(""getDefaultSensor wake-up returns non wake sensor"" +
                        curr_sensor.getName(),
                        curr_sensor.isWakeUpSensor());
            }
        }
    }

    @Presubmit"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testSensorStringTypes"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testSensorStringTypes() {
        for (Sensor sensor : mSensorList) {
            if (sensor.getType() < MAX_OFFICIAL_ANDROID_SENSOR_TYPE &&
                    !sensor.getStringType().startsWith(""android.sensor."")) {
                fail(""StringType not set correctly for android defined sensor "" +
                        sensor.getName() + "" "" + sensor.getStringType());
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testRequestTriggerWithNonTriggerSensor"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testRequestTriggerWithNonTriggerSensor() {
        mTriggerSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER);
        if (mTriggerSensor == null) {
            throw new SensorNotSupportedException(Sensor.TYPE_ACCELEROMETER);
        }
        boolean  result =
            mSensorManager.requestTriggerSensor(mNullTriggerEventListener, mTriggerSensor);
        assertFalse(result);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testCancelTriggerWithNonTriggerSensor"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testCancelTriggerWithNonTriggerSensor() {
        mTriggerSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER);
        if (mTriggerSensor == null) {
            throw new SensorNotSupportedException(Sensor.TYPE_ACCELEROMETER);
        }
        boolean result =
            mSensorManager.cancelTriggerSensor(mNullTriggerEventListener, mTriggerSensor);
        assertFalse(result);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testRegisterWithTriggerSensor"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testRegisterWithTriggerSensor() {
        Sensor sensor = mSensorManager.getDefaultSensor(Sensor.TYPE_SIGNIFICANT_MOTION);
        if (sensor == null) {
            throw new SensorNotSupportedException(Sensor.TYPE_SIGNIFICANT_MOTION);
        }
        boolean result = mSensorManager.registerListener(
                mNullSensorEventListener,
                sensor,
                SensorManager.SENSOR_DELAY_NORMAL);
        assertFalse(result);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testRegisterTwiceWithSameSensor"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testRegisterTwiceWithSameSensor() {
        Sensor sensor = mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER);
        if (sensor == null) {
            throw new SensorNotSupportedException(Sensor.TYPE_ACCELEROMETER);
        }

        boolean result = mSensorManager.registerListener(mNullSensorEventListener, sensor,
                SensorManager.SENSOR_DELAY_NORMAL);
        assertTrue(result);

        result = mSensorManager.registerListener(mNullSensorEventListener, sensor,
                SensorManager.SENSOR_DELAY_NORMAL);
        assertFalse(result);
    }

    /**
     * Verifies that if the UID is idle the continuous events are being reported
     * but sanitized - all events are the same as the first one delivered except
     * for their timestamps. From the point of view of an idle app these events are
     * being properly generated but the sensor reading does not change - privacy.
     */
    // TODO: remove when parametrized tests are supported and EventTimestampSynchronization"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testSanitizedContinuousEventsUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testSanitizedContinuousEventsUidIdle() throws Exception {
        ArrayList<Throwable> errorsFound = new ArrayList<>();
        for (Sensor sensor : mAndroidSensorList) {
            // If the UID is active no sanitization should be performed
            verifyLongActivation(sensor, 0 /* maxReportLatencyUs */,
                    5 /* duration */, TimeUnit.SECONDS, ""continuous event"",
                    false /* sanitized */, errorsFound);
            verifyLongActivation(sensor, (int) TimeUnit.SECONDS.toMicros(10),
                    5 /* duration */, TimeUnit.SECONDS, ""continuous event"",
                    false /* sanitized */, errorsFound);

            // If the UID is idle sanitization should be performed

            SensorCtsHelper.makeMyPackageIdle();
            try {
                verifyLongActivation(sensor, 0 /* maxReportLatencyUs */,
                        5 /* duration */, TimeUnit.SECONDS, ""continuous event"",
                        true /* sanitized */, errorsFound);
                verifyLongActivation(sensor, (int) TimeUnit.SECONDS.toMicros(10),
                        5 /* duration */, TimeUnit.SECONDS, ""continuous event"",
                        true /* sanitized */, errorsFound);
            } finally {
                SensorCtsHelper.makeMyPackageActive();
            }

            // If the UID is active no sanitization should be performed
            verifyLongActivation(sensor, 0 /* maxReportLatencyUs */,
                    5 /* duration */, TimeUnit.SECONDS, ""continuous event"",
                    false /* sanitized */, errorsFound);
            verifyLongActivation(sensor, (int) TimeUnit.SECONDS.toMicros(10),
                    5 /* duration */, TimeUnit.SECONDS, ""continuous event"",
                    false /* sanitized */, errorsFound);
        }
        assertOnErrors(errorsFound);
    }

    // TODO: remove when parametrized tests are supported and EventTimestampSynchronization
    //       verification is added to default verifications"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testSensorTimeStamps"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testSensorTimeStamps() throws Exception {
        ArrayList<Throwable> errorsFound = new ArrayList<>();
        for (Sensor sensor : mAndroidSensorList) {
            // test both continuous and batching mode sensors
            verifyLongActivation(sensor, 0 /* maxReportLatencyUs */,
                    20 /* duration */, TimeUnit.SECONDS, ""timestamp"", false
                    /* sanitized */, errorsFound);
            verifyLongActivation(sensor, (int) TimeUnit.SECONDS.toMicros(10),
                    20 /* duration */, TimeUnit.SECONDS, ""timestamp"",
                    false /* sanitized */, errorsFound);
        }
        assertOnErrors(errorsFound);
    }

    // TODO: remove when parameterized tests are supported (see SensorBatchingTests.java)"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testBatchAndFlush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testBatchAndFlush() throws Exception {
        SensorCtsHelper.sleep(3, TimeUnit.SECONDS);
        ArrayList<Throwable> errorsFound = new ArrayList<>();
        for (Sensor sensor : mAndroidSensorList) {
            verifyRegisterListenerCallFlush(sensor, null /* handler */, errorsFound,
                    false /* flushWhileIdle */);
        }
        assertOnErrors(errorsFound);
    }

    /**
     * Verifies that if the UID is idle flush events are reported. Since
     * these events have no payload with private data they are working as
     * for a non-idle UID.
     */
    // TODO: remove when parametized tests are supported and EventTimestampSynchronization"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testBatchAndFlushUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testBatchAndFlushUidIdle() throws Exception {
        SensorCtsHelper.sleep(3, TimeUnit.SECONDS);
        ArrayList<Throwable> errorsFound = new ArrayList<>();
        for (Sensor sensor : mAndroidSensorList) {
            verifyRegisterListenerCallFlush(sensor, null /* handler */, errorsFound,
                    true /* flushWhileIdle */);
        }
        assertOnErrors(errorsFound);
    }

    /**
     * Verifies that sensor events arrive in the given message queue (Handler).
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testBatchAndFlushWithHandler"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testBatchAndFlushWithHandler() throws Exception {
        SensorCtsHelper.sleep(3, TimeUnit.SECONDS);
        Sensor sensor = null;
        for (Sensor s : mAndroidSensorList) {
            if (s.getReportingMode() == Sensor.REPORTING_MODE_CONTINUOUS) {
                sensor = s;
                break;
            }
        }
        if (sensor == null) {
            throw new SensorTestStateNotSupportedException(
                    ""There are no Continuous sensors in the device."");
        }

        TestSensorEnvironment environment = new TestSensorEnvironment(
                getContext(),
                sensor,
                SensorManager.SENSOR_DELAY_FASTEST,
                (int) TimeUnit.SECONDS.toMicros(5));
        mTestSensorManager = new TestSensorManager(environment);

        HandlerThread handlerThread = new HandlerThread(""sensorThread"");
        handlerThread.start();
        Handler handler = new Handler(handlerThread.getLooper());
        TestSensorEventListener listener = new TestSensorEventListener(environment, handler);

        CountDownLatch eventLatch = mTestSensorManager.registerListener(listener, 1);
        listener.waitForEvents(eventLatch, 1, true);
        CountDownLatch flushLatch = mTestSensorManager.requestFlush();
        listener.waitForFlushComplete(flushLatch, true);
        listener.assertEventsReceivedInHandler();
    }

    /**
     *  Explicit testing the SensorManager.registerListener(SensorEventListener, Sensor, int, int).
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testBatchAndFlushUseDefaultHandler"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testBatchAndFlushUseDefaultHandler() throws Exception {
        SensorCtsHelper.sleep(3, TimeUnit.SECONDS);
        Sensor sensor = null;
        for (Sensor s : mAndroidSensorList) {
            if (s.getReportingMode() == Sensor.REPORTING_MODE_CONTINUOUS) {
                sensor = s;
                break;
            }
        }
        if (sensor == null) {
            throw new SensorTestStateNotSupportedException(
                    ""There are no Continuous sensors in the device."");
        }

        TestSensorEnvironment environment = new TestSensorEnvironment(
                getContext(),
                sensor,
                SensorManager.SENSOR_DELAY_FASTEST,
                (int) TimeUnit.SECONDS.toMicros(5));
        mTestSensorManager = new TestSensorManager(environment);

        TestSensorEventListener listener = new TestSensorEventListener(environment, null);

        // specifyHandler <= false, use the SensorManager API without Handler parameter
        CountDownLatch eventLatch = mTestSensorManager.registerListener(listener, 1, false);
        listener.waitForEvents(eventLatch, 1, true);
        CountDownLatch flushLatch = mTestSensorManager.requestFlush();
        listener.waitForFlushComplete(flushLatch, true);
        listener.assertEventsReceivedInHandler();
    }

    // TODO: after L release move to SensorBatchingTests and run in all sensors with default
    //       verifications enabled"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testBatchAndFlushWithMultipleSensors"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testBatchAndFlushWithMultipleSensors() throws Exception {
        SensorCtsHelper.sleep(3, TimeUnit.SECONDS);
        final int maxSensors = 3;
        final int maxReportLatencyUs = (int) TimeUnit.SECONDS.toMicros(10);
        List<Sensor> sensorsToTest = new ArrayList<Sensor>();
        for (Sensor sensor : mAndroidSensorList) {
            if (sensor.getReportingMode() == Sensor.REPORTING_MODE_CONTINUOUS) {
                sensorsToTest.add(sensor);
                if (sensorsToTest.size()  == maxSensors) break;
            }
        }
        final int numSensorsToTest = sensorsToTest.size();
        if (numSensorsToTest == 0) {
            return;
        }

        StringBuilder builder = new StringBuilder();
        ParallelSensorOperation parallelSensorOperation = new ParallelSensorOperation();
        for (Sensor sensor : sensorsToTest) {
            TestSensorEnvironment environment = new TestSensorEnvironment(
                    getContext(),
                    sensor,
                    shouldEmulateSensorUnderLoad(),
                    SensorManager.SENSOR_DELAY_FASTEST,
                    maxReportLatencyUs);
            FlushExecutor executor = new FlushExecutor(environment, 500 /* eventCount */,
                    false /* flushWhileIdle */);
            parallelSensorOperation.add(new TestSensorOperation(environment, executor));
            builder.append(sensor.getName()).append("", "");
        }

        Log.i(TAG, ""Testing batch/flush for sensors: "" + builder);
        parallelSensorOperation.execute(getCurrentTestNode());
    }

    private void assertSensorValues(Sensor sensor) {
        assertTrue(""Max range must be positive. Range="" + sensor.getMaximumRange()
                + "" "" + sensor.getName(), sensor.getMaximumRange() >= 0);
        assertTrue(""Max power must be positive. Power="" + sensor.getPower() + "" "" +
                sensor.getName(), sensor.getPower() >= 0);

        // Only assert sensor resolution is non-zero for official sensor types since that's what's
        // required by the CDD.
        if (sensor.getType() < MAX_OFFICIAL_ANDROID_SENSOR_TYPE) {
            assertTrue(""Max resolution must be non-zero and positive. Resolution="" + sensor.getResolution() +
                    "" "" + sensor.getName(), sensor.getResolution() > 0);
        } else {
            assertTrue(""Max resolution must be positive. Resolution="" + sensor.getResolution() +
                    "" "" + sensor.getName(), sensor.getResolution() >= 0);
        }

        boolean hasHifiSensors = getContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_HIFI_SENSORS);
        if (SensorCtsHelper.hasMaxResolutionRequirement(sensor, hasHifiSensors)) {
            float maxResolution = SensorCtsHelper.getRequiredMaxResolutionForSensor(sensor);
            assertTrue(""Resolution must be <= "" + maxResolution + "". Resolution="" +
                    sensor.getResolution() + "" "" + sensor.getName(),
                    sensor.getResolution() <= maxResolution);
        }

        // The minimum resolution requirement was introduced to the CDD in R so
        // it's only possible to assert compliance for devices that release with
        // R or later.
        if (PropertyUtil.getFirstApiLevel() >= VERSION_CODES.R &&
                SensorCtsHelper.hasMinResolutionRequirement(sensor)) {
            float minResolution = SensorCtsHelper.getRequiredMinResolutionForSensor(sensor);
            assertTrue(""Resolution must be >= "" + minResolution + "". Resolution ="" +
                    sensor.getResolution() + "" "" + sensor.getName(),
                    sensor.getResolution() >= minResolution);
        }

        assertNotNull(""Vendor name must not be null "" + sensor.getName(), sensor.getVendor());
        assertTrue(""Version must be positive version="" + sensor.getVersion() + "" "" +
                sensor.getName(), sensor.getVersion() > 0);
        int fifoMaxEventCount = sensor.getFifoMaxEventCount();
        int fifoReservedEventCount = sensor.getFifoReservedEventCount();
        assertTrue(fifoMaxEventCount >= 0);
        assertTrue(fifoReservedEventCount >= 0);
        assertTrue(fifoReservedEventCount <= fifoMaxEventCount);
        if (sensor.getReportingMode() == Sensor.REPORTING_MODE_ONE_SHOT) {
            assertTrue(""One shot sensors should have zero FIFO Size "" + sensor.getName(),
                    sensor.getFifoMaxEventCount() == 0);
            assertTrue(""One shot sensors should have zero FIFO Size ""  + sensor.getName(),
                    sensor.getFifoReservedEventCount() == 0);
        }
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTest"	"testLegacySensorOperations"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTest.java"	""	"public void testLegacySensorOperations() {
        final SensorManager mSensorManager =
                (SensorManager) getContext().getSystemService(Context.SENSOR_SERVICE);

        // We expect the set of sensors reported by the new and legacy APIs to be consistent.
        int sensors = 0;
        if (mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER) != null) {
            sensors |= SensorManager.SENSOR_ACCELEROMETER;
        }
        if (mSensorManager.getDefaultSensor(Sensor.TYPE_MAGNETIC_FIELD) != null) {
            sensors |= SensorManager.SENSOR_MAGNETIC_FIELD;
        }
        if (mSensorManager.getDefaultSensor(Sensor.TYPE_ORIENTATION) != null) {
            sensors |= SensorManager.SENSOR_ORIENTATION | SensorManager.SENSOR_ORIENTATION_RAW;
        }
        assertEquals(sensors, mSensorManager.getSensors());
    }

    /**
     * Verifies that a continuous sensor produces events that have timestamps synchronized with
     * {@link SystemClock#elapsedRealtimeNanos()} and that the events are sanitized/non-sanitized.
     */
    private void verifyLongActivation(
            Sensor sensor,
            int maxReportLatencyUs,
            long duration,
            TimeUnit durationTimeUnit,
            String testType,
            boolean sanitized,
            ArrayList<Throwable> errorsFound) throws InterruptedException {
        if (sensor.getReportingMode() != Sensor.REPORTING_MODE_CONTINUOUS) {
            return;
        }

        try {
            TestSensorEnvironment environment = new TestSensorEnvironment(
                    getContext(),
                    sensor,
                    shouldEmulateSensorUnderLoad(),
                    SensorManager.SENSOR_DELAY_FASTEST,
                    maxReportLatencyUs);
            TestSensorOperation operation = TestSensorOperation.createOperation(
                    environment, duration, durationTimeUnit);
            if (sanitized) {
                final long verificationDelayNano = TimeUnit.NANOSECONDS.convert(
                        maxReportLatencyUs, TimeUnit.MICROSECONDS) * 2;
                operation.addVerification(ContinuousEventSanitizedVerification
                        .getDefault(environment, verificationDelayNano));
            } else {
                operation.addVerification(EventGapVerification.getDefault(environment));
                operation.addVerification(EventOrderingVerification.getDefault(environment));
                operation.addVerification(EventTimestampSynchronizationVerification
                        .getDefault(environment));
            }
            Log.i(TAG, ""Running "" + testType + "" test on: "" + sensor.getName());
            operation.execute(getCurrentTestNode());
        } catch (InterruptedException e) {
            // propagate so the test can stop
            throw e;
        } catch (Throwable e) {
            errorsFound.add(e);
            Log.e(TAG, e.getMessage());
        }
    }

    /**
     * Verifies that a client can listen for events, and that
     * {@link SensorManager#flush(SensorEventListener)} will trigger the appropriate notification
     * for {@link SensorEventListener2#onFlushCompleted(Sensor)}.
     */
    private void verifyRegisterListenerCallFlush(
            Sensor sensor,
            Handler handler,
            ArrayList<Throwable> errorsFound,
            boolean flushWhileIdle)
            throws InterruptedException {
        if (sensor.getReportingMode() == Sensor.REPORTING_MODE_ONE_SHOT) {
            return;
        }

        try {
            TestSensorEnvironment environment = new TestSensorEnvironment(
                    getContext(),
                    sensor,
                    shouldEmulateSensorUnderLoad(),
                    SensorManager.SENSOR_DELAY_FASTEST,
                    (int) TimeUnit.SECONDS.toMicros(10));
            FlushExecutor executor = new FlushExecutor(environment, 500 /* eventCount */,
                    flushWhileIdle);
            TestSensorOperation operation = new TestSensorOperation(environment, executor, handler);

            Log.i(TAG, ""Running flush test on: "" + sensor.getName());
            operation.execute(getCurrentTestNode());
        } catch (InterruptedException e) {
            // propagate so the test can stop
            throw e;
        } catch (Throwable e) {
            errorsFound.add(e);
            Log.e(TAG, e.getMessage());
        }
    }

    private void assertOnErrors(List<Throwable> errorsFound) {
        if (!errorsFound.isEmpty()) {
            StringBuilder builder = new StringBuilder();
            for (Throwable error : errorsFound) {
                builder.append(error.getMessage()).append(""\n"");
            }
            Assert.fail(builder.toString());
        }
    }

    /**
     * A delegate that drives the execution of Batch/Flush tests.
     * It performs several operations in order:
     * - registration
     * - for continuous sensors it first ensures that the FIFO is filled
     *      - if events do not arrive on time, an assert will be triggered
     * - requests flush of sensor data
     * - waits for {@link SensorEventListener2#onFlushCompleted(Sensor)}
     *      - if the event does not arrive, an assert will be triggered
     */
    private class FlushExecutor implements TestSensorOperation.Executor {
        private final TestSensorEnvironment mEnvironment;
        private final int mEventCount;
        private final boolean mFlushWhileIdle;

        public FlushExecutor(TestSensorEnvironment environment, int eventCount,
                boolean flushWhileIdle) {
            mEnvironment = environment;
            mEventCount = eventCount;
            mFlushWhileIdle = flushWhileIdle;
        }

        /**
         * Consider only continuous mode sensors for testing register listener.
         *
         * For on-change sensors, we only use
         * {@link TestSensorManager#registerListener(TestSensorEventListener)} to associate the
         * listener with the sensor. So that {@link TestSensorManager#requestFlush()} can be
         * invoked on it.
         */
        @Override
        public void execute(TestSensorManager sensorManager, TestSensorEventListener listener)
                throws Exception {
            int sensorReportingMode = mEnvironment.getSensor().getReportingMode();
            try {
                CountDownLatch eventLatch = sensorManager.registerListener(listener, mEventCount);
                if (sensorReportingMode == Sensor.REPORTING_MODE_CONTINUOUS) {
                    listener.waitForEvents(eventLatch, mEventCount, true);
                }
                if (mFlushWhileIdle) {
                    SensorCtsHelper.makeMyPackageIdle();
                    sensorManager.assertFlushFail();
                } else {
                    CountDownLatch flushLatch = sensorManager.requestFlush();
                    listener.waitForFlushComplete(flushLatch, true);
                }
            } finally {
                sensorManager.unregisterListener();
                if (mFlushWhileIdle) {
                    SensorCtsHelper.makeMyPackageActive();
                }
            }
        }
    }

    private class NullTriggerEventListener extends TriggerEventListener {
        @Override
        public void onTrigger(TriggerEvent event) {}
    }

    private class NullSensorEventListener implements SensorEventListener {
        @Override
        public void onSensorChanged(SensorEvent event) {}

        @Override
        public void onAccuracyChanged(Sensor sensor, int accuracy) {}
    }

}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.GyroscopeMeasurementTestActivity"	"GyroscopeMeasurementTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/GyroscopeMeasurementTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;
import com.android.cts.verifier.sensors.renderers.GLRotationGuideRenderer;

import android.hardware.Sensor;
import android.hardware.SensorManager;
import android.hardware.cts.helpers.SensorCalibratedUncalibratedVerifier;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.sensoroperations.TestSensorOperation;
import android.hardware.cts.helpers.sensorverification.GyroscopeIntegrationVerification;

import java.util.concurrent.TimeUnit;

/**
 * Semi-automated test that focuses on characteristics associated with Gyroscope measurements.
 */
public class GyroscopeMeasurementTestActivity extends SensorCtsVerifierTestActivity {
    private static final float THRESHOLD_CALIBRATED_UNCALIBRATED_RAD_SEC = 0.01f;
    private static final float THRESHOLD_AXIS_UNDER_ROTATION_DEG = 10.0f;
    private static final float THRESHOLD_AXIS_UNDER_NO_ROTATION_DEG = 50.0f;

    private static final int ROTATE_360_DEG = 360;
    private static final int ROTATION_COLLECTION_SEC = 10;

    private static final int X_AXIS = 0;
    private static final int Y_AXIS = 1;
    private static final int Z_AXIS = 2;

    private final GLRotationGuideRenderer mRenderer = new GLRotationGuideRenderer();

    public GyroscopeMeasurementTestActivity() {
        super(GyroscopeMeasurementTestActivity.class, true);
    }

    @Override
    protected void activitySetUp() throws InterruptedException {
        getTestLogger().logInstructions(R.string.snsr_gyro_device_placement);
        waitForUserToContinue();
        initializeGlSurfaceView(mRenderer);
    }

    @Override
    protected void activityCleanUp() {
        closeGlSurfaceView();
    }

    @SuppressWarnings(""unused"")
    public String testDeviceStatic() throws Throwable {
        return verifyMeasurements(
                R.string.snsr_gyro_device_static,
                -1 /* rotationAxis */,
                0 /* expectationDeg */);
    }

    @SuppressWarnings(""unused"")
    public String testRotateClockwise() throws Throwable {
        return verifyMeasurements(R.string.snsr_gyro_rotate_device, Z_AXIS, -ROTATE_360_DEG);
    }

    @SuppressWarnings(""unused"")
    public String testRotateCounterClockwise() throws Throwable {
        return verifyMeasurements(R.string.snsr_gyro_rotate_device, Z_AXIS, ROTATE_360_DEG);
    }

    @SuppressWarnings(""unused"")
    public String testRotateRightSide() throws Throwable {
        return verifyMeasurements(R.string.snsr_gyro_rotate_device, Y_AXIS, ROTATE_360_DEG);
    }

    @SuppressWarnings(""unused"")
    public String testRotateLeftSide() throws Throwable {
        return verifyMeasurements(R.string.snsr_gyro_rotate_device, Y_AXIS, -ROTATE_360_DEG);
    }

    @SuppressWarnings(""unused"")
    public String testRotateTopSide() throws Throwable {
        return verifyMeasurements(R.string.snsr_gyro_rotate_device, X_AXIS, -ROTATE_360_DEG);
    }

    @SuppressWarnings(""unused"")
    public String testRotateBottomSide() throws Throwable {
        return verifyMeasurements(R.string.snsr_gyro_rotate_device, X_AXIS, ROTATE_360_DEG);
    }

    /**
     * Verifies that the relationship between readings from calibrated and their corresponding
     * uncalibrated sensors comply to the following equation:
     *      calibrated = uncalibrated - bias
     */
    @SuppressWarnings(""unused"")
    public String testCalibratedAndUncalibrated() throws Throwable {
        setRendererRotation(Z_AXIS, false);

        setFirstExecutionInstruction(R.string.snsr_keep_device_rotating_clockwise);

        getTestLogger().logWaitForSound();

        TestSensorEnvironment calibratedEnvironment = new TestSensorEnvironment(
                getApplicationContext(),
                Sensor.TYPE_GYROSCOPE,
                SensorManager.SENSOR_DELAY_FASTEST);
        TestSensorEnvironment uncalibratedEnvironment = new TestSensorEnvironment(
                getApplicationContext(),
                Sensor.TYPE_GYROSCOPE_UNCALIBRATED,
                SensorManager.SENSOR_DELAY_FASTEST);
        SensorCalibratedUncalibratedVerifier verifier = new SensorCalibratedUncalibratedVerifier(
                calibratedEnvironment,
                uncalibratedEnvironment,
                THRESHOLD_CALIBRATED_UNCALIBRATED_RAD_SEC);

        try {
            verifier.execute();
        } finally {
            playSound();
        }
        return null;
    }

    /**
     * This test verifies that the Gyroscope measures the appropriate angular position.
     *
     * The test takes a set of samples from the sensor under test and calculates the angular
     * position for each axis that the sensor data collects. It then compares it against the test
     * expectations that are represented by signed values. It verifies that the readings have the
     * right magnitude.
     */
    private String verifyMeasurements(int instructionsResId, int rotationAxis, int expectationDeg)
            throws Throwable {
        setRendererRotation(rotationAxis, expectationDeg >= 0);

        setFirstExecutionInstruction(instructionsResId);

        getTestLogger().logWaitForSound();

        TestSensorEnvironment environment = new TestSensorEnvironment(
                getApplicationContext(),
                Sensor.TYPE_GYROSCOPE,
                SensorManager.SENSOR_DELAY_FASTEST);
        TestSensorOperation sensorOperation = TestSensorOperation
                .createOperation(environment, ROTATION_COLLECTION_SEC, TimeUnit.SECONDS);

        int gyroscopeAxes = environment.getSensorAxesCount();
        int[] expectationsDeg = getExpectationsDeg(gyroscopeAxes, rotationAxis, expectationDeg);
        float[] thresholdsDeg = getThresholdsDeg(gyroscopeAxes, rotationAxis);
        GyroscopeIntegrationVerification integrationVerification =
                new GyroscopeIntegrationVerification(expectationsDeg, thresholdsDeg);
        sensorOperation.addVerification(integrationVerification);

        try {
            sensorOperation.execute(getCurrentTestNode());
        } finally {
            playSound();
        }
        return null;
    }

    private int[] getExpectationsDeg(int axes, int rotationAxis, int expectationDeg) {
        int[] expectationsDeg = new int[axes];
        for (int i = 0; i < axes; ++i) {
            // tests assume that rotation is expected on one axis at a time
            expectationsDeg[i] = (i == rotationAxis) ? expectationDeg : 0;
        }
        return expectationsDeg;
    }

    private float[] getThresholdsDeg(int axes, int rotationAxis) {
        float[] thresholdsDeg = new float[axes];
        for (int i = 0; i < axes; ++i) {
            // tests set a high threshold on the axes where rotation is not expected, to account
            // for movement from the operator
            // the rotation axis has a lower threshold to ensure the gyroscope's accuracy
            thresholdsDeg[i] = (i == rotationAxis)
                    ? THRESHOLD_AXIS_UNDER_ROTATION_DEG
                    : THRESHOLD_AXIS_UNDER_NO_ROTATION_DEG;
        }
        return thresholdsDeg;
    }

    private void setRendererRotation(int rotationAxis, boolean positiveRotation) {
        int axis1 = 0;
        int axis2 = 0;
        int axis3 = 0;
        switch (rotationAxis) {
            case X_AXIS:
                axis1 = positiveRotation ? 1 : -1;
                break;
            case Y_AXIS:
                axis2 = positiveRotation ? 1 : -1;
                break;
            case Z_AXIS:
                axis3 = positiveRotation ? 1 : -1;
                break;
        }
        mRenderer.setRotation(axis1, axis2, axis3);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.Utils"	"isBusy"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/Utils.java"	""	"public void test/*
 *.
 */

package android.server.biometrics;

import static androidx.test.platform.app.InstrumentationRegistry.getInstrumentation;

import android.content.ComponentName;
import android.hardware.biometrics.BiometricManager;
import android.hardware.biometrics.BiometricPrompt;
import android.hardware.biometrics.SensorProperties;
import android.os.ParcelFileDescriptor;
import android.security.keystore.KeyGenParameterSpec;
import android.security.keystore.KeyProperties;
import android.server.wm.Condition;
import android.util.Log;

import androidx.annotation.NonNull;
import androidx.annotation.Nullable;

import com.android.server.biometrics.nano.BiometricServiceStateProto;

import java.io.ByteArrayOutputStream;
import java.io.FileInputStream;
import java.io.IOException;
import java.security.KeyStore;
import java.util.List;
import java.util.function.BooleanSupplier;
import java.util.function.Consumer;

import javax.crypto.Cipher;
import javax.crypto.KeyGenerator;
import javax.crypto.SecretKey;

public class Utils {

    private static final String TAG = ""BiometricTestUtils"";
    private static final String KEYSTORE_PROVIDER = ""AndroidKeyStore"";

    /** adb command for dumping the biometric proto */
    public static final String DUMPSYS_BIOMETRIC = ""dumpsys biometric --proto"";

    /**
     * Retrieves the current SensorStates.
     */
    public interface SensorStatesSupplier {
        SensorStates getSensorStates() throws Exception;
    }

    /**
     * Waits for the service to become idle
     * @throws Exception
     */
    public static void waitForIdleService(@NonNull SensorStatesSupplier supplier) throws Exception {
        for (int i = 0; i < 10; i++) {
            if (!supplier.getSensorStates().areAllSensorsIdle()) {
                Log.d(TAG, ""Not idle yet.."");
                Thread.sleep(300);
            } else {
                return;
            }
        }
        Log.d(TAG, ""Timed out waiting for idle"");
    }

    /**
     * Waits for the specified sensor to become non-idle
     */
    public static void waitForBusySensor(int sensorId, @NonNull SensorStatesSupplier supplier)
            throws Exception {
        for (int i = 0; i < 10; i++) {
            if (!supplier.getSensorStates().sensorStates.get(sensorId).isBusy()) {
                Log.d(TAG, ""Not busy yet.."");
                Thread.sleep(300);
            } else {
                return;
            }
        }
        Log.d(TAG, ""Timed out waiting to become busy"");
    }

    public static void waitFor(@NonNull String message, @NonNull BooleanSupplier condition) {
        waitFor(message, condition, null /* onFailure */);
    }

    public static void waitFor(@NonNull String message, @NonNull BooleanSupplier condition,
            @Nullable Consumer<Object> onFailure) {
        Condition.waitFor(new Condition<>(message, condition)
                .setRetryIntervalMs(500)
                .setRetryLimit(20)
                .setOnFailure(onFailure));
    }

    /**
     * Retrieves the current states of all biometric sensor services (e.g. FingerprintService,
     * FaceService, etc).
     *
     * Note that the states are retrieved from BiometricService, instead of individual services.
     * This is because 1) BiometricService is the source of truth for all public API-facing things,
     * and 2) This to include other information, such as UI states, etc as well.
     */
    @NonNull
    public static BiometricServiceState getBiometricServiceCurrentState() throws Exception {
        final byte[] dump = Utils.executeShellCommand(DUMPSYS_BIOMETRIC);
        final BiometricServiceStateProto proto = BiometricServiceStateProto.parseFrom(dump);
        return BiometricServiceState.parseFrom(proto);
    }

    /**
     * Runs a shell command, similar to running ""adb shell ..."" from the command line.
     * @param cmd A command, without the preceding ""adb shell"" portion. For example,
     *            passing in ""dumpsys fingerprint"" would be the equivalent of running
     *            ""adb shell dumpsys fingerprint"" from the command line.
     * @return The result of the command.
     */
    public static byte[] executeShellCommand(String cmd) {
        Log.d(TAG, ""execute: "" + cmd);
        try {
            ParcelFileDescriptor pfd = getInstrumentation().getUiAutomation()
                    .executeShellCommand(cmd);
            byte[] buf = new byte[512];
            int bytesRead;
            FileInputStream fis = new ParcelFileDescriptor.AutoCloseInputStream(pfd);
            ByteArrayOutputStream stdout = new ByteArrayOutputStream();
            while ((bytesRead = fis.read(buf)) != -1) {
                stdout.write(buf, 0, bytesRead);
            }
            fis.close();
            return stdout.toByteArray();
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }

    public static void forceStopActivity(ComponentName componentName) {
        executeShellCommand(""am force-stop "" + componentName.getPackageName()
                + "" "" + componentName.getShortClassName().replaceAll(""\\."", """"));
    }

    public static int numberOfSpecifiedOperations(@NonNull BiometricServiceState state,
            int sensorId, int operation) {
        int count = 0;
        final List<Integer> recentOps = state.mSensorStates.sensorStates.get(sensorId)
                .getSchedulerState().getRecentOperations();
        for (Integer i : recentOps) {
            if (i == operation) {
                count++;
            }
        }
        return count;
    }

    public static void createTimeBoundSecretKey_deprecated(String keyName, boolean useStrongBox)
            throws Exception {
        KeyStore keyStore = KeyStore.getInstance(""AndroidKeyStore"");
        keyStore.load(null);
        KeyGenerator keyGenerator = KeyGenerator.getInstance(
                KeyProperties.KEY_ALGORITHM_AES, ""AndroidKeyStore"");

        // Set the alias of the entry in Android KeyStore where the key will appear
        // and the constrains (purposes) in the constructor of the Builder
        keyGenerator.init(new KeyGenParameterSpec.Builder(keyName,
                KeyProperties.PURPOSE_ENCRYPT | KeyProperties.PURPOSE_DECRYPT)
                .setBlockModes(KeyProperties.BLOCK_MODE_CBC)
                .setUserAuthenticationRequired(true)
                .setEncryptionPaddings(KeyProperties.ENCRYPTION_PADDING_PKCS7)
                .setIsStrongBoxBacked(useStrongBox)
                .setUserAuthenticationValidityDurationSeconds(5 /* seconds */)
                .build());
        keyGenerator.generateKey();
    }

    static void createTimeBoundSecretKey(String keyName, int authTypes, boolean useStrongBox)
            throws Exception {
        KeyStore keyStore = KeyStore.getInstance(""AndroidKeyStore"");
        keyStore.load(null);
        KeyGenerator keyGenerator = KeyGenerator.getInstance(
                KeyProperties.KEY_ALGORITHM_AES, ""AndroidKeyStore"");

        // Set the alias of the entry in Android KeyStore where the key will appear
        // and the constrains (purposes) in the constructor of the Builder
        keyGenerator.init(new KeyGenParameterSpec.Builder(keyName,
                KeyProperties.PURPOSE_ENCRYPT | KeyProperties.PURPOSE_DECRYPT)
                .setBlockModes(KeyProperties.BLOCK_MODE_CBC)
                .setUserAuthenticationRequired(true)
                .setEncryptionPaddings(KeyProperties.ENCRYPTION_PADDING_PKCS7)
                .setIsStrongBoxBacked(useStrongBox)
                .setUserAuthenticationParameters(1 /* seconds */, authTypes)
                .build());
        keyGenerator.generateKey();
    }

    public static void generateBiometricBoundKey(String keyName, boolean useStrongBox)
            throws Exception {
        final KeyStore keystore = KeyStore.getInstance(KEYSTORE_PROVIDER);
        keystore.load(null);
        KeyGenParameterSpec.Builder builder = new KeyGenParameterSpec.Builder(
                keyName,
                KeyProperties.PURPOSE_ENCRYPT | KeyProperties.PURPOSE_DECRYPT)
                .setBlockModes(KeyProperties.BLOCK_MODE_CBC)
                .setEncryptionPaddings(KeyProperties.ENCRYPTION_PADDING_PKCS7)
                .setUserAuthenticationRequired(true)
                .setInvalidatedByBiometricEnrollment(true)
                .setIsStrongBoxBacked(useStrongBox)
                .setUserAuthenticationParameters(0, KeyProperties.AUTH_BIOMETRIC_STRONG);

        KeyGenerator keyGenerator = KeyGenerator
                .getInstance(KeyProperties.KEY_ALGORITHM_AES, KEYSTORE_PROVIDER);
        keyGenerator.init(builder.build());

        // Generates and stores the key in Android KeyStore under the keystoreAlias (keyName)
        // specified in the builder.
        keyGenerator.generateKey();
    }

    public static BiometricPrompt.CryptoObject initializeCryptoObject(String keyName)
            throws Exception {
        final KeyStore keystore = KeyStore.getInstance(KEYSTORE_PROVIDER);
        keystore.load(null);
        final SecretKey secretKey = (SecretKey) keystore.getKey(
                keyName, null /* password */);
        final Cipher cipher = Cipher.getInstance(KeyProperties.KEY_ALGORITHM_AES + ""/""
                + KeyProperties.BLOCK_MODE_CBC + ""/""
                + KeyProperties.ENCRYPTION_PADDING_PKCS7);
        cipher.init(Cipher.ENCRYPT_MODE, secretKey);

        final BiometricPrompt.CryptoObject cryptoObject =
                new BiometricPrompt.CryptoObject(cipher);
        return cryptoObject;
    }

    public static boolean isPublicAuthenticatorConstant(int authenticator) {
        switch (authenticator) {
            case BiometricManager.Authenticators.BIOMETRIC_STRONG:
            case BiometricManager.Authenticators.BIOMETRIC_WEAK:
            case BiometricManager.Authenticators.DEVICE_CREDENTIAL:
                return true;
            default:
                return false;
        }
    }

    public static int testApiStrengthToAuthenticatorStrength(int testApiStrength) {
        switch (testApiStrength) {
            case SensorProperties.STRENGTH_STRONG:
                return BiometricManager.Authenticators.BIOMETRIC_STRONG;
            case SensorProperties.STRENGTH_WEAK:
                return BiometricManager.Authenticators.BIOMETRIC_WEAK;
            default:
                throw new IllegalArgumentException(""Unable to convert testApiStrength: ""
                        + testApiStrength);
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Utils.TestPhase.ComplexMovementTest"	"executeComplexMovementTests"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Utils/TestPhase/ComplexMovementTest.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors.sixdof.Utils.TestPhase;

import com.android.cts.verifier.sensors.sixdof.Dialogs.BaseResultsDialog;
import com.android.cts.verifier.sensors.sixdof.Utils.Manager;
import com.android.cts.verifier.sensors.sixdof.Utils.TestReport;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.ComplexMovementPath;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.ReferencePath;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Ring;

import android.util.Log;

import java.util.ArrayList;
import java.util.HashMap;

/**
 * Handles all the ComplexMovement test related features.
 */
public class ComplexMovementTest extends Test {
    private boolean mResultsGiven = false;

    /**
     * Created a new ComplexMovement path which is to be used in this test.
     *
     * @param referencePath Reference the the reference path.
     * @param testReport    The test report object to record the tests.
     * @param manager       The manager to call when the test is done.
     */
    public ComplexMovementTest(ReferencePath referencePath, TestReport testReport, Manager manager) {
        super(referencePath, testReport, manager, ""Complex Movement Test"");
        mTestPath = new ComplexMovementPath(mReferencePathDistances, mReferencePath.getCurrentPath());
    }

    /**
     * Implementation of the abstract method which check whether the test is complete.
     */
    @Override
    protected void runAdditionalMethods() {
        if (mTestPath.getPathMarkersSize() == MAX_MARKER_NUMBER && !mResultsGiven) {
            mResultsGiven = true;
            executeComplexMovementTests();
        }
    }

    /**
     * Starts the ComplexMovement tests.
     */
    private void executeComplexMovementTests() {
        HashMap<BaseResultsDialog.ResultType, Boolean> complexMovementTestResults;
        complexMovementTestResults = executeTests(true, false);
        complexMovementTestResults.put(BaseResultsDialog.ResultType.RINGS, testRings());
        mManager.onComplexMovementTestCompleted(complexMovementTestResults);
    }

    /**
     * Tests whether the current location enters a ring.
     *
     * @param location the current location of the user
     */
    public void checkIfARingHasBeenPassed(float[] location) {
        Ring ring = ((ComplexMovementPath) mTestPath).hasRingBeenEntered(location);
        if (ring != null && !ring.isEntered()) {
            // If ring has not already been entered.
            mManager.ringEntered(ring);
            ring.setEntered(true);
        }
    }

    /**
     * Finds the rings that have not been entered.
     *
     * @return true if all rings are entered and false if there is at least one ring not entered
     */
    public boolean testRings() {
        ArrayList<Ring> testArray = ((ComplexMovementPath) mTestPath).getRings();
        boolean state = true;
        for (int i = 0; i < testArray.size(); i++) {
            if (!testArray.get(i).isEntered()) {
                recordRingTestResults(i);
                state = false;
            }
        }
        return state;
    }

    /**
     * Forms a string for the failed ring and updates the test report with the string.
     *
     * @param ringIndex the index of the array the ring is in
     */
    private void recordRingTestResults(int ringIndex) {
        Ring ring = ((ComplexMovementPath) mTestPath).getRings().get(ringIndex);
        String testDetails =
                ""Ring Test: Ring was not entered. Path number: "" + ring.getPathNumber() +
                        ""Ring number:"" + ((ringIndex % ComplexMovementPath.RINGS_PER_PATH) + 1) + ""\n"";
        Log.e(""Ring Result"", testDetails);
        mTestReport.setFailDetails(testDetails);

    }

    /**
     * Returns the rings in the path.
     */
    public ArrayList<Ring> getRings() {
        return ((ComplexMovementPath) mTestPath).getRings();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.devicepolicy.MixedDeviceOwnerTest"	"testAdminControlOverSensorPermissionGrantsDefault"	"CtsDevicePolicyManagerTestCases"	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/src/com/android/cts/devicepolicy/MixedDeviceOwnerTest.java"	""	"public void testAdminControlOverSensorPermissionGrantsDefault() throws Exception {
        // In Device Owner mode, by default, admin should be able to grant sensors-related
        // permissions.
        executeDeviceTestMethod("".SensorPermissionGrantTest"",
                ""testAdminCanGrantSensorsPermissions"");
    }

    @Override"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.devicepolicy.MixedDeviceOwnerTest"	"testGrantOfSensorsRelatedPermissions"	"CtsDevicePolicyManagerTestCases"	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/src/com/android/cts/devicepolicy/MixedDeviceOwnerTest.java"	""	"public void testGrantOfSensorsRelatedPermissions() throws Exception {
        // Skip for now, re-enable when the code path sets DO as able to grant permissions.
    }

    @Override"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.devicepolicy.MixedDeviceOwnerTest"	"testSensorsRelatedPermissionsNotGrantedViaPolicy"	"CtsDevicePolicyManagerTestCases"	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/src/com/android/cts/devicepolicy/MixedDeviceOwnerTest.java"	""	"public void testSensorsRelatedPermissionsNotGrantedViaPolicy() throws Exception {
        // Skip for now, re-enable when the code path sets DO as able to grant permissions.
    }

    @Override"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.devicepolicy.MixedDeviceOwnerTest"	"testStateOfSensorsRelatedPermissionsCannotBeRead"	"CtsDevicePolicyManagerTestCases"	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/src/com/android/cts/devicepolicy/MixedDeviceOwnerTest.java"	""	"public void testStateOfSensorsRelatedPermissionsCannotBeRead() throws Exception {
        // Skip because in DO mode the admin can read permission state.
    }

    //TODO(b/180413140) Investigate why the test fails on DO mode.
    @Override"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.MagneticFieldMeasurementTestActivity"	"MagneticFieldMeasurementTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/MagneticFieldMeasurementTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import android.content.Context;
import android.hardware.GeomagneticField;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorManager;
import android.hardware.cts.helpers.SensorCalibratedUncalibratedVerifier;
import android.hardware.cts.helpers.SensorCtsHelper;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEventListener;
import android.hardware.cts.helpers.TestSensorManager;
import android.hardware.cts.helpers.sensoroperations.TestSensorOperation;
import android.hardware.cts.helpers.sensorverification.MagnitudeVerification;
import android.hardware.cts.helpers.sensorverification.OffsetVerification;
import android.hardware.cts.helpers.sensorverification.StandardDeviationVerification;
import android.location.Location;
import android.location.LocationManager;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;
import com.android.cts.verifier.sensors.helpers.SensorFeaturesDeactivator;

import java.util.List;

/**
 * Semi-automated test that focuses characteristics associated with Accelerometer measurements.
 * These test cases require calibration of the sensor before performing the verifications.
 * Also, it is recommended to execute these tests outdoors, or at least far from magnetic
 * disturbances.
 */
public class MagneticFieldMeasurementTestActivity extends SensorCtsVerifierTestActivity {
    private static final float THRESHOLD_CALIBRATED_UNCALIBRATED_UT = 3f;
    private static final float NANOTESLA_TO_MICROTESLA = 1.0f / 1000;
    private static final int LOCATION_TRIES = 2;

    public MagneticFieldMeasurementTestActivity() {
        super(MagneticFieldMeasurementTestActivity.class);
    }

    @Override
    public void activitySetUp() throws InterruptedException {
        SensorFeaturesDeactivator sensorFeaturesDeactivator = new SensorFeaturesDeactivator(this);
        sensorFeaturesDeactivator.requestToSetLocationMode(true /* state */);
        calibrateMagnetometer();
    }

    /**
     * This test verifies that the Norm of the sensor data is close to the expected reference value.
     * The units of the reference value are dependent on the type of sensor.
     * This test is used to verify that the data reported by the sensor is close to the expected
     * range and scale.
     *
     * The test takes a sample from the sensor under test and calculates the Euclidean Norm of the
     * vector represented by the sampled data. It then compares it against the test expectations
     * that are represented by a reference value and a threshold.
     *
     * The test is susceptible to errors when the Sensor under test is uncalibrated, or the units in
     * which the data are reported and the expectations are set are different.
     *
     * The assertion associated with the test provides the required data needed to identify any
     * possible issue. It provides:
     * - the thread id on which the failure occurred
     * - the sensor type and sensor handle that caused the failure
     * - the values representing the expectation of the test
     * - the values sampled from the sensor
     */
    @SuppressWarnings(""unused"")
    public String testNorm() throws Throwable {
        getTestLogger().logMessage(R.string.snsr_mag_verify_norm);

        TestSensorEnvironment environment = new TestSensorEnvironment(
                getApplicationContext(),
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorManager.SENSOR_DELAY_FASTEST);
        TestSensorOperation verifyNorm =
                TestSensorOperation.createOperation(environment, 100 /* event count */);

        float expectedMagneticFieldEarth;
        float magneticFieldEarthThreshold = (SensorManager.MAGNETIC_FIELD_EARTH_MAX
                - SensorManager.MAGNETIC_FIELD_EARTH_MIN) / 2;

        Location location = null;
        LocationManager lm = (LocationManager) getApplicationContext().getSystemService(
                Context.LOCATION_SERVICE);

        int tries = LOCATION_TRIES;
        while (lm != null && location == null && tries > 0)  {
            tries--;
            List<String> providers = lm.getProviders(true /* enabledOnly */);
            int providerIndex = providers.size();
            while (providerIndex > 0 && location == null) {
                providerIndex--;
                location = lm.getLastKnownLocation(providers.get(providerIndex));
            }
            if (location == null) {
                getTestLogger().logMessage(R.string.snsr_mag_move_outside);
                waitForUserToContinue();
            }
        }

        if (location == null) {
            expectedMagneticFieldEarth = (SensorManager.MAGNETIC_FIELD_EARTH_MAX
                    + SensorManager.MAGNETIC_FIELD_EARTH_MIN) / 2;
            getTestLogger().logMessage(R.string.snsr_mag_no_location, expectedMagneticFieldEarth);
            waitForUserToContinue();
        } else {
            GeomagneticField geomagneticField = new GeomagneticField((float) location.getLatitude(),
                    (float) location.getLongitude(), (float) location.getAltitude(),
                    location.getTime());
            expectedMagneticFieldEarth =
                    geomagneticField.getFieldStrength() * NANOTESLA_TO_MICROTESLA;
        }

        verifyNorm.addVerification(new MagnitudeVerification(
                expectedMagneticFieldEarth,
                magneticFieldEarthThreshold));
        verifyNorm.execute(getCurrentTestNode());
        return null;
    }

    /**
     * This test verifies that the norm of the sensor offset is less than the reference value.
     * The units of the reference value are dependent on the type of sensor.
     *
     * The test takes a sample from the sensor under test and calculates the Euclidean Norm of the
     * offset represented by the sampled data. It then compares it against the test expectations
     * that are represented by a reference value.
     *
     * The assertion associated with the test provides the required data needed to identify any
     * possible issue. It provides:
     * - the thread id on which the failure occurred
     * - the sensor type and sensor handle that caused the failure
     * - the values representing the expectation of the test
     * - the values sampled from the sensor
     */
    @SuppressWarnings(""unused"")
    public String testOffset() throws Throwable {
        getTestLogger().logMessage(R.string.snsr_mag_verify_offset);

        TestSensorEnvironment environment = new TestSensorEnvironment(
                getApplicationContext(),
                Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED,
                SensorManager.SENSOR_DELAY_FASTEST);
        TestSensorOperation verifyOffset =
                TestSensorOperation.createOperation(environment, 100 /* event count */);

        verifyOffset.addVerification(OffsetVerification.getDefault(environment));
        verifyOffset.execute(getCurrentTestNode());
        return null;
    }

    /**
     * This test verifies that the standard deviation of a set of sampled data from a particular
     * sensor falls into the expectations defined in the CDD. The verification applies to each axis
     * of the sampled data reported by the Sensor under test.
     * This test is used to validate the requirement imposed by the CDD to Sensors in Android. And
     * characterizes how the Sensor behaves while static.
     *
     * The test takes a set of samples from the sensor under test, and calculates the Standard
     * Deviation for each of the axes the Sensor reports data for. The StdDev is compared against
     * the expected value documented in the CDD.
     *
     * The test is susceptible to errors if the device is moving while the test is running, or if
     * the Sensor's sampled data indeed falls into a large StdDev.
     *
     * The assertion associated with the test provides the required data to identify any possible
     * issue. It provides:
     * - the thread id on which the failure occurred
     * - the sensor type and sensor handle that caused the failure
     * - the expectation of the test
     * - the std dev calculated and the axis it applies to
     * Additionally, the device's debug output (adb logcat) dumps the set of values associated with
     * the failure to help track down the issue.
     */
    @SuppressWarnings(""unused"")
    public String testStandardDeviation() throws Throwable {
        getTestLogger().logMessage(R.string.snsr_mag_verify_std_dev);

        TestSensorEnvironment environment = new TestSensorEnvironment(
                getApplicationContext(),
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorManager.SENSOR_DELAY_FASTEST);
        TestSensorOperation verifyStdDev =
                TestSensorOperation.createOperation(environment, 100 /* event count */);

        verifyStdDev.addVerification(new StandardDeviationVerification(
                new float[]{2f, 2f, 2f} /* uT */));
        verifyStdDev.execute(getCurrentTestNode());
        return null;
    }

    /**
     * Verifies that the relationship between readings from calibrated and their corresponding
     * uncalibrated sensors comply to the following equation:
     *      calibrated = uncalibrated - bias
     */
    @SuppressWarnings(""unused"")
    public String testCalibratedAndUncalibrated() throws Throwable {
        getTestLogger().logMessage(R.string.snsr_mag_verify_calibrated_uncalibrated);

        TestSensorEnvironment calibratedEnvironment = new TestSensorEnvironment(
                getApplicationContext(),
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorManager.SENSOR_DELAY_FASTEST);
        TestSensorEnvironment uncalibratedEnvironment = new TestSensorEnvironment(
                getApplicationContext(),
                Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED,
                SensorManager.SENSOR_DELAY_FASTEST);
        SensorCalibratedUncalibratedVerifier verifier = new SensorCalibratedUncalibratedVerifier(
                calibratedEnvironment,
                uncalibratedEnvironment,
                THRESHOLD_CALIBRATED_UNCALIBRATED_UT);

        try {
            verifier.execute();
        } finally {
            playSound();
        }
        return null;
    }

    /**
     * A routine to help operators calibrate the magnetometer.
     */
    private void calibrateMagnetometer() throws InterruptedException {
        TestSensorEnvironment environment = new TestSensorEnvironment(
                getApplicationContext(),
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorManager.SENSOR_DELAY_NORMAL);

        SensorTestLogger logger = getTestLogger();
        logger.logInstructions(R.string.snsr_mag_calibration_description);
        logger.logInstructions(R.string.snsr_mag_calibration_complete);
        waitForUserToContinue();

        TestSensorEventListener listener = new TestSensorEventListener(environment) {
            @Override
            public void onSensorChanged(SensorEvent event) {
                clearText();

                float values[] = event.values;
                logger.logMessage(
                        R.string.snsr_mag_measurement,
                        values[0],
                        values[1],
                        values[2],
                        SensorCtsHelper.getMagnitude(values));
            }
        };

        TestSensorManager magnetometer = new TestSensorManager(environment);
        try {
            magnetometer.registerListener(listener);
            waitForUserToContinue();
        } finally {
            magnetometer.unregisterListener();
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSecurityTests"	"testBiometricStrength_StrongSensor"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSecurityTests.java"	""	"public void testBiometricStrength_StrongSensor() throws Exception {
        final List<Integer> sensors = getSensorsOfTargetStrength(SensorProperties.STRENGTH_STRONG);
        assumeTrue(""testBiometricStrength_StrongSensor: numSensors="" + sensors.size(),
                sensors.size() > 0);

        // Tuple of originalStrength and requestedStrength
        final int[][] testCases = {
                // Request Strong auth
                {Authenticators.BIOMETRIC_STRONG, Authenticators.BIOMETRIC_STRONG},

                // Request Weak auth
                {Authenticators.BIOMETRIC_STRONG, Authenticators.BIOMETRIC_WEAK}
        };

        for (Integer sensorId : sensors) {
            for (int i = 0; i < testCases.length; i++) {
                testBiometricStrength_forSensor_authAllowed(sensorId,
                        testCases[i][0] /* originalStrength */,
                        testCases[i][1] /* requestedStrength */);
            }
        }
    }

    /**
     * A weak biometric may or may not be able to perform auth, depending on the requested strength.
     * For example,
     * +-------------------+--------------------+----------+
     * | Original Strength | Requested Strength | Result   |
     * +-------------------+--------------------+----------+
     * | BIOMETRIC_WEAK    | BIOMETRIC_STRONG   | Error    |
     * +-------------------+--------------------+----------+
     * | BIOMETRIC_WEAK    | BIOMETRIC_WEAK     | Accepted |
     * +-------------------+--------------------+----------+
     * Note that since BiometricPrompt does not support Convenience biometrics, currently we don't
     * have a way to test cases where the requested strength is BIOMETRIC_CONVENIENCE.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSecurityTests"	"testBiometricStrength_WeakSensor"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSecurityTests.java"	""	"public void testBiometricStrength_WeakSensor() throws Exception {
        final List<Integer> sensors = getSensorsOfTargetStrength(SensorProperties.STRENGTH_WEAK);
        assumeTrue(""testBiometricStrength_WeakSensor: numSensors: "" + sensors.size(),
                sensors.size() > 0);

        for (Integer sensorId : sensors) {
            testBiometricStrength_forSensor_authDisallowed(sensorId,
                    Authenticators.BIOMETRIC_WEAK /* originalStrength */,
                    Authenticators.BIOMETRIC_STRONG /* requestedStrength */,
                    mSensorProperties.size() > 1 /* hasMultiSensors */);

            testBiometricStrength_forSensor_authAllowed(sensorId,
                    Authenticators.BIOMETRIC_WEAK /* originalStrength */,
                    Authenticators.BIOMETRIC_WEAK /* requestedStrength */);
        }
    }

    /**
     * A convenience biometric should not be able to perform auth with the following requested
     * strength, due to insufficient strength.
     * +-----------------------+--------------------+--------+
     * | Original Strength     | Requested Strength | Result |
     * +-----------------------+--------------------+--------+
     * | BIOMETRIC_CONVENIENCE | BIOMETRIC_STRONG   | Error  |
     * +-----------------------+--------------------+--------+
     * | BIOMETRIC_CONVENIENCE | BIOMETRIC_WEAK     | Error  |
     * +-----------------------+--------------------+--------+
     * Note that since BiometricPrompt does not support Convenience biometrics, currently we don't
     * have a way to test cases where the requested strength is BIOMETRIC_CONVENIENCE.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSecurityTests"	"testBiometricStrength_ConvenienceSensor"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSecurityTests.java"	""	"public void testBiometricStrength_ConvenienceSensor() throws Exception {
        final List<Integer> sensors =
                getSensorsOfTargetStrength(SensorProperties.STRENGTH_CONVENIENCE);
        assumeTrue(""testBiometricStrength_ConvenienceSensor: numSensors="" + sensors.size(),
                sensors.size() > 0);

        // Tuple of originalStrength and requestedStrength
        final int[][] testCases = {
                // Request Strong auth
                {Authenticators.BIOMETRIC_CONVENIENCE, Authenticators.BIOMETRIC_STRONG},

                // Request Weak auth
                {Authenticators.BIOMETRIC_CONVENIENCE, Authenticators.BIOMETRIC_WEAK}
        };

        for (Integer sensorId : sensors) {
            for (int i = 0; i < testCases.length; i++) {
                testBiometricStrength_forSensor_authDisallowed(sensorId,
                        testCases[i][0] /* originalStrength */,
                        testCases[i][1] /* requestedStrength */,
                        sensors.size() > 1 /* hasMultiSensors */);
            }
        }
    }

    private void testBiometricStrength_forSensor_authAllowed(int sensorId, int originalStrength,
            int requestedStrength) throws Exception {
        Log.d(TAG, ""testBiometricStrength_forSensor_authAllowed: ""
                + "", sensorId="" + sensorId
                + "", originalStrength="" + originalStrength
                + "", requestedStrength="" + requestedStrength);

        final ComponentName componentName = getComponentName(requestedStrength);

        // Reset to the original strength in case it's ever changed before the test
        updateStrengthAndVerify(sensorId, originalStrength);

        try (BiometricTestSession session = mBiometricManager.createTestSession(sensorId);
             ActivitySession activitySession = new ActivitySession(this, componentName)) {
            final int userId = 0;
            waitForAllUnenrolled();
            enrollForSensor(session, sensorId);
            final TestJournal journal =
                    TestJournalContainer.get(activitySession.getComponentName());

            // No error code should be returned for the requested strength
            int errCode = mBiometricManager.canAuthenticate(requestedStrength);
            assertEquals(""Device should allow auth with the requested biometric"",
                    BiometricManager.BIOMETRIC_SUCCESS, errCode);

            // Launch test activity
            launchActivityAndWaitForResumed(activitySession);

            BiometricCallbackHelper.State callbackState = getCallbackState(journal);
            assertNotNull(callbackState);

            BiometricServiceState state = getCurrentState();
            assertTrue(state.toString(), state.mSensorStates.sensorStates.get(sensorId).isBusy());

            // Auth should work
            successfullyAuthenticate(session, userId);
            mInstrumentation.waitForIdleSync();
            callbackState = getCallbackState(journal);
            assertNotNull(callbackState);
            assertEquals(callbackState.toString(), 0, callbackState.mNumAuthRejected);
            assertEquals(callbackState.toString(), 1, callbackState.mNumAuthAccepted);
            assertEquals(callbackState.toString(), 0, callbackState.mAcquiredReceived.size());
            assertEquals(callbackState.toString(), 0, callbackState.mErrorsReceived.size());
        }
    }

    private void testBiometricStrength_forSensor_authDisallowed(int sensorId, int originalStrength,
            int requestedStrength, boolean hasMultiSensors) throws Exception {
        Log.d(TAG, ""testBiometricStrength_forSensor_authDisallowed: ""
                + "", sensorId="" + sensorId
                + "", originalStrength="" + originalStrength
                + "", requestedStrength="" + requestedStrength
                + "", hasMultiSensors="" + hasMultiSensors);

        final ComponentName componentName = getComponentName(requestedStrength);

        // Reset to the original strength in case it's ever changed before the test
        updateStrengthAndVerify(sensorId, originalStrength);

        try (BiometricTestSession session = mBiometricManager.createTestSession(sensorId);
             ActivitySession activitySession = new ActivitySession(this, componentName)) {
            waitForAllUnenrolled();
            enrollForSensor(session, sensorId);
            final TestJournal journal =
                    TestJournalContainer.get(activitySession.getComponentName());

            // Error code should be returned for the requested strength due to insufficient strength
            int errCode = mBiometricManager.canAuthenticate(requestedStrength);
            checkErrCode(""Device shouldn't allow auth with biometrics that have insufficient""
                            + "" strength. errCode: "" + errCode,
                    errCode, BiometricManager.BIOMETRIC_ERROR_NO_HARDWARE,
                    hasMultiSensors);

            // Launch test activity
            launchActivityAndWaitForResumed(activitySession);

            // Auth shouldn't work and error code should be returned
            mInstrumentation.waitForIdleSync();
            BiometricCallbackHelper.State callbackState = getCallbackState(journal);
            assertNotNull(callbackState);
            assertEquals(callbackState.toString(), 0, callbackState.mNumAuthRejected);
            assertEquals(callbackState.toString(), 0, callbackState.mNumAuthAccepted);
            assertEquals(callbackState.toString(), 0, callbackState.mAcquiredReceived.size());
            assertEquals(callbackState.toString(), 1, callbackState.mErrorsReceived.size());
            checkErrCode(callbackState.toString(), (int) callbackState.mErrorsReceived.get(0),
                    BiometricManager.BIOMETRIC_ERROR_NO_HARDWARE, hasMultiSensors);
        }
    }

    /**
     * The strength of a Strong biometric may need to be downgraded to a weaker one if the biometric
     * requires a security update. After downgrading, the biometric may or may not be able to
     * perform auth with the requested strength. For example,
     * +-------------------+-----------------------+--------------------+----------+
     * | Original Strength | Target Strength       | Requested Strength | Result   |
     * +-------------------+-----------------------+--------------------+----------+
     * | BIOMETRIC_STRONG  | BIOMETRIC_WEAK        | BIOMETRIC_STRONG   | Error    |
     * +-------------------+-----------------------+--------------------+----------+
     * | BIOMETRIC_STRONG  | BIOMETRIC_WEAK        | BIOMETRIC_WEAK     | Accepted |
     * +-------------------+-----------------------+--------------------+----------+
     * | BIOMETRIC_STRONG  | BIOMETRIC_CONVENIENCE | BIOMETRIC_STRONG   | Error    |
     * +-------------------+-----------------------+--------------------+----------+
     * | BIOMETRIC_STRONG  | BIOMETRIC_CONVENIENCE | BIOMETRIC_WEAK     | Error    |
     * +-------------------+-----------------------+--------------------+----------+
     * Note that since BiometricPrompt does not support Convenience biometrics, currently we don't
     * have a way to test cases where the requested strength is BIOMETRIC_CONVENIENCE.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSecurityTests"	"testBiometricStrengthDowngraded_StrongSensor"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSecurityTests.java"	""	"public void testBiometricStrengthDowngraded_StrongSensor() throws Exception {
        final List<Integer> sensors = getSensorsOfTargetStrength(SensorProperties.STRENGTH_STRONG);
        assumeTrue(""testBiometricStrengthDowngraded_StrongSensor: numSensors="" + sensors.size(),
                sensors.size() > 0);

        // Tuple of originalStrength, targetStrength, and requestedStrength
        final int[][] testCases = {
                // Downgrade Strong to Weak, and request Strong auth
                {Authenticators.BIOMETRIC_STRONG, Authenticators.BIOMETRIC_WEAK,
                        Authenticators.BIOMETRIC_STRONG},

                // Downgrade Strong to Weak, and request Weak auth
                {Authenticators.BIOMETRIC_STRONG, Authenticators.BIOMETRIC_WEAK,
                        Authenticators.BIOMETRIC_WEAK},

                // Downgrade Strong to Convenience, and request Strong auth
                {Authenticators.BIOMETRIC_STRONG, Authenticators.BIOMETRIC_CONVENIENCE,
                        Authenticators.BIOMETRIC_STRONG},

                // Downgrade Strong to Convenience, and request Weak auth
                {Authenticators.BIOMETRIC_STRONG, Authenticators.BIOMETRIC_CONVENIENCE,
                        Authenticators.BIOMETRIC_WEAK}
        };

        for (Integer sensorId : sensors) {
            for (int i = 0; i < testCases.length; i++) {
                testBiometricStrengthDowngraded_forSensor(sensorId,
                        testCases[i][0] /* originalStrength */,
                        testCases[i][1] /* targetStrength */,
                        testCases[i][2] /* requestedStrength */,
                        mSensorProperties.size() > 1 /* hasMultiSensors */);
            }
        }
    }

    /**
     * The strength of a Weak biometric may need to be downgraded to a weaker one if the biometric
     * requires a security update. After downgrading, the biometric may or may not be able to
     * perform auth with the requested strength. For example,
     * +-------------------+-----------------------+--------------------+--------+
     * | Original Strength | Target Strength       | Requested Strength | Result |
     * +-------------------+-----------------------+--------------------+--------+
     * | BIOMETRIC_WEAK    | BIOMETRIC_CONVENIENCE | BIOMETRIC_WEAK     | Error  |
     * +-------------------+-----------------------+--------------------+--------+
     * Note that since BiometricPrompt does not support Convenience biometrics, currently we don't
     * have a way to test cases where the requested strength is BIOMETRIC_CONVENIENCE.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSecurityTests"	"testBiometricStrengthDowngraded_WeakSensor"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSecurityTests.java"	""	"public void testBiometricStrengthDowngraded_WeakSensor() throws Exception {
        final List<Integer> sensors = getSensorsOfTargetStrength(SensorProperties.STRENGTH_WEAK);
        assumeTrue(""testBiometricStrengthDowngraded_WeakSensor: numSensors: "" + sensors.size(),
                sensors.size() > 0);

        // Tuple of originalStrength, targetStrength, and requestedStrength
        final int[][] testCases = {
                // Downgrade Weak to Convenience, and request Weak auth
                {Authenticators.BIOMETRIC_WEAK, Authenticators.BIOMETRIC_CONVENIENCE,
                        Authenticators.BIOMETRIC_WEAK}
        };

        for (Integer sensorId : sensors) {
            for (int i = 0; i < testCases.length; i++) {
                testBiometricStrengthDowngraded_forSensor(sensorId,
                        testCases[i][0] /* originalStrength */,
                        testCases[i][1] /* targetStrength */,
                        testCases[i][2] /* requestedStrength */,
                        mSensorProperties.size() > 1 /* hasMultiSensors */);
            }
        }
    }

    private void testBiometricStrengthDowngraded_forSensor(int sensorId, int originalStrength,
            int targetStrength, int requestedStrength, boolean hasMultiSensors) throws Exception {
        Log.d(TAG, ""testBiometricStrengthDowngraded_forSensor: ""
                + "", sensorId="" + sensorId
                + "", originalStrength="" + originalStrength
                + "", targetStrength="" + targetStrength
                + "", requestedStrength="" + requestedStrength
                + "", hasMultiSensors="" + hasMultiSensors);

        final ComponentName componentName = getComponentName(requestedStrength);

        try (BiometricTestSession session = mBiometricManager.createTestSession(sensorId);
             ActivitySession activitySession = new ActivitySession(this, componentName)) {
            final int userId = 0;
            waitForAllUnenrolled();
            enrollForSensor(session, sensorId);
            final TestJournal journal =
                    TestJournalContainer.get(activitySession.getComponentName());

            BiometricCallbackHelper.State callbackState;
            BiometricServiceState state;

            // Downgrade the biometric strength to the target strength
            updateStrengthAndVerify(sensorId, targetStrength);

            // After downgrading, check whether auth works
            // TODO: should check if targetStrength is at least as strong as the requestedStrength,
            // but some strength constants that are needed for the calculation are not exposed in
            // BiometricManager.
            if (targetStrength == requestedStrength) {
                Log.d(TAG, ""The targetStrength is as strong as the requestedStrength"");
                // No error code should be returned since biometric has sufficient strength if
                // request weak auth
                int errCode = mBiometricManager.canAuthenticate(requestedStrength);
                assertEquals(""Device should allow auth with the requested biometric"",
                        BiometricManager.BIOMETRIC_SUCCESS, errCode);

                // Launch test activity
                launchActivityAndWaitForResumed(activitySession);

                state = getCurrentState();
                assertTrue(state.toString(),
                        state.mSensorStates.sensorStates.get(sensorId).isBusy());

                // Auth should work
                successfullyAuthenticate(session, userId);
                mInstrumentation.waitForIdleSync();
                callbackState = getCallbackState(journal);
                assertNotNull(callbackState);
                assertEquals(callbackState.toString(), 0, callbackState.mNumAuthRejected);
                assertEquals(callbackState.toString(), 1, callbackState.mNumAuthAccepted);
                assertEquals(callbackState.toString(), 0, callbackState.mAcquiredReceived.size());
                assertEquals(callbackState.toString(), 0, callbackState.mErrorsReceived.size());
            } else {
                Log.d(TAG, ""The targetStrength is not strong enough"");
                // Error code should be returned
                int errCode = mBiometricManager.canAuthenticate(requestedStrength);
                checkErrCode(""Device shouldn't allow auth with biometrics that require security""
                                + "" update. errCode: "" + errCode,
                        errCode, BiometricManager.BIOMETRIC_ERROR_SECURITY_UPDATE_REQUIRED,
                        hasMultiSensors);

                // Launch test activity
                launchActivityAndWaitForResumed(activitySession);

                // Auth shouldn't work and error code should be returned
                mInstrumentation.waitForIdleSync();
                callbackState = getCallbackState(journal);
                assertNotNull(callbackState);
                assertEquals(callbackState.toString(), 0, callbackState.mNumAuthRejected);
                assertEquals(callbackState.toString(), 0, callbackState.mNumAuthAccepted);
                assertEquals(callbackState.toString(), 0, callbackState.mAcquiredReceived.size());
                assertEquals(callbackState.toString(), 1, callbackState.mErrorsReceived.size());
                checkErrCode(callbackState.toString(), (int) callbackState.mErrorsReceived.get(0),
                        BiometricManager.BIOMETRIC_ERROR_SECURITY_UPDATE_REQUIRED, hasMultiSensors);
            }
        }
    }

    /**
     * Trying to upgrade the strength of a Weak biometric to a stronger strength will not
     * succeed (ie, it's no-op and the biometric strength is still Weak), since the biometric's
     * actual strength can't go past its original strength. After upgrading, the biometric without
     * sufficient strength should not be able to perform the requested auth. For example,
     * +-------------------+------------------+--------------------+--------+
     * | Original Strength | Target Strength  | Requested Strength | Result |
     * +-------------------+------------------+--------------------+--------+
     * | BIOMETRIC_WEAK    | BIOMETRIC_STRONG | BIOMETRIC_STRONG   | Error  |
     * +-------------------+------------------+--------------------+--------+
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSecurityTests"	"testBiometricStrengthUpgraded_WeakSensor"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSecurityTests.java"	""	"public void testBiometricStrengthUpgraded_WeakSensor() throws Exception {
        final List<Integer> sensors = getSensorsOfTargetStrength(SensorProperties.STRENGTH_WEAK);
        assumeTrue(""testBiometricStrengthUpgraded_WeakSensor: numSensors: "" + sensors.size(),
                sensors.size() > 0);

        // Tuple of originalStrength, targetStrength, and requestedStrength
        final int[][] testCases = {
                // Upgrade Weak to Strong, and request Strong auth
                {Authenticators.BIOMETRIC_WEAK, Authenticators.BIOMETRIC_STRONG,
                        Authenticators.BIOMETRIC_STRONG}
        };

        for (Integer sensorId : sensors) {
            for (int i = 0; i < testCases.length; i++) {
                testBiometricStrengthUpgraded_forSensor(sensorId,
                        testCases[i][0] /* originalStrength */,
                        testCases[i][1] /* targetStrength */,
                        testCases[i][2] /* requestedStrength */,
                        mSensorProperties.size() > 1 /* hasMultiSensors */);
            }
        }
    }

    /**
     * Trying to upgrade the strength of a Convenience biometric to a stronger strength will not
     * succeed (ie, it's no-op and the biometric strength is still Convenience), since the
     * biometric's actual strength can't go past its original strength. After upgrading, the
     * biometric without sufficient strength should not be able to perform the requested auth.
     * For example,
     * +-----------------------+------------------+--------------------+--------+
     * | Original Strength     | Target Strength  | Requested Strength | Result |
     * +-----------------------+------------------+--------------------+--------+
     * | BIOMETRIC_CONVENIENCE | BIOMETRIC_STRONG | BIOMETRIC_STRONG   | Error  |
     * +-----------------------+------------------+--------------------+--------+
     * | BIOMETRIC_CONVENIENCE | BIOMETRIC_STRONG | BIOMETRIC_WEAK     | Error  |
     * +-----------------------+------------------+--------------------+--------+
     * | BIOMETRIC_CONVENIENCE | BIOMETRIC_WEAK   | BIOMETRIC_WEAK     | Error  |
     * +-----------------------+------------------+--------------------+--------+
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSecurityTests"	"testBiometricStrengthUpgraded_ConvenienceSensor"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSecurityTests.java"	""	"public void testBiometricStrengthUpgraded_ConvenienceSensor() throws Exception {
        final List<Integer> sensors =
                getSensorsOfTargetStrength(SensorProperties.STRENGTH_CONVENIENCE);
        assumeTrue(""testBiometricStrengthUpgraded_ConvenienceSensor: numSensors="" + sensors.size(),
                sensors.size() > 0);

        // Tuple of originalStrength, targetStrength, and requestedStrength
        final int[][] testCases = {
                // Upgrade Convenience to Strong, and request Strong auth
                {Authenticators.BIOMETRIC_CONVENIENCE, Authenticators.BIOMETRIC_STRONG,
                        Authenticators.BIOMETRIC_STRONG},

                // Upgrade Convenience to Strong, and request Weak auth
                {Authenticators.BIOMETRIC_CONVENIENCE, Authenticators.BIOMETRIC_STRONG,
                        Authenticators.BIOMETRIC_WEAK},

                // Upgrade Convenience to Weak, and request Weak auth
                {Authenticators.BIOMETRIC_CONVENIENCE, Authenticators.BIOMETRIC_WEAK,
                        Authenticators.BIOMETRIC_WEAK}
        };

        for (Integer sensorId : sensors) {
            for (int i = 0; i < testCases.length; i++) {
                testBiometricStrengthUpgraded_forSensor(sensorId,
                        testCases[i][0] /* originalStrength */,
                        testCases[i][1] /* targetStrength */,
                        testCases[i][2] /* requestedStrength */,
                        sensors.size() > 1 /* hasMultiSensors */);
            }
        }
    }

    private void testBiometricStrengthUpgraded_forSensor(int sensorId, int originalStrength,
            int targetStrength, int requestedStrength, boolean hasMultiSensors) throws Exception {
        Log.d(TAG, ""testBiometricStrengthUpgraded_forSensor: ""
                + ""sensorId="" + sensorId
                + "", originalStrength="" + originalStrength
                + "", targetStrength="" + targetStrength
                + "", requestedStrength="" + requestedStrength
                + "", hasMultiSensors="" + hasMultiSensors);

        final ComponentName componentName = getComponentName(requestedStrength);

        // Reset to the original strength in case it's ever changed before the test
        updateStrengthAndVerify(sensorId, originalStrength);

        try (BiometricTestSession session = mBiometricManager.createTestSession(sensorId);
             ActivitySession activitySession = new ActivitySession(this, componentName)) {
            waitForAllUnenrolled();
            enrollForSensor(session, sensorId);
            final TestJournal journal =
                    TestJournalContainer.get(activitySession.getComponentName());

            // Try to upgrade the biometric strength to the target strength. The upgrading operation
            // is no-op since the biometric can't be upgraded past its original strength.
            updateStrengthAndIdle(sensorId, targetStrength);
            final int currentStrength = getCurrentStrength(sensorId);
            assertTrue(""currentStrength: "" + currentStrength, currentStrength == originalStrength);

            // After upgrading, check whether auth works
            // Error code should be returned
            int errCode = mBiometricManager.canAuthenticate(requestedStrength);
            checkErrCode(""Device shouldn't allow auth with biometrics without sufficient strength.""
                            + "" errCode: "" + errCode,
                    errCode, BiometricManager.BIOMETRIC_ERROR_NO_HARDWARE, hasMultiSensors);

            // Launch test activity
            launchActivityAndWaitForResumed(activitySession);

            // Auth shouldn't work and error code should be returned
            mInstrumentation.waitForIdleSync();
            BiometricCallbackHelper.State callbackState = getCallbackState(journal);
            assertNotNull(callbackState);
            assertEquals(callbackState.toString(), 0, callbackState.mNumAuthRejected);
            assertEquals(callbackState.toString(), 0, callbackState.mNumAuthAccepted);
            assertEquals(callbackState.toString(), 0, callbackState.mAcquiredReceived.size());
            assertEquals(callbackState.toString(), 1, callbackState.mErrorsReceived.size());
            checkErrCode(callbackState.toString(), (int) callbackState.mErrorsReceived.get(0),
                    BiometricManager.BIOMETRIC_ERROR_NO_HARDWARE, hasMultiSensors);
        }
    }

    private void checkErrCode(String msg, int errCode, int expectedErrCode,
            boolean hasMultiSensors) {
        if (!hasMultiSensors) {
            assertTrue(msg, errCode == expectedErrCode);
        } else {
            // In the multi-sensor case, error code for the first ineligible sensor may be
            // returned so the following error codes are accepted
            assertTrue(msg, errCode == expectedErrCode
                    || errCode == BiometricManager.BIOMETRIC_ERROR_NONE_ENROLLED
                    || errCode == BiometricManager.BIOMETRIC_ERROR_NO_HARDWARE);
        }
    }

    private static ComponentName getComponentName(int requestedStrength) {
        assertTrue(""requestedStrength: "" + requestedStrength,
                requestedStrength == Authenticators.BIOMETRIC_STRONG ||
                        requestedStrength == Authenticators.BIOMETRIC_WEAK);

        if (requestedStrength == Authenticators.BIOMETRIC_STRONG) {
            return CLASS_3_BIOMETRIC_ACTIVITY;
        }
        return CLASS_2_BIOMETRIC_ACTIVITY;
    }

    private static void revertSensorStrengths() throws Exception {
        Log.d(TAG, ""revertSensorStrengths"");
        Utils.executeShellCommand(""device_config delete "" +
                DEVICE_CONFIG_NAMESPACE + "" "" +
                DEVICE_CONFIG_BIO_STRENGTH_KEY);
        // this is probably not needed, but there are not too many tests so pause to ensure
        // the settings have settled
        Thread.sleep(1000);
    }

    private void updateStrengthAndVerify(int sensorId, int targetStrength) throws Exception {
        updateSensorStrength(sensorId, targetStrength, /* verify */ true);
    }

    private void updateStrengthAndIdle(int sensorId, int targetStrength) throws Exception {
        updateSensorStrength(sensorId, targetStrength, /* verify */ false);
    }

    private void updateSensorStrength(int sensorId, int targetStrength, boolean verify)
            throws Exception {
        Log.d(TAG, ""updateStrength: update sensorId="" + sensorId + "" to targetStrength=""
                + targetStrength);
        Utils.executeShellCommand(""device_config put "" +
                DEVICE_CONFIG_NAMESPACE + "" "" +
                DEVICE_CONFIG_BIO_STRENGTH_KEY + "" "" +
                String.format(""%s:%s"", sensorId, targetStrength));

        final boolean matchesTarget = waitForSensorToBecomeStrength(sensorId, targetStrength);
        if (verify && !matchesTarget) {
            fail(""Timed out waiting for sensorId "" + sensorId + "" to become target strength: ""
                    + targetStrength);
        }
    }

    private boolean waitForSensorToBecomeStrength(int sensorId, int targetStrength)
            throws Exception {
        for (int i = 0; i < 20; i++) {
            final int currentStrength = getCurrentStrength(sensorId);
            if (currentStrength == targetStrength) {
                return true;
            }
            Log.d(TAG, ""Not at target strength yet, current: "" + currentStrength);
            Thread.sleep(300);
        }
        return false;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.MotionIndicatorView"	"testUI"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/MotionIndicatorView.java"	""	"public void testUI()  {
 *     final int MAX_TILT_ANGLE = 70; // +/- 70
 *
 *     final int TILT_ANGLE_STEP = 5; // 5 degree(s) per step
 *     final int YAW_ANGLE_STEP = 10; // 10 degree(s) per step
 *
 *     RangeCoveredRegister xCovered, yCovered, zCovered;
 *     xCovered = new RangeCoveredRegister(-MAX_TILT_ANGLE, +MAX_TILT_ANGLE, TILT_ANGLE_STEP);
 *
 *     yCovered = new RangeCoveredRegister(-MAX_TILT_ANGLE, +MAX_TILT_ANGLE, TILT_ANGLE_STEP);
 *     zCovered = new RangeCoveredRegister(YAW_ANGLE_STEP);
 *
 *     xCovered.update(40);
 *     xCovered.update(-40);
 *     xCovered.update(12);
 *
 *     yCovered.update(50);
 *     yCovered.update(-51);
 *
 *     zCovered.update(150);
 *     zCovered.update(42);
 *
 *     setDataProvider(xCovered, yCovered, zCovered);
 *     enableAxis(RVCVRecordActivity.AXIS_ALL); //debug mode, show all three axis
 * }
 */
public class MotionIndicatorView extends View {
    private final String TAG = ""MotionIndicatorView"";
    private final boolean LOCAL_LOGV = false;

    private Paint mCursorPaint;
    private Paint mLimitPaint;
    private Paint mCoveredPaint;
    private Paint mRangePaint;
    private Paint mEraserPaint;

    // UI settings
    private final int XBAR_WIDTH = 50;
    private final int XBAR_MARGIN = 50;
    private final int XBAR_CURSOR_ADD = 20;

    private final int YBAR_WIDTH = 50;
    private final int YBAR_MARGIN = 50;
    private final int YBAR_CURSOR_ADD = 20;

    private final int ZRING_WIDTH = 50;
    private final int ZRING_CURSOR_ADD = 30;


    private int mXSize, mYSize;
    private RectF mZBoundOut, mZBoundOut2, mZBoundIn, mZBoundIn2;

    private RangeCoveredRegister mXCovered, mYCovered, mZCovered;

    private boolean mXEnabled, mYEnabled, mZEnabled;

    private boolean mIsDeviceRotated = false;

    /**
     * Constructor
     * @param context
     */
    public MotionIndicatorView(Context context) {
        super(context);
        init();
    }

    /**
     * Constructor
     * @param context Application context
     * @param attrs
     */
    public MotionIndicatorView(Context context, AttributeSet attrs) {
        super(context, attrs);
        init();
    }

    /**
     * Initialize the Paint objects
     */
    private void init() {

        mCursorPaint = new Paint();
        mCursorPaint.setColor(Color.BLUE);

        mLimitPaint = new Paint();
        mLimitPaint.setColor(Color.YELLOW);

        mCoveredPaint = new Paint();
        mCoveredPaint.setColor(Color.CYAN);

        mRangePaint = new Paint();
        mRangePaint.setColor(Color.DKGRAY);

        mEraserPaint = new Paint();
        mEraserPaint.setColor(Color.TRANSPARENT);
        // ensure the erasing effect
        mEraserPaint.setXfermode(new PorterDuffXfermode(PorterDuff.Mode.SRC));
    }

    /**
     * Connect the view to certain data provider objects
     * @param x Data provider for x direction tilt angle
     * @param y Data provider for y direction tilt angle
     * @param z Data provider for z rotation
     */
    public void setDataProvider(RangeCoveredRegister x,
                                RangeCoveredRegister y,
                                RangeCoveredRegister z)    {
        mXCovered = x;
        mYCovered = y;
        mZCovered = z;
    }

    /**
     * Set the device's current rotation
     * @param rotation Surface.ROTATION_0, Surface.ROTATION_90, Surface.ROTATION_180, or
     *                 Surface.ROTATION_270
     */
    public void setDeviceRotation(int rotation) {
        mIsDeviceRotated = (rotation == Surface.ROTATION_90 || rotation == Surface.ROTATION_270);
    }

    /**
     * Set the active axis for display
     *
     * @param axis AXIS_X, AXIS_Y, AXIS_Z for x, y, z axis indicators, or AXIS_ALL for all three.
     */
    public void enableAxis(int axis)  {
        mXEnabled = mYEnabled = mZEnabled = false;

        switch(axis)
        {
            case SensorManager.AXIS_X:
                mXEnabled = true;
                break;
            case SensorManager.AXIS_Y:
                mYEnabled = true;
                break;
            case SensorManager.AXIS_Z:
                mZEnabled = true;
                break;
            case RVCVRecordActivity.AXIS_ALL:
                mXEnabled = mYEnabled = mZEnabled = true;
        }
    }

    /**
     * Doing some pre-calculation that only changes when view dimensions are changed.
     * @param w
     * @param h
     * @param oldw
     * @param oldh
     */
    @Override
    protected void onSizeChanged (int w, int h, int oldw, int oldh) {
        mXSize = w;
        mYSize = h;

        float halfSideLength = 0.4f * Math.min(w, h);
        float leftSide = w/2 - halfSideLength;
        float topSide = h/2 - halfSideLength;
        float rightSide = w/2 + halfSideLength;
        float bottomSide = h/2 + halfSideLength;

        mZBoundOut = new RectF(leftSide, topSide, rightSide, bottomSide);
        mZBoundOut2 = new RectF(
                leftSide-ZRING_CURSOR_ADD, topSide-ZRING_CURSOR_ADD,
                rightSide+ZRING_CURSOR_ADD, bottomSide+ZRING_CURSOR_ADD);
        mZBoundIn = new RectF(
                leftSide+ZRING_WIDTH, topSide+ZRING_WIDTH,
                rightSide-ZRING_WIDTH, bottomSide-ZRING_WIDTH);
        mZBoundIn2 = new RectF(
                leftSide+ZRING_WIDTH+ZRING_CURSOR_ADD, topSide+ZRING_WIDTH+ZRING_CURSOR_ADD,
                rightSide-ZRING_WIDTH-ZRING_CURSOR_ADD, bottomSide-ZRING_WIDTH-ZRING_CURSOR_ADD);

        if (LOCAL_LOGV) Log.v(TAG, ""New view size = (""+w+"", ""+h+"")"");
    }

    /**
     * Draw UI depends on the selected axis and registered value
     *
     * @param canvas the canvas to draw on
     */
    @Override
    protected void onDraw(Canvas canvas) {
        super.onDraw(canvas);
        int i,t;

        Paint p = new Paint();
        p.setColor(Color.YELLOW);
        canvas.drawRect(10,10, 50, 50, p);

        // In order to determine which progress bar to draw, the device's rotation must be accounted
        // for since the accelerometer rotates with the display.
        boolean drawX = (mXEnabled && !mIsDeviceRotated) || (mYEnabled && mIsDeviceRotated);
        boolean drawY = (mYEnabled && !mIsDeviceRotated) || (mXEnabled && mIsDeviceRotated);

        if (drawX && mXCovered != null) {
            RangeCoveredRegister covered = mIsDeviceRotated ? mYCovered : mXCovered;
            int xNStep = covered.getNSteps() + 4; // two on each side as a buffer
            int xStepSize = mXSize * 3/4 / xNStep;
            int xLeft = mXSize * 1/8 + (mXSize * 3/4 % xNStep)/2;

            // base bar
            canvas.drawRect(xLeft, XBAR_MARGIN,
                    xLeft+xStepSize*xNStep-1, XBAR_WIDTH+XBAR_MARGIN, mRangePaint);

            // covered range
            for (i=0; i<covered.getNSteps(); ++i) {
                if (covered.isCovered(i)) {
                    canvas.drawRect(
                            xLeft+xStepSize*(i+2), XBAR_MARGIN,
                            xLeft+xStepSize*(i+3)-1, XBAR_WIDTH + XBAR_MARGIN,
                            mCoveredPaint);
                }
            }

            // limit
            canvas.drawRect(xLeft+xStepSize*2-4, XBAR_MARGIN,
                    xLeft+xStepSize*2+3, XBAR_WIDTH+XBAR_MARGIN, mLimitPaint);
            canvas.drawRect(xLeft+xStepSize*(xNStep-2)-4, XBAR_MARGIN,
                    xLeft+xStepSize*(xNStep-2)+3, XBAR_WIDTH+XBAR_MARGIN, mLimitPaint);

            // cursor
            t = (int)(xLeft+xStepSize*(covered.getLastValue()+2));
            canvas.drawRect(t-4, XBAR_MARGIN-XBAR_CURSOR_ADD, t+3,
                    XBAR_WIDTH+XBAR_MARGIN+XBAR_CURSOR_ADD, mCursorPaint);
        }

        if (drawY && mYCovered != null) {
            RangeCoveredRegister covered = mIsDeviceRotated ? mXCovered : mYCovered;
            int yNStep = covered.getNSteps() + 4; // two on each side as a buffer
            int yStepSize = mYSize * 3/4 / yNStep;
            int yLeft = mYSize * 1/8 + (mYSize * 3/4 % yNStep)/2;

            // base bar
            canvas.drawRect(YBAR_MARGIN, yLeft,
                    YBAR_WIDTH+YBAR_MARGIN, yLeft+yStepSize*yNStep-1, mRangePaint);

            // covered range
            for (i=0; i<covered.getNSteps(); ++i) {
                if (covered.isCovered(i)) {
                    canvas.drawRect(
                            YBAR_MARGIN, yLeft+yStepSize*(i+2),
                            YBAR_WIDTH + YBAR_MARGIN, yLeft+yStepSize*(i+3)-1,
                            mCoveredPaint);
                }
            }

            // limit
            canvas.drawRect(YBAR_MARGIN, yLeft + yStepSize * 2 - 4,
                    YBAR_WIDTH + YBAR_MARGIN, yLeft + yStepSize * 2 + 3, mLimitPaint);
            canvas.drawRect(YBAR_MARGIN, yLeft + yStepSize * (yNStep - 2) - 4,
                    YBAR_WIDTH + YBAR_MARGIN, yLeft + yStepSize * (yNStep - 2) + 3, mLimitPaint);

            // cursor
            t = (int)(yLeft+yStepSize*(covered.getLastValue()+2));
            canvas.drawRect( YBAR_MARGIN-YBAR_CURSOR_ADD, t-4,
                    YBAR_WIDTH+YBAR_MARGIN+YBAR_CURSOR_ADD, t+3, mCursorPaint);
        }

        if (mZEnabled && mZCovered != null) {
            float stepSize  = 360.0f/mZCovered.getNSteps();

            // base bar
            canvas.drawArc(mZBoundOut,0, 360, true, mRangePaint);

            // covered range
            for (i=0; i<mZCovered.getNSteps(); ++i) {
                if (mZCovered.isCovered(i)) {
                    canvas.drawArc(mZBoundOut,i*stepSize-0.2f, stepSize+0.4f,
                            true, mCoveredPaint);
                }
            }
            // clear center
            canvas.drawArc(mZBoundIn, 0, 360, true, mEraserPaint);
            // cursor
            canvas.drawArc(mZBoundOut2, mZCovered.getLastValue()*stepSize- 1, 2,
                    true, mCursorPaint);
            canvas.drawArc(mZBoundIn2, mZCovered.getLastValue()*stepSize-1.5f, 3,
                    true, mEraserPaint);
        }
    }
}

/**
 *  A range register class for the RVCVRecord Activity
 */
class RangeCoveredRegister {
    enum MODE {
        LINEAR,
        ROTATE2D
    }

    private boolean[] mCovered;
    private MODE mMode;
    private int mStep;
    private int mLow, mHigh;
    private int mLastData;

    // high is not inclusive
    RangeCoveredRegister(int low, int high, int step) {
        mMode = MODE.LINEAR;
        mStep = step;
        mLow = low;
        mHigh = high;
        init();
    }

    RangeCoveredRegister(int step) {
        mMode = MODE.ROTATE2D;
        mStep = step;
        mLow = 0;
        mHigh = 360;
        init();
    }

    private void init() {
        if (mMode == MODE.LINEAR) {
            mCovered = new boolean[(mHigh-mLow)/mStep];
        }else {
            mCovered = new boolean[360/mStep];
        }
    }

    /**
     * Test if the range specified by (low, high) is covered.
     *
     * If it is LINEAR mode, the range will be quantized to nearest step boundary. If it is the
     * ROTATE2D mode, it is the same as isFullyCovered().
     *
     * @param low The low end of the range.
     * @param high The high end of the range.
     * @return if the specified range is covered, return true; otherwise false.
     */
    public boolean isRangeCovered(int low, int high) {
        if (mMode == MODE.LINEAR) {
            int iLow = Math.max(Math.round((low - mLow) / mStep), 0);
            int iHigh = Math.min(Math.round((high - mLow) / mStep), mCovered.length-1);

            for (int i = iLow; i <= iHigh; ++i) {
                if (!mCovered[i]) {
                    return false;
                }
            }
            return true;

        } else {
            return isFullyCovered();
        }
    }

    /**
     * Test if the range defined is fully covered.
     *
     * @return if the range is fully covered, return true; otherwise false.
     */
    public boolean isFullyCovered() {
        for (boolean i : mCovered) {
            if (!i) return false;
        }
        return true;
    }

    /**
     * Test if a specific step is covered.
     *
     * @param i the step number
     * @return if the step specified is covered, return true; otherwise false.
     */
    public boolean isCovered(int i) {
        return mCovered[i];
    }

    /**
     *
     *
     * @param data
     * @return if this update changes the status of
     */
    public boolean update(int data) {
        mLastData = data;

        if (mMode == MODE.ROTATE2D) {
            data %= 360;
        }

        int iStep = (data - mLow)/mStep;

        if (iStep>=0 && iStep<getNSteps()) {
            // only record valid data
            mLastData = data;

            if (mCovered[iStep]) {
                return false;
            } else {
                mCovered[iStep] = true;
                return true;
            }
        }
        return false;
    }

    /**
     * Get the number of steps in this register
     *
     * @return The number of steps in this register
     */
    public int getNSteps() {
        //if (mCovered == null) {
        //return 0;
        //}
        return mCovered.length;
    }

    /**
     * Get the last value updated
     *
     * @return The last value updated
     */
    public float getLastValue() {
        // ensure float division
        return ((float)(mLastData - mLow))/mStep;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Utils.Path.ComplexMovementPath"	"isEntered"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Utils/Path/ComplexMovementPath.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Utils.Path;

import java.util.ArrayList;
import java.util.Random;

import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.VECTOR_2D;
import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.X;
import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.Y;
import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.Z;
import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.dotProduct;

import com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointRingNotEnteredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Ring;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Waypoint;

/**
 * Handles all the path properties of the ComplexMovement Path.
 */
public class ComplexMovementPath extends com.android.cts.verifier.sensors.sixdof.Utils.Path.Path {
    public static final float DISTANCE_FOR_RING_POSITION = 0.25f;
    public static final int RINGS_PER_PATH = 5;

    private ArrayList<Ring> mRings = new ArrayList<>();
    private Random mRandomGenerator = new Random();
    private int mCurrentLap = 0;
    private float mLocationMapping[][];

    /**
     * Possible locations for a ring.
     */
    private enum RingLocations {
        ORIGINAL,
        TOP,
        DOWN,
        LEFT,
        RIGHT,
        TOP_LEFT,
        TOP_RIGHT,
        BOTTOM_LEFT,
        BOTTOM_RIGHT,
    }

    /**
     * Constructor for this class does the mapping and the creation of rings.
     *
     * @param referencePathDistances The distance between the markers in the reference path
     * @param referencePath          The reference path
     */
    public ComplexMovementPath(
            ArrayList<Float> referencePathDistances, ArrayList<Waypoint> referencePath) {
        mapNineRingLocations();
        generatePathRings(referencePathDistances, referencePath);
    }

    /**
     * Defines the different ring locations that can be used when adding the rings.
     */
    private void mapNineRingLocations() {
        mLocationMapping = new float[RingLocations.values().length][2];
        mLocationMapping[RingLocations.ORIGINAL.ordinal()] = new float[]{0f, 0f};
        mLocationMapping[RingLocations.TOP.ordinal()] =
                new float[]{0f, DISTANCE_FOR_RING_POSITION};
        mLocationMapping[RingLocations.DOWN.ordinal()] =
                new float[]{0f, -DISTANCE_FOR_RING_POSITION};
        mLocationMapping[RingLocations.LEFT.ordinal()] =
                new float[]{-DISTANCE_FOR_RING_POSITION, 0f};
        mLocationMapping[RingLocations.RIGHT.ordinal()] =
                new float[]{DISTANCE_FOR_RING_POSITION, 0f};
        mLocationMapping[RingLocations.TOP_LEFT.ordinal()] =
                new float[]{-DISTANCE_FOR_RING_POSITION, DISTANCE_FOR_RING_POSITION};
        mLocationMapping[RingLocations.TOP_RIGHT.ordinal()] =
                new float[]{DISTANCE_FOR_RING_POSITION, DISTANCE_FOR_RING_POSITION};
        mLocationMapping[RingLocations.BOTTOM_LEFT.ordinal()] =
                new float[]{-DISTANCE_FOR_RING_POSITION, -DISTANCE_FOR_RING_POSITION};
        mLocationMapping[RingLocations.BOTTOM_RIGHT.ordinal()] =
                new float[]{DISTANCE_FOR_RING_POSITION, -DISTANCE_FOR_RING_POSITION};
    }

    /**
     * Performs ComplexMovement path related checks on a marker.
     *
     * @param coordinates the coordinates for the waypoint
     * @throws WaypointRingNotEnteredException if a ring is not entered
     */
    @Override
    public void additionalChecks(float[] coordinates) throws WaypointRingNotEnteredException {
        if (mCurrentLap != 0) {
            for (Ring ring : mRings) {
                if (ring.getPathNumber() == mCurrentLap && !ring.isEntered()) {
                    throw new WaypointRingNotEnteredException();
                }
            }
        }
        mCurrentLap++;
    }

    /**
     * Generates the rings for this path.
     *
     * @param referencePathDistances The distance between the markers in the reference path
     * @param referencePath          The reference path
     */
    private void generatePathRings(
            ArrayList<Float> referencePathDistances, ArrayList<Waypoint> referencePath) {
        ArrayList<Float> distanceBetweenRingSections;
        distanceBetweenRingSections = calculateSectionDistance(referencePathDistances);
        addRingsToPath(referencePath, distanceBetweenRingSections);
    }

    /**
     * Calculates the distance between the rings in a path.
     *
     * @param referencePathDistances The distance between the markers in the reference path.
     * @return The length of a section in the different paths.
     */
    private ArrayList<Float> calculateSectionDistance(ArrayList<Float> referencePathDistances) {
        ArrayList<Float> arrayToReturn = new ArrayList<>();
        for (Float distance : referencePathDistances) {
            arrayToReturn.add(distance / (RINGS_PER_PATH + 1f));
        }
        return arrayToReturn;
    }

    /**
     * Calculates the location for the ring and adds it to the path.
     *
     * @param referencePath               The reference path.
     * @param distanceBetweenRingSections The length of a section in the different paths.
     */
    private void addRingsToPath(
            ArrayList<Waypoint> referencePath, ArrayList<Float> distanceBetweenRingSections) {
        int currentPath = 0;
        Waypoint currentWaypoint = referencePath.get(0);
        for (Float pathIntervalDistance : distanceBetweenRingSections) {
            currentPath++;
            for (int i = 0; i < RINGS_PER_PATH; i++) {
                currentWaypoint = calculateRingLocationOnPath(
                        referencePath, referencePath.indexOf(currentWaypoint), pathIntervalDistance);
                mRings.add(createRing(referencePath, currentWaypoint, currentPath));
            }
            while (!currentWaypoint.isUserGenerated()) {
                currentWaypoint = referencePath.get(referencePath.indexOf(currentWaypoint) + 1);
            }
        }
    }

    /**
     * Creates the ring that will be added onto the path.
     *
     * @param referencePath The reference path.
     * @param waypoint      The waypoint which the ring will be located at.
     * @param currentPath   The part of the lap in which the ring will be placed.
     * @return A reference to the ring created.
     */
    private Ring createRing(ArrayList<Waypoint> referencePath, Waypoint waypoint, int currentPath) {
        float[] ringCenter = waypoint.getCoordinates();
        float[] pointRotation = calculateRingRotation(ringCenter,
                referencePath.get(referencePath.indexOf(waypoint) - 1).getCoordinates());
        int randomNumber = mRandomGenerator.nextInt(RingLocations.values().length);
        RingLocations ringLocationDifference = RingLocations.values()[randomNumber];
        ringCenter[X] += mLocationMapping[ringLocationDifference.ordinal()][0];
        ringCenter[Z] += mLocationMapping[ringLocationDifference.ordinal()][1];
        ArrayList<float[]> rotatedRect = calculateRectangleHitbox(ringCenter, pointRotation);
        return new Ring(ringCenter, currentPath, pointRotation, rotatedRect);
    }

    /**
     * Calculates the orientation of the ring.
     *
     * @param location1 The location of the first point.
     * @param location2 The location of the second point.
     * @return the rotation needed to get the orientation of the ring.
     */
    private float[] calculateRingRotation(float[] location1, float[] location2) {
        float[] rotation = new float[3];
        rotation[X] = location2[X] - location1[X];
        rotation[Y] = location2[Y] - location1[Y];
        rotation[Z] = location2[Z] - location1[Z];
        return rotation;
    }

    /**
     * Calculates the next possible position for the ring to be placed at.
     *
     * @param referencePath        The reference path.
     * @param currentLocation      The location to start calculating from.
     * @param pathIntervalDistance The distance indicating how far apart the rings are going to be.
     * @return The waypoint where the ring will be placed at.
     */
    private Waypoint calculateRingLocationOnPath(
            ArrayList<Waypoint> referencePath, int currentLocation, Float pathIntervalDistance) {
        float pathRemaining = 0;
        while (currentLocation < referencePath.size() - 1) {
            pathRemaining += MathsUtils.distanceCalculationOnXYPlane(
                    referencePath.get(currentLocation).getCoordinates(),
                    referencePath.get(currentLocation + 1).getCoordinates());
            if (pathRemaining >= pathIntervalDistance) {
                return referencePath.get(currentLocation);
            }
            currentLocation++;
        }
        throw new AssertionError(
                ""calculateRingLocationOnPath: Ring number and section number don't seem to match up"");
    }

    /**
     * Calculates the rectangular hit box for the ring.
     *
     * @param centre   the middle location of the ring.
     * @param rotation the rotation to get the same orientation of the ring.
     * @return The four corners of the rectangle.
     */
    private ArrayList<float[]> calculateRectangleHitbox(float[] centre, float[] rotation) {
        ArrayList<float[]> rectangle = new ArrayList<>();
        float magnitude = (float) Math.sqrt(Math.pow(rotation[X], 2) +
                Math.pow(rotation[Z], 2));
        float lengthScaleFactor = 0.02f / magnitude;
        float widthScaleFactor = 0.17f / magnitude;

        float[] rotationInverse = {0 - rotation[X], 0 - rotation[Y]};
        float[] rotationNinety = {rotation[Y], 0 - rotation[X]};
        float[] rotationNinetyInverse = {0 - rotation[Y], rotation[X]};

        float[] midFront = new float[2];
        midFront[X] = centre[X] + (lengthScaleFactor * rotation[X]);
        midFront[Y] = centre[Y] + (lengthScaleFactor * rotation[Y]);
        float[] midRear = new float[2];
        midRear[X] = centre[X] + (lengthScaleFactor * rotationInverse[X]);
        midRear[Y] = centre[Y] + (lengthScaleFactor * rotationInverse[Y]);

        float[] frontLeft = new float[3];
        frontLeft[Z] = centre[Z];
        frontLeft[X] = midFront[X] + (widthScaleFactor * rotationNinetyInverse[X]);
        frontLeft[Y] = midFront[Y] + (widthScaleFactor * rotationNinetyInverse[Y]);
        float[] frontRight = new float[3];
        frontRight[Z] = centre[Z];
        frontRight[X] = midFront[X] + (widthScaleFactor * rotationNinety[X]);
        frontRight[Y] = midFront[Y] + (widthScaleFactor * rotationNinety[Y]);
        float[] rearLeft = new float[3];
        rearLeft[Z] = centre[Z];
        rearLeft[X] = midRear[X] + (widthScaleFactor * rotationNinetyInverse[X]);
        rearLeft[Y] = midRear[Y] + (widthScaleFactor * rotationNinetyInverse[Y]);
        float[] rearRight = new float[3];
        rearRight[Z] = centre[Z];
        rearRight[X] = midRear[X] + (widthScaleFactor * rotationNinety[X]);
        rearRight[Y] = midRear[Y] + (widthScaleFactor * rotationNinety[Y]);

        rectangle.add(frontLeft);
        rectangle.add(frontRight);
        rectangle.add(rearRight);
        rectangle.add(rearLeft);
        return rectangle;
    }

    /**
     * Check to see if a ring has been entered.
     *
     * @param location the location of the user to be tested.
     */
    public Ring hasRingBeenEntered(float[] location) {
        float xDifference, yDifference, zDifference;
        for (int i = 0; i < mRings.size(); i++) {
            if (mRings.get(i).getPathNumber() == mCurrentLap) {
                xDifference = Math.abs(mRings.get(i).getLocation()[X] - location[X]);
                yDifference = Math.abs(mRings.get(i).getLocation()[Y] - location[Y]);
                zDifference = Math.abs(mRings.get(i).getLocation()[Z] - location[Z]);
                if (xDifference < 0.17 && yDifference < 0.17 && zDifference < 0.17) {
                    if (checkCollision(mRings.get(i), location)) {
                        return mRings.get(i);
                    }
                }
            }
        }
        return null;
    }

    /**
     * Calculates whether the location of the user is in the rectangular hit box or not.
     *
     * @param ring     the ring to be tested.
     * @param location the location of the user.
     * @return true if the ring is entered and false if it is not.
     */
    private boolean checkCollision(Ring ring, float[] location) {
        float[] rectangleVector1 = new float[2];
        rectangleVector1[X] = ring.getRectangleHitBox().get(0)[X] - ring.getRectangleHitBox().get(3)[X];
        rectangleVector1[Y] = ring.getRectangleHitBox().get(0)[Y] - ring.getRectangleHitBox().get(3)[Y];

        float[] rectangleVector2 = new float[2];
        rectangleVector2[X] = ring.getRectangleHitBox().get(2)[X] - ring.getRectangleHitBox().get(3)[X];
        rectangleVector2[Y] = ring.getRectangleHitBox().get(2)[Y] - ring.getRectangleHitBox().get(3)[Y];

        float[] locationVector = new float[2];
        locationVector[X] = location[X] - ring.getRectangleHitBox().get(3)[X];
        locationVector[Y] = location[Y] - ring.getRectangleHitBox().get(3)[Y];

        if (dotProduct(rectangleVector1, locationVector, VECTOR_2D) > 0) {
            if (dotProduct(rectangleVector1, rectangleVector1, VECTOR_2D)
                    > dotProduct(rectangleVector1, locationVector, VECTOR_2D)) {
                if (dotProduct(rectangleVector2, locationVector, VECTOR_2D) > 0) {
                    if (dotProduct(rectangleVector2, rectangleVector2, VECTOR_2D)
                            > dotProduct(rectangleVector2, locationVector, VECTOR_2D)) {
                        return true;
                    }
                }
            }
        }
        return false;
    }

    /**
     * Returns the list of rings.
     */
    public ArrayList<Ring> getRings() {
        return new ArrayList<>(mRings);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Ring"	"isEntered"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Utils/Path/PathUtilityClasses/Ring.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses;

import com.android.cts.verifier.sensors.sixdof.Renderer.Renderable.RingRenderable;

import java.util.ArrayList;

/**
 * Ring object, contains all the information about a ring.
 */
public class Ring {
    private final float[] mLocation;
    private final ArrayList<float[]> mRectangleHitBox;
    private final float[] mRotation;
    private final int mPathNumber;
    private boolean mEntered;
    private RingRenderable mRingRenderable;
    private boolean mSoundPlayed = false;

    /**
     * Constructor to the ring. The ring is always initialised to not entered.
     *
     * @param location        the location of the center of the ring
     * @param pathNumber      the path that the ring is located along
     * @param rotation        the orientation of the ring
     * @param rectangleHitBox the four corners of the rectangular hit box covered by the ring in a
     *                        top down view
     */
    public Ring(float[] location, int pathNumber,
                float[] rotation, ArrayList<float[]> rectangleHitBox) {
        mLocation = location;
        mEntered = false;
        mPathNumber = pathNumber;
        mRotation = rotation;
        mRectangleHitBox = rectangleHitBox;
        mSoundPlayed = false;
    }

    /**
     * Sets whether the ring has been entered or not.
     *
     * @param entered true if the ring is entered, false if the ring has not been entered
     */
    public void setEntered(boolean entered) {
        mEntered = entered;
    }

    /**
     * Sets whether the sound has been played or not.
     *
     * @param soundPlayed the state of whether the sound has been played or not
     */
    public void setSoundPlayed(boolean soundPlayed) {
        mSoundPlayed = soundPlayed;
    }

    /**
     * Returns the location if the center of the ring.
     */
    public float[] getLocation() {
        return mLocation;
    }

    /**
     * Returns the path the ring is located along.
     */
    public int getPathNumber() {
        return mPathNumber;
    }

    /**
     * Returns the coordinates of the four corners of the rectangular hit box.
     */
    public ArrayList<float[]> getRectangleHitBox() {
        return new ArrayList<>(mRectangleHitBox);
    }

    /**
     * Returns the orientation the ring is at.
     */
    public float[] getRingRotation() {
        return mRotation;
    }

    /**
     * Returns true if the ring had been entered, false if the ring has not been entered.
     */
    public boolean isEntered() {
        return mEntered;
    }

    public RingRenderable getRingRenderable() {
        return mRingRenderable;
    }

    /**
     * Returns true if the sound has been played, false if the sound has not been played.
     */
    public boolean isSoundPlayed() {
        return mSoundPlayed;
    }

    public void setRingRenderable(RingRenderable mRingRenderable) {
        this.mRingRenderable = mRingRenderable;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Utils.TestPhase.RobustnessTest"	"executeRobustnessTests"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Utils/TestPhase/RobustnessTest.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors.sixdof.Utils.TestPhase;


import com.android.cts.verifier.sensors.sixdof.Dialogs.BaseResultsDialog;
import com.android.cts.verifier.sensors.sixdof.Utils.Manager;
import com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils;
import com.android.cts.verifier.sensors.sixdof.Utils.TestReport;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.ReferencePath;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.RobustnessPath;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.RotationData;

import android.util.Log;

import java.util.ArrayList;
import java.util.HashMap;

/**
 * Handles all the Robustness test related features.
 */
public class RobustnessTest extends Test {
    private static final float MAXIMUM_PERCENT_ROTATION_FAILURE = 50f;
    private boolean mResultsGiven = false;
    private ArrayList<Long> mTimeDifferences = new ArrayList<>();
    private float mDistanceOfPathToFail;

    /**
     * Created a new robustness path which is to be used in this test.
     *
     * @param referencePath Reference the the reference path.
     * @param testReport    The test report object to record the tests.
     * @param manager       The manager to call when the test is done.
     */
    public RobustnessTest(ReferencePath referencePath, TestReport testReport, Manager manager,
                          int openGlRotation) {
        super(referencePath, testReport, manager, ""Robustness Test"");
        mTestPath = new RobustnessPath(openGlRotation);
        float mPathTotalDistance = 0;
        for (float distance : mReferencePathDistances) {
            mPathTotalDistance += distance;
        }
        mDistanceOfPathToFail = (MAXIMUM_PERCENT_ROTATION_FAILURE / 100f) * mPathTotalDistance;
    }

    /**
     * Implementation of the abstract method which check whether the test is complete.
     */
    @Override
    protected void runAdditionalMethods() {
        if (mTestPath.getPathMarkersSize() == MAX_MARKER_NUMBER && !mResultsGiven) {
            mResultsGiven = true;
            executeRobustnessTests();
        }
    }

    /**
     * Starts the robustness tests.
     */
    private void executeRobustnessTests() {
        HashMap<BaseResultsDialog.ResultType, Boolean> robustnessTestResults;
        robustnessTestResults = executeTests(true, true);
        robustnessTestResults.put(BaseResultsDialog.ResultType.TIME, timerTest());
        robustnessTestResults.put(BaseResultsDialog.ResultType.ROTATION, rotationTest());
        mManager.onRobustnessTestCompleted(robustnessTestResults);
    }

    /**
     * Test to check whether the waypoint was placed in the appropriate time.
     *
     * @return true if all waypoint times were met, fail if a waypoint was placed after the time
     * expired
     */
    private boolean timerTest() {
        calculateTimeBetweenMarkers();
        boolean state = true;
        for (int i = 0; i < mTimeDifferences.size(); i++) {
            if (mTimeDifferences.get(i) > RobustnessPath.TIME_TO_ADD_MARKER) {
                recordTimerTestResults(i);
                state = false;
            }
        }
        return state;
    }

    /**
     * Calculates the time it took to place a waypoint.
     */
    private void calculateTimeBetweenMarkers() {
        long timeDifference;
        ArrayList<Long> markerTimeStamps = ((RobustnessPath) mTestPath).getMarkerTimeStamp();
        for (int i = 1; i < ((RobustnessPath) mTestPath).getMarkerTimeStampSize(); i++) {
            timeDifference = markerTimeStamps.get(i) - markerTimeStamps.get(i - 1);
            mTimeDifferences.add(timeDifference);
        }
    }

    /**
     * Formats the failed times into a string to add it to the test report.
     *
     * @param markerLocation The marker location which failed the test. Used to get the data needed
     *                       for the test report
     */
    private void recordTimerTestResults(int markerLocation) {
        long failedTime = mTimeDifferences.get(markerLocation);
        String markerToPlace = MathsUtils.coordinatesToString(
                mTestPath.getPathMarkers().get(markerLocation).getCoordinates());
        String testDetails =
                ""Timer test: Marker placement was too slow that timer expired. Target time: ""
                        + RobustnessPath.TIME_TO_ADD_MARKER / 1000 + "" Completed time: "" + Math.abs(failedTime) / 1000 +
                        "" Marker: "" + markerLocation + "" Coordinates:"" + markerToPlace + ""\n"";
        Log.e(""Timer Result"", testDetails);
        mTestReport.setFailDetails(testDetails);
    }

    /**
     * Test to check whether the rotation test has passed based on the percent of failed rotations.
     *
     * @return true if the test passes, false if the test fails
     */
    private boolean rotationTest() {
        float failedRotations = ((RobustnessPath) mTestPath).getFailedRotationsSize();
        float totalRotations = ((RobustnessPath) mTestPath).getRobustnessPathRotationsSize();
        float percentage = (failedRotations / totalRotations) * 100;
        if (totalRotations == 0) {
            Log.e(""rotationResult"", ""Total was 0"");
            return false;
        }
        if (percentage > MAXIMUM_PERCENT_ROTATION_FAILURE) {
            Log.d(""rotationResult"", ""failed"");
            recordRotationTestResults(percentage, failedRotations, totalRotations);
            return false;
        } else {
            Log.d(""getFailedRotationSize"", """" + failedRotations);
            Log.d(""total"", """" + totalRotations);
            Log.d(""rotationResult"", ""passed "");
            Log.d(""rotationResult"", """" + percentage);
            return true;
        }
    }

    /**
     * Formats the failed rotations into a string to add it to the test report.
     *
     * @param percentFailed   Percentage of failed rotations
     * @param failedRotations number of failed rotations
     * @param totalRotations  number of rotations made
     */
    private void recordRotationTestResults(float percentFailed, float failedRotations, float totalRotations) {
        String testDetails =
                ""Rotation test: Rotation fails were too great. Target rotation percent: ""
                        + MAXIMUM_PERCENT_ROTATION_FAILURE + "" GivenRotation percent: "" + percentFailed +
                        "" Failed rotation: "" + failedRotations + "" Total rotations:"" + totalRotations + ""\n"";
        Log.e(""Timer Result"", testDetails);
        mTestReport.setFailDetails(testDetails);
    }

    /**
     * gets the result of comparing the current rotation
     *
     * @param rotationQuaternion The quaternions of the current rotation
     * @param location           The location of the point with the rotation
     * @return The rotation about the current rotation
     */
    public RotationData getRotationData(float[] rotationQuaternion, float[] location) {
        RotationData rotation = ((RobustnessPath) mTestPath).handleRotation(
                rotationQuaternion, location, mReferencePath.getPathMarkers(), mDistanceOfPathToFail);
        if (rotation == null) {
            if (!mResultsGiven) {
                mResultsGiven = true;
                HashMap<BaseResultsDialog.ResultType, Boolean> testFailed = new HashMap<>();
                testFailed.put(BaseResultsDialog.ResultType.WAYPOINT, false);
                testFailed.put(BaseResultsDialog.ResultType.PATH, false);
                testFailed.put(BaseResultsDialog.ResultType.TIME, false);
                testFailed.put(BaseResultsDialog.ResultType.ROTATION, false);
                String testDetails = ""Test terminated as it its impossible to pass the remaining rotations"";
                Log.e(""Rotation test:"", mDistanceOfPathToFail + """");
                Log.e(""Rotation test:"", testDetails);
                mTestReport.setFailDetails(testDetails);
                mManager.onRobustnessTestCompleted(testFailed);
            }
            return null;
        } else {
            return rotation;
        }

    }

    /**
     * Returns the time remaining for the user to place the marker
     */
    public long getTimeRemaining() {
        return ((RobustnessPath) mTestPath).calculateTimeRemaining();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.SensorCalibratedUncalibratedVerifier"	"unregisterListener"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/SensorCalibratedUncalibratedVerifier.java"	""	"public void test/*
 *
 */

package android.hardware.cts.helpers;

import junit.framework.Assert;

import java.util.List;
import java.util.concurrent.TimeUnit;

/**
 * A bundled sensor test operation/verification.
 *
 * It verifies the relationship between measurements from calibrated sensors and their corresponding
 * uncalibrated sensors comply to the following equation:
 *  calibrated = uncalibrated - bias
 */
// TODO: refactor into proper test operation/verification classes:
// currently this is the only verification that requires input from multiple sensors, and the class
// is factored into: operation, verification, and listener as other sensor test operations
public class SensorCalibratedUncalibratedVerifier {

    private final TestSensorManager mCalibratedSensorManager;
    private final TestSensorManager mUncalibratedSensorManager;
    private final TestSensorEventListener mCalibratedTestListener;
    private final TestSensorEventListener mUncalibratedTestListener;
    private final float mThreshold;

    public SensorCalibratedUncalibratedVerifier(
            TestSensorEnvironment calibratedEnvironment,
            TestSensorEnvironment uncalibratedEnvironment,
            float threshold) {
        mCalibratedSensorManager = new TestSensorManager(calibratedEnvironment);
        mUncalibratedSensorManager = new TestSensorManager(uncalibratedEnvironment);
        mCalibratedTestListener = new TestSensorEventListener(calibratedEnvironment);
        mUncalibratedTestListener = new TestSensorEventListener(uncalibratedEnvironment);
        mThreshold = threshold;
    }

    /**
     * Executes the operation: it collects the data and run verifications on it.
     */
    public void execute() throws Throwable {
        mCalibratedSensorManager.registerListener(mCalibratedTestListener);
        mUncalibratedSensorManager.registerListener(mUncalibratedTestListener);

        Thread.sleep(TimeUnit.SECONDS.toMillis(10));

        mCalibratedSensorManager.unregisterListener();
        mUncalibratedSensorManager.unregisterListener();

        verifyMeasurements(
                mCalibratedTestListener.getCollectedEvents(),
                mUncalibratedTestListener.getCollectedEvents(),
                mThreshold);
    }

    private void verifyMeasurements(
            List<TestSensorEvent> calibratedEvents,
            List<TestSensorEvent> uncalibratedEvents,
            float threshold) {
        long measuredSamplingPeriodNs = SensorCtsHelper.getSamplingPeriodNs(calibratedEvents);
        long synchronizationPeriodNs = measuredSamplingPeriodNs / 2;
        int eventsValidated = 0;

        // TODO: this makes the algorithm O(n^2) when we could have it O(n), but it has little
        // impact on the overall test duration because the data collection is what takes the most
        // time
        for (TestSensorEvent calibratedEvent : calibratedEvents) {
            long calibratedTimestampNs = calibratedEvent.timestamp;
            long lowerTimestampThresholdNs = calibratedTimestampNs - synchronizationPeriodNs;
            long upperTimestampThresholdNs = calibratedTimestampNs + synchronizationPeriodNs;

            for (TestSensorEvent uncalibratedEvent : uncalibratedEvents) {
                long uncalibratedTimestampNs = uncalibratedEvent.timestamp;
                if (uncalibratedTimestampNs > lowerTimestampThresholdNs
                        && uncalibratedTimestampNs < upperTimestampThresholdNs) {
                    // perform validation
                    verifyCalibratedUncalibratedPair(
                            calibratedEvent,
                            uncalibratedEvent,
                            threshold);
                    ++eventsValidated;
                }
            }
        }

        String eventsValidatedMessage = String.format(
                ""Expected to find at least one Calibrated/Uncalibrated event pair for validation.""
                        + "" Found=%d"",
                eventsValidated);
        Assert.assertTrue(eventsValidatedMessage, eventsValidated > 0);
    }

    private void verifyCalibratedUncalibratedPair(
            TestSensorEvent calibratedEvent,
            TestSensorEvent uncalibratedEvent,
            float threshold) {
        for (int i = 0; i < 3; ++i) {
            float calibrated = calibratedEvent.values[i];
            float uncalibrated = uncalibratedEvent.values[i];
            float bias = uncalibratedEvent.values[i + 3];
            String message = String.format(
                    ""Calibrated (%s) and Uncalibrated (%s) sensor readings are expected to satisfy:""
                            + "" calibrated = uncalibrated - bias. Axis=%d, Calibrated=%s, ""
                            + ""Uncalibrated=%s, Bias=%s, Threshold=%s"",
                    calibratedEvent.sensor.getName(),
                    uncalibratedEvent.sensor.getName(),
                    i,
                    calibrated,
                    uncalibrated,
                    bias,
                    threshold);
            Assert.assertEquals(message, calibrated, uncalibrated - bias, threshold);
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.devicepolicy.cts.AdminPermissionControlParamsTests"	"getPermission"	"CtsDevicePolicyTestCases"	"/home/gpoor/cts-12-source/cts/tests/devicepolicy/src/android/devicepolicy/cts/AdminPermissionControlParamsTests.java"	""	"public void correctParcelingAndUnparceling() {
        AdminPermissionControlParams params = createViaParcel();

        Parcel parcel = Parcel.obtain();
        params.writeToParcel(parcel, 0);
        parcel.setDataPosition(0);
        AdminPermissionControlParams loadedParams =
                AdminPermissionControlParams.CREATOR.createFromParcel(parcel);

        assertThat(params.getGranteePackageName()).isEqualTo(loadedParams.getGranteePackageName());
        assertThat(params.getPermission()).isEqualTo(loadedParams.getPermission());
        assertThat(params.getGrantState()).isEqualTo(loadedParams.getGrantState());
        assertThat(params.canAdminGrantSensorsPermissions())
                .isEqualTo(loadedParams.canAdminGrantSensorsPermissions());
    }

    private AdminPermissionControlParams createViaParcel(
            String packageName, String permission, int grantState, boolean canAdminGrant) {
        Parcel parcel = Parcel.obtain();
        parcel.writeString(packageName);
        parcel.writeString(permission);
        parcel.writeInt(grantState);
        parcel.writeBoolean(canAdminGrant);
        parcel.setDataPosition(0);

        return AdminPermissionControlParams.CREATOR.createFromParcel(parcel);
    }

    private AdminPermissionControlParams createViaParcel() {
        return createViaParcel(PKG, PERMISSION, GRANT_STATE, CAN_ADMIN_GRANT);
    }
}"	""	""	"sensor sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.car.cts.CarPropertyManagerTest"	"testRegisterCallback"	"CtsCarTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/car/src/android/car/cts/CarPropertyManagerTest.java"	""	"public void testRegisterCallback() throws Exception {
        //Test on registering a invalid property
        int invalidPropertyId = -1;
        boolean isRegistered = mCarPropertyManager.registerCallback(
                new CarPropertyEventCounter(), invalidPropertyId, 0);
        assertThat(isRegistered).isFalse();

        // Test for continuous properties
        int vehicleSpeed = VehiclePropertyIds.PERF_VEHICLE_SPEED;
        CarPropertyEventCounter speedListenerUI = new CarPropertyEventCounter();
        CarPropertyEventCounter speedListenerFast = new CarPropertyEventCounter();

        assertThat(speedListenerUI.receivedEvent(vehicleSpeed)).isEqualTo(NO_EVENTS);
        assertThat(speedListenerUI.receivedError(vehicleSpeed)).isEqualTo(NO_EVENTS);
        assertThat(speedListenerUI.receivedErrorWithErrorCode(vehicleSpeed)).isEqualTo(NO_EVENTS);
        assertThat(speedListenerFast.receivedEvent(vehicleSpeed)).isEqualTo(NO_EVENTS);
        assertThat(speedListenerFast.receivedError(vehicleSpeed)).isEqualTo(NO_EVENTS);
        assertThat(speedListenerFast.receivedErrorWithErrorCode(vehicleSpeed)).isEqualTo(NO_EVENTS);

        mCarPropertyManager.registerCallback(speedListenerUI, vehicleSpeed,
                CarPropertyManager.SENSOR_RATE_UI);
        mCarPropertyManager.registerCallback(speedListenerFast, vehicleSpeed,
                CarPropertyManager.SENSOR_RATE_FASTEST);
        speedListenerUI.resetCountDownLatch(UI_RATE_EVENT_COUNTER);
        speedListenerUI.assertOnChangeEventCalled();
        assertThat(speedListenerUI.receivedEvent(vehicleSpeed)).isGreaterThan(NO_EVENTS);
        assertThat(speedListenerFast.receivedEvent(vehicleSpeed)).isGreaterThan(
                speedListenerUI.receivedEvent(vehicleSpeed));
        // The test did not change property values, it should not get error with error codes.
        assertThat(speedListenerUI.receivedErrorWithErrorCode(vehicleSpeed)).isEqualTo(NO_EVENTS);
        assertThat(speedListenerFast.receivedErrorWithErrorCode(vehicleSpeed)).isEqualTo(NO_EVENTS);

        mCarPropertyManager.unregisterCallback(speedListenerFast);
        mCarPropertyManager.unregisterCallback(speedListenerUI);

        // Test for on_change properties
        int nightMode = VehiclePropertyIds.NIGHT_MODE;
        CarPropertyEventCounter nightModeListener = new CarPropertyEventCounter();
        nightModeListener.resetCountDownLatch(ONCHANGE_RATE_EVENT_COUNTER);
        mCarPropertyManager.registerCallback(nightModeListener, nightMode, 0);
        nightModeListener.assertOnChangeEventCalled();
        assertThat(nightModeListener.receivedEvent(nightMode)).isEqualTo(1);
        mCarPropertyManager.unregisterCallback(nightModeListener);

    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.car.cts.CarPropertyManagerTest"	"testUnregisterCallback"	"CtsCarTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/car/src/android/car/cts/CarPropertyManagerTest.java"	""	"public void testUnregisterCallback() throws Exception {

        int vehicleSpeed = VehiclePropertyIds.PERF_VEHICLE_SPEED;
        CarPropertyEventCounter speedListenerNormal = new CarPropertyEventCounter();
        CarPropertyEventCounter speedListenerUI = new CarPropertyEventCounter();

        mCarPropertyManager.registerCallback(speedListenerNormal, vehicleSpeed,
                CarPropertyManager.SENSOR_RATE_NORMAL);

        // test on unregistering a callback that was never registered
        try {
            mCarPropertyManager.unregisterCallback(speedListenerUI);
        } catch (Exception e) {
            Assert.fail();
        }

        mCarPropertyManager.registerCallback(speedListenerUI, vehicleSpeed,
                CarPropertyManager.SENSOR_RATE_UI);
        speedListenerUI.resetCountDownLatch(UI_RATE_EVENT_COUNTER);
        speedListenerUI.assertOnChangeEventCalled();
        mCarPropertyManager.unregisterCallback(speedListenerNormal, vehicleSpeed);

        int currentEventNormal = speedListenerNormal.receivedEvent(vehicleSpeed);
        int currentEventUI = speedListenerUI.receivedEvent(vehicleSpeed);
        speedListenerNormal.assertOnChangeEventNotCalled();

        assertThat(speedListenerNormal.receivedEvent(vehicleSpeed)).isEqualTo(currentEventNormal);
        assertThat(speedListenerUI.receivedEvent(vehicleSpeed)).isNotEqualTo(currentEventUI);

        mCarPropertyManager.unregisterCallback(speedListenerUI);
        speedListenerUI.assertOnChangeEventNotCalled();

        currentEventUI = speedListenerUI.receivedEvent(vehicleSpeed);
        assertThat(speedListenerUI.receivedEvent(vehicleSpeed)).isEqualTo(currentEventUI);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.car.cts.CarPropertyManagerTest"	"testUnregisterWithPropertyId"	"CtsCarTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/car/src/android/car/cts/CarPropertyManagerTest.java"	""	"public void testUnregisterWithPropertyId() throws Exception {
        // Ignores the test if wheel_tick property does not exist in the car.
        Assume.assumeTrue(""WheelTick is not available, skip unregisterCallback test"",
                mCarPropertyManager.isPropertyAvailable(
                        VehiclePropertyIds.WHEEL_TICK, VehicleAreaType.VEHICLE_AREA_TYPE_GLOBAL));

        CarPropertyConfig wheelTickConfig = mCarPropertyManager.getCarPropertyConfig(
                VehiclePropertyIds.WHEEL_TICK);
        CarPropertyConfig speedConfig = mCarPropertyManager.getCarPropertyConfig(
                VehiclePropertyIds.PERF_VEHICLE_SPEED);
        float maxSampleRateHz =
                Math.max(wheelTickConfig.getMaxSampleRate(), speedConfig.getMaxSampleRate());
        int eventCounter = getCounterBySampleRate(maxSampleRateHz);

        // Ignores the test if sampleRates for properties are too low.
        Assume.assumeTrue(""The SampleRates for properties are too low, ""
                + ""skip testUnregisterWithPropertyId test"", eventCounter != 0);
        CarPropertyEventCounter speedAndWheelTicksListener = new CarPropertyEventCounter();

        // CarService will register them to the maxSampleRate in CarPropertyConfig
        mCarPropertyManager.registerCallback(speedAndWheelTicksListener,
                VehiclePropertyIds.PERF_VEHICLE_SPEED, CarPropertyManager.SENSOR_RATE_FASTEST);
        mCarPropertyManager.registerCallback(speedAndWheelTicksListener,
                VehiclePropertyIds.WHEEL_TICK, CarPropertyManager.SENSOR_RATE_FASTEST);
        speedAndWheelTicksListener.resetCountDownLatch(eventCounter);
        speedAndWheelTicksListener.assertOnChangeEventCalled();

        // Tests unregister the individual property
        mCarPropertyManager.unregisterCallback(speedAndWheelTicksListener,
                VehiclePropertyIds.PERF_VEHICLE_SPEED);

        // Updates counter after unregistering the PERF_VEHICLE_SPEED
        int wheelTickEventCounter = getCounterBySampleRate(wheelTickConfig.getMaxSampleRate());
        speedAndWheelTicksListener.resetCountDownLatch(wheelTickEventCounter);
        speedAndWheelTicksListener.assertOnChangeEventCalled();
        int speedEventCountAfterFirstCountDown = speedAndWheelTicksListener.receivedEvent(
                VehiclePropertyIds.PERF_VEHICLE_SPEED);
        int wheelTickEventCountAfterFirstCountDown = speedAndWheelTicksListener.receivedEvent(
                VehiclePropertyIds.WHEEL_TICK);

        speedAndWheelTicksListener.resetCountDownLatch(wheelTickEventCounter);
        speedAndWheelTicksListener.assertOnChangeEventCalled();
        int speedEventCountAfterSecondCountDown = speedAndWheelTicksListener.receivedEvent(
                VehiclePropertyIds.PERF_VEHICLE_SPEED);
        int wheelTickEventCountAfterSecondCountDown = speedAndWheelTicksListener.receivedEvent(
                VehiclePropertyIds.WHEEL_TICK);

        assertThat(speedEventCountAfterFirstCountDown).isEqualTo(
                speedEventCountAfterSecondCountDown);
        assertThat(wheelTickEventCountAfterSecondCountDown)
                .isGreaterThan(wheelTickEventCountAfterFirstCountDown);
    }

    private int getCounterBySampleRate(float maxSampleRateHz) {
        if (Float.compare(maxSampleRateHz, (float) FAST_OR_FASTEST_EVENT_COUNTER) > 0) {
            return FAST_OR_FASTEST_EVENT_COUNTER;
        } else if (Float.compare(maxSampleRateHz, (float) UI_RATE_EVENT_COUNTER) > 0) {
            return UI_RATE_EVENT_COUNTER;
        } else if (Float.compare(maxSampleRateHz, (float) ONCHANGE_RATE_EVENT_COUNTER) > 0) {
            return ONCHANGE_RATE_EVENT_COUNTER;
        } else {
            return 0;
        }
    }

    // Returns {0} if the property is global property, otherwise query areaId for CarPropertyConfig
    private int[] getAreaIdsHelper(CarPropertyConfig config) {
        if (config.isGlobalProperty()) {
            return new int[]{0};
        } else {
            return config.getAreaIds();
        }
    }

    private static class CarPropertyEventCounter implements CarPropertyEventCallback {
        private final Object mLock = new Object();
        @GuardedBy(""mLock"")
        private final SparseArray<Integer> mEventCounter = new SparseArray<>();
        @GuardedBy(""mLock"")
        private final SparseArray<Integer> mErrorCounter = new SparseArray<>();
        @GuardedBy(""mLock"")
        private final SparseArray<Integer> mErrorWithErrorCodeCounter = new SparseArray<>();
        private int mCounter = FAST_OR_FASTEST_EVENT_COUNTER;
        private CountDownLatch mCountDownLatch = new CountDownLatch(mCounter);

        public int receivedEvent(int propId) {
            int val;
            synchronized (mLock) {
                val = mEventCounter.get(propId, 0);
            }
            return val;
        }

        public int receivedError(int propId) {
            int val;
            synchronized (mLock) {
                val = mErrorCounter.get(propId, 0);
            }
            return val;
        }

        public int receivedErrorWithErrorCode(int propId) {
            int val;
            synchronized (mLock) {
                val = mErrorWithErrorCodeCounter.get(propId, 0);
            }
            return val;
        }

        @Override
        public void onChangeEvent(CarPropertyValue value) {
            synchronized (mLock) {
                int val = mEventCounter.get(value.getPropertyId(), 0) + 1;
                mEventCounter.put(value.getPropertyId(), val);
            }
            mCountDownLatch.countDown();
        }

        @Override
        public void onErrorEvent(int propId, int zone) {
            synchronized (mLock) {
                int val = mErrorCounter.get(propId, 0) + 1;
                mErrorCounter.put(propId, val);
            }
        }

        @Override
        public void onErrorEvent(int propId, int areaId, int errorCode) {
            synchronized (mLock) {
                int val = mErrorWithErrorCodeCounter.get(propId, 0) + 1;
                mErrorWithErrorCodeCounter.put(propId, val);
            }
        }

        public void resetCountDownLatch(int counter) {
            mCountDownLatch = new CountDownLatch(counter);
            mCounter = counter;
        }

        public void assertOnChangeEventCalled() throws InterruptedException {
            if (!mCountDownLatch.await(WAIT_CALLBACK, TimeUnit.MILLISECONDS)) {
                throw new IllegalStateException(""Callback is not called:"" + mCounter + ""times in ""
                        + WAIT_CALLBACK + "" ms."");
            }
        }

        public void assertOnChangeEventNotCalled() throws InterruptedException {
            // Once get an event, fail the test.
            mCountDownLatch = new CountDownLatch(1);
            if (mCountDownLatch.await(WAIT_CALLBACK, TimeUnit.MILLISECONDS)) {
                throw new IllegalStateException(""Callback is called in ""
                        + WAIT_CALLBACK + "" ms."");
            }
        }

    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.DngCreatorTest"	"testSingleImageBasic"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/DngCreatorTest.java"	""	"public void testSingleImageBasic() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            String deviceId = mCameraIdsUnderTest[i];
            ImageReader captureReader = null;
            FileOutputStream fileStream = null;
            ByteArrayOutputStream outputStream = null;
            try {
                if (!mAllStaticInfo.get(deviceId).isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_RAW)) {
                    Log.i(TAG, ""RAW capability is not supported in camera "" + mCameraIdsUnderTest[i] +
                            "". Skip the test."");
                    continue;
                }

                openDevice(deviceId);
                Size activeArraySize = mStaticInfo.getRawDimensChecked();

                // Create capture image reader
                CameraTestUtils.SimpleImageReaderListener captureListener
                        = new CameraTestUtils.SimpleImageReaderListener();
                captureReader = createImageReader(activeArraySize, ImageFormat.RAW_SENSOR, 2,
                        captureListener);
                Pair<Image, CaptureResult> resultPair = captureSingleRawShot(activeArraySize,
                        /*waitForAe*/false, captureReader, captureListener);
                CameraCharacteristics characteristics = mStaticInfo.getCharacteristics();

                // Test simple writeImage, no header checks
                DngCreator dngCreator = new DngCreator(characteristics, resultPair.second);
                outputStream = new ByteArrayOutputStream();
                dngCreator.writeImage(outputStream, resultPair.first);

                if (VERBOSE) {
                    // Write DNG to file
                    String dngFilePath = mDebugFileNameBase + ""/camera_basic_"" + deviceId + ""_"" +
                            DEBUG_DNG_FILE;
                    // Write out captured DNG file for the first camera device if setprop is enabled
                    fileStream = new FileOutputStream(dngFilePath);
                    fileStream.write(outputStream.toByteArray());
                    fileStream.flush();
                    fileStream.close();
                    Log.v(TAG, ""Test DNG file for camera "" + deviceId + "" saved to "" + dngFilePath);
                }
                assertTrue(""Generated DNG file does not pass validation"",
                        validateDngNative(outputStream.toByteArray()));
            } finally {
                closeDevice(deviceId);
                closeImageReader(captureReader);

                if (outputStream != null) {
                    outputStream.close();
                }

                if (fileStream != null) {
                    fileStream.close();
                }
            }
        }
    }

    /**
     * Test basic maximum resolution raw capture and DNG saving functionality for each of the
     * available ultra high resolution cameras.
     *
     * <p>
     * For ultra high resolution each camera, capture a single RAW16 image at the first capture size
     * reported for the maximum resolution raw format on that device, and save that image as a DNG
     * file. No further validation is done.
     * </p>
     *
     * <p>
     * Note: Enabling adb shell setprop log.tag.DngCreatorTest VERBOSE will also cause the
     * raw image captured for the first reported camera device to be saved to an output file.
     * </p>
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.DngCreatorTest"	"testSingleImageBasicMaximumResolution"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/DngCreatorTest.java"	""	"public void testSingleImageBasicMaximumResolution() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            String deviceId = mCameraIdsUnderTest[i];
            ImageReader captureReader = null;
            ImageReader reprocessCaptureReader = null;
            FileOutputStream fileStream = null;
            ByteArrayOutputStream outputStream = null;
            try {
                // All ultra high resolution sensors must necessarily support RAW
                if (!mAllStaticInfo.get(deviceId).isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_ULTRA_HIGH_RESOLUTION_SENSOR)) {
                    Log.i(TAG, ""ULTRA_HIGH_RESOLUTION_SENSOR capability is not supported in "" +
                            "" camera "" + mCameraIdsUnderTest[i] + "". Skip the test."");
                    continue;
                }

                openDevice(deviceId);
                Size activeArraySize = mStaticInfo.getRawDimensChecked(/*maxResolution*/true);

                // Create capture image reader
                CameraTestUtils.SimpleImageReaderListener captureReaderListener
                        = new CameraTestUtils.SimpleImageReaderListener();
                CameraTestUtils.SimpleImageReaderListener reprocessReaderListener
                        = new CameraTestUtils.SimpleImageReaderListener();

                captureReader = createImageReader(activeArraySize, ImageFormat.RAW_SENSOR, 2,
                        captureReaderListener);

                reprocessCaptureReader = createImageReader(activeArraySize, ImageFormat.RAW_SENSOR,
                        2, reprocessReaderListener);
                Pair<Image, CaptureResult> resultPair = null;
                if (mAllStaticInfo.get(deviceId).isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_REMOSAIC_REPROCESSING)) {
                    resultPair =
                            captureReprocessedRawShot(activeArraySize, captureReader,
                                    reprocessCaptureReader, captureReaderListener,
                                    reprocessReaderListener, /*waitForAe*/false);
                } else {
                    resultPair = captureSingleShotMaximumResolution(activeArraySize,
                            captureReader, /*waitForAe*/false, captureReaderListener);
                }
                CameraCharacteristics characteristics = mStaticInfo.getCharacteristics();

                // Test simple writeImage, no header checks
                DngCreator dngCreator = new DngCreator(characteristics, resultPair.second);
                outputStream = new ByteArrayOutputStream();
                dngCreator.writeImage(outputStream, resultPair.first);

                if (VERBOSE) {
                    // Write DNG to file
                    String dngFilePath = mDebugFileNameBase + ""/camera_basic_max_resolution_"" +
                            deviceId + ""_"" + DEBUG_DNG_FILE;
                    // Write out captured DNG file for the first camera device if setprop is enabled
                    fileStream = new FileOutputStream(dngFilePath);
                    fileStream.write(outputStream.toByteArray());
                    fileStream.flush();
                    fileStream.close();
                    Log.v(TAG, ""Test DNG file for camera "" + deviceId + "" saved to "" + dngFilePath);
                }
                assertTrue(""Generated DNG file does not pass validation"",
                        validateDngNative(outputStream.toByteArray()));
            } finally {
                closeDevice(deviceId);
                closeImageReader(captureReader);
                closeImageReader(reprocessCaptureReader);

                if (outputStream != null) {
                    outputStream.close();
                }

                if (fileStream != null) {
                    fileStream.close();
                }
            }
        }
    }

    /**
     * Test basic raw capture and DNG saving with a thumbnail, rotation, usercomment, and GPS tags
     * set.
     *
     * <p>
     * For each camera, capture a single RAW16 image at the first capture size reported for
     * the raw format on that device, and save that image as a DNG file. GPS information validation
     * is done via ExifInterface.
     * </p>
     *
     * <p>
     * Note: Enabling adb shell setprop log.tag.DngCreatorTest VERBOSE will also cause the
     * raw image captured for the first reported camera device to be saved to an output file.
     * </p>
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.DngCreatorTest"	"testSingleImageThumbnail"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/DngCreatorTest.java"	""	"public void testSingleImageThumbnail() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            String deviceId = mCameraIdsUnderTest[i];
            List<ImageReader> captureReaders = new ArrayList<ImageReader>();
            List<CameraTestUtils.SimpleImageReaderListener> captureListeners =
                    new ArrayList<CameraTestUtils.SimpleImageReaderListener>();
            FileOutputStream fileStream = null;
            ByteArrayOutputStream outputStream = null;
            try {
                if (!mAllStaticInfo.get(deviceId).isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_RAW)) {
                    Log.i(TAG, ""RAW capability is not supported in camera "" + mCameraIdsUnderTest[i] +
                            "". Skip the test."");
                    continue;
                }

                openDevice(deviceId);
                Size activeArraySize = mStaticInfo.getRawDimensChecked();

                Size[] targetPreviewSizes =
                        mStaticInfo.getAvailableSizesForFormatChecked(ImageFormat.YUV_420_888,
                                StaticMetadata.StreamDirection.Output);
                // Get smallest preview size
                Size previewSize = mOrderedPreviewSizes.get(mOrderedPreviewSizes.size() - 1);

                // Create capture image reader
                CameraTestUtils.SimpleImageReaderListener captureListener
                        = new CameraTestUtils.SimpleImageReaderListener();
                captureReaders.add(createImageReader(activeArraySize, ImageFormat.RAW_SENSOR, 2,
                        captureListener));
                captureListeners.add(captureListener);

                CameraTestUtils.SimpleImageReaderListener previewListener
                        = new CameraTestUtils.SimpleImageReaderListener();

                captureReaders.add(createImageReader(previewSize, ImageFormat.YUV_420_888, 2,
                        previewListener));
                captureListeners.add(previewListener);

                Date beforeCaptureDate = new Date();
                Pair<List<Image>, CaptureResult> resultPair = captureSingleRawShot(activeArraySize,
                        captureReaders, /*waitForAe*/false, captureListeners);
                Date afterCaptureDate = new Date();
                CameraCharacteristics characteristics = mStaticInfo.getCharacteristics();

                if (VERBOSE) {
                    Log.v(TAG, ""Sensor timestamp (ms): "" +
                            resultPair.second.get(CaptureResult.SENSOR_TIMESTAMP) / 1000000);
                    Log.v(TAG, ""SystemClock.elapsedRealtimeNanos (ms): "" +
                            SystemClock.elapsedRealtimeNanos() / 1000000);
                    Log.v(TAG, ""SystemClock.uptimeMillis(): "" + SystemClock.uptimeMillis());
                }
                // Test simple writeImage, no header checks
                DngCreator dngCreator = new DngCreator(characteristics, resultPair.second);
                Location l = new Location(""test"");
                l.reset();
                l.setLatitude(GPS_LATITUDE);
                l.setLongitude(GPS_LONGITUDE);
                l.setTime(GPS_CALENDAR.getTimeInMillis());
                dngCreator.setLocation(l);

                dngCreator.setDescription(""helloworld"");
                dngCreator.setOrientation(ExifInterface.ORIENTATION_FLIP_VERTICAL);
                dngCreator.setThumbnail(resultPair.first.get(1));
                outputStream = new ByteArrayOutputStream();
                dngCreator.writeImage(outputStream, resultPair.first.get(0));

                String filePath = mDebugFileNameBase + ""/camera_thumb_"" + deviceId + ""_"" +
                        DEBUG_DNG_FILE;
                // Write out captured DNG file for the first camera device
                fileStream = new FileOutputStream(filePath);
                fileStream.write(outputStream.toByteArray());
                fileStream.flush();
                fileStream.close();
                if (VERBOSE) {
                    Log.v(TAG, ""Test DNG file for camera "" + deviceId + "" saved to "" + filePath);
                }

                assertTrue(""Generated DNG file does not pass validation"",
                        validateDngNative(outputStream.toByteArray()));

                ExifInterface exifInterface = new ExifInterface(filePath);
                // Verify GPS data.
                float[] latLong = new float[2];
                assertTrue(exifInterface.getLatLong(latLong));
                assertEquals(GPS_LATITUDE, latLong[0], GPS_DIFFERENCE_TOLERANCE);
                assertEquals(GPS_LONGITUDE, latLong[1], GPS_DIFFERENCE_TOLERANCE);
                assertEquals(GPS_DATESTAMP,
                        exifInterface.getAttribute(ExifInterface.TAG_GPS_DATESTAMP));
                assertEquals(GPS_TIMESTAMP,
                        exifInterface.getAttribute(ExifInterface.TAG_GPS_TIMESTAMP));

                // Verify the orientation.
                assertEquals(ExifInterface.ORIENTATION_FLIP_VERTICAL,
                        exifInterface.getAttributeInt(ExifInterface.TAG_ORIENTATION,
                                ExifInterface.ORIENTATION_UNDEFINED));

                // Verify the date/time
                final SimpleDateFormat dngDateTimeStampFormat =
                        new SimpleDateFormat(""yyyy:MM:dd HH:mm:ss"");
                dngDateTimeStampFormat.setLenient(false);

                String dateTimeString =
                        exifInterface.getAttribute(ExifInterface.TAG_DATETIME);
                assertTrue(dateTimeString != null);

                Date dateTime = dngDateTimeStampFormat.parse(dateTimeString);
                long captureTimeMs = dateTime.getTime();

                Log.i(TAG, ""DNG DateTime tag: "" + dateTimeString);
                Log.i(TAG, ""Before capture time: "" + beforeCaptureDate.getTime());
                Log.i(TAG, ""Capture time: "" + captureTimeMs);
                Log.i(TAG, ""After capture time: "" + afterCaptureDate.getTime());

                // Offset beforeCaptureTime by 1 second to account for rounding down of
                // DNG tag
                long beforeCaptureTimeMs = beforeCaptureDate.getTime() - 1000;
                long afterCaptureTimeMs = afterCaptureDate.getTime();
                assertTrue(captureTimeMs >= beforeCaptureTimeMs);
                assertTrue(captureTimeMs <= afterCaptureTimeMs);

                if (!VERBOSE) {
                    // Delete the captured DNG file.
                    File dngFile = new File(filePath);
                    assertTrue(dngFile.delete());
                }
            } finally {
                closeDevice(deviceId);
                for (ImageReader r : captureReaders) {
                    closeImageReader(r);
                }

                if (outputStream != null) {
                    outputStream.close();
                }

                if (fileStream != null) {
                    fileStream.close();
                }
            }
        }
    }

    /**
     * Test basic maximum resolution RAW capture, and ensure that the rendered RAW output is
     * similar to the maximum resolution JPEG created for a similar frame.
     *
     * Since mandatory streams for maximum resolution sensor pixel mode do not guarantee 2 maximum
     * resolution streams we can't capture RAW + JPEG images of the same frame. Therefore, 2
     * sessions are created, one for RAW capture and the other for JPEG capture.
     *
     * <p>
     * This test renders the RAW buffer into an RGB bitmap using a rendering pipeline
     * similar to one in the Adobe DNG validation tool.  JPEGs produced by the vendor hardware may
     * have different tonemapping and saturation applied than the RGB bitmaps produced
     * from this DNG rendering pipeline, and this test allows for fairly wide variations
     * between the histograms for the RAW and JPEG buffers to avoid false positives.
     * </p>
     *
     * <p>
     * To ensure more subtle errors in the colorspace transforms returned for the HAL's RAW
     * metadata, the DNGs and JPEGs produced here should also be manually compared using external
     * DNG rendering tools.  The DNG, rendered RGB bitmap, and JPEG buffer for this test can be
     * dumped to the SD card for further examination by enabling the 'verbose' mode for this test
     * using:
     * adb shell setprop log.tag.DngCreatorTest VERBOSE
     * </p>
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.DngCreatorTest"	"testRaw16JpegMaximumResolutionConsistency"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/DngCreatorTest.java"	""	"public void testRaw16JpegMaximumResolutionConsistency() throws Exception {
        for (String deviceId : mCameraIdsUnderTest) {
            ImageReader rawImageReader = null;
            ImageReader jpegImageReader = null;
            FileOutputStream fileStream = null;
            FileChannel fileChannel = null;
            try {
                // All ultra high resolution sensors must necessarily support RAW
                if (!mAllStaticInfo.get(deviceId).isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_ULTRA_HIGH_RESOLUTION_SENSOR)) {
                    Log.i(TAG, ""ULTRA_HIGH_RESOLUTION_SENSOR capability is not supported in "" +
                            "" camera "" + deviceId + "". Skip "" +
                            ""testRaw16JpegMaximumResolutionConsistency"");
                    continue;
                }

                CapturedDataMaximumResolution data =
                        captureRawJpegImagePairMaximumResolution(deviceId, rawImageReader,
                                jpegImageReader);
                if (data == null) {
                    continue;
                }
                Image raw = data.raw.first;
                Image jpeg = data.jpeg.first;

                Bitmap rawBitmap = Bitmap.createBitmap(raw.getWidth(), raw.getHeight(),
                        Bitmap.Config.ARGB_8888);

                byte[] rawPlane = new byte[raw.getPlanes()[0].getRowStride() * raw.getHeight()];

                // Render RAW image to a bitmap
                raw.getPlanes()[0].getBuffer().get(rawPlane);
                raw.getPlanes()[0].getBuffer().rewind();

                RawConverter.convertToSRGB(RenderScriptSingleton.getRS(), raw.getWidth(),
                        raw.getHeight(), raw.getPlanes()[0].getRowStride(), rawPlane,
                        data.characteristics, /*captureREsult*/data.raw.second, /*offsetX*/ 0,
                        /*offsetY*/ 0, /*out*/ rawBitmap);

                rawPlane = null;
                System.gc(); // Hint to VM

                if (VERBOSE) {
                    DngDebugParams params = new DngDebugParams();
                    params.deviceId = deviceId;
                    params.characteristics = data.characteristics;
                    params.captureResult = data.raw.second;
                    params.fileStream = fileStream;
                    params.raw = raw;
                    params.jpeg = jpeg;
                    params.fileChannel = fileChannel;
                    params.rawBitmap = rawBitmap;
                    params.intermediateStr = ""maximum_resolution_"";

                    debugDumpDng(params);
                }

                validateRawJpegImagePair(rawBitmap, jpeg, deviceId);
            } finally {
                closeImageReader(rawImageReader);
                closeImageReader(jpegImageReader);

                if (fileChannel != null) {
                    fileChannel.close();
                }
                if (fileStream != null) {
                    fileStream.close();
                }
            }
        }
    }



    /**
     * Test basic RAW capture, and ensure that the rendered RAW output is similar to the JPEG
     * created for the same frame.
     *
     * <p>
     * This test renders the RAW buffer into an RGB bitmap using a rendering pipeline
     * similar to one in the Adobe DNG validation tool.  JPEGs produced by the vendor hardware may
     * have different tonemapping and saturation applied than the RGB bitmaps produced
     * from this DNG rendering pipeline, and this test allows for fairly wide variations
     * between the histograms for the RAW and JPEG buffers to avoid false positives.
     * </p>
     *
     * <p>
     * To ensure more subtle errors in the colorspace transforms returned for the HAL's RAW
     * metadata, the DNGs and JPEGs produced here should also be manually compared using external
     * DNG rendering tools.  The DNG, rendered RGB bitmap, and JPEG buffer for this test can be
     * dumped to the SD card for further examination by enabling the 'verbose' mode for this test
     * using:
     * adb shell setprop log.tag.DngCreatorTest VERBOSE
     * </p>
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.DngCreatorTest"	"testDngRenderingByBitmapFactor"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/DngCreatorTest.java"	""	"public void testDngRenderingByBitmapFactor() throws Exception {
        for (String deviceId : mCameraIdsUnderTest) {
            List<ImageReader> captureReaders = new ArrayList<>();

            CapturedData data = captureRawJpegImagePair(deviceId, captureReaders);
            if (data == null) {
                continue;
            }
            Image raw = data.imagePair.first.get(0);
            Image jpeg = data.imagePair.first.get(1);

            // Generate DNG file
            DngCreator dngCreator = new DngCreator(data.characteristics, data.imagePair.second);

            // Write DNG to file
            String dngFilePath = mDebugFileNameBase + ""/camera_"" +
                deviceId + ""_"" + TEST_DNG_FILE;

            // Write out captured DNG file for the first camera device if setprop is enabled
            try (FileOutputStream fileStream = new FileOutputStream(dngFilePath)) {
                dngCreator.writeImage(fileStream, raw);

                // Render the DNG file using BitmapFactory.
                Bitmap rawBitmap = BitmapFactory.decodeFile(dngFilePath);
                assertNotNull(rawBitmap);

                validateRawJpegImagePair(rawBitmap, jpeg, deviceId);
            } finally {
                for (ImageReader r : captureReaders) {
                    closeImageReader(r);
                }

                System.gc(); // Hint to VM
            }
        }
    }

    /*
     * Create RAW + JPEG image pair with characteristics info.
     */
    private CapturedData captureRawJpegImagePair(String deviceId, List<ImageReader> captureReaders)
            throws Exception {
        CapturedData data = new CapturedData();
        List<CameraTestUtils.SimpleImageReaderListener> captureListeners = new ArrayList<>();
        try {
            if (!mAllStaticInfo.get(deviceId).isCapabilitySupported(
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_RAW)) {
                Log.i(TAG, ""RAW capability is not supported in camera "" + deviceId
                        + "". Skip the test."");
                return null;
            }

            openDevice(deviceId);
            Size activeArraySize = mStaticInfo.getRawDimensChecked();

            // Get largest jpeg size
            Size[] targetJpegSizes = mStaticInfo.getAvailableSizesForFormatChecked(
                    ImageFormat.JPEG, StaticMetadata.StreamDirection.Output);

            Size largestJpegSize = Collections.max(Arrays.asList(targetJpegSizes),
                    new CameraTestUtils.SizeComparator());

            // Create raw image reader and capture listener
            CameraTestUtils.SimpleImageReaderListener rawListener =
                    new CameraTestUtils.SimpleImageReaderListener();
            captureReaders.add(createImageReader(activeArraySize, ImageFormat.RAW_SENSOR, 2,
                    rawListener));
            captureListeners.add(rawListener);


            // Create jpeg image reader and capture listener
            CameraTestUtils.SimpleImageReaderListener jpegListener =
                    new CameraTestUtils.SimpleImageReaderListener();
            captureReaders.add(createImageReader(largestJpegSize, ImageFormat.JPEG, 2,
                    jpegListener));
            captureListeners.add(jpegListener);

            data.imagePair = captureSingleRawShot(activeArraySize,
                    captureReaders, /*waitForAe*/ true, captureListeners);
            data.characteristics = mStaticInfo.getCharacteristics();

            Image raw = data.imagePair.first.get(0);
            Size rawBitmapSize = new Size(raw.getWidth(), raw.getHeight());
            assertTrue(""Raw bitmap size must be equal to either pre-correction active array"" +
                    "" size or pixel array size."", rawBitmapSize.equals(activeArraySize));

            return data;
        } finally {
            closeDevice(deviceId);
        }
    }

   private void debugDumpDng(DngDebugParams params) throws Exception {
        // Generate DNG file
        DngCreator dngCreator =
                new DngCreator(params.characteristics, params.captureResult);

        // Write DNG to file
        String dngFilePath = mDebugFileNameBase + ""/camera_"" + params.intermediateStr +
                params.deviceId + ""_"" + DEBUG_DNG_FILE;
        // Write out captured DNG file for the first camera device if setprop is enabled
        params.fileStream = new FileOutputStream(dngFilePath);
        dngCreator.writeImage(params.fileStream, params.raw);
        params.fileStream.flush();
        params.fileStream.close();
        Log.v(TAG, ""Test DNG file for camera "" + params.deviceId + "" saved to "" + dngFilePath);

        // Write JPEG to file
        String jpegFilePath = mDebugFileNameBase + ""/camera_"" + params.intermediateStr  +
                params.deviceId + ""_jpeg.jpg"";
        // Write out captured DNG file for the first camera device if setprop is enabled
        params.fileChannel = new FileOutputStream(jpegFilePath).getChannel();
        ByteBuffer jPlane = params.jpeg.getPlanes()[0].getBuffer();
        params.fileChannel.write(jPlane);
        params.fileChannel.close();
        jPlane.rewind();
        Log.v(TAG, ""Test JPEG file for camera "" + params.deviceId + "" saved to "" +
                jpegFilePath);

        // Write jpeg generated from demosaiced RAW frame to file
        String rawFilePath = mDebugFileNameBase + ""/camera_"" + params.intermediateStr +
                params.deviceId + ""_raw.jpg"";
        // Write out captured DNG file for the first camera device if setprop is enabled
        params.fileStream = new FileOutputStream(rawFilePath);
        params.rawBitmap.compress(Bitmap.CompressFormat.JPEG, 90, params.fileStream);
        params.fileStream.flush();
        params.fileStream.close();
        Log.v(TAG, ""Test converted RAW file for camera "" + params.deviceId + "" saved to "" +
                rawFilePath);
   }

    /*
     * Create RAW + JPEG image pair with characteristics info. Assumes the device supports the RAW
     * capability.
     */
    private CapturedDataMaximumResolution captureRawJpegImagePairMaximumResolution(String deviceId,
            ImageReader rawCaptureReader, ImageReader jpegCaptureReader)
            throws Exception {
        CapturedDataMaximumResolution data = new CapturedDataMaximumResolution();
        try {

            openDevice(deviceId);
            Size activeArraySize = mStaticInfo.getRawDimensChecked(/*maxResolution*/true);

            // Get largest jpeg size
            Size[] targetJpegSizes = mStaticInfo.getAvailableSizesForFormatChecked(
                    ImageFormat.JPEG, StaticMetadata.StreamDirection.Output, /*fastSizes*/ true,
                    /*slowSizes*/ true, /*maxResolution*/true);

            Size largestJpegSize = Collections.max(Arrays.asList(targetJpegSizes),
                    new CameraTestUtils.SizeComparator());

            // Create raw image reader and capture listener
            CameraTestUtils.SimpleImageReaderListener rawCaptureReaderListener =
                    new CameraTestUtils.SimpleImageReaderListener();
            rawCaptureReader = createImageReader(activeArraySize, ImageFormat.RAW_SENSOR, 2,
                    rawCaptureReaderListener);

            // Create jpeg image reader and capture listener
            CameraTestUtils.SimpleImageReaderListener jpegCaptureListener =
                    new CameraTestUtils.SimpleImageReaderListener();
            jpegCaptureReader = createImageReader(largestJpegSize, ImageFormat.JPEG, 2,
                    jpegCaptureListener);

            Pair<Image, CaptureResult> jpegResultPair =
                    captureSingleShotMaximumResolution(activeArraySize,
                             jpegCaptureReader, /*waitForAe*/true, jpegCaptureListener);
            data.jpeg = jpegResultPair;
            data.characteristics = mStaticInfo.getCharacteristics();
            // Create capture image reader
            CameraTestUtils.SimpleImageReaderListener outputRawCaptureReaderListener
                    = new CameraTestUtils.SimpleImageReaderListener();
            CameraTestUtils.SimpleImageReaderListener reprocessReaderListener
                    = new CameraTestUtils.SimpleImageReaderListener();

            ImageReader outputRawCaptureReader = createImageReader(activeArraySize,
                    ImageFormat.RAW_SENSOR, 2, outputRawCaptureReaderListener);
            Pair<Image, CaptureResult> rawResultPair = null;
            if (mAllStaticInfo.get(deviceId).isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_REMOSAIC_REPROCESSING)) {
                rawResultPair =
                        captureReprocessedRawShot(activeArraySize, outputRawCaptureReader,
                                    rawCaptureReader, outputRawCaptureReaderListener,
                                    reprocessReaderListener, /*waitForAe*/ true);
            } else {
                rawResultPair = captureSingleShotMaximumResolution(activeArraySize,
                        rawCaptureReader, /*waitForAe*/true, rawCaptureReaderListener);
            }
            data.raw = rawResultPair;
            Size rawBitmapSize =
                    new Size(rawResultPair.first.getWidth(), rawResultPair.first.getHeight());
            assertTrue(""Raw bitmap size must be equal to either pre-correction active array"" +
                    "" size or pixel array size."", rawBitmapSize.equals(activeArraySize));

            return data;
        } finally {
            closeDevice(deviceId);
        }
    }

    /*
     * Verify the image pair by comparing the center patch.
     */
    private void validateRawJpegImagePair(Bitmap rawBitmap, Image jpeg, String deviceId)
            throws Exception {
        // Decompress JPEG image to a bitmap
        byte[] compressedJpegData = CameraTestUtils.getDataFromImage(jpeg);

        // Get JPEG dimensions without decoding
        BitmapFactory.Options opt0 = new BitmapFactory.Options();
        opt0.inJustDecodeBounds = true;
        BitmapFactory.decodeByteArray(compressedJpegData, /*offset*/0,
                compressedJpegData.length, /*inout*/opt0);
        Rect jpegDimens = new Rect(0, 0, opt0.outWidth, opt0.outHeight);

        // Find square center patch from JPEG and RAW bitmaps
        RectF jpegRect = new RectF(jpegDimens);
        RectF rawRect = new RectF(0, 0, rawBitmap.getWidth(), rawBitmap.getHeight());
        int sideDimen = Math.min(Math.min(Math.min(Math.min(DEFAULT_PATCH_DIMEN,
                jpegDimens.width()), jpegDimens.height()), rawBitmap.getWidth()),
                rawBitmap.getHeight());

        RectF jpegIntermediate = new RectF(0, 0, sideDimen, sideDimen);
        jpegIntermediate.offset(jpegRect.centerX() - jpegIntermediate.centerX(),
                jpegRect.centerY() - jpegIntermediate.centerY());

        RectF rawIntermediate = new RectF(0, 0, sideDimen, sideDimen);
        rawIntermediate.offset(rawRect.centerX() - rawIntermediate.centerX(),
                rawRect.centerY() - rawIntermediate.centerY());
        Rect jpegFinal = new Rect();
        jpegIntermediate.roundOut(jpegFinal);
        Rect rawFinal = new Rect();
        rawIntermediate.roundOut(rawFinal);

        // Get RAW center patch, and free up rest of RAW image
        Bitmap rawPatch = Bitmap.createBitmap(rawBitmap, rawFinal.left, rawFinal.top,
                rawFinal.width(), rawFinal.height());
        rawBitmap.recycle();
        rawBitmap = null;
        System.gc(); // Hint to VM

        BitmapFactory.Options opt = new BitmapFactory.Options();
        opt.inPreferredConfig = Bitmap.Config.ARGB_8888;
        Bitmap jpegPatch = BitmapRegionDecoder.newInstance(compressedJpegData,
                /*offset*/0, compressedJpegData.length, /*isShareable*/true).
                decodeRegion(jpegFinal, opt);

        // Compare center patch from JPEG and rendered RAW bitmap
        double difference = BitmapUtils.calcDifferenceMetric(jpegPatch, rawPatch);
        if (difference > IMAGE_DIFFERENCE_TOLERANCE) {
            FileOutputStream fileStream = null;
            try {
                // Write JPEG patch to file
                String jpegFilePath = mDebugFileNameBase + ""/camera_"" + deviceId +
                        ""_jpeg_patch.jpg"";
                fileStream = new FileOutputStream(jpegFilePath);
                jpegPatch.compress(Bitmap.CompressFormat.JPEG, 90, fileStream);
                fileStream.flush();
                fileStream.close();
                Log.e(TAG, ""Failed JPEG patch file for camera "" + deviceId + "" saved to "" +
                        jpegFilePath);

                // Write RAW patch to file
                String rawFilePath = mDebugFileNameBase + ""/camera_"" + deviceId +
                        ""_raw_patch.jpg"";
                fileStream = new FileOutputStream(rawFilePath);
                rawPatch.compress(Bitmap.CompressFormat.JPEG, 90, fileStream);
                fileStream.flush();
                fileStream.close();
                Log.e(TAG, ""Failed RAW patch file for camera "" + deviceId + "" saved to "" +
                        rawFilePath);

                fail(""Camera "" + deviceId + "": RAW and JPEG image at  for the same "" +
                        ""frame are not similar, center patches have difference metric of "" +
                        difference);
            } finally {
                if (fileStream != null) {
                    fileStream.close();
                }
            }
        }
    }

    private Pair<Image, CaptureResult> captureSingleRawShot(Size s, boolean waitForAe,
            ImageReader captureReader,
            CameraTestUtils.SimpleImageReaderListener captureListener) throws Exception {
        List<ImageReader> readers = new ArrayList<ImageReader>();
        readers.add(captureReader);
        List<CameraTestUtils.SimpleImageReaderListener> listeners =
                new ArrayList<CameraTestUtils.SimpleImageReaderListener>();
        listeners.add(captureListener);
        Pair<List<Image>, CaptureResult> res = captureSingleRawShot(s, readers, waitForAe,
                listeners);
        return new Pair<Image, CaptureResult>(res.first.get(0), res.second);
    }

    private Pair<List<Image>, CaptureResult> captureSingleRawShot(Size s,
            List<ImageReader> captureReaders, boolean waitForAe,
            List<CameraTestUtils.SimpleImageReaderListener> captureListeners) throws Exception {
        return captureRawShots(s, captureReaders, waitForAe, captureListeners, 1,
                /*maxResolution*/false).get(0);
    }

    private Pair<Image, CaptureResult> captureSingleShotMaximumResolution(Size s,
            ImageReader captureReader, boolean waitForAe,
            CameraTestUtils.SimpleImageReaderListener captureListener)
            throws Exception {
        List<ImageReader> readers = new ArrayList<ImageReader>();
        readers.add(captureReader);
        List<CameraTestUtils.SimpleImageReaderListener> listeners =
                new ArrayList<CameraTestUtils.SimpleImageReaderListener>();
        listeners.add(captureListener);
        Pair<List<Image>, CaptureResult> res = captureRawShots(s, readers, waitForAe,
                listeners, /*numShots*/ 1, /*maxResolution*/ true).get(0);
        return new Pair<Image, CaptureResult>(res.first.get(0), res.second);
    }

    private Pair<Image, CaptureResult> captureReprocessedRawShot(Size sz,
            ImageReader inputReader,
            ImageReader reprocessOutputReader,
            CameraTestUtils.SimpleImageReaderListener inputReaderListener,
            CameraTestUtils.SimpleImageReaderListener reprocessReaderListener,
            boolean waitForAe) throws Exception {

        InputConfiguration inputConfig =
            new InputConfiguration(sz.getWidth(), sz.getHeight(), ImageFormat.RAW_SENSOR);
        CameraTestUtils.SimpleCaptureCallback inputCaptureListener =
                new CameraTestUtils.SimpleCaptureCallback();
        CameraTestUtils.SimpleCaptureCallback reprocessOutputCaptureListener =
                new CameraTestUtils.SimpleCaptureCallback();

        inputReader.setOnImageAvailableListener(inputReaderListener, mHandler);
        reprocessOutputReader.setOnImageAvailableListener(reprocessReaderListener, mHandler);

        ArrayList<Surface> outputSurfaces = new ArrayList<Surface>();
        outputSurfaces.add(inputReader.getSurface());
        outputSurfaces.add(reprocessOutputReader.getSurface());
        BlockingSessionCallback sessionListener = new BlockingSessionCallback();
        ImageReader previewReader = null;
        if (waitForAe) {
            // Also setup a small YUV output for AE metering if needed
            Size yuvSize = (mOrderedPreviewSizes.size() == 0) ? null :
                    mOrderedPreviewSizes.get(mOrderedPreviewSizes.size() - 1);
            assertNotNull(""Must support at least one small YUV size."", yuvSize);
            previewReader = createImageReader(yuvSize, ImageFormat.YUV_420_888,
                        /*maxNumImages*/2, new CameraTestUtils.ImageDropperListener());
            outputSurfaces.add(previewReader.getSurface());
        }

        createReprocessableSession(inputConfig, outputSurfaces);

        if (waitForAe) {
            CaptureRequest.Builder precaptureRequest =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
            assertNotNull(""Fail to get captureRequest"", precaptureRequest);
            precaptureRequest.addTarget(previewReader.getSurface());
            precaptureRequest.set(CaptureRequest.CONTROL_MODE,
                    CaptureRequest.CONTROL_MODE_AUTO);
            precaptureRequest.set(CaptureRequest.CONTROL_AE_MODE,
                    CaptureRequest.CONTROL_AE_MODE_ON);

            final ConditionVariable waitForAeCondition = new ConditionVariable(/*isOpen*/false);
            CameraCaptureSession.CaptureCallback captureCallback =
                    new CameraCaptureSession.CaptureCallback() {
                @Override
                public void onCaptureProgressed(CameraCaptureSession session,
                        CaptureRequest request, CaptureResult partialResult) {
                    Integer aeState = partialResult.get(CaptureResult.CONTROL_AE_STATE);
                    if (aeState != null &&
                            (aeState == CaptureRequest.CONTROL_AE_STATE_CONVERGED ||
                             aeState == CaptureRequest.CONTROL_AE_STATE_FLASH_REQUIRED)) {
                        waitForAeCondition.open();
                    }
                }

                @Override
                public void onCaptureCompleted(CameraCaptureSession session,
                        CaptureRequest request, TotalCaptureResult result) {
                    int aeState = result.get(CaptureResult.CONTROL_AE_STATE);
                    if (aeState == CaptureRequest.CONTROL_AE_STATE_CONVERGED ||
                            aeState == CaptureRequest.CONTROL_AE_STATE_FLASH_REQUIRED) {
                        waitForAeCondition.open();
                    }
                }
            };

            startCapture(precaptureRequest.build(), /*repeating*/true, captureCallback, mHandler);

            precaptureRequest.set(CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER,
                    CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_START);
            startCapture(precaptureRequest.build(), /*repeating*/false, captureCallback, mHandler);
            assertTrue(""Timeout out waiting for AE to converge"",
                    waitForAeCondition.block(AE_TIMEOUT_MS));
        }
        ImageWriter inputWriter =
                ImageWriter.newInstance(mCameraSession.getInputSurface(), 1);
        // Prepare a request for reprocess input
        CaptureRequest.Builder builder = mCamera.createCaptureRequest(
                CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG);
        builder.addTarget(inputReader.getSurface());
        // This is a max resolution capture
        builder.set(CaptureRequest.SENSOR_PIXEL_MODE,
                CameraMetadata.SENSOR_PIXEL_MODE_MAXIMUM_RESOLUTION);
        CaptureRequest inputRequest = builder.build();
        mCameraSession.capture(inputRequest, inputCaptureListener, mHandler);
        List<CaptureRequest> reprocessCaptureRequests = new ArrayList<>();

        TotalCaptureResult inputResult =
                inputCaptureListener.getTotalCaptureResult(
                        MAX_RESOLUTION_CAPTURE_WAIT_TIMEOUT_MS);
        builder = mCamera.createReprocessCaptureRequest(inputResult);
        inputWriter.queueInputImage(inputReaderListener.getImage(
                        MAX_RESOLUTION_CAPTURE_WAIT_TIMEOUT_MS));
        builder.addTarget(reprocessOutputReader.getSurface());
        reprocessCaptureRequests.add(builder.build());
        mCameraSession.captureBurst(reprocessCaptureRequests, reprocessOutputCaptureListener,
                mHandler);
        TotalCaptureResult result = reprocessOutputCaptureListener.getTotalCaptureResult(
                CAPTURE_WAIT_TIMEOUT_MS);
        return new Pair<Image, CaptureResult>(reprocessReaderListener.getImage(
                MAX_RESOLUTION_CAPTURE_WAIT_TIMEOUT_MS), result);
    }

    /**
     * Capture raw images.
     *
     * <p>Capture raw images for a given size.</p>
     *
     * @param sz The size of the raw image to capture.  Must be one of the available sizes for this
     *          device.
     *
     * @param captureReaders The image readers which are associated with the targets for this
     *        capture.
     *
     * @param waitForAe Whether we should wait for AE to converge before capturing outputs for
     *                  the captureReaders targets
     *
     * @param captureListeners ImageReader listeners which wait on the captured images to be
     *                         available.
     *
     * @param numShots The number of shots to be captured
     *
     * @param maxResolution Whether the target in captureReaders are max resolution captures. If
     *                      this is set to true, captureReaders.size() must be == 1 ( in order to
     *                      satisfy mandatory streams for maximum resolution sensor pixel mode).
     *
     * @return a list of pairs containing a {@link Image} and {@link CaptureResult} used for
     *          each capture.
     */
    private List<Pair<List<Image>, CaptureResult>> captureRawShots(Size sz,
            List<ImageReader> captureReaders, boolean waitForAe,
            List<CameraTestUtils.SimpleImageReaderListener> captureListeners,
            int numShots, boolean maxResolution) throws Exception {
        if (VERBOSE) {
            Log.v(TAG, ""captureSingleRawShot - Capturing raw image."");
        }

        int timeoutScale = maxResolution ? MAX_RESOLUTION_CAPTURE_WAIT_TIMEOUT_SCALE : 1;
        Size[] targetCaptureSizes =
                mStaticInfo.getAvailableSizesForFormatChecked(ImageFormat.RAW_SENSOR,
                        StaticMetadata.StreamDirection.Output, /*fastSizes*/ true,
                        /*slowSizes*/ true, maxResolution);

        if (maxResolution) {
            assertTrue(""Maximum number of maximum resolution targets for a session should be 1 as"" +
                "" per the mandatory streams guarantee"", captureReaders.size() == 1);
        }

        // Validate size
        boolean validSize = false;
        for (int i = 0; i < targetCaptureSizes.length; ++i) {
            if (targetCaptureSizes[i].equals(sz)) {
                validSize = true;
                break;
            }
        }
        assertTrue(""Capture size is supported."", validSize);

        // Capture images.
        final List<Surface> outputSurfaces = new ArrayList<Surface>();
        for (ImageReader captureReader : captureReaders) {
            Surface captureSurface = captureReader.getSurface();
            outputSurfaces.add(captureSurface);
        }

        // Set up still capture template targeting JPEG/RAW outputs
        CaptureRequest.Builder request =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
        assertNotNull(""Fail to get captureRequest"", request);
        for (Surface surface : outputSurfaces) {
            request.addTarget(surface);
        }

        ImageReader previewReader = null;
        if (waitForAe) {
            // Also setup a small YUV output for AE metering if needed
            Size yuvSize = (mOrderedPreviewSizes.size() == 0) ? null :
                    mOrderedPreviewSizes.get(mOrderedPreviewSizes.size() - 1);
            assertNotNull(""Must support at least one small YUV size."", yuvSize);
            previewReader = createImageReader(yuvSize, ImageFormat.YUV_420_888,
                        /*maxNumImages*/2, new CameraTestUtils.ImageDropperListener());
            outputSurfaces.add(previewReader.getSurface());
        }

        createSession(outputSurfaces);

        if (waitForAe) {
            CaptureRequest.Builder precaptureRequest =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
            assertNotNull(""Fail to get captureRequest"", precaptureRequest);
            precaptureRequest.addTarget(previewReader.getSurface());
            precaptureRequest.set(CaptureRequest.CONTROL_MODE,
                    CaptureRequest.CONTROL_MODE_AUTO);
            precaptureRequest.set(CaptureRequest.CONTROL_AE_MODE,
                    CaptureRequest.CONTROL_AE_MODE_ON);

            final ConditionVariable waitForAeCondition = new ConditionVariable(/*isOpen*/false);
            CameraCaptureSession.CaptureCallback captureCallback =
                    new CameraCaptureSession.CaptureCallback() {
                @Override
                public void onCaptureProgressed(CameraCaptureSession session,
                        CaptureRequest request, CaptureResult partialResult) {
                    Integer aeState = partialResult.get(CaptureResult.CONTROL_AE_STATE);
                    if (aeState != null &&
                            (aeState == CaptureRequest.CONTROL_AE_STATE_CONVERGED ||
                             aeState == CaptureRequest.CONTROL_AE_STATE_FLASH_REQUIRED)) {
                        waitForAeCondition.open();
                    }
                }

                @Override
                public void onCaptureCompleted(CameraCaptureSession session,
                        CaptureRequest request, TotalCaptureResult result) {
                    int aeState = result.get(CaptureResult.CONTROL_AE_STATE);
                    if (aeState == CaptureRequest.CONTROL_AE_STATE_CONVERGED ||
                            aeState == CaptureRequest.CONTROL_AE_STATE_FLASH_REQUIRED) {
                        waitForAeCondition.open();
                    }
                }
            };
            startCapture(precaptureRequest.build(), /*repeating*/true, captureCallback, mHandler);

            precaptureRequest.set(CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER,
                    CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_START);
            startCapture(precaptureRequest.build(), /*repeating*/false, captureCallback, mHandler);
            assertTrue(""Timeout out waiting for AE to converge"",
                    waitForAeCondition.block(AE_TIMEOUT_MS));
        }

        request.set(CaptureRequest.STATISTICS_LENS_SHADING_MAP_MODE,
                CaptureRequest.STATISTICS_LENS_SHADING_MAP_MODE_ON);
        if (maxResolution) {
            request.set(CaptureRequest.SENSOR_PIXEL_MODE,
                    CaptureRequest.SENSOR_PIXEL_MODE_MAXIMUM_RESOLUTION);
        }
        CameraTestUtils.SimpleCaptureCallback resultListener =
                new CameraTestUtils.SimpleCaptureCallback();

        CaptureRequest request1 = request.build();
        for (int i = 0; i < numShots; i++) {
            startCapture(request1, /*repeating*/false, resultListener, mHandler);
        }
        List<Pair<List<Image>, CaptureResult>> ret = new ArrayList<>();
        for (int i = 0; i < numShots; i++) {
            // Verify capture result and images
            CaptureResult result = resultListener.getCaptureResult(CAPTURE_WAIT_TIMEOUT_MS);

            List<Image> resultImages = new ArrayList<Image>();
            for (CameraTestUtils.SimpleImageReaderListener captureListener : captureListeners) {
                Image captureImage =
                        captureListener.getImage(CAPTURE_WAIT_TIMEOUT_MS * timeoutScale);

            /*CameraTestUtils.validateImage(captureImage, s.getWidth(), s.getHeight(),
                    ImageFormat.RAW_SENSOR, null);*/
                resultImages.add(captureImage);
            }
            ret.add(new Pair<List<Image>, CaptureResult>(resultImages, result));
        }
        // Stop capture, delete the streams.
        stopCapture(/*fast*/false);

        return ret;
    }

    /**
     * Use the DNG SDK to validate a DNG file stored in the buffer.
     *
     * Returns false if the DNG has validation errors. Validation warnings/errors
     * will be printed to logcat.
     */
    private static native boolean validateDngNative(byte[] dngBuffer);
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.OrientationListenerTest"	"testConstructor"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/OrientationListenerTest.java"	""	"public void testConstructor() {
        new MockOrientationListener(mContext);

        new MockOrientationListener(mContext, SensorManager.SENSOR_DELAY_UI);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.OrientationListenerTest"	"testOnAccuracyChanged"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/OrientationListenerTest.java"	""	"public void testOnAccuracyChanged() {
        // this method is called to assure that no exception is thrown
        new MockOrientationListener(mContext).onAccuracyChanged(SensorManager.SENSOR_ACCELEROMETER,
                SensorManager.SENSOR_STATUS_ACCURACY_HIGH);

        new MockOrientationListener(mContext).onAccuracyChanged(SensorManager.SENSOR_ORIENTATION,
                SensorManager.SENSOR_STATUS_ACCURACY_MEDIUM);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.OrientationListenerTest"	"testOnSensorChanged"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/OrientationListenerTest.java"	""	"public void testOnSensorChanged() {
        // this method is called to assure that no exception is thrown
        MockOrientationListener listener = new MockOrientationListener(mContext);
        float[] mockData = new float[SensorManager.RAW_DATA_Z + 1];
        mockData[SensorManager.RAW_DATA_X] = 3.0f;
        mockData[SensorManager.RAW_DATA_Y] = 4.0f;
        mockData[SensorManager.RAW_DATA_Z] = 5.0f * 2.0f + 0.1f;
        new MockOrientationListener(mContext).onSensorChanged(SensorManager.SENSOR_ACCELEROMETER,
                mockData);

        mockData[SensorManager.RAW_DATA_X] = 4.0f;
        mockData[SensorManager.RAW_DATA_Y] = 4.0f;
        mockData[SensorManager.RAW_DATA_Z] = 5.0f * 2.0f;
        new MockOrientationListener(mContext).onSensorChanged(SensorManager.SENSOR_MAGNETIC_FIELD,
                mockData);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.OrientationListenerTest"	"testOnOrientationChanged"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/OrientationListenerTest.java"	""	"public void testOnOrientationChanged() {
        MockOrientationListener listener = new MockOrientationListener(mContext);
        listener.enable();
        // TODO can not simulate sensor events on the emulator.
    }

    private class MockOrientationListener extends OrientationListener {
        public MockOrientationListener(Context context) {
            super(context);
        }

        public MockOrientationListener(Context context, int rate) {
            super(context, rate);
        }

        @Override
        public void onOrientationChanged(int orientation) {
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.car.GearSelectionTestActivity"	"setPassFailButtonClickListeners"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/car/GearSelectionTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.car;

import android.car.Car;
import android.car.VehicleGear;
import android.car.hardware.CarPropertyConfig;
import android.car.hardware.CarPropertyValue;
import android.car.hardware.property.CarPropertyManager;
import android.car.VehicleAreaType;
import android.car.VehiclePropertyIds;
import android.os.Bundle;
import android.widget.TextView;
import android.util.ArraySet;
import android.util.Log;

import com.android.cts.verifier.PassFailButtons;
import com.android.cts.verifier.R;

import java.util.Arrays;
import java.util.List;

/** A CTS Verifier test case to verify GEAR_SELECTION is implemented correctly.*/
public class GearSelectionTestActivity extends PassFailButtons.Activity {
    private static final String TAG = GearSelectionTestActivity.class.getSimpleName();
    private List<Integer> mSupportedGears;
    private Integer mGearsAchievedCount = 0;
    private TextView mExpectedGearSelectionTextView;
    private TextView mCurrentGearSelectionTextView;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);

        // Setup the UI.
        setContentView(R.layout.gear_selection_test);
        setPassFailButtonClickListeners();
        setInfoResources(R.string.gear_selection_test, R.string.gear_selection_test_desc, -1);
        getPassButton().setEnabled(false);

        mExpectedGearSelectionTextView = (TextView) findViewById(R.id.expected_gear_selection);
        mCurrentGearSelectionTextView = (TextView) findViewById(R.id.current_gear_selection);

        CarPropertyManager carPropertyManager =
            (CarPropertyManager) Car.createCar(this).getCarManager(Car.PROPERTY_SERVICE);

        // TODO(b/138961351): Verify test works on manual transmission.
        mSupportedGears = carPropertyManager.getPropertyList(new ArraySet<>(Arrays.asList(new
                Integer[]{VehiclePropertyIds.GEAR_SELECTION}))).get(0).getConfigArray();

        if(mSupportedGears.size() != 0){
          Log.i(TAG, ""New Expected Gear: "" + VehicleGear.toString(mSupportedGears.get(0)));
          mExpectedGearSelectionTextView.setText(VehicleGear.toString(mSupportedGears.get(0)));
        } else {
          Log.e(TAG, ""No gears specified in the config array of GEAR_SELECTION property"");
          mExpectedGearSelectionTextView.setText(""ERROR"");
        }

        if(!carPropertyManager.registerCallback(mCarPropertyEventCallback,
            VehiclePropertyIds.GEAR_SELECTION, CarPropertyManager.SENSOR_RATE_ONCHANGE)) {
          Log.e(TAG, ""Failed to register callback for GEAR_SELECTION with CarPropertyManager"");
        }
    }

    private final CarPropertyManager.CarPropertyEventCallback mCarPropertyEventCallback =
      new CarPropertyManager.CarPropertyEventCallback() {
        @Override
        public void onChangeEvent(CarPropertyValue value) {
            if(value.getStatus() != CarPropertyValue.STATUS_AVAILABLE) {
                Log.e(TAG, ""New CarPropertyValue's status is not available - propId: "" +
                    value.getPropertyId() + "" status: "" + value.getStatus());
                return;
            }
            Integer newGearSelection = (Integer) value.getValue();
            mCurrentGearSelectionTextView.setText(VehicleGear.toString(newGearSelection));
            Log.i(TAG, ""New Gear Selection: "" + VehicleGear.toString(newGearSelection));

            if (mSupportedGears.size() == 0) {
                Log.e(TAG, ""No gears specified in the config array of GEAR_SELECTION property"");
                return;
            }

            // Check to see if new gear matches the expected gear.
            if (newGearSelection.equals(mSupportedGears.get(mGearsAchievedCount))) {
                mGearsAchievedCount++;
                Log.i(TAG, ""Matched gear: "" + VehicleGear.toString(newGearSelection));
                // Check to see if the test is finished.
                if (mGearsAchievedCount >= mSupportedGears.size()) {
                    mExpectedGearSelectionTextView.setText(""Finished"");
                    getPassButton().setEnabled(true);
                    Log.i(TAG, ""Finished Test"");
                } else {
                    // Test is not finished so update the expected gear.
                    mExpectedGearSelectionTextView.setText(
                        VehicleGear.toString(mSupportedGears.get(mGearsAchievedCount)));
                    Log.i(TAG, ""New Expected Gear: "" + 
                        VehicleGear.toString(mSupportedGears.get(mGearsAchievedCount)));
                }
            }
        }

        @Override
        public void onErrorEvent(int propId, int zone) {
            Log.e(TAG, ""propId: "" + propId + "" zone: "" + zone);
        }
      };
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Renderer.ComplexMovementRenderer"	"doTestSpecificRendering"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Renderer/ComplexMovementRenderer.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Renderer;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.sixdof.Renderer.RenderUtils.ModelMatrixCalculator;
import com.android.cts.verifier.sensors.sixdof.Renderer.RenderUtils.ObjImporter;
import com.android.cts.verifier.sensors.sixdof.Renderer.Renderable.ConeRenderable;
import com.android.cts.verifier.sensors.sixdof.Renderer.Renderable.Light;
import com.android.cts.verifier.sensors.sixdof.Renderer.Renderable.RingRenderable;
import com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Ring;
import com.android.cts.verifier.sensors.sixdof.Utils.PoseProvider.Intrinsics;
import com.android.cts.verifier.sensors.sixdof.Utils.PoseProvider.PoseData;

import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.MATRIX_4X4;

import android.content.Context;
import android.media.MediaPlayer;
import android.opengl.GLES20;
import android.opengl.Matrix;

import java.util.ArrayList;

import javax.microedition.khronos.egl.EGLConfig;
import javax.microedition.khronos.opengles.GL10;

/**
 * Renderer for the robustness test
 */
public class ComplexMovementRenderer extends BaseRenderer {
    private static final String TAG = ""ComplexMovementRenderer"";
    private static final float[] DEFAULT_LIGHT_POSITION = new float[]{
            0.0f, 3.0f, 0.0f};
    private static final Object RING_LOCK = new Object();
    private ModelMatrixCalculator mCameraModelMatrixCalculator;
    private ConeRenderable mCone;
    private Light mLight;
    private float[] mPoseViewMatrix = new float[MATRIX_4X4];
    private float[] mAugmentedRealityProjectMatrix = new float[MATRIX_4X4];

    protected boolean mIsCameraConfigured = false;

    protected double mCameraPoseTimestamp = 0;
    private PoseData mLastFramePose;

    private Context mContext;

    private int mWaypointCount = 0;
    private MediaPlayer mMediaPlayer;
    private ArrayList<Ring> mRings;

    public ComplexMovementRenderer(Context context, ArrayList<Ring> rings) {
        super(context);
        mCameraModelMatrixCalculator = new ModelMatrixCalculator(mOpenGlRotation);
        mContext = context;
        mMediaPlayer = MediaPlayer.create(context, R.raw.ring_sound);
        mRings = rings;
    }

    @Override
    public void onSurfaceCreated(GL10 glUnused, EGLConfig config) {
        super.onSurfaceCreated(glUnused, config);
        mCone = new ConeRenderable(mOpenGlRotation, mOpenGlUpVector);
        mLight = new Light(DEFAULT_LIGHT_POSITION, 2.0f);
        setUpExtrinsics();

        ObjImporter.ObjectData ringData = ObjImporter.parse(mContext.getResources(), R.raw.ring_obj);

        for (Ring ring : mRings) {
            final float[] position =
                    MathsUtils.convertToOpenGlCoordinates(ring.getLocation(), mOpenGlRotation);
            final float[] rotation =
                    MathsUtils.convertToOpenGlCoordinates(ring.getRingRotation(), mOpenGlRotation);
            RingRenderable ringRenderable = new RingRenderable(position, rotation, mOpenGlUpVector);
            ringRenderable.initialise(ringData);
            ring.setRingRenderable(ringRenderable);
        }

        ObjImporter.ObjectData coneData = ObjImporter.parse(mContext.getResources(), R.raw.cone_obj);
        mCone.initialise(coneData);
    }

    @Override
    protected void doPreRenderingSetup() {
        // Set up drawing of background camera preview (orthogonal).
        mViewMatrix = mOrthogonalViewMatrix;
        mProjectionMatrix = mOrthogonalProjectionMatrix;
    }

    @Override
    protected void doTestSpecificRendering() {
        GLES20.glClear(GLES20.GL_DEPTH_BUFFER_BIT);
        if (mPoseProvider != null) {
            // Update the texture with the latest camera frame.
            updateCameraTexture();

            // We delay the camera set-up until now because if we do it earlier (i.e., when the
            // camera is connected to the renderer) the PoseProvider service may still not have the
            // necessary intrinsic and extrinsic transformation information available.
            if (!mIsCameraConfigured) {
                configureCamera();
            }

            // Calculate the device pose at the camera frame update time.
            mLastFramePose = mPoseProvider.getLatestPoseData();
            // Update the camera pose from the renderer
            updateRenderCameraPose(mLastFramePose);
            // Update the MV matrix with new pose data.
            updatePoseViewMatrix();
            // Update light with new translation.
            mLight.updateLightPosition(MathsUtils.convertToOpenGlCoordinates(
                    mLastFramePose.getTranslationAsFloats(), mOpenGlRotation));
            mCameraPoseTimestamp = mLastFramePose.timestamp;
        }

        // Render objects with latest pose information available.
        renderAugmentedRealityObjects();
    }

    private void renderAugmentedRealityObjects() {
        // Set up projection matrix to match camera intrinsics.
        mProjectionMatrix = mAugmentedRealityProjectMatrix;
        // Set up view matrix to match current device positioning.
        mViewMatrix = mPoseViewMatrix;

        mDrawParameters.update(mViewMatrix, mProjectionMatrix, mLight);
        for (Ring ring : mRings) {
            // If we have placed the initial waypoint, we want rings for the first path, path 0.
            if (ring.getPathNumber() == mWaypointCount && !ring.isEntered()) {
                // Only draw the rings that are on our current path and have not been entered.
                ring.getRingRenderable().draw(mDrawParameters);
            }
        }
        // Clear depth buffer so cone does not clip with rings.
        GLES20.glClear(GLES20.GL_DEPTH_BUFFER_BIT);

        // Set cone to look at nearest ring.
        boolean lookingAt = false;
        for (Ring ring : mRings) {
            if (!ring.isEntered() && !lookingAt && ring.getPathNumber() == mWaypointCount) {
                // If the ring has not been entered, the cone has not been set to look at anything
                // yet, and we are on the correct lap for this ring.

                mCone.updateModelMatrix(mLastFramePose.getTranslationAsFloats(),
                        mLastFramePose.getRotationAsFloats(), ring.getLocation());
                lookingAt = true;
            }
        }

        if (lookingAt) {
            // Only draw the cone if it has something to look at.
            mCone.draw(mDrawParameters);
        }
    }

    protected void configureCamera() {
        // This should never happen, but it never hurts to double-check.
        if (mPoseProvider == null) {
            return;
        }

        Intrinsics intrinsics = mPoseProvider.getIntrinsics();

        mAugmentedRealityProjectMatrix = calculateProjectionMatrix(
                intrinsics.getWidth(), intrinsics.getHeight(),
                intrinsics.getFocalLengthInPixelsX(), intrinsics.getFocalLengthInPixelsY());
        mIsCameraConfigured = true;
    }

    /**
     * Called when a waypoint is placed in the last test. Used to show and hide rings.
     *
     * @param waypointCount Number of waypoints placed.
     */
    public void onWaypointPlaced(int waypointCount) {
        mWaypointCount = waypointCount;
    }

    /**
     * Called when a ring has been entered. Plays a sound and then hides the ring.
     *
     * @param ring Ring that has just been entered.
     */
    public void onRingEntered(Ring ring) {
        synchronized (RING_LOCK) {
            ring.setSoundPlayed(true);
        }
        mMediaPlayer.start();
    }

    /**
     * Setup the extrinsics of the device.
     */
    private void setUpExtrinsics() {
    }

    /**
     * Update the scene camera based on the provided pose. The
     * device pose should match the pose of the device at the time the last rendered RGB frame.
     */
    public void updateRenderCameraPose(PoseData devicePose) {
        mCameraModelMatrixCalculator.updateModelMatrix(devicePose.getTranslationAsFloats(),
                devicePose.getRotationAsFloats());
    }

    /**
     * Update the view matrix of the Renderer to follow the position of the device in the current
     * perspective.
     */
    public void updatePoseViewMatrix() {
        float[] invertModelMat = new float[MATRIX_4X4];
        Matrix.setIdentityM(invertModelMat, 0);

        float[] temporaryMatrix = new float[MATRIX_4X4];
        Matrix.setIdentityM(temporaryMatrix, 0);

        Matrix.setIdentityM(mPoseViewMatrix, 0);
        Matrix.invertM(invertModelMat, 0,
                mCameraModelMatrixCalculator.getModelMatrix(), 0);
        Matrix.multiplyMM(temporaryMatrix, 0, mPoseViewMatrix, 0,
                invertModelMat, 0);
        System.arraycopy(temporaryMatrix, 0, mPoseViewMatrix, 0, MATRIX_4X4);
    }

    /**
     * Use camera intrinsics to calculate the projection Matrix.
     */
    private float[] calculateProjectionMatrix(int width, int height,
                                              double focalLengthX, double focalLengthY) {
        // Uses frustumM to create a projection matrix taking into account calibrated camera
        // intrinsic parameter.
        // Reference: http://ksimek.github.io/2013/06/03/calibrated_cameras_in_opengl/
        float near = 0.1f;
        float far = 100f;

        float xScale = (float) (near / focalLengthX);
        float yScale = (float) (near / focalLengthY);

        float[] projectionMatrix = new float[16];
        Matrix.frustumM(projectionMatrix, 0,
                xScale * -width / 2.0f,
                xScale * width / 2.0f,
                yScale * -height / 2.0f,
                yScale * height / 2.0f,
                near, far);
        return projectionMatrix;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.SensorRatePermissionDirectReportTestHelper"	"toList"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/SensorRatePermissionDirectReportTestHelper.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers;

import android.content.Context;
import android.hardware.HardwareBuffer;
import android.hardware.Sensor;
import android.hardware.SensorDirectChannel;
import android.hardware.SensorManager;
import android.hardware.SensorPrivacyManager;
import android.hardware.cts.SensorDirectReportTest;

import com.android.compatibility.common.util.ShellUtils;
import com.android.compatibility.common.util.SystemUtil;

import com.google.common.collect.ImmutableSet;

import org.junit.Assert;
import org.junit.Assume;

import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.util.List;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

/**
 * A helper class to test sampling rates of direct sensor channels.
 */
public class SensorRatePermissionDirectReportTestHelper {
    public static final int CAPPED_SAMPLE_RATE_HZ = 200;
    public static final int CAPPED_DIRECT_REPORT_RATE_LEVEL = SensorDirectChannel.RATE_NORMAL;
    // Set of sensors that are throttled
    public static final ImmutableSet<Integer> CAPPED_SENSOR_TYPE_SET = ImmutableSet.of(
            Sensor.TYPE_ACCELEROMETER,
            Sensor.TYPE_ACCELEROMETER_UNCALIBRATED,
            Sensor.TYPE_GYROSCOPE,
            Sensor.TYPE_GYROSCOPE_UNCALIBRATED,
            Sensor.TYPE_MAGNETIC_FIELD,
            Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED
    );
    public static final int TEST_RUN_TIME_PERIOD_MILLISEC = 1000;
    public static final int SENSORS_EVENT_SIZE = 104;

    static {
        System.loadLibrary(""cts-sensors-ndk-jni"");
    }

    private final SensorManager mSensorManager;

    private Sensor mSensor;

    public SensorRatePermissionDirectReportTestHelper(Context context, int sensorType) {
        mSensorManager = context.getSystemService(SensorManager.class);
        mSensor = null;
        for (Sensor sensor : mSensorManager.getSensorList(sensorType)) {
            if (!CAPPED_SENSOR_TYPE_SET.contains(sensor.getType())) {
                continue;
            }
            if (sensor.isDirectChannelTypeSupported(SensorDirectChannel.TYPE_HARDWARE_BUFFER)) {
                mSensor = sensor;
                break;
            }
        }
        Assume.assumeTrue(""Failed to find a sensor!"", mSensor != null);
    }

    private static native boolean nativeReadHardwareBuffer(HardwareBuffer hardwareBuffer,
            byte[] buffer, int srcOffset, int destOffset, int count);

    public static double computeAvgRate(List<SensorDirectReportTest.DirectReportSensorEvent> events,
            long startTimestamp, long endTimestamp) {

        List<SensorDirectReportTest.DirectReportSensorEvent> filteredEvents = events.stream()
                .filter(event -> event.ts > startTimestamp && event.ts < endTimestamp)
                .collect(Collectors.toList());

        double rate = Double.MIN_VALUE;
        int numOfEvents = filteredEvents.size();
        if (numOfEvents >= 2) {
            long lastTimestamp = filteredEvents.get(numOfEvents - 1).ts;
            long firstTimestamp = filteredEvents.get(0).ts;
            rate = SensorCtsHelper.getFrequency(
                    (lastTimestamp - firstTimestamp) / (numOfEvents - 1),
                    TimeUnit.NANOSECONDS);
        }
        return rate;
    }

    public Sensor getSensor() {
        return mSensor;
    }

    /**
     * Error message being shown in Assert statements of unit tests when the sampling rate exceeds
     * the allowed capped rate.
     */
    public String errorWhenExceedCappedRate() {
        return String.format(
                ""%s: Sampling rate is expected to be less than or equal to %d (Hz)"",
                mSensor.getName(),
                CAPPED_SAMPLE_RATE_HZ);
    }

    /**
     * Error message being shown in Assert statements of unit tests when the sampling rate is below
     * its expected rate.
     */
    public String errorWhenBelowExpectedRate() {
        return String.format(
                ""%s: Sampling rate is expected to larger than to %d (Hz)"",
                mSensor.getName(),
                CAPPED_SAMPLE_RATE_HZ);
    }

    /**
     * Flip the microphone toggle to off and assert that it is indeed off.
     */
    public void flipAndAssertMicToggleOff(int userID, SensorPrivacyManager spm) {
        ShellUtils.runShellCommand(""cmd sensor_privacy disable "" + userID + "" microphone"");
        SystemUtil.runWithShellPermissionIdentity(() -> {
            Assert.assertTrue(""Failed to switch the mic toggle off!"",
                    !spm.isSensorPrivacyEnabled(SensorPrivacyManager.Sensors.MICROPHONE));
        });
    }

    /**
     * Flip the microphone toggle to off and assert that it is indeed on.
     */
    public void flipAndAssertMicToggleOn(int userID, SensorPrivacyManager spm) {
        ShellUtils.runShellCommand(""cmd sensor_privacy enable "" + userID + "" microphone"");
        SystemUtil.runWithShellPermissionIdentity(() -> {
            Assert.assertTrue(""Failed to switch the mic toggle on!"",
                    spm.isSensorPrivacyEnabled(SensorPrivacyManager.Sensors.MICROPHONE));
        });
    }

    /**
     * Configure a direct channel and return the sensor data in a DirectReportSensorEvent list.
     */
    public List<SensorDirectReportTest.DirectReportSensorEvent> getSensorEvents(int rateLevel)
            throws InterruptedException {
        int sensorEventCount = 2000; // 800 Hz * 2.2 * 1s + extra
        int sharedMemorySize = sensorEventCount * SENSORS_EVENT_SIZE;
        HardwareBuffer hardwareBuffer = HardwareBuffer.create(
                sharedMemorySize, 1, HardwareBuffer.BLOB, 1,
                HardwareBuffer.USAGE_CPU_READ_OFTEN | HardwareBuffer.USAGE_GPU_DATA_BUFFER
                        | HardwareBuffer.USAGE_SENSOR_DIRECT_DATA);

        SensorDirectChannel channel = mSensorManager.createDirectChannel(hardwareBuffer);
        int token = channel.configure(mSensor, rateLevel);
        SensorCtsHelper.sleep(TEST_RUN_TIME_PERIOD_MILLISEC, TimeUnit.MILLISECONDS);
        channel.configure(mSensor, SensorDirectChannel.RATE_STOP);
        List<SensorDirectReportTest.DirectReportSensorEvent> events =
                readEventsFromHardwareBuffer(token, hardwareBuffer, sensorEventCount);
        channel.close();
        hardwareBuffer.close();
        return events;
    }

    /**
     * Parse HardwareBuffer to return a list of DirectReportSensorEvents
     */
    public List<SensorDirectReportTest.DirectReportSensorEvent> readEventsFromHardwareBuffer(
            int token, HardwareBuffer hardwareBuffer, int sensorEventCount) {
        int sharedMemorySize = sensorEventCount * SENSORS_EVENT_SIZE;
        SensorDirectReportTest.EventPool eventPool = new SensorDirectReportTest.EventPool(
                10 * sensorEventCount);
        ByteBuffer byteBuffer = ByteBuffer.allocate(sharedMemorySize);
        byte[] buffer = byteBuffer.array();
        byteBuffer.order(ByteOrder.nativeOrder());
        nativeReadHardwareBuffer(hardwareBuffer, buffer, 0, 0, sharedMemorySize);
        List<SensorDirectReportTest.DirectReportSensorEvent> events =
                SensorDirectReportTest.parseEntireBuffer(token, eventPool, byteBuffer,
                        sharedMemorySize);
        eventPool.reset();
        byteBuffer.clear();
        return events;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"getCharacteristics"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"/*
 *.
 */

package android.hardware.camera2.cts;

import android.content.Context;
import android.content.pm.PackageManager;
import android.graphics.ImageFormat;
import android.graphics.Rect;
import android.graphics.SurfaceTexture;
import android.hardware.Camera;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.CameraCharacteristics.Key;
import android.hardware.camera2.CameraDevice;
import android.hardware.camera2.CameraManager;
import android.hardware.camera2.CameraMetadata;
import android.hardware.camera2.CaptureRequest;
import android.hardware.camera2.CaptureResult;
import android.hardware.camera2.cts.helpers.CameraErrorCollector;
import android.hardware.camera2.cts.helpers.StaticMetadata;
import android.hardware.camera2.cts.testcases.Camera2AndroidTestCase;
import android.hardware.camera2.params.BlackLevelPattern;
import android.hardware.camera2.params.ColorSpaceTransform;
import android.hardware.camera2.params.RecommendedStreamConfigurationMap;
import android.hardware.camera2.params.StreamConfigurationMap;
import android.media.CamcorderProfile;
import android.media.ImageReader;
import android.os.Build;
import android.util.ArraySet;
import android.util.DisplayMetrics;
import android.util.Log;
import android.util.Rational;
import android.util.Range;
import android.util.Size;
import android.util.Pair;
import android.util.Patterns;
import android.view.Display;
import android.view.Surface;
import android.view.WindowManager;

import com.android.compatibility.common.util.CddTest;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Objects;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.Set;

import org.junit.runners.Parameterized;
import org.junit.runner.RunWith;
import org.junit.Test;

import static android.hardware.camera2.cts.helpers.AssertHelpers.*;
import static android.hardware.camera2.cts.CameraTestUtils.SimpleCaptureCallback;
import static android.hardware.cts.helpers.CameraUtils.matchParametersToCharacteristics;

import static junit.framework.Assert.*;

import static org.mockito.Mockito.*;

/**
 * Extended tests for static camera characteristics.
 */
@RunWith(Parameterized.class)
public class ExtendedCameraCharacteristicsTest extends Camera2AndroidTestCase {
    private static final String TAG = ""ExChrsTest""; // must be short so next line doesn't throw
    private static final boolean VERBOSE = Log.isLoggable(TAG, Log.VERBOSE);

    private static final String PREFIX_ANDROID = ""android"";

    /*
     * Constants for static RAW metadata.
     */
    private static final int MIN_ALLOWABLE_WHITELEVEL = 32; // must have sensor bit depth > 5

    private List<CameraCharacteristics> mCharacteristics;

    private static final Size FULLHD = new Size(1920, 1080);
    private static final Size FULLHD_ALT = new Size(1920, 1088);
    private static final Size HD = new Size(1280, 720);
    private static final Size VGA = new Size(640, 480);
    private static final Size QVGA = new Size(320, 240);
    private static final Size UHD = new Size(3840, 2160);
    private static final Size DC4K = new Size(4096, 2160);

    private static final long MIN_BACK_SENSOR_RESOLUTION = 2000000;
    private static final long MIN_FRONT_SENSOR_RESOLUTION = VGA.getHeight() * VGA.getWidth();
    private static final long LOW_LATENCY_THRESHOLD_MS = 200;
    private static final float LATENCY_TOLERANCE_FACTOR = 1.1f; // 10% tolerance
    private static final int MAX_NUM_IMAGES = 5;
    private static final long PREVIEW_RUN_MS = 500;
    private static final long FRAME_DURATION_30FPS_NSEC = (long) 1e9 / 30;

    private static final long MIN_BACK_SENSOR_PERF_CLASS_RESOLUTION = 12000000;
    private static final long MIN_FRONT_SENSOR_S_PERF_CLASS_RESOLUTION = 5000000;
    private static final long MIN_FRONT_SENSOR_R_PERF_CLASS_RESOLUTION = 4000000;

    private static final long MIN_UHR_SENSOR_RESOLUTION = 24000000;
    /*
     * HW Levels short hand
     */
    private static final int LEGACY = CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_LEGACY;
    private static final int LIMITED = CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED;
    private static final int FULL = CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_FULL;
    private static final int LEVEL_3 = CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_3;
    private static final int EXTERNAL = CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_EXTERNAL;
    private static final int OPT = Integer.MAX_VALUE;  // For keys that are optional on all hardware levels.

    /*
     * Capabilities short hand
     */
    private static final int NONE = -1;
    private static final int BC =
            CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE;
    private static final int MANUAL_SENSOR =
            CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR;
    private static final int MANUAL_POSTPROC =
            CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_POST_PROCESSING;
    private static final int RAW =
            CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_RAW;
    private static final int YUV_REPROCESS =
            CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_YUV_REPROCESSING;
    private static final int OPAQUE_REPROCESS =
            CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING;
    private static final int CONSTRAINED_HIGH_SPEED =
            CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_CONSTRAINED_HIGH_SPEED_VIDEO;
    private static final int MONOCHROME =
            CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MONOCHROME;
    private static final int HIGH_SPEED_FPS_LOWER_MIN = 30;
    private static final int HIGH_SPEED_FPS_UPPER_MIN = 120;

    @Override
    public void setUp() throws Exception {
        super.setUp();
        mCharacteristics = new ArrayList<>();
        for (int i = 0; i < mAllCameraIds.length; i++) {
            mCharacteristics.add(mAllStaticInfo.get(mAllCameraIds[i]).getCharacteristics());
        }
    }

    @Override
    public void tearDown() throws Exception {
        super.tearDown();
        mCharacteristics = null;
    }

    /**
     * Test that the available stream configurations contain a few required formats and sizes.
     */
    @CddTest(requirement=""7.5.1/C-1-2"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"testAvailableStreamConfigs"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"public void testAvailableStreamConfigs() throws Exception {
        boolean firstBackFacingCamera = true;
        for (int i = 0; i < mAllCameraIds.length; i++) {
            CameraCharacteristics c = mCharacteristics.get(i);
            StreamConfigurationMap config =
                    c.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
            assertNotNull(String.format(""No stream configuration map found for: ID %s"",
                    mAllCameraIds[i]), config);
            int[] outputFormats = config.getOutputFormats();

            int[] actualCapabilities = c.get(CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
            assertNotNull(""android.request.availableCapabilities must never be null"",
                    actualCapabilities);

            // Check required formats exist (JPEG, and YUV_420_888).
            if (!arrayContains(actualCapabilities, BC)) {
                Log.i(TAG, ""Camera "" + mAllCameraIds[i] +
                    "": BACKWARD_COMPATIBLE capability not supported, skipping test"");
                continue;
            }

            boolean isMonochromeWithY8 = arrayContains(actualCapabilities, MONOCHROME)
                    && arrayContains(outputFormats, ImageFormat.Y8);
            boolean isHiddenPhysicalCamera = !arrayContains(mCameraIdsUnderTest, mAllCameraIds[i]);
            boolean supportHeic = arrayContains(outputFormats, ImageFormat.HEIC);

            assertArrayContains(
                    String.format(""No valid YUV_420_888 preview formats found for: ID %s"",
                            mAllCameraIds[i]), outputFormats, ImageFormat.YUV_420_888);
            if (isMonochromeWithY8) {
                assertArrayContains(
                        String.format(""No valid Y8 preview formats found for: ID %s"",
                                mAllCameraIds[i]), outputFormats, ImageFormat.Y8);
            }
            assertArrayContains(String.format(""No JPEG image format for: ID %s"",
                    mAllCameraIds[i]), outputFormats, ImageFormat.JPEG);

            Size[] yuvSizes = config.getOutputSizes(ImageFormat.YUV_420_888);
            Size[] y8Sizes = config.getOutputSizes(ImageFormat.Y8);
            Size[] jpegSizes = config.getOutputSizes(ImageFormat.JPEG);
            Size[] heicSizes = config.getOutputSizes(ImageFormat.HEIC);
            Size[] privateSizes = config.getOutputSizes(ImageFormat.PRIVATE);

            CameraTestUtils.assertArrayNotEmpty(yuvSizes,
                    String.format(""No sizes for preview format %x for: ID %s"",
                            ImageFormat.YUV_420_888, mAllCameraIds[i]));
            if (isMonochromeWithY8) {
                CameraTestUtils.assertArrayNotEmpty(y8Sizes,
                    String.format(""No sizes for preview format %x for: ID %s"",
                            ImageFormat.Y8, mAllCameraIds[i]));
            }

            Rect activeRect = CameraTestUtils.getValueNotNull(
                    c, CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE);
            Size pixelArraySize = CameraTestUtils.getValueNotNull(
                    c, CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE);

            int activeArrayHeight = activeRect.height();
            int activeArrayWidth = activeRect.width();
            long sensorResolution = pixelArraySize.getHeight() * pixelArraySize.getWidth() ;
            Integer lensFacing = c.get(CameraCharacteristics.LENS_FACING);
            assertNotNull(""Can't get lens facing info for camera id: "" + mAllCameraIds[i],
                    lensFacing);

            // Check that the sensor sizes are atleast what the CDD specifies
            switch(lensFacing) {
                case CameraCharacteristics.LENS_FACING_FRONT:
                    assertTrue(""Front Sensor resolution should be at least "" +
                            MIN_FRONT_SENSOR_RESOLUTION + "" pixels, is ""+ sensorResolution,
                            sensorResolution >= MIN_FRONT_SENSOR_RESOLUTION);
                    break;
                case CameraCharacteristics.LENS_FACING_BACK:
                    if (firstBackFacingCamera) {
                        assertTrue(""Back Sensor resolution should be at least ""
                                + MIN_BACK_SENSOR_RESOLUTION +
                                "" pixels, is ""+ sensorResolution,
                                sensorResolution >= MIN_BACK_SENSOR_RESOLUTION);
                        firstBackFacingCamera = false;
                    }
                    break;
                default:
                    break;
            }

            Integer hwLevel = c.get(CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL);

            if (activeArrayWidth >= FULLHD.getWidth() &&
                    activeArrayHeight >= FULLHD.getHeight()) {
                assertArrayContainsAnyOf(String.format(
                        ""Required FULLHD size not found for format %x for: ID %s"",
                        ImageFormat.JPEG, mAllCameraIds[i]), jpegSizes,
                        new Size[] {FULLHD, FULLHD_ALT});
                if (supportHeic) {
                    assertArrayContainsAnyOf(String.format(
                            ""Required FULLHD size not found for format %x for: ID %s"",
                            ImageFormat.HEIC, mAllCameraIds[i]), heicSizes,
                            new Size[] {FULLHD, FULLHD_ALT});
                }
            }

            if (activeArrayWidth >= HD.getWidth() &&
                    activeArrayHeight >= HD.getHeight()) {
                assertArrayContains(String.format(
                        ""Required HD size not found for format %x for: ID %s"",
                        ImageFormat.JPEG, mAllCameraIds[i]), jpegSizes, HD);
                if (supportHeic) {
                    assertArrayContains(String.format(
                            ""Required HD size not found for format %x for: ID %s"",
                            ImageFormat.HEIC, mAllCameraIds[i]), heicSizes, HD);
                }
            }

            if (activeArrayWidth >= VGA.getWidth() &&
                    activeArrayHeight >= VGA.getHeight()) {
                assertArrayContains(String.format(
                        ""Required VGA size not found for format %x for: ID %s"",
                        ImageFormat.JPEG, mAllCameraIds[i]), jpegSizes, VGA);
                if (supportHeic) {
                    assertArrayContains(String.format(
                            ""Required VGA size not found for format %x for: ID %s"",
                            ImageFormat.HEIC, mAllCameraIds[i]), heicSizes, VGA);
                }
            }

            if (activeArrayWidth >= QVGA.getWidth() &&
                    activeArrayHeight >= QVGA.getHeight()) {
                assertArrayContains(String.format(
                        ""Required QVGA size not found for format %x for: ID %s"",
                        ImageFormat.JPEG, mAllCameraIds[i]), jpegSizes, QVGA);
                if (supportHeic) {
                    assertArrayContains(String.format(
                            ""Required QVGA size not found for format %x for: ID %s"",
                            ImageFormat.HEIC, mAllCameraIds[i]), heicSizes, QVGA);
                }

            }

            ArrayList<Size> jpegSizesList = new ArrayList<>(Arrays.asList(jpegSizes));
            ArrayList<Size> yuvSizesList = new ArrayList<>(Arrays.asList(yuvSizes));
            ArrayList<Size> privateSizesList = new ArrayList<>(Arrays.asList(privateSizes));
            boolean isExternalCamera = (hwLevel ==
                    CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_EXTERNAL);
            Size maxVideoSize = null;
            if (isExternalCamera || isHiddenPhysicalCamera) {
                // TODO: for now, use FULLHD 30 as largest possible video size for external camera.
                // For hidden physical camera, since we don't require CamcorderProfile to be
                // available, use FULLHD 30 as maximum video size as well.
                List<Size> videoSizes = CameraTestUtils.getSupportedVideoSizes(
                        mAllCameraIds[i], mCameraManager, FULLHD);
                for (Size sz : videoSizes) {
                    long minFrameDuration = config.getOutputMinFrameDuration(
                            android.media.MediaRecorder.class, sz);
                    // Give some margin for rounding error
                    if (minFrameDuration < (1e9 / 29.9)) {
                        maxVideoSize = sz;
                        break;
                    }
                }
            } else {
                int cameraId = Integer.valueOf(mAllCameraIds[i]);
                CamcorderProfile maxVideoProfile = CamcorderProfile.get(
                        cameraId, CamcorderProfile.QUALITY_HIGH);
                maxVideoSize = new Size(
                        maxVideoProfile.videoFrameWidth, maxVideoProfile.videoFrameHeight);
            }
            if (maxVideoSize == null) {
                fail(""Camera "" + mAllCameraIds[i] + "" does not support any 30fps video output"");
            }

            // Handle FullHD special case first
            if (jpegSizesList.contains(FULLHD)) {
                if (compareHardwareLevel(hwLevel, LEVEL_3) >= 0 || hwLevel == FULL ||
                        (hwLevel == LIMITED &&
                        maxVideoSize.getWidth() >= FULLHD.getWidth() &&
                        maxVideoSize.getHeight() >= FULLHD.getHeight())) {
                    boolean yuvSupportFullHD = yuvSizesList.contains(FULLHD) ||
                            yuvSizesList.contains(FULLHD_ALT);
                    boolean privateSupportFullHD = privateSizesList.contains(FULLHD) ||
                            privateSizesList.contains(FULLHD_ALT);
                    assertTrue(""Full device FullHD YUV size not found"", yuvSupportFullHD);
                    assertTrue(""Full device FullHD PRIVATE size not found"", privateSupportFullHD);

                    if (isMonochromeWithY8) {
                        ArrayList<Size> y8SizesList = new ArrayList<>(Arrays.asList(y8Sizes));
                        boolean y8SupportFullHD = y8SizesList.contains(FULLHD) ||
                                y8SizesList.contains(FULLHD_ALT);
                        assertTrue(""Full device FullHD Y8 size not found"", y8SupportFullHD);
                    }
                }
                // remove all FullHD or FullHD_Alt sizes for the remaining of the test
                jpegSizesList.remove(FULLHD);
                jpegSizesList.remove(FULLHD_ALT);
            }

            // Check all sizes other than FullHD
            if (hwLevel == LIMITED) {
                // Remove all jpeg sizes larger than max video size
                ArrayList<Size> toBeRemoved = new ArrayList<>();
                for (Size size : jpegSizesList) {
                    if (size.getWidth() >= maxVideoSize.getWidth() &&
                            size.getHeight() >= maxVideoSize.getHeight()) {
                        toBeRemoved.add(size);
                    }
                }
                jpegSizesList.removeAll(toBeRemoved);
            }

            if (compareHardwareLevel(hwLevel, LEVEL_3) >= 0 || hwLevel == FULL ||
                    hwLevel == LIMITED) {
                if (!yuvSizesList.containsAll(jpegSizesList)) {
                    for (Size s : jpegSizesList) {
                        if (!yuvSizesList.contains(s)) {
                            fail(""Size "" + s + "" not found in YUV format"");
                        }
                    }
                }

                if (isMonochromeWithY8) {
                    ArrayList<Size> y8SizesList = new ArrayList<>(Arrays.asList(y8Sizes));
                    if (!y8SizesList.containsAll(jpegSizesList)) {
                        for (Size s : jpegSizesList) {
                            if (!y8SizesList.contains(s)) {
                                fail(""Size "" + s + "" not found in Y8 format"");
                            }
                        }
                    }
                }
            }

            if (!privateSizesList.containsAll(yuvSizesList)) {
                for (Size s : yuvSizesList) {
                    if (!privateSizesList.contains(s)) {
                        fail(""Size "" + s + "" not found in PRIVATE format"");
                    }
                }
            }
        }
    }

    private void verifyCommonRecommendedConfiguration(String id, CameraCharacteristics c,
            RecommendedStreamConfigurationMap config, boolean checkNoInput,
            boolean checkNoHighRes, boolean checkNoHighSpeed, boolean checkNoPrivate,
            boolean checkNoDepth) {
        StreamConfigurationMap fullConfig = c.get(
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
        assertNotNull(String.format(""No stream configuration map found for ID: %s!"", id),
                fullConfig);

        Set<Integer> recommendedOutputFormats = config.getOutputFormats();

        if (checkNoInput) {
            Set<Integer> inputFormats = config.getInputFormats();
            assertTrue(String.format(""Recommended configuration must not include any input "" +
                    ""streams for ID: %s"", id),
                    ((inputFormats == null) || (inputFormats.size() == 0)));
        }

        if (checkNoHighRes) {
            for (int format : recommendedOutputFormats) {
                Set<Size> highResSizes = config.getHighResolutionOutputSizes(format);
                assertTrue(String.format(""Recommended configuration should not include any "" +
                        ""high resolution sizes, which cannot operate at full "" +
                        ""BURST_CAPTURE rate for ID: %s"", id),
                        ((highResSizes == null) || (highResSizes.size() == 0)));
            }
        }

        if (checkNoHighSpeed) {
            Set<Size> highSpeedSizes = config.getHighSpeedVideoSizes();
            assertTrue(String.format(""Recommended configuration must not include any high "" +
                    ""speed configurations for ID: %s"", id),
                    ((highSpeedSizes == null) || (highSpeedSizes.size() == 0)));
        }

        int[] exhaustiveOutputFormats = fullConfig.getOutputFormats();
        for (Integer formatInteger : recommendedOutputFormats) {
            int format = formatInteger.intValue();
            assertArrayContains(String.format(""Unsupported recommended output format: %d for "" +
                    ""ID: %s "", format, id), exhaustiveOutputFormats, format);
            Set<Size> recommendedSizes = config.getOutputSizes(format);

            switch (format) {
                case ImageFormat.PRIVATE:
                    if (checkNoPrivate) {
                        fail(String.format(""Recommended configuration must not include "" +
                                ""PRIVATE format entries for ID: %s"", id));
                    }

                    Set<Size> classOutputSizes = config.getOutputSizes(ImageReader.class);
                    assertCollectionContainsAnyOf(String.format(""Recommended output sizes for "" +
                            ""ImageReader class don't match the output sizes for the "" +
                            ""corresponding format for ID: %s"", id), classOutputSizes,
                            recommendedSizes);
                    break;
                case ImageFormat.DEPTH16:
                case ImageFormat.DEPTH_POINT_CLOUD:
                    if (checkNoDepth) {
                        fail(String.format(""Recommended configuration must not include any DEPTH "" +
                                ""formats for ID: %s"", id));
                    }
                    break;
                default:
            }
            Size [] exhaustiveSizes = fullConfig.getOutputSizes(format);
            for (Size sz : recommendedSizes) {
                assertArrayContains(String.format(""Unsupported recommended size %s for "" +
                        ""format: %d for ID: %s"", sz.toString(), format, id),
                        exhaustiveSizes, sz);

                long recommendedMinDuration = config.getOutputMinFrameDuration(format, sz);
                long availableMinDuration = fullConfig.getOutputMinFrameDuration(format, sz);
                assertTrue(String.format(""Recommended minimum frame duration %d for size "" +
                        ""%s format: %d doesn't match with currently available minimum"" +
                        "" frame duration of %d for ID: %s"", recommendedMinDuration,
                        sz.toString(), format, availableMinDuration, id),
                        (recommendedMinDuration == availableMinDuration));
                long recommendedStallDuration = config.getOutputStallDuration(format, sz);
                long availableStallDuration = fullConfig.getOutputStallDuration(format, sz);
                assertTrue(String.format(""Recommended stall duration %d for size %s"" +
                        "" format: %d doesn't match with currently available stall "" +
                        ""duration of %d for ID: %s"", recommendedStallDuration,
                        sz.toString(), format, availableStallDuration, id),
                        (recommendedStallDuration == availableStallDuration));

                ImageReader reader = ImageReader.newInstance(sz.getWidth(), sz.getHeight(), format,
                        /*maxImages*/1);
                Surface readerSurface = reader.getSurface();
                assertTrue(String.format(""ImageReader surface using format %d and size %s is not"" +
                        "" supported for ID: %s"", format, sz.toString(), id),
                        config.isOutputSupportedFor(readerSurface));
                if (format == ImageFormat.PRIVATE) {
                    long classMinDuration = config.getOutputMinFrameDuration(ImageReader.class, sz);
                    assertTrue(String.format(""Recommended minimum frame duration %d for size "" +
                            ""%s format: %d doesn't match with the duration %d for "" +
                            ""ImageReader class of the same size"", recommendedMinDuration,
                            sz.toString(), format, classMinDuration),
                            classMinDuration == recommendedMinDuration);
                    long classStallDuration = config.getOutputStallDuration(ImageReader.class, sz);
                    assertTrue(String.format(""Recommended stall duration %d for size "" +
                            ""%s format: %d doesn't match with the stall duration %d for "" +
                            ""ImageReader class of the same size"", recommendedStallDuration,
                            sz.toString(), format, classStallDuration),
                            classStallDuration == recommendedStallDuration);
                }
            }
        }
    }

    private void verifyRecommendedPreviewConfiguration(String cameraId, CameraCharacteristics c,
            RecommendedStreamConfigurationMap previewConfig) {
        verifyCommonRecommendedConfiguration(cameraId, c, previewConfig, /*checkNoInput*/ true,
                /*checkNoHighRes*/ true, /*checkNoHighSpeed*/ true, /*checkNoPrivate*/ false,
                /*checkNoDepth*/ true);

        Set<Integer> outputFormats = previewConfig.getOutputFormats();
        assertTrue(String.format(""No valid YUV_420_888 and PRIVATE preview "" +
                ""formats found in recommended preview configuration for ID: %s"", cameraId),
                outputFormats.containsAll(Arrays.asList(new Integer(ImageFormat.YUV_420_888),
                        new Integer(ImageFormat.PRIVATE))));
    }

    private void verifyRecommendedVideoConfiguration(String cameraId, CameraCharacteristics c,
            RecommendedStreamConfigurationMap videoConfig) {
        verifyCommonRecommendedConfiguration(cameraId, c, videoConfig, /*checkNoInput*/ true,
                /*checkNoHighRes*/ true, /*checkNoHighSpeed*/ false, /*checkNoPrivate*/false,
                /*checkNoDepth*/ true);

        Set<Size> highSpeedSizes = videoConfig.getHighSpeedVideoSizes();
        StreamConfigurationMap fullConfig = c.get(
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
        assertNotNull(""No stream configuration map found!"", fullConfig);
        Size [] availableHighSpeedSizes = fullConfig.getHighSpeedVideoSizes();
        if ((highSpeedSizes != null) && (highSpeedSizes.size() > 0)) {
            for (Size sz : highSpeedSizes) {
                assertArrayContains(String.format(""Recommended video configuration includes "" +
                        ""unsupported high speed configuration with size %s for ID: %s"",
                        sz.toString(), cameraId), availableHighSpeedSizes, sz);
                Set<Range<Integer>>  highSpeedFpsRanges =
                    videoConfig.getHighSpeedVideoFpsRangesFor(sz);
                Range<Integer> [] availableHighSpeedFpsRanges =
                    fullConfig.getHighSpeedVideoFpsRangesFor(sz);
                for (Range<Integer> fpsRange : highSpeedFpsRanges) {
                    assertArrayContains(String.format(""Recommended video configuration includes "" +
                            ""unsupported high speed fps range [%d %d] for ID: %s"",
                            fpsRange.getLower().intValue(), fpsRange.getUpper().intValue(),
                            cameraId), availableHighSpeedFpsRanges, fpsRange);
                }
            }
        }

        final int[] profileList = {
            CamcorderProfile.QUALITY_2160P,
            CamcorderProfile.QUALITY_1080P,
            CamcorderProfile.QUALITY_480P,
            CamcorderProfile.QUALITY_720P,
            CamcorderProfile.QUALITY_CIF,
            CamcorderProfile.QUALITY_HIGH,
            CamcorderProfile.QUALITY_LOW,
            CamcorderProfile.QUALITY_QCIF,
            CamcorderProfile.QUALITY_QVGA,
        };
        Set<Size> privateSizeSet = videoConfig.getOutputSizes(ImageFormat.PRIVATE);
        for (int profile : profileList) {
            int idx = Integer.valueOf(cameraId);
            if (CamcorderProfile.hasProfile(idx, profile)) {
                CamcorderProfile videoProfile = CamcorderProfile.get(idx, profile);
                Size profileSize  = new Size(videoProfile.videoFrameWidth,
                        videoProfile.videoFrameHeight);
                assertCollectionContainsAnyOf(String.format(""Recommended video configuration "" +
                        ""doesn't include supported video profile size %s with Private format "" +
                        ""for ID: %s"", profileSize.toString(), cameraId), privateSizeSet,
                        Arrays.asList(profileSize));
            }
        }
    }

    private Pair<Boolean, Size> isSizeWithinSensorMargin(Size sz, Size sensorSize) {
        final float SIZE_ERROR_MARGIN = 0.03f;
        float croppedWidth = (float)sensorSize.getWidth();
        float croppedHeight = (float)sensorSize.getHeight();
        float sensorAspectRatio = (float)sensorSize.getWidth() / (float)sensorSize.getHeight();
        float maxAspectRatio = (float)sz.getWidth() / (float)sz.getHeight();
        if (sensorAspectRatio < maxAspectRatio) {
            croppedHeight = (float)sensorSize.getWidth() / maxAspectRatio;
        } else if (sensorAspectRatio > maxAspectRatio) {
            croppedWidth = (float)sensorSize.getHeight() * maxAspectRatio;
        }
        Size croppedSensorSize = new Size((int)croppedWidth, (int)croppedHeight);

        Boolean match = new Boolean(
            (sz.getWidth() <= croppedSensorSize.getWidth() * (1.0 + SIZE_ERROR_MARGIN) &&
             sz.getWidth() >= croppedSensorSize.getWidth() * (1.0 - SIZE_ERROR_MARGIN) &&
             sz.getHeight() <= croppedSensorSize.getHeight() * (1.0 + SIZE_ERROR_MARGIN) &&
             sz.getHeight() >= croppedSensorSize.getHeight() * (1.0 - SIZE_ERROR_MARGIN)));

        return Pair.create(match, croppedSensorSize);
    }

    private void verifyRecommendedSnapshotConfiguration(String cameraId, CameraCharacteristics c,
            RecommendedStreamConfigurationMap snapshotConfig) {
        verifyCommonRecommendedConfiguration(cameraId, c, snapshotConfig, /*checkNoInput*/ true,
                /*checkNoHighRes*/ false, /*checkNoHighSpeed*/ true, /*checkNoPrivate*/false,
                /*checkNoDepth*/ false);
        Rect activeRect = CameraTestUtils.getValueNotNull(
                c, CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE);
        Size arraySize = new Size(activeRect.width(), activeRect.height());


        ArraySet<Size> snapshotSizeSet = new ArraySet<>(snapshotConfig.getOutputSizes(
                    ImageFormat.JPEG));
        Set<Size> highResSnapshotSizeSet = snapshotConfig.getHighResolutionOutputSizes(
                ImageFormat.JPEG);
        if (highResSnapshotSizeSet != null) {
            snapshotSizeSet.addAll(highResSnapshotSizeSet);
        }
        Size[] snapshotSizes = new Size[snapshotSizeSet.size()];
        snapshotSizes = snapshotSizeSet.toArray(snapshotSizes);
        Size maxJpegSize = CameraTestUtils.getMaxSize(snapshotSizes);
        assertTrue(String.format(""Maximum recommended Jpeg size %s should be within 3 percent "" +
                ""of the area of the advertised array size %s for ID: %s"",
                maxJpegSize.toString(), arraySize.toString(), cameraId),
                isSizeWithinSensorMargin(maxJpegSize, arraySize).first.booleanValue());
    }

    private void verifyRecommendedVideoSnapshotConfiguration(String cameraId,
            CameraCharacteristics c,
            RecommendedStreamConfigurationMap videoSnapshotConfig,
            RecommendedStreamConfigurationMap videoConfig) {
        verifyCommonRecommendedConfiguration(cameraId, c, videoSnapshotConfig,
                /*checkNoInput*/ true, /*checkNoHighRes*/ false, /*checkNoHighSpeed*/ true,
                /*checkNoPrivate*/ true, /*checkNoDepth*/ true);

        Set<Integer> outputFormats = videoSnapshotConfig.getOutputFormats();
        assertCollectionContainsAnyOf(String.format(""No valid JPEG format found "" +
                ""in recommended video snapshot configuration for ID: %s"", cameraId),
                outputFormats, Arrays.asList(new Integer(ImageFormat.JPEG)));
        assertTrue(String.format(""Recommended video snapshot configuration must only advertise "" +
                ""JPEG format for ID: %s"", cameraId), outputFormats.size() == 1);

        Set<Size> privateVideoSizeSet = videoConfig.getOutputSizes(ImageFormat.PRIVATE);
        Size[] privateVideoSizes = new Size[privateVideoSizeSet.size()];
        privateVideoSizes = privateVideoSizeSet.toArray(privateVideoSizes);
        Size maxVideoSize = CameraTestUtils.getMaxSize(privateVideoSizes);
        Set<Size> outputSizes = videoSnapshotConfig.getOutputSizes(ImageFormat.JPEG);
        assertCollectionContainsAnyOf(String.format(""The maximum recommended video size %s "" +
                ""should be present in the recommended video snapshot configurations for ID: %s"",
                maxVideoSize.toString(), cameraId), outputSizes, Arrays.asList(maxVideoSize));
    }

    private void verifyRecommendedRawConfiguration(String cameraId,
            CameraCharacteristics c, RecommendedStreamConfigurationMap rawConfig) {
        verifyCommonRecommendedConfiguration(cameraId, c, rawConfig, /*checkNoInput*/ true,
                /*checkNoHighRes*/ false, /*checkNoHighSpeed*/ true, /*checkNoPrivate*/ true,
                /*checkNoDepth*/ true);

        Set<Integer> outputFormats = rawConfig.getOutputFormats();
        for (Integer outputFormatInteger : outputFormats) {
            int outputFormat = outputFormatInteger.intValue();
            switch (outputFormat) {
                case ImageFormat.RAW10:
                case ImageFormat.RAW12:
                case ImageFormat.RAW_PRIVATE:
                case ImageFormat.RAW_SENSOR:
                    break;
                default:
                    fail(String.format(""Recommended raw configuration map must not contain "" +
                            "" non-RAW formats like: %d for ID: %s"", outputFormat, cameraId));

            }
        }
    }

    private void verifyRecommendedZSLConfiguration(String cameraId, CameraCharacteristics c,
            RecommendedStreamConfigurationMap zslConfig) {
        verifyCommonRecommendedConfiguration(cameraId, c, zslConfig, /*checkNoInput*/ false,
                /*checkNoHighRes*/ false, /*checkNoHighSpeed*/ true, /*checkNoPrivate*/ false,
                /*checkNoDepth*/ false);

        StreamConfigurationMap fullConfig =
            c.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
        assertNotNull(String.format(""No stream configuration map found for ID: %s!"", cameraId),
                fullConfig);
        Set<Integer> inputFormats = zslConfig.getInputFormats();
        int [] availableInputFormats = fullConfig.getInputFormats();
        for (Integer inputFormatInteger : inputFormats) {
            int inputFormat = inputFormatInteger.intValue();
            assertArrayContains(String.format(""Recommended ZSL configuration includes "" +
                    ""unsupported input format %d for ID: %s"", inputFormat, cameraId),
                    availableInputFormats, inputFormat);

            Set<Size> inputSizes = zslConfig.getInputSizes(inputFormat);
            Size [] availableInputSizes = fullConfig.getInputSizes(inputFormat);
            assertTrue(String.format(""Recommended ZSL configuration input format %d includes "" +
                    ""invalid input sizes for ID: %s"", inputFormat, cameraId),
                    ((inputSizes != null) && (inputSizes.size() > 0)));
            for (Size inputSize : inputSizes) {
                assertArrayContains(String.format(""Recommended ZSL configuration includes "" +
                        ""unsupported input format %d with size %s ID: %s"", inputFormat,
                        inputSize.toString(), cameraId), availableInputSizes, inputSize);
            }
            Set<Integer> validOutputFormats = zslConfig.getValidOutputFormatsForInput(inputFormat);
            int [] availableValidOutputFormats = fullConfig.getValidOutputFormatsForInput(
                    inputFormat);
            for (Integer outputFormatInteger : validOutputFormats) {
                int outputFormat = outputFormatInteger.intValue();
                assertArrayContains(String.format(""Recommended ZSL configuration includes "" +
                        ""unsupported output format %d for input %s ID: %s"", outputFormat,
                        inputFormat, cameraId), availableValidOutputFormats, outputFormat);
            }
        }
    }

    private void checkFormatLatency(int format, long latencyThresholdMs,
            RecommendedStreamConfigurationMap configMap) throws Exception {
        Set<Size> availableSizes = configMap.getOutputSizes(format);
        assertNotNull(String.format(""No available sizes for output format: %d"", format),
                availableSizes);

        ImageReader previewReader = null;
        long threshold = (long) (latencyThresholdMs * LATENCY_TOLERANCE_FACTOR);
        // for each resolution, check that the end-to-end latency doesn't exceed the given threshold
        for (Size sz : availableSizes) {
            try {
                // Create ImageReaders, capture session and requests
                final ImageReader.OnImageAvailableListener mockListener = mock(
                        ImageReader.OnImageAvailableListener.class);
                createDefaultImageReader(sz, format, MAX_NUM_IMAGES, mockListener);
                Size previewSize = mOrderedPreviewSizes.get(0);
                previewReader = createImageReader(previewSize, ImageFormat.YUV_420_888,
                        MAX_NUM_IMAGES, new CameraTestUtils.ImageDropperListener());
                Surface previewSurface = previewReader.getSurface();
                List<Surface> surfaces = new ArrayList<Surface>();
                surfaces.add(previewSurface);
                surfaces.add(mReaderSurface);
                createSession(surfaces);
                CaptureRequest.Builder captureBuilder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
                captureBuilder.addTarget(previewSurface);
                CaptureRequest request = captureBuilder.build();

                // Let preview run for a while
                startCapture(request, /*repeating*/ true, new SimpleCaptureCallback(), mHandler);
                Thread.sleep(PREVIEW_RUN_MS);

                // Start capture.
                captureBuilder = mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
                captureBuilder.addTarget(mReaderSurface);
                request = captureBuilder.build();

                for (int i = 0; i < MAX_NUM_IMAGES; i++) {
                    startCapture(request, /*repeating*/ false, new SimpleCaptureCallback(),
                            mHandler);
                    verify(mockListener, timeout(threshold).times(1)).onImageAvailable(
                            any(ImageReader.class));
                    reset(mockListener);
                }

                // stop capture.
                stopCapture(/*fast*/ false);
            } finally {
                closeDefaultImageReader();

                if (previewReader != null) {
                    previewReader.close();
                    previewReader = null;
                }
            }

        }
    }

    private void verifyRecommendedLowLatencyConfiguration(String cameraId, CameraCharacteristics c,
            RecommendedStreamConfigurationMap lowLatencyConfig) throws Exception {
        verifyCommonRecommendedConfiguration(cameraId, c, lowLatencyConfig, /*checkNoInput*/ true,
                /*checkNoHighRes*/ false, /*checkNoHighSpeed*/ true, /*checkNoPrivate*/ false,
                /*checkNoDepth*/ true);

        try {
            openDevice(cameraId);

            Set<Integer> formats = lowLatencyConfig.getOutputFormats();
            for (Integer format : formats) {
                checkFormatLatency(format.intValue(), LOW_LATENCY_THRESHOLD_MS, lowLatencyConfig);
            }
        } finally {
            closeDevice(cameraId);
        }

    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"testKeys"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"public void testKeys() {
        for (int i = 0; i < mAllCameraIds.length; i++) {
            CameraCharacteristics c = mCharacteristics.get(i);
            mCollector.setCameraId(mAllCameraIds[i]);

            if (VERBOSE) {
                Log.v(TAG, ""testKeys - testing characteristics for camera "" + mAllCameraIds[i]);
            }

            List<CameraCharacteristics.Key<?>> allKeys = c.getKeys();
            assertNotNull(""Camera characteristics keys must not be null"", allKeys);
            assertFalse(""Camera characteristics keys must have at least 1 key"",
                    allKeys.isEmpty());

            for (CameraCharacteristics.Key<?> key : allKeys) {
                assertKeyPrefixValid(key.getName());

                // All characteristics keys listed must never be null
                mCollector.expectKeyValueNotNull(c, key);

                // TODO: add a check that key must not be @hide
            }

            /*
             * List of keys that must be present in camera characteristics (not null).
             *
             * Keys for LIMITED, FULL devices might be available despite lacking either
             * the hardware level or the capability. This is *OK*. This only lists the
             * *minimal* requirements for a key to be listed.
             *
             * LEGACY devices are a bit special since they map to api1 devices, so we know
             * for a fact most keys are going to be illegal there so they should never be
             * available.
             *
             * For LIMITED-level keys, if the level is >= LIMITED, then the capabilities are used to
             * do the actual checking.
             */
            {
                //                                           (Key Name)                                     (HW Level)  (Capabilities <Var-Arg>)
                expectKeyAvailable(c, CameraCharacteristics.COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES     , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_AVAILABLE_MODES                         , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_AE_AVAILABLE_ANTIBANDING_MODES          , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_AE_AVAILABLE_MODES                      , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES          , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_AE_COMPENSATION_RANGE                   , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_AE_COMPENSATION_STEP                    , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_AE_LOCK_AVAILABLE                       , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_AF_AVAILABLE_MODES                      , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_AVAILABLE_EFFECTS                       , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_AVAILABLE_SCENE_MODES                   , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_AVAILABLE_VIDEO_STABILIZATION_MODES     , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_AWB_AVAILABLE_MODES                     , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_AWB_LOCK_AVAILABLE                      , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_MAX_REGIONS_AE                          , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_MAX_REGIONS_AF                          , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.CONTROL_MAX_REGIONS_AWB                         , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.EDGE_AVAILABLE_EDGE_MODES                       , FULL     ,   NONE                 );
                expectKeyAvailable(c, CameraCharacteristics.FLASH_INFO_AVAILABLE                            , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.HOT_PIXEL_AVAILABLE_HOT_PIXEL_MODES             , OPT      ,   RAW                  );
                expectKeyAvailable(c, CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL                   , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.INFO_VERSION                                    , OPT      ,   NONE                 );
                expectKeyAvailable(c, CameraCharacteristics.JPEG_AVAILABLE_THUMBNAIL_SIZES                  , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.LENS_FACING                                     , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.LENS_INFO_AVAILABLE_APERTURES                   , FULL     ,   MANUAL_SENSOR        );
                expectKeyAvailable(c, CameraCharacteristics.LENS_INFO_AVAILABLE_FILTER_DENSITIES            , FULL     ,   MANUAL_SENSOR        );
                expectKeyAvailable(c, CameraCharacteristics.LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION       , LIMITED  ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.LENS_INFO_FOCUS_DISTANCE_CALIBRATION            , LIMITED  ,   MANUAL_SENSOR        );
                expectKeyAvailable(c, CameraCharacteristics.LENS_INFO_HYPERFOCAL_DISTANCE                   , LIMITED  ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.LENS_INFO_MINIMUM_FOCUS_DISTANCE                , LIMITED  ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.NOISE_REDUCTION_AVAILABLE_NOISE_REDUCTION_MODES , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES                  , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.REQUEST_MAX_NUM_INPUT_STREAMS                   , OPT      ,   YUV_REPROCESS, OPAQUE_REPROCESS);
                expectKeyAvailable(c, CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP                 , OPT      ,   CONSTRAINED_HIGH_SPEED);
                expectKeyAvailable(c, CameraCharacteristics.REQUEST_MAX_NUM_OUTPUT_PROC                     , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.REQUEST_MAX_NUM_OUTPUT_PROC_STALLING            , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.REQUEST_MAX_NUM_OUTPUT_RAW                      , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.REQUEST_PARTIAL_RESULT_COUNT                    , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.REQUEST_PIPELINE_MAX_DEPTH                      , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.SCALER_AVAILABLE_MAX_DIGITAL_ZOOM               , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP                 , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.SCALER_CROPPING_TYPE                            , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_BLACK_LEVEL_PATTERN                      , FULL     ,   RAW                  );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE                   , OPT      ,   BC, RAW              );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT            , FULL     ,   RAW                  );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_INFO_EXPOSURE_TIME_RANGE                 , FULL     ,   MANUAL_SENSOR        );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_INFO_MAX_FRAME_DURATION                  , FULL     ,   MANUAL_SENSOR        );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE                    , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_INFO_SENSITIVITY_RANGE                   , FULL     ,   MANUAL_SENSOR        );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_INFO_WHITE_LEVEL                         , OPT      ,   RAW                  );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_INFO_TIMESTAMP_SOURCE                    , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_MAX_ANALOG_SENSITIVITY                   , FULL     ,   MANUAL_SENSOR        );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_ORIENTATION                              , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.SHADING_AVAILABLE_MODES                         , LIMITED  ,   MANUAL_POSTPROC, RAW );
                expectKeyAvailable(c, CameraCharacteristics.STATISTICS_INFO_AVAILABLE_FACE_DETECT_MODES     , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.STATISTICS_INFO_AVAILABLE_HOT_PIXEL_MAP_MODES   , OPT      ,   RAW                  );
                expectKeyAvailable(c, CameraCharacteristics.STATISTICS_INFO_AVAILABLE_LENS_SHADING_MAP_MODES, LIMITED  ,   RAW                  );
                expectKeyAvailable(c, CameraCharacteristics.STATISTICS_INFO_MAX_FACE_COUNT                  , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.SYNC_MAX_LATENCY                                , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.TONEMAP_AVAILABLE_TONE_MAP_MODES                , FULL     ,   MANUAL_POSTPROC      );
                expectKeyAvailable(c, CameraCharacteristics.TONEMAP_MAX_CURVE_POINTS                        , FULL     ,   MANUAL_POSTPROC      );

                // Future: Use column editors for modifying above, ignore line length to keep 1 key per line

                // TODO: check that no other 'android' keys are listed in #getKeys if they aren't in the above list
            }

            int[] actualCapabilities = c.get(CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
            assertNotNull(""android.request.availableCapabilities must never be null"",
                    actualCapabilities);
            boolean isMonochrome = arrayContains(actualCapabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MONOCHROME);
            if (!isMonochrome) {
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_CALIBRATION_TRANSFORM1                   , OPT      ,   RAW                  );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_COLOR_TRANSFORM1                         , OPT      ,   RAW                  );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_FORWARD_MATRIX1                          , OPT      ,   RAW                  );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT1                    , OPT      ,   RAW                  );


                // Only check for these if the second reference illuminant is included
                if (allKeys.contains(CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT2)) {
                    expectKeyAvailable(c, CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT2                    , OPT      ,   RAW                  );
                    expectKeyAvailable(c, CameraCharacteristics.SENSOR_COLOR_TRANSFORM2                         , OPT      ,   RAW                  );
                    expectKeyAvailable(c, CameraCharacteristics.SENSOR_CALIBRATION_TRANSFORM2                   , OPT      ,   RAW                  );
                    expectKeyAvailable(c, CameraCharacteristics.SENSOR_FORWARD_MATRIX2                          , OPT      ,   RAW                  );
                }
            }

            // Required key if any of RAW format output is supported
            StreamConfigurationMap config =
                    c.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
            assertNotNull(String.format(""No stream configuration map found for: ID %s"",
                    mAllCameraIds[i]), config);
            if (config.isOutputSupportedFor(ImageFormat.RAW_SENSOR) ||
                    config.isOutputSupportedFor(ImageFormat.RAW10)  ||
                    config.isOutputSupportedFor(ImageFormat.RAW12)  ||
                    config.isOutputSupportedFor(ImageFormat.RAW_PRIVATE)) {
                expectKeyAvailable(c,
                        CameraCharacteristics.CONTROL_POST_RAW_SENSITIVITY_BOOST_RANGE, OPT, BC);
            }

            // External Camera exceptional keys
            Integer hwLevel = c.get(CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL);
            boolean isExternalCamera = (hwLevel ==
                    CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_EXTERNAL);
            if (!isExternalCamera) {
                expectKeyAvailable(c, CameraCharacteristics.LENS_INFO_AVAILABLE_FOCAL_LENGTHS               , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_AVAILABLE_TEST_PATTERN_MODES             , OPT      ,   BC                   );
                expectKeyAvailable(c, CameraCharacteristics.SENSOR_INFO_PHYSICAL_SIZE                       , OPT      ,   BC                   );
            }


            // Verify version is a short text string.
            if (allKeys.contains(CameraCharacteristics.INFO_VERSION)) {
                final String TEXT_REGEX = ""[\\p{Alnum}\\p{Punct}\\p{Space}]*"";
                final int MAX_VERSION_LENGTH = 256;

                String version = c.get(CameraCharacteristics.INFO_VERSION);
                mCollector.expectTrue(""Version contains non-text characters: "" + version,
                        version.matches(TEXT_REGEX));
                mCollector.expectLessOrEqual(""Version too long: "" + version, MAX_VERSION_LENGTH,
                        version.length());
            }
        }
    }

    /**
     * Test values for static metadata used by the RAW capability.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"testStaticRawCharacteristics"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"public void testStaticRawCharacteristics() {
        for (int i = 0; i < mAllCameraIds.length; i++) {
            CameraCharacteristics c = mCharacteristics.get(i);
            int[] actualCapabilities = c.get(CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
            assertNotNull(""android.request.availableCapabilities must never be null"",
                    actualCapabilities);
            if (!arrayContains(actualCapabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_RAW)) {
                Log.i(TAG, ""RAW capability is not supported in camera "" + mAllCameraIds[i] +
                        "". Skip the test."");
                continue;
            }

            Integer actualHwLevel = c.get(CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL);
            if (actualHwLevel != null && actualHwLevel == FULL) {
                mCollector.expectKeyValueContains(c,
                        CameraCharacteristics.HOT_PIXEL_AVAILABLE_HOT_PIXEL_MODES,
                        CameraCharacteristics.HOT_PIXEL_MODE_FAST);
            }
            mCollector.expectKeyValueContains(c,
                    CameraCharacteristics.STATISTICS_INFO_AVAILABLE_HOT_PIXEL_MAP_MODES, false);
            mCollector.expectKeyValueGreaterThan(c, CameraCharacteristics.SENSOR_INFO_WHITE_LEVEL,
                    MIN_ALLOWABLE_WHITELEVEL);


            boolean isMonochrome = arrayContains(actualCapabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MONOCHROME);
            if (!isMonochrome) {
                mCollector.expectKeyValueIsIn(c,
                        CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT,
                        CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_RGGB,
                        CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_GRBG,
                        CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_GBRG,
                        CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_BGGR);
                // TODO: SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_RGB isn't supported yet.

                mCollector.expectKeyValueInRange(c,
                        CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT1,
                        CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT1_DAYLIGHT,
                        CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT1_ISO_STUDIO_TUNGSTEN);
                // Only check the range if the second reference illuminant is avaliable
                if (c.get(CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT2) != null) {
                        mCollector.expectKeyValueInRange(c,
                        CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT2,
                        (byte) CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT1_DAYLIGHT,
                        (byte) CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT1_ISO_STUDIO_TUNGSTEN);
                }

                Rational[] zeroes = new Rational[9];
                Arrays.fill(zeroes, Rational.ZERO);

                ColorSpaceTransform zeroed = new ColorSpaceTransform(zeroes);
                mCollector.expectNotEquals(""Forward Matrix1 should not contain all zeroes."", zeroed,
                        c.get(CameraCharacteristics.SENSOR_FORWARD_MATRIX1));
                mCollector.expectNotEquals(""Forward Matrix2 should not contain all zeroes."", zeroed,
                        c.get(CameraCharacteristics.SENSOR_FORWARD_MATRIX2));
                mCollector.expectNotEquals(""Calibration Transform1 should not contain all zeroes."",
                        zeroed, c.get(CameraCharacteristics.SENSOR_CALIBRATION_TRANSFORM1));
                mCollector.expectNotEquals(""Calibration Transform2 should not contain all zeroes."",
                        zeroed, c.get(CameraCharacteristics.SENSOR_CALIBRATION_TRANSFORM2));
                mCollector.expectNotEquals(""Color Transform1 should not contain all zeroes."",
                        zeroed, c.get(CameraCharacteristics.SENSOR_COLOR_TRANSFORM1));
                mCollector.expectNotEquals(""Color Transform2 should not contain all zeroes."",
                        zeroed, c.get(CameraCharacteristics.SENSOR_COLOR_TRANSFORM2));
            } else {
                mCollector.expectKeyValueIsIn(c,
                        CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT,
                        CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_MONO,
                        CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_NIR);
                // TODO: SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_RGB isn't supported yet.
            }

            BlackLevelPattern blackLevel = mCollector.expectKeyValueNotNull(c,
                    CameraCharacteristics.SENSOR_BLACK_LEVEL_PATTERN);
            if (blackLevel != null) {
                String blackLevelPatternString = blackLevel.toString();
                if (VERBOSE) {
                    Log.v(TAG, ""Black level pattern: "" + blackLevelPatternString);
                }
                int[] blackLevelPattern = new int[BlackLevelPattern.COUNT];
                blackLevel.copyTo(blackLevelPattern, /*offset*/0);
                if (isMonochrome) {
                    for (int index = 1; index < BlackLevelPattern.COUNT; index++) {
                        mCollector.expectEquals(
                                ""Monochrome camera 2x2 channels blacklevel value must be the same."",
                                blackLevelPattern[index], blackLevelPattern[0]);
                    }
                }

                Integer whitelevel = c.get(CameraCharacteristics.SENSOR_INFO_WHITE_LEVEL);
                if (whitelevel != null) {
                    mCollector.expectValuesInRange(""BlackLevelPattern"", blackLevelPattern, 0,
                            whitelevel);
                } else {
                    mCollector.addMessage(
                            ""No WhiteLevel available, cannot check BlackLevelPattern range."");
                }
            }

            // TODO: profileHueSatMap, and profileToneCurve aren't supported yet.
        }
    }

    /**
     * Test values for the available session keys.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"testStaticBurstCharacteristics"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"public void testStaticBurstCharacteristics() throws Exception {
        for (int i = 0; i < mAllCameraIds.length; i++) {
            CameraCharacteristics c = mCharacteristics.get(i);
            int[] actualCapabilities = CameraTestUtils.getValueNotNull(
                    c, CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);

            // Check if the burst capability is defined
            boolean haveBurstCapability = arrayContains(actualCapabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_BURST_CAPTURE);
            boolean haveBC = arrayContains(actualCapabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE);

            if(haveBurstCapability && !haveBC) {
                fail(""Must have BACKWARD_COMPATIBLE capability if BURST_CAPTURE capability is defined"");
            }

            if (!haveBC) continue;

            StreamConfigurationMap config =
                    c.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
            assertNotNull(String.format(""No stream configuration map found for: ID %s"",
                    mAllCameraIds[i]), config);
            Rect activeRect = CameraTestUtils.getValueNotNull(
                    c, CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE);
            Size sensorSize = new Size(activeRect.width(), activeRect.height());

            // Ensure that max YUV size matches max JPEG size
            Size maxYuvSize = CameraTestUtils.getMaxSize(
                    config.getOutputSizes(ImageFormat.YUV_420_888));
            Size maxFastYuvSize = maxYuvSize;

            Size[] slowYuvSizes = config.getHighResolutionOutputSizes(ImageFormat.YUV_420_888);
            Size maxSlowYuvSizeLessThan24M = null;
            if (haveBurstCapability && slowYuvSizes != null && slowYuvSizes.length > 0) {
                Size maxSlowYuvSize = CameraTestUtils.getMaxSize(slowYuvSizes);
                final int SIZE_24MP_BOUND = 24000000;
                maxSlowYuvSizeLessThan24M =
                        CameraTestUtils.getMaxSizeWithBound(slowYuvSizes, SIZE_24MP_BOUND);
                maxYuvSize = CameraTestUtils.getMaxSize(new Size[]{maxYuvSize, maxSlowYuvSize});
            }

            Size maxJpegSize = CameraTestUtils.getMaxSize(CameraTestUtils.getSupportedSizeForFormat(
                    ImageFormat.JPEG, mAllCameraIds[i], mCameraManager));

            boolean haveMaxYuv = maxYuvSize != null ?
                (maxJpegSize.getWidth() <= maxYuvSize.getWidth() &&
                        maxJpegSize.getHeight() <= maxYuvSize.getHeight()) : false;

            Pair<Boolean, Size> maxYuvMatchSensorPair = isSizeWithinSensorMargin(maxYuvSize,
                    sensorSize);

            // No need to do null check since framework will generate the key if HAL don't supply
            boolean haveAeLock = CameraTestUtils.getValueNotNull(
                    c, CameraCharacteristics.CONTROL_AE_LOCK_AVAILABLE);
            boolean haveAwbLock = CameraTestUtils.getValueNotNull(
                    c, CameraCharacteristics.CONTROL_AWB_LOCK_AVAILABLE);

            // Ensure that some >=8MP YUV output is fast enough - needs to be at least 20 fps

            long maxFastYuvRate =
                    config.getOutputMinFrameDuration(ImageFormat.YUV_420_888, maxFastYuvSize);
            final long MIN_8MP_DURATION_BOUND_NS = 50000000; // 50 ms, 20 fps
            boolean haveFastYuvRate = maxFastYuvRate <= MIN_8MP_DURATION_BOUND_NS;

            final int SIZE_8MP_BOUND = 8000000;
            boolean havefast8MPYuv = (maxFastYuvSize.getWidth() * maxFastYuvSize.getHeight()) >
                    SIZE_8MP_BOUND;

            // Ensure that max YUV output smaller than 24MP is fast enough
            // - needs to be at least 10 fps
            final long MIN_MAXSIZE_DURATION_BOUND_NS = 100000000; // 100 ms, 10 fps
            long maxYuvRate = maxFastYuvRate;
            if (maxSlowYuvSizeLessThan24M != null) {
                maxYuvRate = config.getOutputMinFrameDuration(
                        ImageFormat.YUV_420_888, maxSlowYuvSizeLessThan24M);
            }
            boolean haveMaxYuvRate = maxYuvRate <= MIN_MAXSIZE_DURATION_BOUND_NS;

            // Ensure that there's an FPS range that's fast enough to capture at above
            // minFrameDuration, for full-auto bursts at the fast resolutions
            Range[] fpsRanges = CameraTestUtils.getValueNotNull(
                    c, CameraCharacteristics.CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES);
            float minYuvFps = 1.f / maxFastYuvRate;

            boolean haveFastAeTargetFps = false;
            for (Range<Integer> r : fpsRanges) {
                if (r.getLower() >= minYuvFps) {
                    haveFastAeTargetFps = true;
                    break;
                }
            }

            // Ensure that maximum sync latency is small enough for fast setting changes, even if
            // it's not quite per-frame

            Integer maxSyncLatencyValue = c.get(CameraCharacteristics.SYNC_MAX_LATENCY);
            assertNotNull(String.format(""No sync latency declared for ID %s"", mAllCameraIds[i]),
                    maxSyncLatencyValue);

            int maxSyncLatency = maxSyncLatencyValue;
            final long MAX_LATENCY_BOUND = 4;
            boolean haveFastSyncLatency =
                (maxSyncLatency <= MAX_LATENCY_BOUND) && (maxSyncLatency >= 0);

            if (haveBurstCapability) {
                assertTrue(""Must have slow YUV size array when BURST_CAPTURE capability is defined!"",
                        slowYuvSizes != null);
                assertTrue(
                        String.format(""BURST-capable camera device %s does not have maximum YUV "" +
                                ""size that is at least max JPEG size"",
                                mAllCameraIds[i]),
                        haveMaxYuv);
                assertTrue(
                        String.format(""BURST-capable camera device %s max-resolution "" +
                                ""YUV frame rate is too slow"" +
                                ""(%d ns min frame duration reported, less than %d ns expected)"",
                                mAllCameraIds[i], maxYuvRate, MIN_MAXSIZE_DURATION_BOUND_NS),
                        haveMaxYuvRate);
                assertTrue(
                        String.format(""BURST-capable camera device %s >= 8MP YUV output "" +
                                ""frame rate is too slow"" +
                                ""(%d ns min frame duration reported, less than %d ns expected)"",
                                mAllCameraIds[i], maxYuvRate, MIN_8MP_DURATION_BOUND_NS),
                        haveFastYuvRate);
                assertTrue(
                        String.format(""BURST-capable camera device %s does not list an AE target "" +
                                "" FPS range with min FPS >= %f, for full-AUTO bursts"",
                                mAllCameraIds[i], minYuvFps),
                        haveFastAeTargetFps);
                assertTrue(
                        String.format(""BURST-capable camera device %s YUV sync latency is too long"" +
                                ""(%d frames reported, [0, %d] frames expected)"",
                                mAllCameraIds[i], maxSyncLatency, MAX_LATENCY_BOUND),
                        haveFastSyncLatency);
                assertTrue(
                        String.format(""BURST-capable camera device %s max YUV size %s should be"" +
                                ""close to active array size %s or cropped active array size %s"",
                                mAllCameraIds[i], maxYuvSize.toString(), sensorSize.toString(),
                                maxYuvMatchSensorPair.second.toString()),
                        maxYuvMatchSensorPair.first.booleanValue());
                assertTrue(
                        String.format(""BURST-capable camera device %s does not support AE lock"",
                                mAllCameraIds[i]),
                        haveAeLock);
                assertTrue(
                        String.format(""BURST-capable camera device %s does not support AWB lock"",
                                mAllCameraIds[i]),
                        haveAwbLock);
            } else {
                assertTrue(""Must have null slow YUV size array when no BURST_CAPTURE capability!"",
                        slowYuvSizes == null);
                assertTrue(
                        String.format(""Camera device %s has all the requirements for BURST"" +
                                "" capability but does not report it!"", mAllCameraIds[i]),
                        !(haveMaxYuv && haveMaxYuvRate && haveFastYuvRate && haveFastAeTargetFps &&
                                haveFastSyncLatency && maxYuvMatchSensorPair.first.booleanValue() &&
                                haveAeLock && haveAwbLock));
            }
        }
    }

    /**
     * Check reprocessing capabilities.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"testReprocessingCharacteristics"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"public void testReprocessingCharacteristics() {
        for (int i = 0; i < mAllCameraIds.length; i++) {
            Log.i(TAG, ""testReprocessingCharacteristics: Testing camera ID "" + mAllCameraIds[i]);

            CameraCharacteristics c = mCharacteristics.get(i);
            int[] capabilities = c.get(CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
            assertNotNull(""android.request.availableCapabilities must never be null"",
                    capabilities);
            boolean supportYUV = arrayContains(capabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_YUV_REPROCESSING);
            boolean supportOpaque = arrayContains(capabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING);
            StreamConfigurationMap configs =
                    c.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
            Integer maxNumInputStreams =
                    c.get(CameraCharacteristics.REQUEST_MAX_NUM_INPUT_STREAMS);
            int[] availableEdgeModes = c.get(CameraCharacteristics.EDGE_AVAILABLE_EDGE_MODES);
            int[] availableNoiseReductionModes = c.get(
                    CameraCharacteristics.NOISE_REDUCTION_AVAILABLE_NOISE_REDUCTION_MODES);

            int[] inputFormats = configs.getInputFormats();
            int[] outputFormats = configs.getOutputFormats();
            boolean isMonochromeWithY8 = arrayContains(capabilities, MONOCHROME)
                    && arrayContains(outputFormats, ImageFormat.Y8);

            boolean supportZslEdgeMode = false;
            boolean supportZslNoiseReductionMode = false;
            boolean supportHiQNoiseReductionMode = false;
            boolean supportHiQEdgeMode = false;

            if (availableEdgeModes != null) {
                supportZslEdgeMode = Arrays.asList(CameraTestUtils.toObject(availableEdgeModes)).
                        contains(CaptureRequest.EDGE_MODE_ZERO_SHUTTER_LAG);
                supportHiQEdgeMode = Arrays.asList(CameraTestUtils.toObject(availableEdgeModes)).
                        contains(CaptureRequest.EDGE_MODE_HIGH_QUALITY);
            }

            if (availableNoiseReductionModes != null) {
                supportZslNoiseReductionMode = Arrays.asList(
                        CameraTestUtils.toObject(availableNoiseReductionModes)).contains(
                        CaptureRequest.NOISE_REDUCTION_MODE_ZERO_SHUTTER_LAG);
                supportHiQNoiseReductionMode = Arrays.asList(
                        CameraTestUtils.toObject(availableNoiseReductionModes)).contains(
                        CaptureRequest.NOISE_REDUCTION_MODE_HIGH_QUALITY);
            }

            if (supportYUV || supportOpaque) {
                mCollector.expectTrue(""Support reprocessing but max number of input stream is "" +
                        maxNumInputStreams, maxNumInputStreams != null && maxNumInputStreams > 0);
                mCollector.expectTrue(""Support reprocessing but EDGE_MODE_ZERO_SHUTTER_LAG is "" +
                        ""not supported"", supportZslEdgeMode);
                mCollector.expectTrue(""Support reprocessing but "" +
                        ""NOISE_REDUCTION_MODE_ZERO_SHUTTER_LAG is not supported"",
                        supportZslNoiseReductionMode);

                // For reprocessing, if we only require OFF and ZSL mode, it will be just like jpeg
                // encoding. We implicitly require FAST to make reprocessing meaningful, which means
                // that we also require HIGH_QUALITY.
                mCollector.expectTrue(""Support reprocessing but EDGE_MODE_HIGH_QUALITY is "" +
                        ""not supported"", supportHiQEdgeMode);
                mCollector.expectTrue(""Support reprocessing but "" +
                        ""NOISE_REDUCTION_MODE_HIGH_QUALITY is not supported"",
                        supportHiQNoiseReductionMode);

                // Verify mandatory input formats are supported
                mCollector.expectTrue(""YUV_420_888 input must be supported for YUV reprocessing"",
                        !supportYUV || arrayContains(inputFormats, ImageFormat.YUV_420_888));
                mCollector.expectTrue(""Y8 input must be supported for YUV reprocessing on "" +
                        ""MONOCHROME devices with Y8 support"", !supportYUV || !isMonochromeWithY8
                        || arrayContains(inputFormats, ImageFormat.Y8));
                mCollector.expectTrue(""PRIVATE input must be supported for OPAQUE reprocessing"",
                        !supportOpaque || arrayContains(inputFormats, ImageFormat.PRIVATE));

                // max capture stall must be reported if one of the reprocessing is supported.
                final int MAX_ALLOWED_STALL_FRAMES = 4;
                Integer maxCaptureStall = c.get(CameraCharacteristics.REPROCESS_MAX_CAPTURE_STALL);
                mCollector.expectTrue(""max capture stall must be non-null and no larger than ""
                        + MAX_ALLOWED_STALL_FRAMES,
                        maxCaptureStall != null && maxCaptureStall <= MAX_ALLOWED_STALL_FRAMES);

                for (int input : inputFormats) {
                    // Verify mandatory output formats are supported
                    int[] outputFormatsForInput = configs.getValidOutputFormatsForInput(input);
                    mCollector.expectTrue(
                        ""YUV_420_888 output must be supported for reprocessing"",
                        input == ImageFormat.Y8
                        || arrayContains(outputFormatsForInput, ImageFormat.YUV_420_888));
                    mCollector.expectTrue(
                        ""Y8 output must be supported for reprocessing on MONOCHROME devices with""
                        + "" Y8 support"", !isMonochromeWithY8 || input == ImageFormat.YUV_420_888
                        || arrayContains(outputFormatsForInput, ImageFormat.Y8));
                    mCollector.expectTrue(""JPEG output must be supported for reprocessing"",
                            arrayContains(outputFormatsForInput, ImageFormat.JPEG));

                    // Verify camera can output the reprocess input formats and sizes.
                    Size[] inputSizes = configs.getInputSizes(input);
                    Size[] outputSizes = configs.getOutputSizes(input);
                    Size[] highResOutputSizes = configs.getHighResolutionOutputSizes(input);
                    mCollector.expectTrue(""no input size supported for format "" + input,
                            inputSizes.length > 0);
                    mCollector.expectTrue(""no output size supported for format "" + input,
                            outputSizes.length > 0);

                    for (Size inputSize : inputSizes) {
                        mCollector.expectTrue(""Camera must be able to output the supported "" +
                                ""reprocessing input size"",
                                arrayContains(outputSizes, inputSize) ||
                                arrayContains(highResOutputSizes, inputSize));
                    }
                }
            } else {
                mCollector.expectTrue(""Doesn't support reprocessing but report input format: "" +
                        Arrays.toString(inputFormats), inputFormats.length == 0);
                mCollector.expectTrue(""Doesn't support reprocessing but max number of input "" +
                        ""stream is "" + maxNumInputStreams,
                        maxNumInputStreams == null || maxNumInputStreams == 0);
                mCollector.expectTrue(""Doesn't support reprocessing but "" +
                        ""EDGE_MODE_ZERO_SHUTTER_LAG is supported"", !supportZslEdgeMode);
                mCollector.expectTrue(""Doesn't support reprocessing but "" +
                        ""NOISE_REDUCTION_MODE_ZERO_SHUTTER_LAG is supported"",
                        !supportZslNoiseReductionMode);
            }
        }
    }

    /**
     * Check ultra high resolution sensor characteristics.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"testUltraHighResolutionSensorCharacteristics"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"public void testUltraHighResolutionSensorCharacteristics() {
        for (int i = 0; i < mAllCameraIds.length; i++) {
            CameraCharacteristics c = mCharacteristics.get(i);
            String cameraId = mAllCameraIds[i];
            int[] capabilities = c.get(CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
            assertNotNull(""android.request.availableCapabilities must never be null"",
                    capabilities);
            boolean isUltraHighResolutionSensor = arrayContains(capabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_ULTRA_HIGH_RESOLUTION_SENSOR);

            boolean supportsRemosaic = arrayContains(capabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_REMOSAIC_REPROCESSING);

            if (!isUltraHighResolutionSensor) {
                Log.i(TAG, ""Camera id "" + cameraId + "" not ultra high resolution. Skipping "" +
                        ""testUltraHighResolutionSensorCharacteristics"");
                continue;
            }
            assertArrayContains(
                    String.format(""Ultra high resolution sensor, camera id %s"" +
                    "" must also have the RAW capability"", cameraId), capabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_RAW);
            StreamConfigurationMap configs =
                    c.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP_MAXIMUM_RESOLUTION);
            assertNotNull(""Maximum resolution stream configuration map must not be null for ultra"" +
                    "" high resolution sensor camera "" + cameraId, configs);
            Size uhrPixelArraySize = CameraTestUtils.getValueNotNull(
                c, CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE_MAXIMUM_RESOLUTION);
            long uhrSensorSize = uhrPixelArraySize.getHeight() * uhrPixelArraySize.getWidth();

            assertTrue(""ULTRA_HIGH_RESOLUTION_SENSOR pixel array size should be at least "" +
                    MIN_UHR_SENSOR_RESOLUTION + "" pixels, is "" + uhrSensorSize + "", for camera id ""
                    + cameraId, uhrSensorSize >= MIN_UHR_SENSOR_RESOLUTION);

            int[] outputFormats = configs.getOutputFormats();
            assertArrayContains(String.format(""No max res JPEG image format for ultra high"" +
                  "" resolution sensor: ID %s"", cameraId), outputFormats, ImageFormat.JPEG);
            assertArrayContains(String.format(""No max res YUV_420_88 image format for ultra high"" +
                  "" resolution sensor: ID %s"", cameraId), outputFormats, ImageFormat.YUV_420_888);
            assertArrayContains(String.format(""No max res RAW_SENSOR image format for ultra high"" +
                  "" resolution sensor: ID %s"", cameraId), outputFormats, ImageFormat.RAW_SENSOR);

            if (supportsRemosaic) {
                testRemosaicReprocessingCharacteristics(cameraId, c);
            }
      }

    }
    /**
     * Check remosaic reprocessing capabilities. Check that ImageFormat.RAW_SENSOR is supported as
     * input and output.
     */
    private void testRemosaicReprocessingCharacteristics(String cameraId, CameraCharacteristics c) {
        StreamConfigurationMap configs =
                c.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP_MAXIMUM_RESOLUTION);
        Integer maxNumInputStreams =
                c.get(CameraCharacteristics.REQUEST_MAX_NUM_INPUT_STREAMS);
        int[] inputFormats = configs.getInputFormats();
        int[] outputFormats = configs.getOutputFormats();

        mCollector.expectTrue(""Support reprocessing but max number of input stream is "" +
                maxNumInputStreams, maxNumInputStreams != null && maxNumInputStreams > 0);

        // Verify mandatory input formats are supported
        mCollector.expectTrue(""RAW_SENSOR input support needed for REMOSAIC reprocessing"",
                arrayContains(inputFormats, ImageFormat.RAW_SENSOR));
        // max capture stall must be reported if one of the reprocessing is supported.
        final int MAX_ALLOWED_STALL_FRAMES = 4;
        Integer maxCaptureStall = c.get(CameraCharacteristics.REPROCESS_MAX_CAPTURE_STALL);
        mCollector.expectTrue(""max capture stall must be non-null and no larger than ""
                + MAX_ALLOWED_STALL_FRAMES,
                maxCaptureStall != null && maxCaptureStall <= MAX_ALLOWED_STALL_FRAMES);

        for (int input : inputFormats) {
            // Verify mandatory output formats are supported
            int[] outputFormatsForInput = configs.getValidOutputFormatsForInput(input);

            // Verify camera can output the reprocess input formats and sizes.
            Size[] inputSizes = configs.getInputSizes(input);
            Size[] outputSizes = configs.getOutputSizes(input);
            Size[] highResOutputSizes = configs.getHighResolutionOutputSizes(input);
            mCollector.expectTrue(""no input size supported for format "" + input,
                    inputSizes.length > 0);
            mCollector.expectTrue(""no output size supported for format "" + input,
                    outputSizes.length > 0);

            for (Size inputSize : inputSizes) {
                mCollector.expectTrue(""Camera must be able to output the supported "" +
                        ""reprocessing input size"",
                        arrayContains(outputSizes, inputSize) ||
                        arrayContains(highResOutputSizes, inputSize));
            }
        }
    }


    /**
     * Check depth output capability
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"testDepthOutputCharacteristics"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"public void testDepthOutputCharacteristics() {
        for (int i = 0; i < mAllCameraIds.length; i++) {
            Log.i(TAG, ""testDepthOutputCharacteristics: Testing camera ID "" + mAllCameraIds[i]);

            CameraCharacteristics c = mCharacteristics.get(i);
            int[] capabilities = c.get(CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
            assertNotNull(""android.request.availableCapabilities must never be null"",
                    capabilities);
            boolean supportDepth = arrayContains(capabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_DEPTH_OUTPUT);
            StreamConfigurationMap configs =
                    c.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);

            int[] outputFormats = configs.getOutputFormats();
            boolean hasDepth16 = arrayContains(outputFormats, ImageFormat.DEPTH16);

            Boolean depthIsExclusive = c.get(CameraCharacteristics.DEPTH_DEPTH_IS_EXCLUSIVE);

            float[] poseRotation = c.get(CameraCharacteristics.LENS_POSE_ROTATION);
            float[] poseTranslation = c.get(CameraCharacteristics.LENS_POSE_TRANSLATION);
            Integer poseReference = c.get(CameraCharacteristics.LENS_POSE_REFERENCE);
            float[] cameraIntrinsics = c.get(CameraCharacteristics.LENS_INTRINSIC_CALIBRATION);
            float[] distortion = getLensDistortion(c);
            Size pixelArraySize = c.get(CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE);
            Rect precorrectionArray = c.get(
                CameraCharacteristics.SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE);
            Rect activeArray = c.get(
                CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE);
            Integer facing = c.get(CameraCharacteristics.LENS_FACING);
            float jpegAspectRatioThreshold = .01f;
            boolean jpegSizeMatch = false;

            // Verify pre-correction array encloses active array
            mCollector.expectTrue(""preCorrectionArray ["" + precorrectionArray.left + "", "" +
                    precorrectionArray.top + "", "" + precorrectionArray.right + "", "" +
                    precorrectionArray.bottom + ""] does not enclose activeArray["" +
                    activeArray.left + "", "" + activeArray.top + "", "" + activeArray.right +
                    "", "" + activeArray.bottom,
                    precorrectionArray.contains(activeArray.left, activeArray.top) &&
                    precorrectionArray.contains(activeArray.right-1, activeArray.bottom-1));

            // Verify pixel array encloses pre-correction array
            mCollector.expectTrue(""preCorrectionArray ["" + precorrectionArray.left + "", "" +
                    precorrectionArray.top + "", "" + precorrectionArray.right + "", "" +
                    precorrectionArray.bottom + ""] isn't enclosed by pixelArray["" +
                    pixelArraySize.getWidth() + "", "" + pixelArraySize.getHeight() + ""]"",
                    precorrectionArray.left >= 0 &&
                    precorrectionArray.left < pixelArraySize.getWidth() &&
                    precorrectionArray.right > 0 &&
                    precorrectionArray.right <= pixelArraySize.getWidth() &&
                    precorrectionArray.top >= 0 &&
                    precorrectionArray.top < pixelArraySize.getHeight() &&
                    precorrectionArray.bottom > 0 &&
                    precorrectionArray.bottom <= pixelArraySize.getHeight());

            if (supportDepth) {
                mCollector.expectTrue(""Supports DEPTH_OUTPUT but does not support DEPTH16"",
                        hasDepth16);
                if (hasDepth16) {
                    Size[] depthSizes = configs.getOutputSizes(ImageFormat.DEPTH16);
                    Size[] jpegSizes = configs.getOutputSizes(ImageFormat.JPEG);
                    mCollector.expectTrue(""Supports DEPTH_OUTPUT but no sizes for DEPTH16 supported!"",
                            depthSizes != null && depthSizes.length > 0);
                    if (depthSizes != null) {
                        for (Size depthSize : depthSizes) {
                            mCollector.expectTrue(""All depth16 sizes must be positive"",
                                    depthSize.getWidth() > 0 && depthSize.getHeight() > 0);
                            long minFrameDuration = configs.getOutputMinFrameDuration(
                                    ImageFormat.DEPTH16, depthSize);
                            mCollector.expectTrue(""Non-negative min frame duration for depth size ""
                                    + depthSize + "" expected, got "" + minFrameDuration,
                                    minFrameDuration >= 0);
                            long stallDuration = configs.getOutputStallDuration(
                                    ImageFormat.DEPTH16, depthSize);
                            mCollector.expectTrue(""Non-negative stall duration for depth size ""
                                    + depthSize + "" expected, got "" + stallDuration,
                                    stallDuration >= 0);
                            if ((jpegSizes != null) && (!jpegSizeMatch)) {
                                for (Size jpegSize : jpegSizes) {
                                    if (jpegSize.equals(depthSize)) {
                                        jpegSizeMatch = true;
                                        break;
                                    } else {
                                        float depthAR = (float) depthSize.getWidth() /
                                                (float) depthSize.getHeight();
                                        float jpegAR = (float) jpegSize.getWidth() /
                                                (float) jpegSize.getHeight();
                                        if (Math.abs(depthAR - jpegAR) <=
                                                jpegAspectRatioThreshold) {
                                            jpegSizeMatch = true;
                                            break;
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
                if (arrayContains(outputFormats, ImageFormat.DEPTH_POINT_CLOUD)) {
                    Size[] depthCloudSizes = configs.getOutputSizes(ImageFormat.DEPTH_POINT_CLOUD);
                    mCollector.expectTrue(""Supports DEPTH_POINT_CLOUD "" +
                            ""but no sizes for DEPTH_POINT_CLOUD supported!"",
                            depthCloudSizes != null && depthCloudSizes.length > 0);
                    if (depthCloudSizes != null) {
                        for (Size depthCloudSize : depthCloudSizes) {
                            mCollector.expectTrue(""All depth point cloud sizes must be nonzero"",
                                    depthCloudSize.getWidth() > 0);
                            mCollector.expectTrue(""All depth point cloud sizes must be N x 1"",
                                    depthCloudSize.getHeight() == 1);
                            long minFrameDuration = configs.getOutputMinFrameDuration(
                                    ImageFormat.DEPTH_POINT_CLOUD, depthCloudSize);
                            mCollector.expectTrue(""Non-negative min frame duration for depth size ""
                                    + depthCloudSize + "" expected, got "" + minFrameDuration,
                                    minFrameDuration >= 0);
                            long stallDuration = configs.getOutputStallDuration(
                                    ImageFormat.DEPTH_POINT_CLOUD, depthCloudSize);
                            mCollector.expectTrue(""Non-negative stall duration for depth size ""
                                    + depthCloudSize + "" expected, got "" + stallDuration,
                                    stallDuration >= 0);
                        }
                    }
                }
                if (arrayContains(outputFormats, ImageFormat.DEPTH_JPEG)) {
                    mCollector.expectTrue(""Supports DEPTH_JPEG but has no DEPTH16 support!"",
                            hasDepth16);
                    mCollector.expectTrue(""Supports DEPTH_JPEG but DEPTH_IS_EXCLUSIVE is not "" +
                            ""defined"", depthIsExclusive != null);
                    mCollector.expectTrue(""Supports DEPTH_JPEG but DEPTH_IS_EXCLUSIVE is true"",
                            !depthIsExclusive.booleanValue());
                    Size[] depthJpegSizes = configs.getOutputSizes(ImageFormat.DEPTH_JPEG);
                    mCollector.expectTrue(""Supports DEPTH_JPEG "" +
                            ""but no sizes for DEPTH_JPEG supported!"",
                            depthJpegSizes != null && depthJpegSizes.length > 0);
                    mCollector.expectTrue(""Supports DEPTH_JPEG but there are no JPEG sizes with"" +
                            "" matching DEPTH16 aspect ratio"", jpegSizeMatch);
                    if (depthJpegSizes != null) {
                        for (Size depthJpegSize : depthJpegSizes) {
                            mCollector.expectTrue(""All depth jpeg sizes must be nonzero"",
                                    depthJpegSize.getWidth() > 0 && depthJpegSize.getHeight() > 0);
                            long minFrameDuration = configs.getOutputMinFrameDuration(
                                    ImageFormat.DEPTH_JPEG, depthJpegSize);
                            mCollector.expectTrue(""Non-negative min frame duration for depth jpeg"" +
                                   "" size "" + depthJpegSize + "" expected, got "" + minFrameDuration,
                                    minFrameDuration >= 0);
                            long stallDuration = configs.getOutputStallDuration(
                                    ImageFormat.DEPTH_JPEG, depthJpegSize);
                            mCollector.expectTrue(""Non-negative stall duration for depth jpeg size ""
                                    + depthJpegSize + "" expected, got "" + stallDuration,
                                    stallDuration >= 0);
                        }
                    }
                } else {
                    boolean canSupportDynamicDepth = jpegSizeMatch && !depthIsExclusive;
                    mCollector.expectTrue(""Device must support DEPTH_JPEG, please check whether "" +
                            ""library libdepthphoto.so is part of the device PRODUCT_PACKAGES"",
                            !canSupportDynamicDepth);
                }


                mCollector.expectTrue(""Supports DEPTH_OUTPUT but DEPTH_IS_EXCLUSIVE is not defined"",
                        depthIsExclusive != null);

                verifyLensCalibration(poseRotation, poseTranslation, poseReference,
                        cameraIntrinsics, distortion, precorrectionArray, facing);

            } else {
                boolean hasFields =
                    hasDepth16 && (poseTranslation != null) &&
                    (poseRotation != null) && (cameraIntrinsics != null) &&
                    (distortion != null) && (depthIsExclusive != null);

                mCollector.expectTrue(
                        ""All necessary depth fields defined, but DEPTH_OUTPUT capability is not listed"",
                        !hasFields);

                boolean reportCalibration = poseTranslation != null ||
                        poseRotation != null || cameraIntrinsics !=null;
                // Verify calibration keys are co-existing
                if (reportCalibration) {
                    mCollector.expectTrue(
                            ""Calibration keys must be co-existing"",
                            poseTranslation != null && poseRotation != null &&
                            cameraIntrinsics !=null);
                }

                boolean reportDistortion = distortion != null;
                if (reportDistortion) {
                    mCollector.expectTrue(
                            ""Calibration keys must present where distortion is reported"",
                            reportCalibration);
                }
            }
        }
    }

    private void verifyLensCalibration(float[] poseRotation, float[] poseTranslation,
            Integer poseReference, float[] cameraIntrinsics, float[] distortion,
            Rect precorrectionArray, Integer facing) {

        mCollector.expectTrue(
            ""LENS_POSE_ROTATION not right size"",
            poseRotation != null && poseRotation.length == 4);
        mCollector.expectTrue(
            ""LENS_POSE_TRANSLATION not right size"",
            poseTranslation != null && poseTranslation.length == 3);
        mCollector.expectTrue(
            ""LENS_POSE_REFERENCE is not defined"",
            poseReference != null);
        mCollector.expectTrue(
            ""LENS_INTRINSIC_CALIBRATION not right size"",
            cameraIntrinsics != null && cameraIntrinsics.length == 5);
        mCollector.expectTrue(
            ""LENS_DISTORTION not right size"",
            distortion != null && distortion.length == 6);

        if (poseRotation != null && poseRotation.length == 4) {
            float normSq =
                    poseRotation[0] * poseRotation[0] +
                    poseRotation[1] * poseRotation[1] +
                    poseRotation[2] * poseRotation[2] +
                    poseRotation[3] * poseRotation[3];
            mCollector.expectTrue(
                ""LENS_POSE_ROTATION quarternion must be unit-length"",
                0.9999f < normSq && normSq < 1.0001f);

            if (facing.intValue() == CameraMetadata.LENS_FACING_FRONT ||
                    facing.intValue() == CameraMetadata.LENS_FACING_BACK) {
                // Use the screen's natural facing to test pose rotation
                int[] facingSensor = new int[]{0, 0, 1};
                float[][] r = new float[][] {
                        { 1.0f - 2 * poseRotation[1] * poseRotation[1]
                              - 2 * poseRotation[2] * poseRotation[2],
                          2 * poseRotation[0] * poseRotation[1]
                              - 2 * poseRotation[2] * poseRotation[3],
                          2 * poseRotation[0] * poseRotation[2]
                              + 2 * poseRotation[1] * poseRotation[3] },
                        { 2 * poseRotation[0] * poseRotation[1]
                              + 2 * poseRotation[2] * poseRotation[3],
                          1.0f - 2 * poseRotation[0] * poseRotation[0]
                              - 2 * poseRotation[2] * poseRotation[2],
                          2 * poseRotation[1] * poseRotation[2]
                              - 2 * poseRotation[0] * poseRotation[3] },
                        { 2 * poseRotation[0] * poseRotation[2]
                              - 2 * poseRotation[1] * poseRotation[3],
                          2 * poseRotation[1] * poseRotation[2]
                              + 2 * poseRotation[0] * poseRotation[3],
                          1.0f - 2 * poseRotation[0] * poseRotation[0]
                              - 2 * poseRotation[1] * poseRotation[1] }
                      };
                // The screen natural facing in camera's coordinate system
                float facingCameraX = r[0][0] * facingSensor[0] + r[0][1] * facingSensor[1] +
                        r[0][2] * facingSensor[2];
                float facingCameraY = r[1][0] * facingSensor[0] + r[1][1] * facingSensor[1] +
                        r[1][2] * facingSensor[2];
                float facingCameraZ = r[2][0] * facingSensor[0] + r[2][1] * facingSensor[1] +
                        r[2][2] * facingSensor[2];

                mCollector.expectTrue(""LENS_POSE_ROTATION must be consistent with lens facing"",
                        (facingCameraZ > 0) ^
                        (facing.intValue() == CameraMetadata.LENS_FACING_BACK));

                if (poseReference == CameraCharacteristics.LENS_POSE_REFERENCE_UNDEFINED) {
                    mCollector.expectTrue(
                            ""LENS_POSE_ROTATION quarternion must be consistent with camera's "" +
                            ""default facing"",
                            Math.abs(facingCameraX) < 0.00001f &&
                            Math.abs(facingCameraY) < 0.00001f &&
                            Math.abs(facingCameraZ) > 0.99999f &&
                            Math.abs(facingCameraZ) < 1.00001f);
                }
            }

            // TODO: Cross-validate orientation and poseRotation
        }

        if (poseTranslation != null && poseTranslation.length == 3) {
            float normSq =
                    poseTranslation[0] * poseTranslation[0] +
                    poseTranslation[1] * poseTranslation[1] +
                    poseTranslation[2] * poseTranslation[2];
            mCollector.expectTrue(""Pose translation is larger than 1 m"",
                    normSq < 1.f);

            // Pose translation should be all 0s for UNDEFINED pose reference.
            if (poseReference != null && poseReference ==
                    CameraCharacteristics.LENS_POSE_REFERENCE_UNDEFINED) {
                mCollector.expectTrue(""Pose translation aren't all 0s "",
                        normSq < 0.00001f);
            }
        }

        if (poseReference != null) {
            int ref = poseReference;
            boolean validReference = false;
            switch (ref) {
                case CameraCharacteristics.LENS_POSE_REFERENCE_PRIMARY_CAMERA:
                case CameraCharacteristics.LENS_POSE_REFERENCE_GYROSCOPE:
                case CameraCharacteristics.LENS_POSE_REFERENCE_UNDEFINED:
                    // Allowed values
                    validReference = true;
                    break;
                default:
            }
            mCollector.expectTrue(""POSE_REFERENCE has unknown value"", validReference);
        }

        mCollector.expectTrue(""Does not have precorrection active array defined"",
                precorrectionArray != null);

        if (cameraIntrinsics != null && precorrectionArray != null) {
            float fx = cameraIntrinsics[0];
            float fy = cameraIntrinsics[1];
            float cx = cameraIntrinsics[2];
            float cy = cameraIntrinsics[3];
            float s = cameraIntrinsics[4];
            mCollector.expectTrue(""Optical center expected to be within precorrection array"",
                    0 <= cx && cx < precorrectionArray.width() &&
                    0 <= cy && cy < precorrectionArray.height());

            // TODO: Verify focal lengths and skew are reasonable
        }

        if (distortion != null) {
            // TODO: Verify radial distortion
        }

    }

    /**
     * Cross-check StreamConfigurationMap output
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"testStreamConfigurationMap"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"public void testStreamConfigurationMap() throws Exception {
        for (int i = 0; i < mAllCameraIds.length; i++) {
            Log.i(TAG, ""testStreamConfigurationMap: Testing camera ID "" + mAllCameraIds[i]);
            CameraCharacteristics c = mCharacteristics.get(i);
            StreamConfigurationMap config =
                    c.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
            assertNotNull(String.format(""No stream configuration map found for: ID %s"",
                            mAllCameraIds[i]), config);

            int[] actualCapabilities = c.get(CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
            assertNotNull(""android.request.availableCapabilities must never be null"",
                    actualCapabilities);

            if (arrayContains(actualCapabilities, BC)) {
                assertTrue(""ImageReader must be supported"",
                    config.isOutputSupportedFor(android.media.ImageReader.class));
                assertTrue(""MediaRecorder must be supported"",
                    config.isOutputSupportedFor(android.media.MediaRecorder.class));
                assertTrue(""MediaCodec must be supported"",
                    config.isOutputSupportedFor(android.media.MediaCodec.class));
                assertTrue(""Allocation must be supported"",
                    config.isOutputSupportedFor(android.renderscript.Allocation.class));
                assertTrue(""SurfaceHolder must be supported"",
                    config.isOutputSupportedFor(android.view.SurfaceHolder.class));
                assertTrue(""SurfaceTexture must be supported"",
                    config.isOutputSupportedFor(android.graphics.SurfaceTexture.class));

                assertTrue(""YUV_420_888 must be supported"",
                    config.isOutputSupportedFor(ImageFormat.YUV_420_888));
                assertTrue(""JPEG must be supported"",
                    config.isOutputSupportedFor(ImageFormat.JPEG));
            } else {
                assertTrue(""YUV_420_88 may not be supported if BACKWARD_COMPATIBLE capability is not listed"",
                    !config.isOutputSupportedFor(ImageFormat.YUV_420_888));
                assertTrue(""JPEG may not be supported if BACKWARD_COMPATIBLE capability is not listed"",
                    !config.isOutputSupportedFor(ImageFormat.JPEG));
            }

            // Check RAW

            if (arrayContains(actualCapabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_RAW)) {
                assertTrue(""RAW_SENSOR must be supported if RAW capability is advertised"",
                    config.isOutputSupportedFor(ImageFormat.RAW_SENSOR));
            }

            // Cross check public formats and sizes

            int[] supportedFormats = config.getOutputFormats();
            for (int format : supportedFormats) {
                assertTrue(""Format "" + format + "" fails cross check"",
                        config.isOutputSupportedFor(format));
                List<Size> supportedSizes = CameraTestUtils.getAscendingOrderSizes(
                        Arrays.asList(config.getOutputSizes(format)), /*ascending*/true);
                if (arrayContains(actualCapabilities,
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_BURST_CAPTURE)) {
                    supportedSizes.addAll(
                        Arrays.asList(config.getHighResolutionOutputSizes(format)));
                    supportedSizes = CameraTestUtils.getAscendingOrderSizes(
                        supportedSizes, /*ascending*/true);
                }
                assertTrue(""Supported format "" + format + "" has no sizes listed"",
                        supportedSizes.size() > 0);
                for (int j = 0; j < supportedSizes.size(); j++) {
                    Size size = supportedSizes.get(j);
                    if (VERBOSE) {
                        Log.v(TAG,
                                String.format(""Testing camera %s, format %d, size %s"",
                                        mAllCameraIds[i], format, size.toString()));
                    }

                    long stallDuration = config.getOutputStallDuration(format, size);
                    switch(format) {
                        case ImageFormat.YUV_420_888:
                            assertTrue(""YUV_420_888 may not have a non-zero stall duration"",
                                    stallDuration == 0);
                            break;
                        case ImageFormat.JPEG:
                        case ImageFormat.RAW_SENSOR:
                            final float TOLERANCE_FACTOR = 2.0f;
                            long prevDuration = 0;
                            if (j > 0) {
                                prevDuration = config.getOutputStallDuration(
                                        format, supportedSizes.get(j - 1));
                            }
                            long nextDuration = Long.MAX_VALUE;
                            if (j < (supportedSizes.size() - 1)) {
                                nextDuration = config.getOutputStallDuration(
                                        format, supportedSizes.get(j + 1));
                            }
                            long curStallDuration = config.getOutputStallDuration(format, size);
                            // Stall duration should be in a reasonable range: larger size should
                            // normally have larger stall duration.
                            mCollector.expectInRange(""Stall duration (format "" + format +
                                    "" and size "" + size + "") is not in the right range"",
                                    curStallDuration,
                                    (long) (prevDuration / TOLERANCE_FACTOR),
                                    (long) (nextDuration * TOLERANCE_FACTOR));
                            break;
                        default:
                            assertTrue(""Negative stall duration for format "" + format,
                                    stallDuration >= 0);
                            break;
                    }
                    long minDuration = config.getOutputMinFrameDuration(format, size);
                    if (arrayContains(actualCapabilities,
                            CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                        assertTrue(""MANUAL_SENSOR capability, need positive min frame duration for""
                                + ""format "" + format + "" for size "" + size + "" minDuration "" +
                                minDuration,
                                minDuration > 0);
                    } else {
                        assertTrue(""Need non-negative min frame duration for format "" + format,
                                minDuration >= 0);
                    }

                    // todo: test opaque image reader when it's supported.
                    if (format != ImageFormat.PRIVATE) {
                        ImageReader testReader = ImageReader.newInstance(
                            size.getWidth(),
                            size.getHeight(),
                            format,
                            1);
                        Surface testSurface = testReader.getSurface();

                        assertTrue(
                            String.format(""isOutputSupportedFor fails for config %s, format %d"",
                                    size.toString(), format),
                            config.isOutputSupportedFor(testSurface));

                        testReader.close();
                    }
                } // sizes

                // Try an invalid size in this format, should round
                Size invalidSize = findInvalidSize(supportedSizes);
                int MAX_ROUNDING_WIDTH = 1920;
                // todo: test opaque image reader when it's supported.
                if (format != ImageFormat.PRIVATE &&
                        invalidSize.getWidth() <= MAX_ROUNDING_WIDTH) {
                    ImageReader testReader = ImageReader.newInstance(
                                                                     invalidSize.getWidth(),
                                                                     invalidSize.getHeight(),
                                                                     format,
                                                                     1);
                    Surface testSurface = testReader.getSurface();

                    assertTrue(
                               String.format(""isOutputSupportedFor fails for config %s, %d"",
                                       invalidSize.toString(), format),
                               config.isOutputSupportedFor(testSurface));

                    testReader.close();
                }
            } // formats

            // Cross-check opaque format and sizes
            if (arrayContains(actualCapabilities, BC)) {
                SurfaceTexture st = new SurfaceTexture(1);
                Surface surf = new Surface(st);

                Size[] opaqueSizes = CameraTestUtils.getSupportedSizeForClass(SurfaceTexture.class,
                        mAllCameraIds[i], mCameraManager);
                assertTrue(""Opaque format has no sizes listed"",
                        opaqueSizes.length > 0);
                for (Size size : opaqueSizes) {
                    long stallDuration = config.getOutputStallDuration(SurfaceTexture.class, size);
                    assertTrue(""Opaque output may not have a non-zero stall duration"",
                            stallDuration == 0);

                    long minDuration = config.getOutputMinFrameDuration(SurfaceTexture.class, size);
                    if (arrayContains(actualCapabilities,
                                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                        assertTrue(""MANUAL_SENSOR capability, need positive min frame duration for""
                                + ""opaque format"",
                                minDuration > 0);
                    } else {
                        assertTrue(""Need non-negative min frame duration for opaque format "",
                                minDuration >= 0);
                    }
                    st.setDefaultBufferSize(size.getWidth(), size.getHeight());

                    assertTrue(
                            String.format(""isOutputSupportedFor fails for SurfaceTexture config %s"",
                                    size.toString()),
                            config.isOutputSupportedFor(surf));

                } // opaque sizes

                // Try invalid opaque size, should get rounded
                Size invalidSize = findInvalidSize(opaqueSizes);
                st.setDefaultBufferSize(invalidSize.getWidth(), invalidSize.getHeight());
                assertTrue(
                        String.format(""isOutputSupportedFor fails for SurfaceTexture config %s"",
                                invalidSize.toString()),
                        config.isOutputSupportedFor(surf));

            }
        } // mCharacteristics
    }

    /**
     * Test high speed capability and cross-check the high speed sizes and fps ranges from
     * the StreamConfigurationMap.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"testOpticalBlackRegions"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"public void testOpticalBlackRegions() {
        for (int i = 0; i < mAllCameraIds.length; i++) {
            CameraCharacteristics c = mCharacteristics.get(i);
            List<CaptureResult.Key<?>> resultKeys = c.getAvailableCaptureResultKeys();
            boolean hasDynamicBlackLevel =
                    resultKeys.contains(CaptureResult.SENSOR_DYNAMIC_BLACK_LEVEL);
            boolean hasDynamicWhiteLevel =
                    resultKeys.contains(CaptureResult.SENSOR_DYNAMIC_WHITE_LEVEL);
            boolean hasFixedBlackLevel =
                    c.getKeys().contains(CameraCharacteristics.SENSOR_BLACK_LEVEL_PATTERN);
            boolean hasFixedWhiteLevel =
                    c.getKeys().contains(CameraCharacteristics.SENSOR_INFO_WHITE_LEVEL);
            // The black and white levels should be either all supported or none of them is
            // supported.
            mCollector.expectTrue(""Dynamic black and white level should be all or none of them""
                    + "" be supported"", hasDynamicWhiteLevel == hasDynamicBlackLevel);
            mCollector.expectTrue(""Fixed black and white level should be all or none of them""
                    + "" be supported"", hasFixedBlackLevel == hasFixedWhiteLevel);
            mCollector.expectTrue(""Fixed black level should be supported if dynamic black""
                    + "" level is supported"", !hasDynamicBlackLevel || hasFixedBlackLevel);

            if (c.getKeys().contains(CameraCharacteristics.SENSOR_OPTICAL_BLACK_REGIONS)) {
                // Regions shouldn't be null or empty.
                Rect[] regions = CameraTestUtils.getValueNotNull(c,
                        CameraCharacteristics.SENSOR_OPTICAL_BLACK_REGIONS);
                CameraTestUtils.assertArrayNotEmpty(regions, ""Optical back region arrays must not""
                        + "" be empty"");

                // Dynamic black level should be supported if the optical black region is
                // advertised.
                mCollector.expectTrue(""Dynamic black and white level keys should be advertised in ""
                        + ""available capture result key list"", hasDynamicWhiteLevel);

                // Range check.
                for (Rect region : regions) {
                    mCollector.expectTrue(""Camera "" + mAllCameraIds[i] + "": optical black region"" +
                            "" shouldn't be empty!"", !region.isEmpty());
                    mCollector.expectGreaterOrEqual(""Optical black region left"", 0/*expected*/,
                            region.left/*actual*/);
                    mCollector.expectGreaterOrEqual(""Optical black region top"", 0/*expected*/,
                            region.top/*actual*/);
                    mCollector.expectTrue(""Optical black region left/right/width/height must be""
                            + "" even number, otherwise, the bayer CFA pattern in this region will""
                            + "" be messed up"",
                            region.left % 2 == 0 && region.top % 2 == 0 &&
                            region.width() % 2 == 0 && region.height() % 2 == 0);
                    mCollector.expectGreaterOrEqual(""Optical black region top"", 0/*expected*/,
                            region.top/*actual*/);
                    Size size = CameraTestUtils.getValueNotNull(c,
                            CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE);
                    mCollector.expectLessOrEqual(""Optical black region width"",
                            size.getWidth()/*expected*/, region.width());
                    mCollector.expectLessOrEqual(""Optical black region height"",
                            size.getHeight()/*expected*/, region.height());
                    Rect activeArray = CameraTestUtils.getValueNotNull(c,
                            CameraCharacteristics.SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE);
                    mCollector.expectTrue(""Optical black region"" + region + "" should be outside of""
                            + "" active array "" + activeArray,
                            !region.intersect(activeArray));
                    // Region need to be disjoint:
                    for (Rect region2 : regions) {
                        mCollector.expectTrue(""Optical black region"" + region + "" should have no ""
                                + ""overlap with "" + region2,
                                region == region2 || !region.intersect(region2));
                    }
                }
            } else {
                Log.i(TAG, ""Camera "" + mAllCameraIds[i] + "" doesn't support optical black regions,""
                        + "" skip the region test"");
            }
        }
    }

    /**
     * Check Logical camera capability
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"testLogicalCameraCharacteristics"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"public void testLogicalCameraCharacteristics() throws Exception {
        for (int i = 0; i < mAllCameraIds.length; i++) {
            CameraCharacteristics c = mCharacteristics.get(i);
            int[] capabilities = CameraTestUtils.getValueNotNull(
                    c, CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
            boolean supportLogicalCamera = arrayContains(capabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_LOGICAL_MULTI_CAMERA);
            if (supportLogicalCamera) {
                Set<String> physicalCameraIds = c.getPhysicalCameraIds();
                assertNotNull(""android.logicalCam.physicalCameraIds shouldn't be null"",
                    physicalCameraIds);
                assertTrue(""Logical camera must contain at least 2 physical camera ids"",
                    physicalCameraIds.size() >= 2);

                mCollector.expectKeyValueInRange(c,
                        CameraCharacteristics.LOGICAL_MULTI_CAMERA_SENSOR_SYNC_TYPE,
                        CameraCharacteristics.LOGICAL_MULTI_CAMERA_SENSOR_SYNC_TYPE_APPROXIMATE,
                        CameraCharacteristics.LOGICAL_MULTI_CAMERA_SENSOR_SYNC_TYPE_CALIBRATED);

                Integer timestampSource = c.get(CameraCharacteristics.SENSOR_INFO_TIMESTAMP_SOURCE);
                for (String physicalCameraId : physicalCameraIds) {
                    assertNotNull(""Physical camera id shouldn't be null"", physicalCameraId);
                    assertTrue(
                            String.format(""Physical camera id %s shouldn't be the same as logical""
                                    + "" camera id %s"", physicalCameraId, mAllCameraIds[i]),
                            physicalCameraId != mAllCameraIds[i]);

                    //validation for depth static metadata of physical cameras
                    CameraCharacteristics pc =
                            mCameraManager.getCameraCharacteristics(physicalCameraId);

                    float[] poseRotation = pc.get(CameraCharacteristics.LENS_POSE_ROTATION);
                    float[] poseTranslation = pc.get(CameraCharacteristics.LENS_POSE_TRANSLATION);
                    Integer poseReference = pc.get(CameraCharacteristics.LENS_POSE_REFERENCE);
                    float[] cameraIntrinsics = pc.get(
                            CameraCharacteristics.LENS_INTRINSIC_CALIBRATION);
                    float[] distortion = getLensDistortion(pc);
                    Integer facing = pc.get(CameraCharacteristics.LENS_FACING);
                    Rect precorrectionArray = pc.get(
                            CameraCharacteristics.SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE);

                    verifyLensCalibration(poseRotation, poseTranslation, poseReference,
                            cameraIntrinsics, distortion, precorrectionArray, facing);

                    Integer timestampSourcePhysical =
                            pc.get(CameraCharacteristics.SENSOR_INFO_TIMESTAMP_SOURCE);
                    mCollector.expectEquals(""Logical camera and physical cameras must have same "" +
                            ""timestamp source"", timestampSource, timestampSourcePhysical);
                }
            }

            // Verify that if multiple focal lengths or apertures are supported, they are in
            // ascending order.
            Integer hwLevel = c.get(CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL);
            boolean isExternalCamera = (hwLevel ==
                    CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_EXTERNAL);
            if (!isExternalCamera) {
                float[] focalLengths = c.get(
                        CameraCharacteristics.LENS_INFO_AVAILABLE_FOCAL_LENGTHS);
                for (int j = 0; j < focalLengths.length-1; j++) {
                    mCollector.expectTrue(""Camera's available focal lengths must be ascending!"",
                            focalLengths[j] < focalLengths[j+1]);
                }
                float[] apertures = c.get(CameraCharacteristics.LENS_INFO_AVAILABLE_APERTURES);
                for (int j = 0; j < apertures.length-1; j++) {
                    mCollector.expectTrue(""Camera's available apertures must be ascending!"",
                            apertures[j] < apertures[j+1]);
                }
            }
        }
    }

    /**
     * Check monochrome camera capability
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"testMonochromeCharacteristics"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"public void testMonochromeCharacteristics() {
        for (int i = 0; i < mAllCameraIds.length; i++) {
            Log.i(TAG, ""testMonochromeCharacteristics: Testing camera ID "" + mAllCameraIds[i]);

            CameraCharacteristics c = mCharacteristics.get(i);
            int[] capabilities = c.get(CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
            assertNotNull(""android.request.availableCapabilities must never be null"",
                    capabilities);
            boolean supportMonochrome = arrayContains(capabilities, MONOCHROME);

            if (!supportMonochrome) {
                continue;
            }

            List<Key<?>> allKeys = c.getKeys();
            List<CaptureRequest.Key<?>> requestKeys = c.getAvailableCaptureRequestKeys();
            List<CaptureResult.Key<?>> resultKeys = c.getAvailableCaptureResultKeys();

            assertTrue(""Monochrome camera must have BACKWARD_COMPATIBLE capability"",
                    arrayContains(capabilities, BC));
            int colorFilterArrangement = c.get(
                    CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT);
            assertTrue(""Monochrome camera must have either MONO or NIR color filter pattern"",
                    colorFilterArrangement ==
                            CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_MONO
                    || colorFilterArrangement ==
                            CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_NIR);

            assertFalse(""Monochrome camera must not contain SENSOR_CALIBRATION_TRANSFORM1 key"",
                    allKeys.contains(CameraCharacteristics.SENSOR_CALIBRATION_TRANSFORM1));
            assertFalse(""Monochrome camera must not contain SENSOR_COLOR_TRANSFORM1 key"",
                    allKeys.contains(CameraCharacteristics.SENSOR_COLOR_TRANSFORM1));
            assertFalse(""Monochrome camera must not contain SENSOR_FORWARD_MATRIX1 key"",
                    allKeys.contains(CameraCharacteristics.SENSOR_FORWARD_MATRIX1));
            assertFalse(""Monochrome camera must not contain SENSOR_REFERENCE_ILLUMINANT1 key"",
                    allKeys.contains(CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT1));
            assertFalse(""Monochrome camera must not contain SENSOR_CALIBRATION_TRANSFORM2 key"",
                    allKeys.contains(CameraCharacteristics.SENSOR_CALIBRATION_TRANSFORM2));
            assertFalse(""Monochrome camera must not contain SENSOR_COLOR_TRANSFORM2 key"",
                    allKeys.contains(CameraCharacteristics.SENSOR_COLOR_TRANSFORM2));
            assertFalse(""Monochrome camera must not contain SENSOR_FORWARD_MATRIX2 key"",
                    allKeys.contains(CameraCharacteristics.SENSOR_FORWARD_MATRIX2));
            assertFalse(""Monochrome camera must not contain SENSOR_REFERENCE_ILLUMINANT2 key"",
                    allKeys.contains(CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT2));

            assertFalse(
                    ""Monochrome capture result must not contain SENSOR_NEUTRAL_COLOR_POINT key"",
                    resultKeys.contains(CaptureResult.SENSOR_NEUTRAL_COLOR_POINT));
            assertFalse(""Monochrome capture result must not contain SENSOR_GREEN_SPLIT key"",
                    resultKeys.contains(CaptureResult.SENSOR_GREEN_SPLIT));

            // Check that color correction tags are not available for monochrome cameras
            assertTrue(""Monochrome camera must not have MANUAL_POST_PROCESSING capability"",
                    !arrayContains(capabilities, MANUAL_POSTPROC));
            assertTrue(""Monochrome camera must not have COLOR_CORRECTION_MODE in request keys"",
                    !requestKeys.contains(CaptureRequest.COLOR_CORRECTION_MODE));
            assertTrue(""Monochrome camera must not have COLOR_CORRECTION_MODE in result keys"",
                    !resultKeys.contains(CaptureResult.COLOR_CORRECTION_MODE));
            assertTrue(""Monochrome camera must not have COLOR_CORRECTION_TRANSFORM in request keys"",
                    !requestKeys.contains(CaptureRequest.COLOR_CORRECTION_TRANSFORM));
            assertTrue(""Monochrome camera must not have COLOR_CORRECTION_TRANSFORM in result keys"",
                    !resultKeys.contains(CaptureResult.COLOR_CORRECTION_TRANSFORM));
            assertTrue(""Monochrome camera must not have COLOR_CORRECTION_GAINS in request keys"",
                    !requestKeys.contains(CaptureRequest.COLOR_CORRECTION_GAINS));
            assertTrue(""Monochrome camera must not have COLOR_CORRECTION_GAINS in result keys"",
                    !resultKeys.contains(CaptureResult.COLOR_CORRECTION_GAINS));

            // Check that awbSupportedModes only contains AUTO
            int[] awbAvailableModes = c.get(CameraCharacteristics.CONTROL_AWB_AVAILABLE_MODES);
            assertTrue(""availableAwbModes must not be null"", awbAvailableModes != null);
            assertTrue(""availableAwbModes must contain only AUTO"", awbAvailableModes.length == 1 &&
                    awbAvailableModes[0] == CaptureRequest.CONTROL_AWB_MODE_AUTO);
        }
    }

    /**
     * Check rotate-and-crop camera reporting.
     * Every device must report NONE; if actually supporting feature, must report NONE, 90, AUTO at
     * least.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"testCameraOrientationAlignedWithDevice"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"public void testCameraOrientationAlignedWithDevice() {
        WindowManager windowManager =
                (WindowManager) mContext.getSystemService(Context.WINDOW_SERVICE);
        Display display = windowManager.getDefaultDisplay();
        DisplayMetrics metrics = new DisplayMetrics();
        display.getMetrics(metrics);

        // For square screen, test is guaranteed to pass
        if (metrics.widthPixels == metrics.heightPixels) {
            return;
        }

        // Handle display rotation
        int displayRotation = display.getRotation();
        if (displayRotation == Surface.ROTATION_90 || displayRotation == Surface.ROTATION_270) {
            int tmp = metrics.widthPixels;
            metrics.widthPixels = metrics.heightPixels;
            metrics.heightPixels = tmp;
        }
        boolean isDevicePortrait = metrics.widthPixels < metrics.heightPixels;

        for (int i = 0; i < mAllCameraIds.length; i++) {
            CameraCharacteristics c = mCharacteristics.get(i);
            // Camera size
            Size pixelArraySize = c.get(CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE);
            // Camera orientation
            int sensorOrientation = c.get(CameraCharacteristics.SENSOR_ORIENTATION);

            // For square sensor, test is guaranteed to pass
            if (pixelArraySize.getWidth() == pixelArraySize.getHeight()) {
                continue;
            }

            // Camera size adjusted for device native orientation.
            Size adjustedSensorSize;
            if (sensorOrientation == 90 || sensorOrientation == 270) {
                adjustedSensorSize = new Size(
                        pixelArraySize.getHeight(), pixelArraySize.getWidth());
            } else {
                adjustedSensorSize = pixelArraySize;
            }

            boolean isCameraPortrait =
                    adjustedSensorSize.getWidth() < adjustedSensorSize.getHeight();
            assertFalse(""Camera "" + mAllCameraIds[i] + ""'s long dimension must ""
                    + ""align with screen's long dimension"", isDevicePortrait^isCameraPortrait);
        }
    }

    /**
     * Check camera characteristics for R and S Performance class requirements as specified
     * in CDD camera section 7.5
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ExtendedCameraCharacteristicsTest"	"testCameraPerfClassCharacteristics"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ExtendedCameraCharacteristicsTest.java"	""	"@CddTest(requirement=""7.5"")
    public void testCameraPerfClassCharacteristics() throws Exception {
        if (mAdoptShellPerm) {
            // Skip test for system camera. Performance class is only applicable for public camera
            // ids.
            return;
        }
        boolean isRPerfClass = CameraTestUtils.isRPerfClass();
        boolean isSPerfClass = CameraTestUtils.isSPerfClass();
        if (!isRPerfClass && !isSPerfClass) {
            return;
        }

        boolean hasPrimaryRear = false;
        boolean hasPrimaryFront = false;
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            String cameraId = mCameraIdsUnderTest[i];
            boolean isPrimaryRear = CameraTestUtils.isPrimaryRearFacingCamera(
                    mCameraManager, cameraId);
            boolean isPrimaryFront = CameraTestUtils.isPrimaryFrontFacingCamera(
                    mCameraManager, cameraId);
            if (!isPrimaryRear && !isPrimaryFront) {
                continue;
            }

            CameraCharacteristics c = mCharacteristics.get(i);
            StaticMetadata staticInfo = mAllStaticInfo.get(cameraId);

            // H-1-1, H-1-2
            Size pixelArraySize = CameraTestUtils.getValueNotNull(
                    c, CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE);
            long sensorResolution = pixelArraySize.getHeight() * pixelArraySize.getWidth();
            StreamConfigurationMap config = staticInfo.getValueFromKeyNonNull(
                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
            assertNotNull(""No stream configuration map found for ID "" + cameraId, config);
            List<Size> videoSizes = CameraTestUtils.getSupportedVideoSizes(cameraId,
                    mCameraManager, null /*bound*/);

            if (isPrimaryRear) {
                hasPrimaryRear = true;
                mCollector.expectTrue(""Primary rear camera resolution should be at least "" +
                        MIN_BACK_SENSOR_PERF_CLASS_RESOLUTION + "" pixels, is ""+
                        sensorResolution,
                        sensorResolution >= MIN_BACK_SENSOR_PERF_CLASS_RESOLUTION);

                // 4K @ 30fps
                boolean supportUHD = videoSizes.contains(UHD);
                boolean supportDC4K = videoSizes.contains(DC4K);
                mCollector.expectTrue(""Primary rear camera should support 4k video recording"",
                        supportUHD || supportDC4K);
                if (supportUHD || supportDC4K) {
                    long minFrameDuration = config.getOutputMinFrameDuration(
                            android.media.MediaRecorder.class, supportDC4K ? DC4K : UHD);
                    mCollector.expectTrue(""Primary rear camera should support 4k video @ 30fps"",
                            minFrameDuration < (1e9 / 29.9));
                }
            } else {
                hasPrimaryFront = true;
                if (isSPerfClass) {
                    mCollector.expectTrue(""Primary front camera resolution should be at least "" +
                            MIN_FRONT_SENSOR_S_PERF_CLASS_RESOLUTION + "" pixels, is ""+
                            sensorResolution,
                            sensorResolution >= MIN_FRONT_SENSOR_S_PERF_CLASS_RESOLUTION);
                } else {
                    mCollector.expectTrue(""Primary front camera resolution should be at least "" +
                            MIN_FRONT_SENSOR_R_PERF_CLASS_RESOLUTION + "" pixels, is ""+
                            sensorResolution,
                            sensorResolution >= MIN_FRONT_SENSOR_R_PERF_CLASS_RESOLUTION);
                }
                // 1080P @ 30fps
                boolean supportFULLHD = videoSizes.contains(FULLHD);
                mCollector.expectTrue(""Primary front camera should support 1080P video recording"",
                        supportFULLHD);
                if (supportFULLHD) {
                    long minFrameDuration = config.getOutputMinFrameDuration(
                            android.media.MediaRecorder.class, FULLHD);
                    mCollector.expectTrue(""Primary front camera should support 1080P video @ 30fps"",
                            minFrameDuration < (1e9 / 29.9));
                }
            }

            String facingString = hasPrimaryRear ? ""rear"" : ""front"";
            // H-1-3
            if (isSPerfClass || (isRPerfClass && isPrimaryRear)) {
                mCollector.expectTrue(""Primary "" + facingString +
                        "" camera should be at least FULL, but is "" +
                        toStringHardwareLevel(staticInfo.getHardwareLevelChecked()),
                        staticInfo.isHardwareLevelAtLeastFull());
            } else {
                mCollector.expectTrue(""Primary "" + facingString +
                        "" camera should be at least LIMITED, but is "" +
                        toStringHardwareLevel(staticInfo.getHardwareLevelChecked()),
                        staticInfo.isHardwareLevelAtLeastLimited());
            }

            // H-1-4
            Integer timestampSource = c.get(CameraCharacteristics.SENSOR_INFO_TIMESTAMP_SOURCE);
            mCollector.expectTrue(
                    ""Primary "" + facingString + "" camera should support real-time timestamp source"",
                    timestampSource != null &&
                    timestampSource.equals(CameraMetadata.SENSOR_INFO_TIMESTAMP_SOURCE_REALTIME));

            // H-1-8
            if (isSPerfClass && isPrimaryRear) {
                mCollector.expectTrue(""Primary rear camera should support RAW capability"",
                        staticInfo.isCapabilitySupported(RAW));
            }
        }
        mCollector.expectTrue(""There must be a primary rear camera for performance class."",
                hasPrimaryRear);
        mCollector.expectTrue(""There must be a primary front camera for performance class."",
                hasPrimaryFront);
    }

    /**
     * Get lens distortion coefficients, as a list of 6 floats; returns null if no valid
     * distortion field is available
     */
    private float[] getLensDistortion(CameraCharacteristics c) {
        float[] distortion = null;
        float[] newDistortion = c.get(CameraCharacteristics.LENS_DISTORTION);
        if (Build.VERSION.DEVICE_INITIAL_SDK_INT > Build.VERSION_CODES.O_MR1 || newDistortion != null) {
            // New devices need to use fixed radial distortion definition; old devices can
            // opt-in to it
            if (newDistortion != null && newDistortion.length == 5) {
                distortion = new float[6];
                distortion[0] = 1.0f;
                for (int i = 1; i < 6; i++) {
                    distortion[i] = newDistortion[i-1];
                }
            }
        } else {
            // Select old field only if on older first SDK and new definition not available
            distortion = c.get(CameraCharacteristics.LENS_RADIAL_DISTORTION);
        }
        return distortion;
    }

    /**
     * Create an invalid size that's close to one of the good sizes in the list, but not one of them
     */
    private Size findInvalidSize(Size[] goodSizes) {
        return findInvalidSize(Arrays.asList(goodSizes));
    }

    /**
     * Create an invalid size that's close to one of the good sizes in the list, but not one of them
     */
    private Size findInvalidSize(List<Size> goodSizes) {
        Size invalidSize = new Size(goodSizes.get(0).getWidth() + 1, goodSizes.get(0).getHeight());
        while(goodSizes.contains(invalidSize)) {
            invalidSize = new Size(invalidSize.getWidth() + 1, invalidSize.getHeight());
        }
        return invalidSize;
    }

    /**
     * Check key is present in characteristics if the hardware level is at least {@code hwLevel};
     * check that the key is present if the actual capabilities are one of {@code capabilities}.
     *
     * @return value of the {@code key} from {@code c}
     */
    private <T> T expectKeyAvailable(CameraCharacteristics c, CameraCharacteristics.Key<T> key,
            int hwLevel, int... capabilities) {

        Integer actualHwLevel = c.get(CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL);
        assertNotNull(""android.info.supportedHardwareLevel must never be null"", actualHwLevel);

        int[] actualCapabilities = c.get(CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
        assertNotNull(""android.request.availableCapabilities must never be null"",
                actualCapabilities);

        List<Key<?>> allKeys = c.getKeys();

        T value = c.get(key);

        // For LIMITED-level targeted keys, rely on capability check, not level
        if ((compareHardwareLevel(actualHwLevel, hwLevel) >= 0) && (hwLevel != LIMITED)) {
            mCollector.expectTrue(
                    String.format(""Key (%s) must be in characteristics for this hardware level "" +
                            ""(required minimal HW level %s, actual HW level %s)"",
                            key.getName(), toStringHardwareLevel(hwLevel),
                            toStringHardwareLevel(actualHwLevel)),
                    value != null);
            mCollector.expectTrue(
                    String.format(""Key (%s) must be in characteristics list of keys for this "" +
                            ""hardware level (required minimal HW level %s, actual HW level %s)"",
                            key.getName(), toStringHardwareLevel(hwLevel),
                            toStringHardwareLevel(actualHwLevel)),
                    allKeys.contains(key));
        } else if (arrayContainsAnyOf(actualCapabilities, capabilities)) {
            if (!(hwLevel == LIMITED && compareHardwareLevel(actualHwLevel, hwLevel) < 0)) {
                // Don't enforce LIMITED-starting keys on LEGACY level, even if cap is defined
                mCollector.expectTrue(
                    String.format(""Key (%s) must be in characteristics for these capabilities "" +
                            ""(required capabilities %s, actual capabilities %s)"",
                            key.getName(), Arrays.toString(capabilities),
                            Arrays.toString(actualCapabilities)),
                    value != null);
                mCollector.expectTrue(
                    String.format(""Key (%s) must be in characteristics list of keys for "" +
                            ""these capabilities (required capabilities %s, actual capabilities %s)"",
                            key.getName(), Arrays.toString(capabilities),
                            Arrays.toString(actualCapabilities)),
                    allKeys.contains(key));
            }
        } else {
            if (actualHwLevel == LEGACY && hwLevel != OPT) {
                if (value != null || allKeys.contains(key)) {
                    Log.w(TAG, String.format(
                            ""Key (%s) is not required for LEGACY devices but still appears"",
                            key.getName()));
                }
            }
            // OK: Key may or may not be present.
        }
        return value;
    }

    private static boolean arrayContains(int[] arr, int needle) {
        if (arr == null) {
            return false;
        }

        for (int elem : arr) {
            if (elem == needle) {
                return true;
            }
        }

        return false;
    }

    private static <T> boolean arrayContains(T[] arr, T needle) {
        if (arr == null) {
            return false;
        }

        for (T elem : arr) {
            if (elem.equals(needle)) {
                return true;
            }
        }

        return false;
    }

    private static boolean arrayContainsAnyOf(int[] arr, int[] needles) {
        for (int needle : needles) {
            if (arrayContains(arr, needle)) {
                return true;
            }
        }
        return false;
    }

    /**
     * The key name has a prefix of either ""android."" or a valid TLD; other prefixes are not valid.
     */
    private static void assertKeyPrefixValid(String keyName) {
        assertStartsWithAndroidOrTLD(
                ""All metadata keys must start with 'android.' (built-in keys) "" +
                ""or valid TLD (vendor-extended keys)"", keyName);
    }

    private static void assertTrueForKey(String msg, CameraCharacteristics.Key<?> key,
            boolean actual) {
        assertTrue(msg + "" (key = '"" + key.getName() + ""')"", actual);
    }

    private static <T> void assertOneOf(String msg, T[] expected, T actual) {
        for (int i = 0; i < expected.length; ++i) {
            if (Objects.equals(expected[i], actual)) {
                return;
            }
        }

        fail(String.format(""%s: (expected one of %s, actual %s)"",
                msg, Arrays.toString(expected), actual));
    }

    private static <T> void assertStartsWithAndroidOrTLD(String msg, String keyName) {
        String delimiter = ""."";
        if (keyName.startsWith(PREFIX_ANDROID + delimiter)) {
            return;
        }
        Pattern tldPattern = Pattern.compile(Patterns.TOP_LEVEL_DOMAIN_STR);
        Matcher match = tldPattern.matcher(keyName);
        if (match.find(0) && (0 == match.start()) && (!match.hitEnd())) {
            if (keyName.regionMatches(match.end(), delimiter, 0, delimiter.length())) {
                return;
            }
        }

        fail(String.format(""%s: (expected to start with %s or valid TLD, but value was %s)"",
                msg, PREFIX_ANDROID + delimiter, keyName));
    }

    /** Return a positive int if left > right, 0 if left==right, negative int if left < right */
    private static int compareHardwareLevel(int left, int right) {
        return remapHardwareLevel(left) - remapHardwareLevel(right);
    }

    /** Remap HW levels worst<->best, 0 = LEGACY, 1 = LIMITED, 2 = FULL, ..., N = LEVEL_N */
    private static int remapHardwareLevel(int level) {
        switch (level) {
            case OPT:
                return Integer.MAX_VALUE;
            case LEGACY:
                return 0; // lowest
            case EXTERNAL:
                return 1; // second lowest
            case LIMITED:
                return 2;
            case FULL:
                return 3; // good
            case LEVEL_3:
                return 4;
            default:
                fail(""Unknown HW level: "" + level);
        }
        return -1;
    }

    private static String toStringHardwareLevel(int level) {
        switch (level) {
            case LEGACY:
                return ""LEGACY"";
            case LIMITED:
                return ""LIMITED"";
            case FULL:
                return ""FULL"";
            case EXTERNAL:
                return ""EXTERNAL"";
            default:
                if (level >= LEVEL_3) {
                    return String.format(""LEVEL_%d"", level);
                }
        }

        // unknown
        Log.w(TAG, ""Unknown hardware level "" + level);
        return Integer.toString(level);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.DynamicSensorDiscoveryTestActivity"	"DynamicSensorDiscoveryTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/DynamicSensorDiscoveryTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;

import android.content.Context;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventCallback;
import android.hardware.SensorManager;
import android.hardware.cts.helpers.SensorTestStateNotSupportedException;
import android.os.Build;
import android.util.Log;

import junit.framework.Assert;

import java.util.List;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

/**
 * CTS Verifier case for verifying dynamic sensor discovery feature.
 */
public class DynamicSensorDiscoveryTestActivity extends SensorCtsVerifierTestActivity {

    private final static String TAG = ""DynamicSensorDiscoveryTestActivity"";
    private final static int CONNECTION_TIMEOUT_SEC = 30;
    private final static int DISCONNECTION_TIMEOUT_SEC = 30;
    private final static int EVENT_TIMEOUT_SEC = 30;
    private SensorManager mSensorManager;
    private boolean mFeatureSupported = false;
    private boolean mSensorConnected = false;
    private boolean mSensorDisconnected = false;
    private Integer mSensorId;
    private Callback mCallback;

    public DynamicSensorDiscoveryTestActivity() {
        super(DynamicSensorDiscoveryTestActivity.class);
    }

    @Override
    protected void activitySetUp() throws InterruptedException {
        mSensorManager = (SensorManager) getSystemService(Context.SENSOR_SERVICE);
        if (mSensorManager == null || !(Build.VERSION.SDK_INT > Build.VERSION_CODES.M ||
                Build.VERSION.CODENAME.startsWith(""N"") /* useful when N in dev */) ) {
            return;
        }
        mFeatureSupported = mSensorManager.isDynamicSensorDiscoverySupported();

        try {
            featureSupportedOrSkip();
        } catch (SensorTestStateNotSupportedException e) {
            // This device doesn't support dynamic sensors.  So we won't
            // be running any of the tests, and really don't want to
            // confuse the user by telling them they need to hoook one up.
            // TODO(b/29606675): This is pretty hack, and should have
            //     a better overall approach.
            return;
        }
        showUserMessage(""This test will requires the user to connect an external sensor ("" +
                ""physical or simulated) and then disconnect it."");
        waitForUserToContinue();

        mCallback = new Callback();
        mSensorManager.registerDynamicSensorCallback(mCallback);
    }

    @SuppressWarnings(""unused"")
    public String test0_OnConnect() {
        featureSupportedOrSkip();

        showUserMessage(String.format(""Please connect an external sensor to device in %d seconds."",
                    CONNECTION_TIMEOUT_SEC));

        Assert.assertTrue(""Cannot detect sensor connection."", mCallback.waitForConnection(null));
        mSensorConnected = true;
        mSensorId = mCallback.getSensorId();
        return ""OnConnect: Success"";
    }

    @SuppressWarnings(""unused"")
    public String test1_DynamicSensorList() {
        featureSupportedOrSkip();
        sensorConnectedOrSkip();

        Assert.assertTrue(""Dynamic sensor flag is not set correctly for at least one sensor"",
                isDynamicFlagSetCorrectly());

        Assert.assertTrue(""Sensor connected, but is not in dynamic sensor list"",
                mCallback.isSensorInList());

        Assert.assertTrue(""Sensor connected, but is not in dynamic sensor list of its type"",
                mCallback.isSensorInListOfSpecificType());

        return ""DynamicSensorList: Success"";
    }

    @SuppressWarnings(""unused"")
    public String test2_SensorOperation() {
        featureSupportedOrSkip();
        sensorConnectedOrSkip();

        showUserMessage(""Testing sensor operation ... Please make sure sensor generates sensor "" +
                ""events if it does not automatically do so."");

        Assert.assertTrue(""Failed to receive sensor events"", mCallback.waitForSensorEvent());
        return ""SensorOperation: Success"";
    }

    @SuppressWarnings(""unused"")
    public String test3_OnDisconnect() {
        featureSupportedOrSkip();
        sensorConnectedOrSkip();

        showUserMessage(String.format(""Please disconnect the external sensor that was previously "" +
                    ""connected in %d seconds"", DISCONNECTION_TIMEOUT_SEC));
        Assert.assertTrue(""Cannot detect sensor disconnection."", mCallback.waitForDisconnection());
        mSensorDisconnected = true;
        return ""OnDisconnect: Success"";
    }

    @SuppressWarnings(""unused"")
    public String test4_OnReconnect() {
        featureSupportedOrSkip();
        sensorConnectedOrSkip();
        sensorDisconnectedOrSkip();

        showUserMessage(String.format(""Please connect the same sensor that was previously "" +
                    ""connected in %d seconds"", CONNECTION_TIMEOUT_SEC));
        Assert.assertTrue(""Cannot detect sensor reconnection."",
                mCallback.waitForConnection(mSensorId));

        Integer sensorId = mCallback.getSensorId();
        boolean match = mSensorId != null && sensorId != null &&
                sensorId.intValue() == mSensorId.intValue();
        Assert.assertTrue(""Id mismatch for the reconnected sensor"", match);
        return ""OnReconnect: Success"";
    }

    private class Callback extends SensorManager.DynamicSensorCallback {

        private Sensor mSensor = null;
        private Integer mExpectSensorId = null;
        private CountDownLatch mConnectLatch;
        private CountDownLatch mDisconnectLatch;

        @Override
        public void onDynamicSensorConnected(Sensor sensor) {
            Log.d(TAG, ""Sensor Connected: "" + sensor);

            if (mExpectSensorId == null || mExpectSensorId == sensor.getId()) {
                mSensor = sensor;
                if (mConnectLatch != null) {
                    mConnectLatch.countDown();
                }
            }
        }

        @Override
        public void onDynamicSensorDisconnected(Sensor sensor) {
            if (mSensor == sensor) {
                mSensor = null;
                if (mDisconnectLatch != null) {
                    mDisconnectLatch.countDown();
                }
            }
        }

        public boolean waitForConnection(Integer sensorId) {
            boolean ret;
            mExpectSensorId = sensorId;
            mConnectLatch = new CountDownLatch(1);
            try {
                ret = mConnectLatch.await(CONNECTION_TIMEOUT_SEC, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                ret = false;
                Thread.currentThread().interrupt();
            } finally {
                mConnectLatch = null;
            }
            return ret;
        }

        public boolean waitForDisconnection() {
            boolean ret;
            mDisconnectLatch = new CountDownLatch(1);
            try {
                ret = mDisconnectLatch.await(DISCONNECTION_TIMEOUT_SEC, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                ret = false;
                Thread.currentThread().interrupt();
            } finally {
                mDisconnectLatch = null;
            }
            return ret;
        }

        public boolean waitForSensorEvent() {
            if (mSensor == null) {
                Log.e(TAG, ""Sensor is not set"");
                return false;
            }

            final CountDownLatch eventLatch = new CountDownLatch(1);

            SensorEventCallback eventCallback =
                    new SensorEventCallback() {
                        @Override
                        public void onSensorChanged(SensorEvent e) {
                            eventLatch.countDown();
                        }
                    };

            if (!mSensorManager.registerListener(
                    eventCallback, mSensor, SensorManager.SENSOR_DELAY_FASTEST)) {
                return false;
            }

            boolean ret;
            try {
                ret = eventLatch.await(EVENT_TIMEOUT_SEC, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                ret = false;
                Thread.currentThread().interrupt();
            } finally {
                mSensorManager.unregisterListener(eventCallback);
            }
            return ret;
        }

        public boolean isSensorInList() {
            // This is intentional event if Sensor did not override equals().
            // Sensor objects representing the same sensor will be the same object.
            return assumeSensorIsSet() &&
                    mSensorManager.getDynamicSensorList(Sensor.TYPE_ALL).contains(mSensor);
        }

        public boolean isSensorInListOfSpecificType() {
            // This is intentional event if Sensor did not override equals().
            // Sensor objects representing the same sensor will be the same object.
            return assumeSensorIsSet() &&
                    mSensorManager.getDynamicSensorList(mSensor.getType()).contains(mSensor);
        }

        public Integer getSensorId() {
            return assumeSensorIsSet() ? mSensor.getId() : null;
        }

        // name assumeSensorIsSet instead of is... because the Log print is one of the main purpose.
        private boolean assumeSensorIsSet() {
            if (mSensor == null) {
                Log.e(TAG, ""Sensor is not set"");
                return false;
            }
            return true;
        }
    }

    private boolean isDynamicFlagSetCorrectly() {
        boolean ret = true;
        List<Sensor> dynamicSensors = mSensorManager.getDynamicSensorList(Sensor.TYPE_ALL);
        for (Sensor s : dynamicSensors) {
            if (!s.isDynamicSensor()) {
                Log.e(TAG, String.format(
                        ""Dynamic sensor \""%s\"" isDynamicSensor() return false"", s.getName()));
                ret = false;
            }
        }

        List<Sensor> staticSensors = mSensorManager.getSensorList(Sensor.TYPE_ALL);
        for (Sensor s : staticSensors) {
            if (s.isDynamicSensor()) {
                Log.e(TAG, String.format(
                        ""Static sensor \""%s\"" isDynamicSensor() return true"", s.getName()));
                ret = false;
            }
        }
        return ret;
    }

    private void featureSupportedOrSkip() {
        if (!mFeatureSupported) {
            throw new SensorTestStateNotSupportedException(
                    ""Dynamic sensor discovery not supported, skip."");
        }
    }

    private void sensorConnectedOrSkip() {
        if (!mSensorConnected) {
            throw new SensorTestStateNotSupportedException(
                    ""Sensor not connected, skip."");
        }
    }

    private void sensorDisconnectedOrSkip() {
        if (!mSensorDisconnected) {
            throw new SensorTestStateNotSupportedException(
                    ""Sensor has not been disconnected, skip."");
        }
    }

    /*
     *  This function serves as a proxy as appendText is marked to be deprecated.
     *  When appendText is removed, this function will have a different implementation.
     *
     */
    private void showUserMessage(String s) {
        appendText(s);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.base.BaseSensorTestActivity"	"SensorTestLogger"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/base/BaseSensorTestActivity.java"	""	"public void test/*

 *.
 */

package com.android.cts.verifier.sensors.base;

import android.content.ActivityNotFoundException;
import android.content.Context;
import android.content.Intent;
import android.content.pm.PackageManager;
import android.hardware.cts.helpers.ActivityResultMultiplexedLatch;
import android.media.MediaPlayer;
import android.opengl.GLSurfaceView;
import android.os.Bundle;
import android.os.SystemClock;
import android.os.Vibrator;
import android.provider.Settings;
import android.text.TextUtils;
import android.text.format.DateUtils;
import android.util.Log;
import android.view.View;
import android.widget.Button;
import android.widget.LinearLayout;
import android.widget.ScrollView;
import android.widget.TextView;

import com.android.cts.verifier.PassFailButtons;
import com.android.cts.verifier.R;
import com.android.cts.verifier.TestResult;
import com.android.cts.verifier.sensors.helpers.SensorFeaturesDeactivator;
import com.android.cts.verifier.sensors.reporting.SensorTestDetails;

import junit.framework.Assert;

import java.util.ArrayList;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;

/**
 * A base Activity that is used to build different methods to execute tests inside CtsVerifier.
 * i.e. CTS tests, and semi-automated CtsVerifier tests.
 *
 * This class provides access to the following flow:
 *      Activity set up
 *          Execute tests (implemented by sub-classes)
 *      Activity clean up
 *
 * Currently the following class structure is available:
 * - BaseSensorTestActivity                 : provides the platform to execute Sensor tests inside
 *      |                                     CtsVerifier, and logging support
 *      |
 *      -- SensorCtsTestActivity            : an activity that can be inherited from to wrap a CTS
 *      |                                     sensor test, and execute it inside CtsVerifier
 *      |                                     these tests do not require any operator interaction
 *      |
 *      -- SensorCtsVerifierTestActivity    : an activity that can be inherited to write sensor
 *                                            tests that require operator interaction
 */
public abstract class BaseSensorTestActivity
        extends PassFailButtons.Activity
        implements View.OnClickListener, Runnable, ISensorTestStateContainer {
    @Deprecated
    protected static final String LOG_TAG = ""SensorTest"";

    protected final Class mTestClass;

    private final int mLayoutId;
    private final SensorFeaturesDeactivator mSensorFeaturesDeactivator;

    private final ExecutorService mExecutorService = Executors.newSingleThreadExecutor();
    private final SensorTestLogger mTestLogger = new SensorTestLogger();
    private final ActivityResultMultiplexedLatch mActivityResultMultiplexedLatch =
            new ActivityResultMultiplexedLatch();
    private final ArrayList<CountDownLatch> mWaitForUserLatches = new ArrayList<CountDownLatch>();

    private ScrollView mLogScrollView;
    private LinearLayout mLogLayout;
    private Button mNextButton;
    private Button mPassButton;
    private Button mFailButton;
    private Button mRetryButton;

    private GLSurfaceView mGLSurfaceView;
    private boolean mUsingGlSurfaceView;

    // Flag for Retry button appearance.
    private boolean mShouldRetry = false;
    private int mRetryCount = 0;

    /**
     * Constructor to be used by subclasses.
     *
     * @param testClass The class that contains the tests. It is dependant on test executor
     *                  implemented by subclasses.
     */
    protected BaseSensorTestActivity(Class testClass) {
        this(testClass, R.layout.sensor_test);
    }

    /**
     * Constructor to be used by subclasses. It allows to provide a custom layout for the test UI.
     *
     * @param testClass The class that contains the tests. It is dependant on test executor
     *                  implemented by subclasses.
     * @param layoutId The Id of the layout to use for the test UI. The layout must contain all the
     *                 elements in the base layout {@code R.layout.sensor_test}.
     */
    protected BaseSensorTestActivity(Class testClass, int layoutId) {
        mTestClass = testClass;
        mLayoutId = layoutId;
        mSensorFeaturesDeactivator = new SensorFeaturesDeactivator(this);
    }

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(mLayoutId);

        mLogScrollView = (ScrollView) findViewById(R.id.log_scroll_view);
        mLogLayout = (LinearLayout) findViewById(R.id.log_layout);
        mNextButton = (Button) findViewById(R.id.next_button);
        mNextButton.setOnClickListener(this);
        mPassButton = (Button) findViewById(R.id.pass_button);
        mFailButton = (Button) findViewById(R.id.fail_button);
        mGLSurfaceView = (GLSurfaceView) findViewById(R.id.gl_surface_view);
        mRetryButton = (Button) findViewById(R.id.retry_button);
        mRetryButton.setOnClickListener(new retryButtonListener());

        updateNextButton(false /*enabled*/);
        mExecutorService.execute(this);
    }

    @Override
    protected void onDestroy() {
        super.onDestroy();
        mExecutorService.shutdownNow();
    }

    @Override
    protected void onPause() {
        super.onPause();
        if (mUsingGlSurfaceView) {
            mGLSurfaceView.onPause();
        }
    }

    @Override
    protected void onResume() {
        super.onResume();
        if (mUsingGlSurfaceView) {
            mGLSurfaceView.onResume();
        }
    }

    @Override
    public void onClick(View target) {
        mShouldRetry = false;

        synchronized (mWaitForUserLatches) {
            for (CountDownLatch latch : mWaitForUserLatches) {
                latch.countDown();
            }
            mWaitForUserLatches.clear();
        }
    }

    private class retryButtonListener implements View.OnClickListener {

        @Override
        public void onClick(View v) {
            mShouldRetry = true;
            ++mRetryCount;

            synchronized (mWaitForUserLatches) {
                for (CountDownLatch latch : mWaitForUserLatches) {
                    latch.countDown();
                }
                mWaitForUserLatches.clear();
            }
        }
    }

    @Override
    protected void onActivityResult(int requestCode, int resultCode, Intent data) {
        mActivityResultMultiplexedLatch.onActivityResult(requestCode, resultCode);
    }

    /**
     * The main execution {@link Thread}.
     *
     * This function executes in a background thread, allowing the test run freely behind the
     * scenes. It provides the following execution hooks:
     *  - Activity SetUp/CleanUp (not available in JUnit)
     *  - executeTests: to implement several execution engines
     */
    @Override
    public void run() {
        long startTimeNs = SystemClock.elapsedRealtimeNanos();
        String testName = getTestClassName();

        SensorTestDetails testDetails;
        try {
            mSensorFeaturesDeactivator.requestDeactivationOfFeatures();
            testDetails = new SensorTestDetails(testName, SensorTestDetails.ResultCode.PASS);
        } catch (Throwable e) {
            testDetails = new SensorTestDetails(testName, ""DeactivateSensorFeatures"", e);
        }

        SensorTestDetails.ResultCode resultCode = testDetails.getResultCode();
        if (resultCode == SensorTestDetails.ResultCode.SKIPPED) {
            // this is an invalid state at this point of the test setup
            throw new IllegalStateException(""Deactivation of features cannot skip the test."");
        }
        if (resultCode == SensorTestDetails.ResultCode.PASS) {
            testDetails = executeActivityTests(testName);
        }

        // we consider all remaining states at this point, because we could have been half way
        // deactivating features
        try {
            mSensorFeaturesDeactivator.requestToRestoreFeatures();
        } catch (Throwable e) {
            testDetails = new SensorTestDetails(testName, ""RestoreSensorFeatures"", e);
        }

        mTestLogger.logTestDetails(testDetails);
        mTestLogger.logExecutionTime(startTimeNs);

        // because we cannot enforce test failures in several devices, set the test UI so the
        // operator can report the result of the test
        promptUserToSetResult(testDetails);
    }

    /**
     * A general set up routine. It executes only once before the first test case.
     *
     * NOTE: implementers must be aware of the interrupted status of the worker thread, and let
     * {@link InterruptedException} propagate.
     *
     * @throws Throwable An exception that denotes the failure of set up. No tests will be executed.
     */
    protected void activitySetUp() throws Throwable {}

    /**
     * A general clean up routine. It executes upon successful execution of {@link #activitySetUp()}
     * and after all the test cases.
     *
     * NOTE: implementers must be aware of the interrupted status of the worker thread, and handle
     * it in two cases:
     * - let {@link InterruptedException} propagate
     * - if it is invoked with the interrupted status, prevent from showing any UI

     * @throws Throwable An exception that will be logged and ignored, for ease of implementation
     *                   by subclasses.
     */
    protected void activityCleanUp() throws Throwable {}

    /**
     * Performs the work of executing the tests.
     * Sub-classes implementing different execution methods implement this method.
     *
     * @return A {@link SensorTestDetails} object containing information about the executed tests.
     */
    protected abstract SensorTestDetails executeTests() throws InterruptedException;

    /**
     * Get mShouldRetry to check if test is required to retry.
     */
    protected boolean getShouldRetry() {
        return mShouldRetry;
    }

    @Override
    public SensorTestLogger getTestLogger() {
        return mTestLogger;
    }

    @Deprecated
    protected void appendText(int resId) {
        mTestLogger.logInstructions(resId);
    }

    @Deprecated
    protected void appendText(String text) {
        TextAppender textAppender = new TextAppender(R.layout.snsr_instruction);
        textAppender.setText(text);
        textAppender.append();
    }

    @Deprecated
    protected void clearText() {
        this.runOnUiThread(new Runnable() {
            @Override
            public void run() {
                mLogLayout.removeAllViews();
            }
        });
    }

    /**
     * Waits for the operator to acknowledge a requested action.
     *
     * @param waitMessageResId The action requested to the operator.
     */
    protected void waitForUser(int waitMessageResId) throws InterruptedException {
        CountDownLatch latch = new CountDownLatch(1);
        synchronized (mWaitForUserLatches) {
            mWaitForUserLatches.add(latch);
        }

        mTestLogger.logInstructions(waitMessageResId);
        setNextButtonText(waitMessageResId);

        updateRetryButton(true);
        updateNextButton(true);
        latch.await();
        updateRetryButton(false);
        updateNextButton(false);
    }

    /**
     * Waits for the operator to acknowledge to begin execution.
     */
    protected void waitForUserToBegin() throws InterruptedException {
        waitForUser(R.string.snsr_wait_to_begin);
    }

    /**
     * Waits for the operator to acknowledge to retry execution.
     */
    protected void waitForUserToRetry() throws InterruptedException {
        mShouldRetry = true;
        waitForUser(R.string.snsr_wait_to_retry);
    }

    /**
     * Waits for the operator to acknowledge to finish execution.
     */
    protected void waitForUserToFinish() throws InterruptedException {
        mShouldRetry = true;
        waitForUser(R.string.snsr_wait_to_finish);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public void waitForUserToContinue() throws InterruptedException {
        waitForUser(R.string.snsr_wait_for_user);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public int executeActivity(String action) throws InterruptedException {
        return executeActivity(new Intent(action));
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public int executeActivity(Intent intent) throws InterruptedException {
        ActivityResultMultiplexedLatch.Latch latch = mActivityResultMultiplexedLatch.bindThread();
        try {
            startActivityForResult(intent, latch.getRequestCode());
        } catch (ActivityNotFoundException e) {
            // handle exception gracefully
            // Among all defined activity results, RESULT_CANCELED offers the semantic closest to
            // represent absent setting activity.
            return RESULT_CANCELED;
        }
        return latch.await();
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public boolean hasSystemFeature(String feature) {
        PackageManager pm = getPackageManager();
        return pm.hasSystemFeature(feature);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public boolean hasActivity(String action) {
        PackageManager pm = getPackageManager();
        return pm.resolveActivity(new Intent(action), PackageManager.MATCH_DEFAULT_ONLY) != null;
    }

    /**
     * Initializes and shows the {@link GLSurfaceView} available to tests.
     * NOTE: initialization can be performed only once, usually inside {@link #activitySetUp()}.
     */
    protected void initializeGlSurfaceView(final GLSurfaceView.Renderer renderer) {
        runOnUiThread(new Runnable() {
            @Override
            public void run() {
                mGLSurfaceView.setVisibility(View.VISIBLE);
                mGLSurfaceView.setRenderer(renderer);
                mUsingGlSurfaceView = true;
            }
        });
    }

    /**
     * Closes and hides the {@link GLSurfaceView}.
     */
    protected void closeGlSurfaceView() {
        runOnUiThread(new Runnable() {
            @Override
            public void run() {
                if (!mUsingGlSurfaceView) {
                    return;
                }
                mGLSurfaceView.setVisibility(View.GONE);
                mGLSurfaceView.onPause();
                mUsingGlSurfaceView = false;
            }
        });
    }

    /**
     * Plays a (default) sound as a notification for the operator.
     */
    protected void playSound() throws InterruptedException {
        MediaPlayer player = MediaPlayer.create(this, Settings.System.DEFAULT_NOTIFICATION_URI);
        if (player == null) {
            Log.e(LOG_TAG, ""MediaPlayer unavailable."");
            return;
        }
        player.start();
        try {
            Thread.sleep(500);
        } finally {
            player.stop();
        }
    }

    /**
     * Makes the device vibrate for the given amount of time.
     */
    protected void vibrate(int timeInMs) {
        Vibrator vibrator = (Vibrator) getSystemService(Context.VIBRATOR_SERVICE);
        vibrator.vibrate(timeInMs);
    }

    /**
     * Makes the device vibrate following the given pattern.
     * See {@link Vibrator#vibrate(long[], int)} for more information.
     */
    protected void vibrate(long[] pattern) {
        Vibrator vibrator = (Vibrator) getSystemService(Context.VIBRATOR_SERVICE);
        vibrator.vibrate(pattern, -1);
    }

    // TODO: move to sensor assertions
    protected String assertTimestampSynchronization(
            long eventTimestamp,
            long receivedTimestamp,
            long deltaThreshold,
            String sensorName) {
        long timestampDelta = Math.abs(eventTimestamp - receivedTimestamp);
        String timestampMessage = getString(
                R.string.snsr_event_time,
                receivedTimestamp,
                eventTimestamp,
                timestampDelta,
                deltaThreshold,
                sensorName);
        Assert.assertTrue(timestampMessage, timestampDelta < deltaThreshold);
        return timestampMessage;
    }

    protected String getTestClassName() {
        if (mTestClass == null) {
            return ""<unknown>"";
        }
        return mTestClass.getName();
    }

    protected void setLogScrollViewListener(View.OnTouchListener listener) {
        mLogScrollView.setOnTouchListener(listener);
    }

    private void setTestResult(SensorTestDetails testDetails) {
        // the name here, must be the Activity's name because it is what CtsVerifier expects
        String name = super.getClass().getName();
        String summary = mTestLogger.getOverallSummary();
        SensorTestDetails.ResultCode resultCode = testDetails.getResultCode();
        switch(resultCode) {
            case SKIPPED:
                TestResult.setPassedResult(this, name, summary);
                break;
            case PASS:
            case WARNING:
                TestResult.setPassedResult(this, name, summary);
                break;
            case FAIL:
                TestResult.setFailedResult(this, name, summary);
                break;
            case INTERRUPTED:
                // do not set a result, just return so the test can complete
                break;
            default:
                throw new IllegalStateException(""Unknown ResultCode: "" + resultCode);
        }
    }

    private SensorTestDetails executeActivityTests(String testName) {
        SensorTestDetails testDetails;
        try {
            activitySetUp();
            testDetails = new SensorTestDetails(testName, SensorTestDetails.ResultCode.PASS);
        } catch (Throwable e) {
            testDetails = new SensorTestDetails(testName, ""ActivitySetUp"", e);
        }

        SensorTestDetails.ResultCode resultCode = testDetails.getResultCode();
        if (resultCode == SensorTestDetails.ResultCode.PASS) {
            // TODO: implement execution filters:
            //      - execute all tests and report results officially
            //      - execute single test or failed tests only
            try {
                testDetails = executeTests();
            } catch (Throwable e) {
                // we catch and continue because we have to guarantee a proper clean-up sequence
                testDetails = new SensorTestDetails(testName, ""TestExecution"", e);
            }
        }

        // clean-up executes for all states, even on SKIPPED and INTERRUPTED there might be some
        // intermediate state that needs to be taken care of
        try {
            activityCleanUp();
        } catch (Throwable e) {
            testDetails = new SensorTestDetails(testName, ""ActivityCleanUp"", e);
        }

        return testDetails;
    }

    private void promptUserToSetResult(SensorTestDetails testDetails) {
        SensorTestDetails.ResultCode resultCode = testDetails.getResultCode();
        if (resultCode == SensorTestDetails.ResultCode.FAIL) {
            mTestLogger.logInstructions(R.string.snsr_test_complete_with_errors);
            enableTestResultButton(
                    mFailButton,
                    R.string.fail_button_text,
                    testDetails.cloneAndChangeResultCode(SensorTestDetails.ResultCode.FAIL));
        } else if (resultCode != SensorTestDetails.ResultCode.INTERRUPTED) {
            mTestLogger.logInstructions(R.string.snsr_test_complete);
            enableTestResultButton(
                    mPassButton,
                    R.string.pass_button_text,
                    testDetails.cloneAndChangeResultCode(SensorTestDetails.ResultCode.PASS));
        }
    }

    private void updateNextButton(final boolean enabled) {
        runOnUiThread(new Runnable() {
            @Override
            public void run() {
                mNextButton.setEnabled(enabled);
            }
        });
    }

    /**
     * Set the text for next button by instruction message.
     * During retry, next button text is changed to notify users.
     *
     * @param waitMessageResId The action requested to the operator.
     */
    private void setNextButtonText(int waitMessageResId) {
        int nextButtonText;
        switch (waitMessageResId) {
            case R.string.snsr_wait_to_retry:
                nextButtonText = R.string.fail_and_next_button_text;
                break;
            case R.string.snsr_wait_to_finish:
                nextButtonText = R.string.finish_button_text;
                break;
            default:
                nextButtonText = R.string.next_button_text;
                break;
        }
        runOnUiThread(new Runnable() {
            @Override
            public void run() {
                mNextButton.setText(nextButtonText);
            }
        });
    }

    /**
     * Update the retry button status.
     * During retry, show retry execution count. If not to retry, make retry button invisible.
     *
     * @param enabled The status of button.
     */
    private void updateRetryButton(final boolean enabled) {
        runOnUiThread(new Runnable() {
            @Override
            public void run() {
                if (mShouldRetry) {
                    String showRetryCount = String.format(
                        ""%s (%d)"", getResources().getText(R.string.retry_button_text), mRetryCount);
                    mRetryButton.setText(showRetryCount);
                    mRetryButton.setVisibility(View.VISIBLE);
                    mRetryButton.setEnabled(enabled);
                } else {
                    mRetryButton.setVisibility(View.GONE);
                    mRetryCount = 0;
                }
            }
        });
    }

    private void enableTestResultButton(
            final Button button,
            final int textResId,
            final SensorTestDetails testDetails) {
        final View.OnClickListener listener = new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                setTestResult(testDetails);
                finish();
            }
        };

        runOnUiThread(new Runnable() {
            @Override
            public void run() {
                mNextButton.setVisibility(View.GONE);
                mRetryButton.setVisibility(View.GONE);
                button.setText(textResId);
                button.setOnClickListener(listener);
                button.setVisibility(View.VISIBLE);
            }
        });
    }

    // a logger available until sensor reporting is in place
    public class SensorTestLogger {
        private static final String SUMMARY_SEPARATOR = "" | "";

        private final StringBuilder mOverallSummaryBuilder = new StringBuilder(""\n"");

        public void logCustomView(View view) {
            new ViewAppender(view).append();
        }

        void logTestStart(String testName) {
            // TODO: log the sensor information and expected execution time of each test
            TextAppender textAppender = new TextAppender(R.layout.snsr_test_title);
            textAppender.setText(testName);
            textAppender.append();
        }

        public void logInstructions(int instructionsResId, Object ... params) {
            TextAppender textAppender = new TextAppender(R.layout.snsr_instruction);
            textAppender.setText(getString(instructionsResId, params));
            textAppender.append();
        }

        public void logMessage(int messageResId, Object ... params) {
            TextAppender textAppender = new TextAppender(R.layout.snsr_message);
            textAppender.setText(getString(messageResId, params));
            textAppender.append();
        }

        public void logWaitForSound() {
            logInstructions(R.string.snsr_test_play_sound);
        }

        public void logTestDetails(SensorTestDetails testDetails) {
            String name = testDetails.getName();
            String summary = testDetails.getSummary();
            SensorTestDetails.ResultCode resultCode = testDetails.getResultCode();
            switch (resultCode) {
                case SKIPPED:
                    logTestSkip(name, summary);
                    break;
                case PASS:
                case WARNING:
                    mShouldRetry = false;
                    logTestPass(name, summary);
                    break;
                case FAIL:
                    logTestFail(name, summary);
                    break;
                case INTERRUPTED:
                    // do nothing, the test was interrupted so do we
                    break;
                default:
                    throw new IllegalStateException(""Unknown ResultCode: "" + resultCode);
            }
        }

        void logTestPass(String testName, String testSummary) {
            testSummary = getValidTestSummary(testSummary, R.string.snsr_test_pass);
            logTestEnd(R.layout.snsr_success, testSummary);
            Log.d(LOG_TAG, testSummary);
            saveResult(testName, SensorTestDetails.ResultCode.PASS, testSummary);
        }

        public void logTestFail(String testName, String testSummary) {
            testSummary = getValidTestSummary(testSummary, R.string.snsr_test_fail);
            logTestEnd(R.layout.snsr_error, testSummary);
            Log.e(LOG_TAG, testSummary);
            saveResult(testName, SensorTestDetails.ResultCode.FAIL, testSummary);
        }

        void logTestSkip(String testName, String testSummary) {
            testSummary = getValidTestSummary(testSummary, R.string.snsr_test_skipped);
            logTestEnd(R.layout.snsr_warning, testSummary);
            Log.i(LOG_TAG, testSummary);
            saveResult(testName, SensorTestDetails.ResultCode.SKIPPED, testSummary);
        }

        String getOverallSummary() {
            return mOverallSummaryBuilder.toString();
        }

        void logExecutionTime(long startTimeNs) {
            if (Thread.currentThread().isInterrupted()) {
                return;
            }
            long executionTimeNs = SystemClock.elapsedRealtimeNanos() - startTimeNs;
            long executionTimeSec = TimeUnit.NANOSECONDS.toSeconds(executionTimeNs);
            // TODO: find a way to format times with nanosecond accuracy and longer than 24hrs
            String formattedElapsedTime = DateUtils.formatElapsedTime(executionTimeSec);
            logMessage(R.string.snsr_execution_time, formattedElapsedTime);
        }

        private void logTestEnd(int textViewResId, String testSummary) {
            TextAppender textAppender = new TextAppender(textViewResId);
            textAppender.setText(testSummary);
            textAppender.append();
        }

        private String getValidTestSummary(String testSummary, int defaultSummaryResId) {
            if (TextUtils.isEmpty(testSummary)) {
                return getString(defaultSummaryResId);
            }
            return testSummary;
        }

        private void saveResult(
                String testName,
                SensorTestDetails.ResultCode resultCode,
                String summary) {
            mOverallSummaryBuilder.append(testName);
            mOverallSummaryBuilder.append(SUMMARY_SEPARATOR);
            mOverallSummaryBuilder.append(resultCode.name());
            mOverallSummaryBuilder.append(SUMMARY_SEPARATOR);
            mOverallSummaryBuilder.append(summary);
            mOverallSummaryBuilder.append(""\n"");
        }
    }

    private class ViewAppender {
        protected final View mView;

        public ViewAppender(View view) {
            mView = view;
        }

        public void append() {
            runOnUiThread(new Runnable() {
                @Override
                public void run() {
                    mLogLayout.addView(mView);
                    mLogScrollView.post(new Runnable() {
                        @Override
                        public void run() {
                            mLogScrollView.fullScroll(View.FOCUS_DOWN);
                        }
                    });
                }
            });
        }
    }

    private class TextAppender extends ViewAppender{
        private final TextView mTextView;

        public TextAppender(int textViewResId) {
            super(getLayoutInflater().inflate(textViewResId, null /* viewGroup */));
            mTextView = (TextView) mView;
        }

        public void setText(String text) {
            mTextView.setText(text);
        }

        public void setText(int textResId) {
            mTextView.setText(textResId);
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Utils.PoseProvider.PoseProvider"	"getLatestPoseData"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Utils/PoseProvider/PoseProvider.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Utils.PoseProvider;

import android.content.Context;

/**
 * Base class for objects that provide pose data to the app.
 */
public abstract class PoseProvider {
    protected Context mContext;
    protected PoseProviderListener mPoseProviderListener;

    protected PoseData mLatestPoseData;
    protected Intrinsics mIntrinsics;

    public static final Object POSE_LOCK = new Object();

    public interface PoseProviderListener {
        void onSetupComplete();

        void onNewPoseData(PoseData newPoseData);
    }

    public PoseProvider(Context context, PoseProviderListener listener) {
        mContext = context;
        mPoseProviderListener = listener;
    }

    public abstract void onStartPoseProviding();

    public abstract void onStopPoseProviding();

    public abstract void setup();

    protected void onNewPoseData(PoseData newPoseData){
        if (mPoseProviderListener != null) {
            mPoseProviderListener.onNewPoseData(newPoseData);
        }
    }

    public PoseData getLatestPoseData() {
        synchronized (POSE_LOCK) {
            return mLatestPoseData;
        }
    }

    public Intrinsics getIntrinsics() {
        return mIntrinsics;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"isDirectChannelTypeSupported"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void test/*
 *.
 */

package android.hardware.cts;

import android.content.Context;
import android.hardware.HardwareBuffer;
import android.hardware.Sensor;
import android.hardware.SensorDirectChannel;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.hardware.cts.helpers.SensorCtsHelper;
import android.hardware.cts.helpers.SensorCtsHelper.TestResultCollector;
import android.os.MemoryFile;
import android.os.SystemClock;
import android.util.Log;

import java.io.IOException;
import java.io.UncheckedIOException;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.concurrent.TimeUnit;

/**
 * Checks Sensor Direct Report functionality
 *
 * This testcase tests operation of:
 *   - SensorManager.createDirectChannel()
 *   - SensorDirectChannel.*
 *   - Sensor.getHighestDirectReportRateLevel()
 *   - Sensor.isDirectChannelTypeSupported()
 *
 * Tests:
 *   - test<Sensor><SharedMemoryType><RateLevel>
 *     tests basic operation of sensor in direct report mode at various rate level specification.
 *   - testRateIndependency<Sensor1><Sensor2>SingleChannel
 *     tests if two sensors in the same direct channel are able to run at different rates.
 *   - testRateIndependency<Sensor>MultiChannel
 *     tests if a sensor is able to be configured to different rate levels for multiple channels.
 *   - testRateIndependency<Sensor>MultiMode
 *     tests if a sensor is able to report at different rates in direct report mode and traditional
 *     report mode (polling).
 *   - testTimestamp<Sensor>
 *     tests if the timestamp is correct both in absolute sense and relative to traditional report.
 *   - testAtomicCounter<Sensor>
 *     test if atomic counter is increased as specified and if sensor event content is fully updated
 *     before update of atomic counter.
 *   - testRegisterMultipleChannels
 *     test scenarios when multiple channels are registered simultaneously.
 *   - testReconfigure
 *     test channel reconfiguration (configure to a rate level; configure to stop; configure to
 *     another rate level)
 *   - testRegisterMultipleChannelsUsingSameMemory
 *     test a negative case when the same memory is being used twice for registering sensor direct
 *     channel
 *   - testCloseWithoutConfigStop
 *     test a common mistake in API usage and make sure no negative effect is made to system.
 */
public class SensorDirectReportTest extends SensorTestCase {
    private static final String TAG = ""SensorDirectReportTest"";
    // nominal rates of each rate level supported
    private static final float RATE_NORMAL_NOMINAL = 50;
    private static final float RATE_FAST_NOMINAL = 200;
    private static final float RATE_VERY_FAST_NOMINAL = 800;

    // actuall value is allowed to be 55% to 220% of nominal value
    private static final float FREQ_LOWER_BOUND = 0.55f;
    private static final float FREQ_UPPER_BOUND = 2.2f;

    // actuall value is allowed to be 90% to 200% of nominal value in poll() interface
    private static final float FREQ_LOWER_BOUND_POLL = 0.90f;
    private static final float FREQ_UPPER_BOUND_POLL = 2.00f;

    // sensor reading assumption
    private static final float GRAVITY_MIN = 9.81f - 1.0f;
    private static final float GRAVITY_MAX = 9.81f + 1.0f;
    private static final float GYRO_NORM_MAX = 0.1f;

    // test constants
    public static final int REST_PERIOD_BEFORE_TEST_MILLISEC = 3000;
    private static final int TEST_RUN_TIME_PERIOD_MILLISEC = 5000;
    private static final int ALLOWED_SENSOR_INIT_TIME_MILLISEC = 500;
    private static final int SENSORS_EVENT_SIZE = 104;
    private static final int ATOMIC_COUNTER_OFFSET = 12;
    private static final int ATOMIC_COUNTER_SIZE = 4;
    private static final int SENSORS_EVENT_COUNT = 10240; // 800Hz * 2.2 * 5 sec + extra
    private static final int SHARED_MEMORY_SIZE = SENSORS_EVENT_COUNT * SENSORS_EVENT_SIZE;
    private static final float MERCY_FACTOR = 0.1f;
    private static final boolean CHECK_ABSOLUTE_LATENCY = false;

    // list of rate levels being tested
    private static final int[] POSSIBLE_RATE_LEVELS = new int[] {
            SensorDirectChannel.RATE_NORMAL,
            SensorDirectChannel.RATE_FAST,
            SensorDirectChannel.RATE_VERY_FAST
        };

    // list of channel types being tested
    private static final int[] POSSIBLE_CHANNEL_TYPES = new int [] {
            SensorDirectChannel.TYPE_MEMORY_FILE,
            SensorDirectChannel.TYPE_HARDWARE_BUFFER
        };

    // list of sensor types being tested
    private static final int[] POSSIBLE_SENSOR_TYPES = new int [] {
            Sensor.TYPE_ACCELEROMETER,
            Sensor.TYPE_GYROSCOPE,
            Sensor.TYPE_MAGNETIC_FIELD
        };

    // list of sampling period being tested
    private static final int[] POSSIBLE_SAMPLE_PERIOD_US = new int [] {
            200_000, // Normal 5 Hz
            66_667,  // UI    15 Hz
            20_000,  // Game  50 Hz
            5_000,   // 200Hz
            0        // fastest
        };

    private static final ByteOrder NATIVE_BYTE_ORDER = ByteOrder.nativeOrder();

    private static native boolean nativeReadHardwareBuffer(HardwareBuffer hardwareBuffer,
            byte[] buffer, int srcOffset, int destOffset, int count);

    private boolean mNeedMemoryFile;
    private MemoryFile mMemoryFile;
    private MemoryFile mMemoryFileSecondary;
    private boolean mNeedHardwareBuffer;
    private HardwareBuffer mHardwareBuffer;
    private HardwareBuffer mHardwareBufferSecondary;
    private ByteBuffer mByteBuffer;
    private byte[] mBuffer;

    private SensorManager mSensorManager;
    private SensorDirectChannel mChannel;
    private SensorDirectChannel mChannelSecondary;

    private EventPool mEventPool;

    static {
        System.loadLibrary(""cts-sensors-ndk-jni"");
    }

    @Override
    protected void setUp() throws Exception {
        super.setUp();

        mByteBuffer = ByteBuffer.allocate(SHARED_MEMORY_SIZE);
        mBuffer = mByteBuffer.array();
        mByteBuffer.order(ByteOrder.nativeOrder());

        mEventPool = new EventPool(10 * SENSORS_EVENT_COUNT);
        mSensorManager = (SensorManager) getContext().getSystemService(Context.SENSOR_SERVICE);

        mNeedMemoryFile = isMemoryTypeNeeded(SensorDirectChannel.TYPE_MEMORY_FILE);
        mNeedHardwareBuffer = isMemoryTypeNeeded(SensorDirectChannel.TYPE_HARDWARE_BUFFER);

        allocateSharedMemory();
    }

    @Override
    protected void tearDown() throws Exception {
        if (mChannel != null) {
            mChannel.close();
            mChannel = null;
        }

        if (mChannelSecondary != null) {
            mChannelSecondary.close();
            mChannelSecondary = null;
        }

        freeSharedMemory();
        super.tearDown();
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAccelerometerAshmemNormal"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAccelerometerAshmemNormal() {
        runSensorDirectReportTest(
                Sensor.TYPE_ACCELEROMETER,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_NORMAL);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAccelerometerAshmemNormalUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAccelerometerAshmemNormalUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_ACCELEROMETER,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_NORMAL);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testGyroscopeAshmemNormal"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testGyroscopeAshmemNormal() {
        runSensorDirectReportTest(
                Sensor.TYPE_GYROSCOPE,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_NORMAL);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testGyroscopeAshmemNormalUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testGyroscopeAshmemNormalUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_GYROSCOPE,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_NORMAL);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testMagneticFieldAshmemNormal"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testMagneticFieldAshmemNormal() {
        runSensorDirectReportTest(
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_NORMAL);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testMagneticFieldAshmemNormalUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testMagneticFieldAshmemNormalUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_NORMAL);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAccelerometerAshmemFast"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAccelerometerAshmemFast() {
        runSensorDirectReportTest(
                Sensor.TYPE_ACCELEROMETER,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAccelerometerAshmemFastUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAccelerometerAshmemFastUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_ACCELEROMETER,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testGyroscopeAshmemFast"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testGyroscopeAshmemFast() {
        runSensorDirectReportTest(
                Sensor.TYPE_GYROSCOPE,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testGyroscopeAshmemFastUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testGyroscopeAshmemFastUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_GYROSCOPE,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testMagneticFieldAshmemFast"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testMagneticFieldAshmemFast() {
        runSensorDirectReportTest(
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testMagneticFieldAshmemFastUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testMagneticFieldAshmemFastUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAccelerometerAshmemVeryFast"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAccelerometerAshmemVeryFast() {
        runSensorDirectReportTest(
                Sensor.TYPE_ACCELEROMETER,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_VERY_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAccelerometerAshmemVeryFastUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAccelerometerAshmemVeryFastUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_ACCELEROMETER,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_VERY_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testGyroscopeAshmemVeryFast"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testGyroscopeAshmemVeryFast() {
        runSensorDirectReportTest(
                Sensor.TYPE_GYROSCOPE,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_VERY_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testGyroscopeAshmemVeryFastUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testGyroscopeAshmemVeryFastUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_GYROSCOPE,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_VERY_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testMagneticFieldAshmemVeryFast"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testMagneticFieldAshmemVeryFast() {
        runSensorDirectReportTest(
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_VERY_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testMagneticFieldAshmemVeryFastUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testMagneticFieldAshmemVeryFastUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorDirectChannel.TYPE_MEMORY_FILE,
                SensorDirectChannel.RATE_VERY_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAccelerometerHardwareBufferNormal"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAccelerometerHardwareBufferNormal() {
        runSensorDirectReportTest(
                Sensor.TYPE_ACCELEROMETER,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_NORMAL);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAccelerometerHardwareBufferNormalUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAccelerometerHardwareBufferNormalUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_ACCELEROMETER,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_NORMAL);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testGyroscopeHardwareBufferNormal"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testGyroscopeHardwareBufferNormal() {
        runSensorDirectReportTest(
                Sensor.TYPE_GYROSCOPE,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_NORMAL);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testGyroscopeHardwareBufferNormalUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testGyroscopeHardwareBufferNormalUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_GYROSCOPE,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_NORMAL);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testMagneticFieldHardwareBufferNormal"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testMagneticFieldHardwareBufferNormal() {
        runSensorDirectReportTest(
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_NORMAL);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testMagneticFieldHardwareBufferNormalUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testMagneticFieldHardwareBufferNormalUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_NORMAL);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAccelerometerHardwareBufferFast"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAccelerometerHardwareBufferFast() {
        runSensorDirectReportTest(
                Sensor.TYPE_ACCELEROMETER,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAccelerometerHardwareBufferFastUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAccelerometerHardwareBufferFastUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_ACCELEROMETER,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testGyroscopeHardwareBufferFast"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testGyroscopeHardwareBufferFast() {
        runSensorDirectReportTest(
                Sensor.TYPE_GYROSCOPE,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testGyroscopeHardwareBufferFastUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testGyroscopeHardwareBufferFastUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_GYROSCOPE,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testMagneticFieldHardwareBufferFast"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testMagneticFieldHardwareBufferFast() {
        runSensorDirectReportTest(
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testMagneticFieldHardwareBufferFastUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testMagneticFieldHardwareBufferFastUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAccelerometerHardwareBufferVeryFast"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAccelerometerHardwareBufferVeryFast() {
        runSensorDirectReportTest(
                Sensor.TYPE_ACCELEROMETER,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_VERY_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAccelerometerHardwareBufferVeryFastUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAccelerometerHardwareBufferVeryFastUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_ACCELEROMETER,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_VERY_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testGyroscopeHardwareBufferVeryFast"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testGyroscopeHardwareBufferVeryFast() {
        runSensorDirectReportTest(
                Sensor.TYPE_GYROSCOPE,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_VERY_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testGyroscopeHardwareBufferVeryFastUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testGyroscopeHardwareBufferVeryFastUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_GYROSCOPE,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_VERY_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testMagneticFieldHardwareBufferVeryFast"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testMagneticFieldHardwareBufferVeryFast() {
        runSensorDirectReportTest(
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_VERY_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testMagneticFieldHardwareBufferVeryFastUidIdle"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testMagneticFieldHardwareBufferVeryFastUidIdle() {
        runSensorDirectReportUidIdleTest(
                Sensor.TYPE_MAGNETIC_FIELD,
                SensorDirectChannel.TYPE_HARDWARE_BUFFER,
                SensorDirectChannel.RATE_VERY_FAST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testRateIndependencyAccelGyroSingleChannel"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testRateIndependencyAccelGyroSingleChannel() {
        runSingleChannelRateIndependencyTestGroup(Sensor.TYPE_ACCELEROMETER,
                                                  Sensor.TYPE_GYROSCOPE);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testRateIndependencyAccelMagSingleChannel"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testRateIndependencyAccelMagSingleChannel() {
        runSingleChannelRateIndependencyTestGroup(Sensor.TYPE_ACCELEROMETER,
                                                  Sensor.TYPE_MAGNETIC_FIELD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testRateIndependencyGyroMagSingleChannel"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testRateIndependencyGyroMagSingleChannel() {
        runSingleChannelRateIndependencyTestGroup(Sensor.TYPE_GYROSCOPE,
                                                  Sensor.TYPE_MAGNETIC_FIELD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testRateIndependencyAccelUncalAccelSingleChannel"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testRateIndependencyAccelUncalAccelSingleChannel() {
        runSingleChannelRateIndependencyTestGroup(Sensor.TYPE_ACCELEROMETER,
                                             Sensor.TYPE_ACCELEROMETER_UNCALIBRATED);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testRateIndependencyGyroUncalGyroSingleChannel"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testRateIndependencyGyroUncalGyroSingleChannel() {
        runSingleChannelRateIndependencyTestGroup(Sensor.TYPE_GYROSCOPE,
                                             Sensor.TYPE_GYROSCOPE_UNCALIBRATED);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testRateIndependencyMagUncalMagSingleChannel"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testRateIndependencyMagUncalMagSingleChannel() {
        runSingleChannelRateIndependencyTestGroup(Sensor.TYPE_MAGNETIC_FIELD,
                                             Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testRateIndependencyAccelMultiChannel"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testRateIndependencyAccelMultiChannel() {
        runMultiChannelRateIndependencyTestGroup(Sensor.TYPE_ACCELEROMETER);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testRateIndependencyGyroMultiChannel"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testRateIndependencyGyroMultiChannel() {
        runMultiChannelRateIndependencyTestGroup(Sensor.TYPE_GYROSCOPE);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testRateIndependencyMagMultiChannel"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testRateIndependencyMagMultiChannel() {
        runMultiChannelRateIndependencyTestGroup(Sensor.TYPE_MAGNETIC_FIELD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testRateIndependencyAccelMultiMode"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testRateIndependencyAccelMultiMode() {
        runMultiModeRateIndependencyTestGroup(Sensor.TYPE_ACCELEROMETER);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testRateIndependencyGyroMultiMode"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testRateIndependencyGyroMultiMode() {
        runMultiModeRateIndependencyTestGroup(Sensor.TYPE_GYROSCOPE);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testRateIndependencyMagMultiMode"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testRateIndependencyMagMultiMode() {
        runMultiModeRateIndependencyTestGroup(Sensor.TYPE_MAGNETIC_FIELD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testTimestampAccel"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testTimestampAccel() {
        runTimestampTestGroup(Sensor.TYPE_ACCELEROMETER);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testTimestampGyro"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testTimestampGyro() {
        runTimestampTestGroup(Sensor.TYPE_GYROSCOPE);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testTimestampMag"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testTimestampMag() {
        runTimestampTestGroup(Sensor.TYPE_MAGNETIC_FIELD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAtomicCounterAccel"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAtomicCounterAccel() {
        for (int memType : POSSIBLE_CHANNEL_TYPES) {
            runAtomicCounterTest(Sensor.TYPE_ACCELEROMETER, memType);
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAtomicCounterGyro"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAtomicCounterGyro() {
        for (int memType : POSSIBLE_CHANNEL_TYPES) {
            runAtomicCounterTest(Sensor.TYPE_GYROSCOPE, memType);
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testAtomicCounterMag"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testAtomicCounterMag() {
        for (int memType : POSSIBLE_CHANNEL_TYPES) {
            runAtomicCounterTest(Sensor.TYPE_MAGNETIC_FIELD, memType);
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testRegisterMultipleChannelsUsingSameMemory"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testRegisterMultipleChannelsUsingSameMemory() throws AssertionError {
        // MemoryFile identification is not supported by Android yet
        int memType = SensorDirectChannel.TYPE_HARDWARE_BUFFER;
        if (!isMemoryTypeNeeded(memType)) {
            return;
        }

        mChannel = prepareDirectChannel(memType, false /* secondary */);
        assertNotNull(""mChannel is null"", mChannel);

        // use same memory to register, should fail.
        mChannelSecondary = prepareDirectChannel(memType, false /* secondary */);
        assertNull(""mChannelSecondary is not null"", mChannelSecondary);

        mChannel.close();
        // after mChannel.close(), memory should free up and this should return non-null
        // channel
        mChannelSecondary = prepareDirectChannel(memType, false /* secondary */);
        assertNotNull(""mChannelSecondary is null"", mChannelSecondary);
        mChannelSecondary.close();
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testReconfigure"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testReconfigure() {
        TestResultCollector c = new TestResultCollector(""testReconfigure"", TAG);

        for (int type : POSSIBLE_SENSOR_TYPES) {
            for (int memType : POSSIBLE_CHANNEL_TYPES) {
                c.perform(() -> { runReconfigureTest(type, memType);},
                        String.format(""sensor type %d, mem type %d"", type, memType));
            }
        }
        c.judge();
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorDirectReportTest"	"testCloseWithoutConfigStop"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorDirectReportTest.java"	""	"public void testCloseWithoutConfigStop() {
        for (int type : POSSIBLE_SENSOR_TYPES) {
            for (int memType : POSSIBLE_CHANNEL_TYPES) {
                Sensor s = mSensorManager.getDefaultSensor(type);
                if (s == null
                        || s.getHighestDirectReportRateLevel() == SensorDirectChannel.RATE_STOP
                        || !s.isDirectChannelTypeSupported(memType)) {
                    continue;
                }

                mChannel = prepareDirectChannel(memType, false /* secondary */);
                assertTrue(""createDirectChannel failed"", mChannel != null);

                try {
                    waitBeforeStartSensor();
                    mChannel.configure(s, s.getHighestDirectReportRateLevel());

                    // wait for a while
                    waitBeforeStartSensor();

                    // The following line is commented out intentionally.
                    // mChannel.configure(s, SensorDirectChannel.RATE_STOP);
                } finally {
                    mChannel.close();
                    mChannel = null;
                }
                waitBeforeStartSensor();
            }
        }
    }

    private void runSingleChannelRateIndependencyTestGroup(int type1, int type2) {
        if (type1 == type2) {
            throw new IllegalArgumentException(""Cannot run single channel rate independency test ""
                    + ""on type "" + type1 + "" and "" + type2);
        }
        String stype1 = SensorCtsHelper.sensorTypeShortString(type1);
        String stype2 = SensorCtsHelper.sensorTypeShortString(type2);

        TestResultCollector c =
                new TestResultCollector(
                    ""testRateIndependency"" + stype1 + stype2 + ""SingleChannel"", TAG);

        for (int rate1 : POSSIBLE_RATE_LEVELS) {
            for (int rate2 : POSSIBLE_RATE_LEVELS) {
                for (int memType : POSSIBLE_CHANNEL_TYPES) {
                    c.perform(
                        () -> {
                            runSingleChannelRateIndependencyTest(
                                    type1, rate1, type2, rate2,
                                    SensorDirectChannel.TYPE_MEMORY_FILE);
                        },
                        String.format(""(%s rate %d, %s rate %d, mem %d)"",
                                      stype1, rate1, stype2, rate2, memType));
                }
            }
        }
        c.judge();
    }

    public void runMultiChannelRateIndependencyTestGroup(int sensorType) {
        TestResultCollector c = new TestResultCollector(
                ""testRateIndependency"" + SensorCtsHelper.sensorTypeShortString(sensorType)
                    + ""MultiChannel"", TAG);

        for (int rate1 : POSSIBLE_RATE_LEVELS) {
            for (int rate2 : POSSIBLE_RATE_LEVELS) {
                for (int type1 : POSSIBLE_CHANNEL_TYPES) {
                    for (int type2 : POSSIBLE_CHANNEL_TYPES) {
                        // only test upper triangle
                        if (rate1 > rate2 || type1 > type2) {
                            continue;
                        }
                        c.perform(() -> {
                                runMultiChannelRateIndependencyTest(
                                        sensorType, rate1, rate2, type1, type2);},
                                String.format(""rate1 %d, rate2 %d, type1 %d, type2 %d"",
                                              rate1, rate2, type1, type2));
                    }
                }
            }
        }
        c.judge();
    }

    public void runMultiModeRateIndependencyTestGroup(int sensorType) {
        TestResultCollector c = new TestResultCollector(
                ""testRateIndependency"" + SensorCtsHelper.sensorTypeShortString(sensorType)
                    + ""MultiMode"", TAG);

        for (int rate : POSSIBLE_RATE_LEVELS) {
            for (int type : POSSIBLE_CHANNEL_TYPES) {
                for (int samplingPeriodUs : POSSIBLE_SAMPLE_PERIOD_US) {
                    c.perform(() -> {runMultiModeRateIndependencyTest(
                                        sensorType, rate, type, samplingPeriodUs);},
                              String.format(""rateLevel %d, memType %d, period %d"",
                                            rate, type, samplingPeriodUs));
                }
            }
        }
        c.judge();
    }

    private void runTimestampTestGroup(int sensorType) {
        String stype = SensorCtsHelper.sensorTypeShortString(sensorType);

        TestResultCollector c =
                new TestResultCollector(""testTimestamp"" + stype, TAG);

        for (int rateLevel : POSSIBLE_RATE_LEVELS) {
            for (int memType : POSSIBLE_CHANNEL_TYPES) {
                c.perform(
                        () -> {
                            runTimestampTest(sensorType, rateLevel, memType);
                        },
                        String.format(""(%s, rate %d, memtype %d)"", stype, rateLevel, memType));
            }
        }
        c.judge();
    }

    private void runSensorDirectReportTest(int sensorType, int memType, int rateLevel)
            throws AssertionError {
        Sensor s = mSensorManager.getDefaultSensor(sensorType);
        if (s == null
                || s.getHighestDirectReportRateLevel() < rateLevel
                || !s.isDirectChannelTypeSupported(memType)) {
            return;
        }
        resetEvent();

        mChannel = prepareDirectChannel(memType, false /* secondary */);
        assertTrue(""createDirectChannel failed"", mChannel != null);

        try {
            assertTrue(""Shared memory is not formatted"", isSharedMemoryFormatted(memType));
            waitBeforeStartSensor();

            int token = mChannel.configure(s, rateLevel);
            assertTrue(""configure direct mChannel failed"", token > 0);

            waitSensorCollection();

            //stop sensor and analyze content
            mChannel.configure(s, SensorDirectChannel.RATE_STOP);
            checkSharedMemoryContent(s, memType, rateLevel, token);
        } finally {
            mChannel.close();
            mChannel = null;
        }
    }

    private void runSensorDirectReportUidIdleTest(int sensorType, int memType, int rateLevel) {
        Sensor s = mSensorManager.getDefaultSensor(sensorType);
        if (s == null
                || s.getHighestDirectReportRateLevel() < rateLevel
                || !s.isDirectChannelTypeSupported(memType)) {
            return;
        }
        resetEvent();

        mChannel = prepareDirectChannel(memType, false /* secondary */);
        assertTrue(""createDirectChannel failed"", mChannel != null);

        try {
            assertTrue(""Shared memory is not formatted"", isSharedMemoryFormatted(memType));
            waitBeforeStartSensor();

            int token = mChannel.configure(s, rateLevel);
            assertTrue(""configure direct mChannel failed"", token > 0);

            // Make package idle and ensure no sensor events are received
            try {
                SensorCtsHelper.makeMyPackageIdle();
            } catch (IOException e) {
                fail(""IOException while making package idle"");
            }

            int originalEventSize = mBuffer.length;
            waitSensorCollection();

            assertEquals(mBuffer.length, originalEventSize);

            try {
                SensorCtsHelper.makeMyPackageActive();
            } catch (IOException e) {
                fail(""IOException while making package active"");
            }

            // Also verify sensor events can be received after becoming active.
            resetEvent();

            waitSensorCollection();

            //stop sensor and analyze content
            mChannel.configure(s, SensorDirectChannel.RATE_STOP);
            checkSharedMemoryContent(s, memType, rateLevel, token);
        } finally {
            mChannel.close();
            mChannel = null;
        }
    }

    private void runSingleChannelRateIndependencyTest(
            int type1, int rateLevel1, int type2, int rateLevel2, int memType)
                throws AssertionError {
        Sensor s1 = mSensorManager.getDefaultSensor(type1);
        Sensor s2 = mSensorManager.getDefaultSensor(type2);
        if (s1 == null
                || s1.getHighestDirectReportRateLevel() < rateLevel1
                || !s1.isDirectChannelTypeSupported(memType)) {
            return;
        }

        if (s2 == null
                || s2.getHighestDirectReportRateLevel() < rateLevel2
                || !s2.isDirectChannelTypeSupported(memType)) {
            return;
        }
        resetEvent();

        mChannel = prepareDirectChannel(memType, false /* secondary */);
        assertTrue(""createDirectChannel failed"", mChannel != null);

        try {
            assertTrue(""Shared memory is not formatted"", isSharedMemoryFormatted(memType));
            waitBeforeStartSensor();

            int token1 = mChannel.configure(s1, rateLevel1);
            int token2 = mChannel.configure(s2, rateLevel2);
            assertTrue(""configure direct mChannel failed, token1 = "" + token1, token1 > 0);
            assertTrue(""configure direct mChannel failed, token2 = "" + token2, token2 > 0);

            // run half amount of time so buffer is enough for both sensors
            try {
                SensorCtsHelper.sleep(TEST_RUN_TIME_PERIOD_MILLISEC / 2, TimeUnit.MILLISECONDS);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }

            //stop sensor and analyze content
            mChannel.configure(s1, SensorDirectChannel.RATE_STOP);
            mChannel.configure(s2, SensorDirectChannel.RATE_STOP);

            readSharedMemory(memType, false /*secondary*/);
            checkEventRate(TEST_RUN_TIME_PERIOD_MILLISEC / 2,
                    parseEntireBuffer(token1, mEventPool, mByteBuffer, SHARED_MEMORY_SIZE),
                    type1, rateLevel1);
            checkEventRate(TEST_RUN_TIME_PERIOD_MILLISEC / 2,
                    parseEntireBuffer(token2, mEventPool, mByteBuffer, SHARED_MEMORY_SIZE),
                    type2, rateLevel2);
        } finally {
            mChannel.close();
            mChannel = null;
        }
    }

    private void runMultiChannelRateIndependencyTest(
            int type, int rateLevel1, int rateLevel2, int memType1, int memType2)
                throws AssertionError {
        Sensor s = mSensorManager.getDefaultSensor(type);
        if (s == null
                || s.getHighestDirectReportRateLevel() < Math.max(rateLevel1, rateLevel2)
                || !s.isDirectChannelTypeSupported(memType1)
                || !s.isDirectChannelTypeSupported(memType2)) {
            return;
        }
        resetEvent();

        mChannel = prepareDirectChannel(memType1, false /* secondary */);
        mChannelSecondary = prepareDirectChannel(memType2, true /* secondary */);

        try {
            assertTrue(""createDirectChannel failed"", mChannel != null);
            assertTrue(""Shared memory is not formatted"",
                       isSharedMemoryFormatted(memType1));

            assertTrue(""createDirectChannel(secondary) failed"", mChannelSecondary != null);
            assertTrue(""Shared memory(secondary) is not formatted"",
                       isSharedMemoryFormatted(memType2, true));

            waitBeforeStartSensor();

            int token1 = mChannel.configure(s, rateLevel1);
            int token2 = mChannelSecondary.configure(s, rateLevel2);
            assertTrue(""configure direct mChannel failed"", token1 > 0);
            assertTrue(""configure direct mChannelSecondary failed"", token2 > 0);

            waitSensorCollection();

            //stop sensor and analyze content
            mChannel.configure(s, SensorDirectChannel.RATE_STOP);
            mChannelSecondary.configure(s, SensorDirectChannel.RATE_STOP);

            // check rate
            readSharedMemory(memType1, false /*secondary*/);
            checkEventRate(TEST_RUN_TIME_PERIOD_MILLISEC, parseEntireBuffer(token1, mEventPool,
                    mByteBuffer, SHARED_MEMORY_SIZE), type, rateLevel1);

            readSharedMemory(memType2, true /*secondary*/);
            checkEventRate(TEST_RUN_TIME_PERIOD_MILLISEC, parseEntireBuffer(token2, mEventPool,
                    mByteBuffer, SHARED_MEMORY_SIZE), type, rateLevel2);
        } finally {
            if (mChannel != null) {
                mChannel.close();
                mChannel = null;
            }
            if (mChannelSecondary != null) {
                mChannelSecondary.close();
                mChannelSecondary = null;
            }
        }
    }

    private void runMultiModeRateIndependencyTest(
            int type , int rateLevel, int memType, int samplingPeriodUs)
                throws AssertionError {
        final Sensor s = mSensorManager.getDefaultSensor(type);
        if (s == null
                || s.getHighestDirectReportRateLevel() < rateLevel
                || !s.isDirectChannelTypeSupported(memType)) {
            return;
        }

        if (samplingPeriodUs == 0) {
            samplingPeriodUs = s.getMinDelay();
        }

        if (samplingPeriodUs < s.getMinDelay()) {
            return;
        }

        if (samplingPeriodUs > s.getMaxDelay()) {
            samplingPeriodUs = s.getMaxDelay();
        }

        resetEvent();

        mChannel = prepareDirectChannel(memType, false /* secondary */);
        assertTrue(""createDirectChannel failed"", mChannel != null);
        SensorEventCollection listener = new SensorEventCollection(s);

        try {
            waitBeforeStartSensor();
            int token = mChannel.configure(s, rateLevel);
            boolean registerRet = mSensorManager.registerListener(listener, s, samplingPeriodUs);
            assertTrue(""Register listener failed"", registerRet);

            waitSensorCollection();

            mChannel.configure(s, SensorDirectChannel.RATE_STOP);
            mSensorManager.unregisterListener(listener);

            // check direct report rate
            readSharedMemory(memType, false /*secondary*/);
            List<DirectReportSensorEvent> events = parseEntireBuffer(token, mEventPool, mByteBuffer,
                    SHARED_MEMORY_SIZE);
            checkEventRate(TEST_RUN_TIME_PERIOD_MILLISEC, events, type, rateLevel);

            // check callback interface rate
            checkEventRateUs(TEST_RUN_TIME_PERIOD_MILLISEC, listener.getEvents(), type,
                             samplingPeriodUs);
        } finally {
            mChannel.close();
            mChannel = null;
            mSensorManager.unregisterListener(listener);
        }
    }

    private void runTimestampTest(int type, int rateLevel, int memType) {
        Sensor s = mSensorManager.getDefaultSensor(type);
        if (s == null
                || s.getHighestDirectReportRateLevel() < rateLevel
                || !s.isDirectChannelTypeSupported(memType)) {
            return;
        }
        resetEvent();

        mChannel = prepareDirectChannel(memType, false /* secondary */);
        assertTrue(""createDirectChannel failed"", mChannel != null);

        SensorEventCollection listener = new SensorEventCollection(s);

        try {
            float nominalFreq = getNominalFreq(rateLevel);
            int samplingPeriodUs = Math.max((int) (1e6f / nominalFreq), s.getMinDelay());

            assertTrue(""Shared memory is not formatted"",
                       isSharedMemoryFormatted(memType));

            int token = mChannel.configure(s, rateLevel);
            assertTrue(""configure direct mChannel failed"", token > 0);

            boolean registerRet = mSensorManager.registerListener(listener, s, samplingPeriodUs);
            assertTrue(""Register listener failed"", registerRet);

            List<DirectReportSensorEvent> events = collectSensorEventsRealtime(
                    memType, false /*secondary*/, TEST_RUN_TIME_PERIOD_MILLISEC);
            assertTrue(""Realtime event collection failed"", events != null);
            assertTrue(""Realtime event collection got no data"", events.size() > 0);

            //stop sensor and analyze content
            mChannel.configure(s, SensorDirectChannel.RATE_STOP);
            mSensorManager.unregisterListener(listener);

            // check rate
            checkTimestampRelative(events, listener.getEvents());
            checkTimestampAbsolute(events);
        } finally {
            mChannel.close();
            mChannel = null;
        }
    }

    private void runAtomicCounterTest(int sensorType, int memType) throws AssertionError {
        Sensor s = mSensorManager.getDefaultSensor(sensorType);
        if (s == null
                || s.getHighestDirectReportRateLevel() == SensorDirectChannel.RATE_STOP
                || !s.isDirectChannelTypeSupported(memType)) {
            return;
        }
        resetEvent();

        mChannel = prepareDirectChannel(memType, false /* secondary */);
        assertTrue(""createDirectChannel failed"", mChannel != null);

        try {
            assertTrue(""Shared memory is not formatted"", isSharedMemoryFormatted(memType));
            waitBeforeStartSensor();

            //int token = mChannel.configure(s, SensorDirectChannel.RATE_FAST);
            int token = mChannel.configure(s, s.getHighestDirectReportRateLevel());
            assertTrue(""configure direct mChannel failed"", token > 0);

            checkAtomicCounterUpdate(memType, 30 * 1000); // half min

            //stop sensor and analyze content
            mChannel.configure(s, SensorDirectChannel.RATE_STOP);
        } finally {
            mChannel.close();
            mChannel = null;
        }
    }

    private void runReconfigureTest(int type, int memType) {
        Sensor s = mSensorManager.getDefaultSensor(type);
        if (s == null
                || s.getHighestDirectReportRateLevel() == SensorDirectChannel.RATE_STOP
                || !s.isDirectChannelTypeSupported(memType)) {
            return;
        }
        resetEvent();

        mChannel = prepareDirectChannel(memType, false /* secondary */);
        assertTrue(""createDirectChannel failed"", mChannel != null);

        try {
            assertTrue(""Shared memory is not formatted"", isSharedMemoryFormatted(memType));
            waitBeforeStartSensor();

            int offset = 0;
            long counter = 1;
            List<Integer> rateLevels = new ArrayList<>();
            List<DirectReportSensorEvent> events;

            rateLevels.add(s.getHighestDirectReportRateLevel());
            rateLevels.add(s.getHighestDirectReportRateLevel());
            if (s.getHighestDirectReportRateLevel() != SensorDirectChannel.RATE_NORMAL) {
                rateLevels.add(SensorDirectChannel.RATE_NORMAL);
            }

            for (int rateLevel : rateLevels) {
                int token = mChannel.configure(s, rateLevel);
                assertTrue(""configure direct mChannel failed"", token > 0);

                events = collectSensorEventsRealtime(memType, false /*secondary*/,
                                                     TEST_RUN_TIME_PERIOD_MILLISEC,
                                                     offset, counter);
                // stop sensor
                mChannel.configure(s, SensorDirectChannel.RATE_STOP);
                checkEventRate(TEST_RUN_TIME_PERIOD_MILLISEC, events, type, rateLevel);

                // collect all events after stop
                events = collectSensorEventsRealtime(memType, false /*secondary*/,
                                                     REST_PERIOD_BEFORE_TEST_MILLISEC,
                                                     offset, counter);
                if (events.size() > 0) {
                    offset += (events.size() * SENSORS_EVENT_SIZE ) % SHARED_MEMORY_SIZE;
                    counter = events.get(events.size() - 1).serial;
                }
            }

            // finally stop the report
            mChannel.configure(s, SensorDirectChannel.RATE_STOP);
        } finally {
            mChannel.close();
            mChannel = null;
        }
    }

    public static void waitBeforeStartSensor() {
        // wait for sensor system to come to a rest after previous test to avoid flakiness.
        try {
            SensorCtsHelper.sleep(REST_PERIOD_BEFORE_TEST_MILLISEC, TimeUnit.MILLISECONDS);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }

    private void waitSensorCollection() {
        // wait for sensor collection to finish
        try {
            SensorCtsHelper.sleep(TEST_RUN_TIME_PERIOD_MILLISEC, TimeUnit.MILLISECONDS);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }

    private List<DirectReportSensorEvent> collectSensorEventsRealtime(
            int memType, boolean secondary, int timeoutMs) {
        return collectSensorEventsRealtime(memType, secondary, timeoutMs,
                                          0 /*initialOffset*/, 1l /*initialCounter*/);
    }

    private List<DirectReportSensorEvent> collectSensorEventsRealtime(
            int memType, boolean secondary, int timeoutMs, int initialOffset, long initialCounter) {
        List<DirectReportSensorEvent> events = new ArrayList<>();
        long endTime = SystemClock.elapsedRealtime() + timeoutMs;

        long atomicCounter = initialCounter;
        int offset = initialOffset;

        long timeA = SystemClock.elapsedRealtimeNanos();
        boolean synced = false;
        int filtered = 0;

        while (SystemClock.elapsedRealtime() < endTime) {
            if (!readSharedMemory(
                    memType, secondary, offset + ATOMIC_COUNTER_OFFSET, ATOMIC_COUNTER_SIZE)) {
                return null;
            }

            long timeB = SystemClock.elapsedRealtimeNanos();
            if (timeB - timeA > 1_000_000L ) { // > 1ms
                synced = false;
            }
            timeA = timeB;

            if (readAtomicCounter(offset) == atomicCounter) {
                // read entire event again and parse
                if (!readSharedMemory(memType, secondary, offset, SENSORS_EVENT_SIZE)) {
                    return null;
                }
                DirectReportSensorEvent e = mEventPool.get();
                assertNotNull(""cannot get event from reserve"", e);
                parseSensorEvent(offset, e, mByteBuffer);

                atomicCounter += 1;
                if (synced) {
                    events.add(e);
                } else {
                    ++filtered;
                }

                offset += SENSORS_EVENT_SIZE;
                if (offset + SENSORS_EVENT_SIZE > SHARED_MEMORY_SIZE) {
                    offset = 0;
                }
            } else {
                synced = true;
            }
        }
        Log.d(TAG, ""filtered "" + filtered + "" events, remain "" + events.size() + "" events"");
        return events;
    }

    private void checkAtomicCounterUpdate(int memType, int timeoutMs) {
        List<DirectReportSensorEvent> events = new ArrayList<>();
        long endTime = SystemClock.elapsedRealtime() + timeoutMs;

        boolean lastValid = false;
        long atomicCounter = 1;
        int lastOffset = 0;
        int offset = 0;

        byte[] lastArray = new byte[SENSORS_EVENT_SIZE];
        DirectReportSensorEvent e = getEvent();

        while (SystemClock.elapsedRealtime() < endTime) {
            if (!readSharedMemory(memType, false/*secondary*/, lastOffset, SENSORS_EVENT_SIZE)
                    || !readSharedMemory(memType, false/*secondary*/,
                                         offset + ATOMIC_COUNTER_OFFSET, ATOMIC_COUNTER_SIZE)) {
                throw new IllegalStateException(""cannot read shared memory, type "" + memType);
            }

            if (lastValid) {
                boolean failed = false;
                int i;
                for (i = 0; i < SENSORS_EVENT_SIZE; ++i) {
                    if (lastArray[i] != mBuffer[lastOffset + i]) {
                        failed = true;
                        break;
                    }
                }

                if (failed) {
                    byte[] currentArray = new byte[SENSORS_EVENT_SIZE];
                    System.arraycopy(mBuffer, lastOffset, currentArray, 0, SENSORS_EVENT_SIZE);

                    // wait for 100ms and read again to see if the change settle
                    try {
                        SensorCtsHelper.sleep(100, TimeUnit.MILLISECONDS);
                    } catch (InterruptedException ex) {
                        Thread.currentThread().interrupt();
                    }

                    byte[] delayedRead = new byte[SENSORS_EVENT_SIZE];
                    if (!readSharedMemory(
                                memType, false/*secondary*/, lastOffset, SENSORS_EVENT_SIZE)) {
                        throw new IllegalStateException(
                                ""cannot read shared memory, type "" + memType);
                    }
                    System.arraycopy(mBuffer, lastOffset, delayedRead, 0, SENSORS_EVENT_SIZE);

                    fail(String.format(
                            ""At offset %d(0x%x), byte %d(0x%x) changed after atomicCounter""
                                + ""(expecting %d, 0x%x) update, old = [%s], new = [%s], ""
                                + ""delayed = [%s]"",
                            lastOffset, lastOffset, i, i, atomicCounter, atomicCounter,
                            SensorCtsHelper.bytesToHex(lastArray, -1, -1),
                            SensorCtsHelper.bytesToHex(currentArray, -1, -1),
                            SensorCtsHelper.bytesToHex(delayedRead, -1, -1)));
                }
            }

            if (readAtomicCounter(offset) == atomicCounter) {
                // read entire event again and parse
                if (!readSharedMemory(memType, false/*secondary*/, offset, SENSORS_EVENT_SIZE)) {
                    throw new IllegalStateException(""cannot read shared memory, type "" + memType);
                }
                parseSensorEvent(offset, e, mByteBuffer);

                atomicCounter += 1;

                lastOffset = offset;
                System.arraycopy(mBuffer, lastOffset, lastArray, 0, SENSORS_EVENT_SIZE);
                lastValid = true;

                offset += SENSORS_EVENT_SIZE;
                if (offset + SENSORS_EVENT_SIZE > SHARED_MEMORY_SIZE) {
                    offset = 0;
                }
            }
        }
        Log.d(TAG, ""at finish checkAtomicCounterUpdate has atomic counter = "" + atomicCounter);
        // atomicCounter will not wrap back in reasonable amount of time
        assertTrue(""Realtime event collection got no data"", atomicCounter != 1);
    }

    private MemoryFile allocateMemoryFile() {
        MemoryFile memFile = null;
        try {
            memFile = new MemoryFile(""Sensor Channel"", SHARED_MEMORY_SIZE);
        } catch (IOException e) {
            Log.e(TAG, ""IOException when allocating MemoryFile"");
        }
        return memFile;
    }

    private HardwareBuffer allocateHardwareBuffer() {
        HardwareBuffer hardwareBuffer;

        hardwareBuffer = HardwareBuffer.create(
                SHARED_MEMORY_SIZE, 1 /* height */, HardwareBuffer.BLOB, 1 /* layer */,
                HardwareBuffer.USAGE_CPU_READ_OFTEN | HardwareBuffer.USAGE_GPU_DATA_BUFFER
                    | HardwareBuffer.USAGE_SENSOR_DIRECT_DATA);
        return hardwareBuffer;
    }

    private SensorDirectChannel prepareDirectChannel(int memType, boolean secondary) {
        SensorDirectChannel channel = null;

        try {
            switch(memType) {
                case SensorDirectChannel.TYPE_MEMORY_FILE: {
                    MemoryFile memoryFile = secondary ? mMemoryFileSecondary : mMemoryFile;
                    assertTrue(""MemoryFile"" + (secondary ? ""(secondary)"" : """") + "" is null"",
                               memoryFile != null);
                    channel = mSensorManager.createDirectChannel(memoryFile);
                    break;
                }
                case SensorDirectChannel.TYPE_HARDWARE_BUFFER: {
                    HardwareBuffer hardwareBuffer
                            = secondary ? mHardwareBufferSecondary : mHardwareBuffer;
                    assertTrue(""HardwareBuffer"" + (secondary ? ""(secondary)"" : """") + "" is null"",
                               hardwareBuffer != null);
                    channel = mSensorManager.createDirectChannel(hardwareBuffer);
                    break;
                }
                default:
                    Log.e(TAG, ""Specified illegal memory type "" + memType);
            }
        } catch (IllegalStateException | UncheckedIOException e) {
            Log.e(TAG, ""Cannot initialize channel for memory type "" + memType
                    + "", details:"" + e);
            channel = null;
        }
        return channel;
    }

    private boolean readSharedMemory(int memType, boolean secondary, int offset, int length) {
        switch(memType) {
            case SensorDirectChannel.TYPE_MEMORY_FILE:
                try {
                    MemoryFile f = secondary ? mMemoryFileSecondary : mMemoryFile;
                    if (f.readBytes(mBuffer, offset, offset, length) != length) {
                        Log.e(TAG, ""cannot read entire MemoryFile"");
                        return false;
                    }
                } catch (IOException e) {
                    Log.e(TAG, ""accessing MemoryFile causes IOException"");
                    return false;
                }
                return true;
            case SensorDirectChannel.TYPE_HARDWARE_BUFFER:
                return nativeReadHardwareBuffer(
                        secondary ? mHardwareBufferSecondary : mHardwareBuffer,
                        mBuffer, offset, offset, length);
            default:
                return false;
        }
    }

    private boolean readSharedMemory(int memType, boolean secondary) {
        return readSharedMemory(memType, secondary, 0, SHARED_MEMORY_SIZE);
    }

    private boolean readSharedMemory(int memType) {
        return readSharedMemory(memType, false /*secondary*/);
    }

    private boolean isMemoryTypeNeeded(int memType) {
        List<Sensor> sensorList = mSensorManager.getSensorList(Sensor.TYPE_ALL);
        for (Sensor s : sensorList) {
            if (s.isDirectChannelTypeSupported(memType)) {
                return true;
            }
        }
        return false;
    }

    private boolean isSharedMemoryFormatted(int memType) {
        return isSharedMemoryFormatted(memType, false /* secondary */);
    }

    private boolean isSharedMemoryFormatted(int memType, boolean secondary) {
        readSharedMemory(memType, secondary);

        for (byte b : mBuffer) {
            if (b != 0) {
                return false;
            }
        }
        return true;
    }

    private void checkSharedMemoryContent(Sensor s, int memType, int rateLevel, int token) {
        assertTrue(""read mem type "" + memType + "" content failed"", readSharedMemory(memType));

        int offset = 0;
        int nextSerial = 1;
        DirectReportSensorEvent e = getEvent();
        while (offset <= SHARED_MEMORY_SIZE - SENSORS_EVENT_SIZE) {
            parseSensorEvent(offset, e, mByteBuffer);

            if (e.serial == 0) {
                // reaches end of events
                break;
            }

            assertTrue(""incorrect size "" + e.size + ""  at offset "" + offset,
                    e.size == SENSORS_EVENT_SIZE);
            assertTrue(""incorrect token "" + e.token + "" at offset "" + offset,
                    e.token == token);
            assertTrue(""incorrect serial "" + e.serial + "" at offset "" + offset,
                    e.serial == nextSerial);
            assertTrue(""incorrect type "" + e.type + "" offset "" + offset,
                    e.type == s.getType());

            switch(s.getType()) {
                case Sensor.TYPE_ACCELEROMETER:
                    double accNorm = Math.sqrt(e.x * e.x + e.y * e.y + e.z * e.z);
                    assertTrue(""incorrect gravity norm "" + accNorm + "" at offset "" + offset,
                            accNorm < GRAVITY_MAX && accNorm > GRAVITY_MIN);
                    break;
                case Sensor.TYPE_GYROSCOPE:
                    double gyroNorm = Math.sqrt(e.x * e.x + e.y * e.y + e.z * e.z);
                    assertTrue(""gyro norm too large ("" + gyroNorm + "") at offset "" + offset,
                            gyroNorm < GYRO_NORM_MAX);
                    break;
            }

            ++nextSerial;
            offset += SENSORS_EVENT_SIZE;
        }

        int nEvents = nextSerial - 1;
        float nominalFreq = 0;

        switch (rateLevel) {
            case SensorDirectChannel.RATE_NORMAL:
                nominalFreq = RATE_NORMAL_NOMINAL;
                break;
            case SensorDirectChannel.RATE_FAST:
                nominalFreq = RATE_FAST_NOMINAL;
                break;
            case SensorDirectChannel.RATE_VERY_FAST:
                nominalFreq = RATE_VERY_FAST_NOMINAL;
                break;
        }

        if (nominalFreq != 0) {
            int minEvents;
            int maxEvents;
            minEvents = (int) Math.floor(
                    nominalFreq
                    * FREQ_LOWER_BOUND
                    * (TEST_RUN_TIME_PERIOD_MILLISEC - ALLOWED_SENSOR_INIT_TIME_MILLISEC)
                    * (1 - MERCY_FACTOR)
                    / 1000);
            maxEvents = (int) Math.ceil(
                    nominalFreq
                    * FREQ_UPPER_BOUND
                    * TEST_RUN_TIME_PERIOD_MILLISEC
                    * (1 + MERCY_FACTOR)
                    / 1000);

            assertTrue(""nEvent is "" + nEvents + "" not between "" + minEvents + "" and "" + maxEvents,
                    nEvents >= minEvents && nEvents <=maxEvents);
        }
    }

    private void checkEventRate(int testTimeMs, List<DirectReportSensorEvent> events,
                                int type, int rateLevel) {
        assertTrue(""insufficient events of type "" + type, events.size() > 1);
        for (DirectReportSensorEvent e : events) {
            assertTrue(""incorrect type "" + e.type + "" expecting "" + type, e.type == type);
        }

        // check number of events
        int[] minMax = calculateExpectedNEvents(testTimeMs, rateLevel);
        assertTrue(
                ""Number of event of type "" + type + "" is "" + events.size()
                    + "", which is not in range ["" + minMax[0] + "", "" + minMax[1] + ""]."",
                minMax[0] <= events.size() && events.size() <= minMax[1]);

        // intervals
        List<Long> intervals = new ArrayList<>(events.size() - 1);
        long minInterval = Long.MAX_VALUE;
        long maxInterval = Long.MIN_VALUE;
        long averageInterval = 0;
        for (int i = 1; i < events.size(); ++i) {
            long d = events.get(i).ts - events.get(i-1).ts;
            averageInterval += d;
            minInterval = Math.min(d, minInterval);
            maxInterval = Math.max(d, maxInterval);
            intervals.add(d);
        }
        averageInterval /= (events.size() - 1);

        // average rate
        float averageFreq = 1e9f / averageInterval;
        float nominalFreq = getNominalFreq(rateLevel);
        Log.d(TAG, String.format(
                ""checkEventRate type %d: averageFreq %f, nominalFreq %f, lbound %f, ubound %f"",
                type, averageFreq, nominalFreq,
                nominalFreq * FREQ_LOWER_BOUND,
                nominalFreq * FREQ_UPPER_BOUND));
        assertTrue(""Average frequency of type "" + type + "" rateLevel "" + rateLevel
                        + "" is "" + averageFreq,
                   nominalFreq * FREQ_LOWER_BOUND * (1 - MERCY_FACTOR) <= averageFreq &&
                       averageFreq <= nominalFreq * FREQ_UPPER_BOUND * (1 + MERCY_FACTOR));

        // jitter variance
        List<Long> percentileValues =
                SensorCtsHelper.getPercentileValue(intervals, 0.025f, (1 - 0.025f));
        assertTrue(""Timestamp jitter of type "" + type + "" rateLevel "" + rateLevel + "" is ""
                        + (percentileValues.get(1) - percentileValues.get(0) / 1000) + "" us, ""
                        + ""while average interval is "" + (averageInterval / 1000) + ""us, over-range"",
                   (percentileValues.get(1) - percentileValues.get(0)) / averageInterval < 0.05);
        Log.d(TAG, String.format(
                ""checkEventRate type %d, timestamp interval range %f - %f ms, "" +
                    ""span %f ms, %.2f%% of averageInterval"",
                    type, percentileValues.get(0)/1e6f, percentileValues.get(1)/1e6f,
                    (percentileValues.get(1) - percentileValues.get(0))/1e6f,
                    (percentileValues.get(1) - percentileValues.get(0)) / averageInterval * 100.f));

    }

    private void checkEventRateUs(int testTimeMs, List<DirectReportSensorEvent> events,
                                  int type, int samplingPeriodUs) {
        // samplingPeriodUs must be a valid one advertised by sensor
        assertTrue(""insufficient events of type "" + type, events.size() > 1);
        for (DirectReportSensorEvent e : events) {
            assertTrue(""incorrect type "" + e.type + "" expecting "" + type, e.type == type);
        }

        // check number of events
        int[] minMax = calculateExpectedNEventsUs(testTimeMs, samplingPeriodUs);
        assertTrue(
                ""Number of event of type "" + type + "" is "" + events.size()
                    + "", which is not in range ["" + minMax[0] + "", "" + minMax[1] + ""]."",
                minMax[0] <= events.size() && events.size() <= minMax[1]);

        // intervals
        List<Long> intervals = new ArrayList<>(events.size() - 1);
        long minInterval = Long.MAX_VALUE;
        long maxInterval = Long.MIN_VALUE;
        long averageInterval = 0;
        for (int i = 1; i < events.size(); ++i) {
            long d = events.get(i).ts - events.get(i-1).ts;
            averageInterval += d;
            minInterval = Math.min(d, minInterval);
            maxInterval = Math.max(d, maxInterval);
            intervals.add(d);
        }
        averageInterval /= (events.size() - 1);

        // average rate
        float averageFreq = 1e9f / averageInterval;
        float nominalFreq = 1e6f / samplingPeriodUs;
        Log.d(TAG, String.format(
                ""checkEventRateUs type %d: averageFreq %f, nominalFreq %f, lbound %f, ubound %f"",
                type, averageFreq, nominalFreq,
                nominalFreq * FREQ_LOWER_BOUND_POLL,
                nominalFreq * FREQ_UPPER_BOUND_POLL));
        assertTrue(""Average frequency of type "" + type
                        + "" is "" + averageFreq,
                   nominalFreq * FREQ_LOWER_BOUND_POLL * (1 - MERCY_FACTOR) <= averageFreq &&
                       averageFreq <= nominalFreq * FREQ_UPPER_BOUND_POLL * (1 + MERCY_FACTOR));

        // jitter variance
        List<Long> percentileValues =
                SensorCtsHelper.getPercentileValue(intervals, 0.025f, (1 - 0.025f));
        assertTrue(""Timestamp jitter of type "" + type + "" is ""
                        + (percentileValues.get(1) - percentileValues.get(0) / 1000) + "" us, ""
                        + ""while average interval is "" + (averageInterval / 1000) + ""us, over-range"",
                   (percentileValues.get(1) - percentileValues.get(0)) / averageInterval < 0.05);
        Log.d(TAG, String.format(
                ""checkEventRateUs type %d, timestamp interval range %f - %f ms, "" +
                    ""span %f ms, %.2f%% of averageInterval"",
                    type, percentileValues.get(0)/1e6f, percentileValues.get(1)/1e6f,
                    (percentileValues.get(1) - percentileValues.get(0)) / 1e6f,
                    (percentileValues.get(1) - percentileValues.get(0)) / averageInterval * 100.f));
    }

    private void allocateSharedMemory() {
        if (mNeedMemoryFile) {
            mMemoryFile = allocateMemoryFile();
            mMemoryFileSecondary = allocateMemoryFile();
        }

        if (mNeedHardwareBuffer) {
            mHardwareBuffer = allocateHardwareBuffer();
            mHardwareBufferSecondary = allocateHardwareBuffer();
        }
    }

    private void freeSharedMemory() {
        if (mMemoryFile != null) {
            mMemoryFile.close();
            mMemoryFile = null;
        }

        if (mMemoryFileSecondary != null) {
            mMemoryFileSecondary.close();
            mMemoryFileSecondary = null;
        }

        if (mHardwareBuffer != null) {
            mHardwareBuffer.close();
            mHardwareBuffer = null;
        }

        if (mHardwareBufferSecondary != null) {
            mHardwareBufferSecondary.close();
            mHardwareBufferSecondary = null;
        }
    }

    private float getNominalFreq(int rateLevel) {
        float nominalFreq = 0;
        switch (rateLevel) {
            case SensorDirectChannel.RATE_NORMAL:
                nominalFreq = RATE_NORMAL_NOMINAL;
                break;
            case SensorDirectChannel.RATE_FAST:
                nominalFreq = RATE_FAST_NOMINAL;
                break;
            case SensorDirectChannel.RATE_VERY_FAST:
                nominalFreq = RATE_VERY_FAST_NOMINAL;
                break;
        }
        return nominalFreq;
    }

    private int[] calculateExpectedNEvents(int timeMs, int rateLevel) {
        int[] minMax = new int[] { -1, Integer.MAX_VALUE };
        float nominalFreq = getNominalFreq(rateLevel);
        if (nominalFreq != 0) {
            // min
            if (timeMs > ALLOWED_SENSOR_INIT_TIME_MILLISEC) {
                minMax[0] = (int) Math.floor(
                        nominalFreq
                        * FREQ_LOWER_BOUND
                        * (timeMs - ALLOWED_SENSOR_INIT_TIME_MILLISEC)
                        * (1 - MERCY_FACTOR)
                        / 1000);
            }
            // max
            minMax[1] = (int) Math.ceil(
                    nominalFreq
                    * FREQ_UPPER_BOUND
                    * timeMs
                    * (1 + MERCY_FACTOR)
                    / 1000);
        }
        return minMax;
    }

    private void checkTimestampAbsolute(List<DirectReportSensorEvent> events) {
        final int MAX_DETAIL_ITEM = 10;

        StringBuffer buf = new StringBuffer();
        int oneMsEarlyCount = 0;
        int fiveMsLateCount = 0;
        int tenMsLateCount = 0;
        int errorCount = 0;

        for (int i = 0; i < events.size(); ++i) {
            DirectReportSensorEvent e = events.get(i);
            long d = e.arrivalTs - e.ts;
            boolean oneMsEarly = d < -1000_000;
            boolean fiveMsLate = d > 5000_000;
            boolean tenMsLate = d > 10_000_000;

            if (oneMsEarly || fiveMsLate || tenMsLate) {
                oneMsEarlyCount += oneMsEarly ? 1 : 0;
                fiveMsLateCount += fiveMsLate ? 1 : 0;
                tenMsLateCount += tenMsLate ? 1 : 0;

                if (errorCount++ < MAX_DETAIL_ITEM) {
                    buf.append(""["").append(i).append(""] diff = "").append(d / 1e6f).append("" ms; "");
                }
            }
        }

        Log.d(TAG, String.format(""Irregular timestamp, %d, %d, %d out of %d"",
                    oneMsEarlyCount, fiveMsLateCount, tenMsLateCount, events.size()));

        if (CHECK_ABSOLUTE_LATENCY) {
            assertTrue(String.format(
                    ""Timestamp error, out of %d events, %d is >1ms early, %d is >5ms late, ""
                        + ""%d is >10ms late, details: %s%s"",
                        events.size(), oneMsEarlyCount, fiveMsLateCount, tenMsLateCount,
                        buf.toString(), errorCount > MAX_DETAIL_ITEM ? ""..."" : """"),
                    oneMsEarlyCount == 0
                        && fiveMsLateCount <= events.size() / 20
                        && tenMsLateCount <= events.size() / 100);
        }
    }

    private void checkTimestampRelative(List<DirectReportSensorEvent> directEvents,
                                        List<DirectReportSensorEvent> pollEvents) {
        if (directEvents.size() < 10 || pollEvents.size() < 10) {
            // cannot check with so few data points
            return;
        }

        long directAverageLatency = 0;
        for (DirectReportSensorEvent e : directEvents) {
            directAverageLatency += e.arrivalTs - e.ts;
        }
        directAverageLatency /= directEvents.size();

        long pollAverageLatency = 0;
        for (DirectReportSensorEvent e : pollEvents) {
            pollAverageLatency += e.arrivalTs - e.ts;
        }
        pollAverageLatency /= pollEvents.size();

        Log.d(TAG, String.format(""Direct, poll latency = %f, %f ms"",
                directAverageLatency / 1e6f, pollAverageLatency / 1e6f));
        assertTrue(
                String.format(""Direct, poll latency = %f, %f ms, expect direct < poll"",
                    directAverageLatency / 1e6f,
                    pollAverageLatency / 1e6f),
                directAverageLatency < pollAverageLatency + 1000_000);
    }

    private int[] calculateExpectedNEventsUs(int timeMs, int samplingPeriodUs) {
        int[] minMax = new int[2];
        minMax[0] = Math.max((int) Math.floor(
                (timeMs - ALLOWED_SENSOR_INIT_TIME_MILLISEC) * 1000/ samplingPeriodUs), 0);
        minMax[1] = (int) Math.ceil(timeMs * 1000 * 2 / samplingPeriodUs);
        return minMax;
    }

    public static class DirectReportSensorEvent {
        public int size;
        public int token;
        public int type;
        public long serial;
        public long ts;
        public float x;
        public float y;
        public float z;
        public long arrivalTs;
    };

    // EventPool to avoid allocating too many event objects and hitting GC during test
    public static class EventPool {
        public EventPool(int n) {
            mEvents = Arrays.asList(new DirectReportSensorEvent[n]);
            for (int i = 0; i < n; ++i) {
                mEvents.set(i, new DirectReportSensorEvent());
            }
            reset();
        }

        public synchronized void reset() {
            Log.d(TAG, ""Reset EventPool ("" + mIndex + "" events used)"");
            mIndex = 0;
        }

        public synchronized DirectReportSensorEvent get() {
            if (mIndex < mEvents.size()) {
                return mEvents.get(mIndex++);
            } else {
                throw new IllegalStateException(""EventPool depleted"");
            }
        }

        private List<DirectReportSensorEvent> mEvents;
        private int mIndex;
    };

    private DirectReportSensorEvent getEvent() {
        return mEventPool.get();
    }

    private DirectReportSensorEvent getEvent(DirectReportSensorEvent e) {
        DirectReportSensorEvent event = mEventPool.get();
        event.size = e.size;
        event.token = e.token;
        event.type = e.type;
        event.serial = e.serial;
        event.ts = e.ts;
        event.x = e.x;
        event.y = e.y;
        event.z = e.z;
        event.arrivalTs = e.arrivalTs;
        return event;
    }

    private void resetEvent() {
        mEventPool.reset();
    }

    private class SensorEventCollection implements SensorEventListener {
        List<DirectReportSensorEvent> mEvents = new ArrayList<>();
        Sensor mSensor;

        public SensorEventCollection(Sensor s) {
            mSensor = s;
        }

        List<DirectReportSensorEvent> getEvents() {
            return mEvents;
        }

        @Override
        public void onSensorChanged(SensorEvent event) {
            if (mSensor == null || event.sensor == mSensor) {
                DirectReportSensorEvent e = mEventPool.get();
                e.size = SENSORS_EVENT_SIZE;
                e.token = event.sensor.getType();
                e.type = e.token;
                e.serial = -1;
                e.ts = event.timestamp;
                e.arrivalTs = SystemClock.elapsedRealtimeNanos();

                e.x = event.values[0];
                if (event.values.length > 1) {
                    e.y = event.values[1];
                }
                if (event.values.length > 2) {
                    e.z = event.values[2];
                }
                mEvents.add(e);
            }
        }

        @Override
        public void onAccuracyChanged(Sensor s, int accuracy) {
            // do nothing
        }
    };

    public static List<DirectReportSensorEvent> parseEntireBuffer(int token, EventPool eventPool,
                ByteBuffer byteBuffer, int sharedMemorySize) {
        int offset = 0;
        int nextSerial = 1;
        List<DirectReportSensorEvent> events = new ArrayList<>();

        while (offset <= sharedMemorySize - SENSORS_EVENT_SIZE) {
            SensorDirectReportTest.DirectReportSensorEvent e = eventPool.get();
            parseSensorEvent(offset, e, byteBuffer);

            if (e.serial == 0) {
                // reaches end of events
                break;
            }

            assertTrue(""incorrect size "" + e.size + ""  at offset "" + offset,
                    e.size == SENSORS_EVENT_SIZE);
            assertTrue(""incorrect serial "" + e.serial + "" at offset "" + offset,
                    e.serial == nextSerial);

            if (e.token == token) {
                events.add(e);
            }

            ++nextSerial;
            offset += SENSORS_EVENT_SIZE;
        }

        return events;
    }

    // parse sensors_event_t from byteBuffer and fill information into DirectReportSensorEvent
    public static void parseSensorEvent(int offset, DirectReportSensorEvent ev,
            ByteBuffer byteBuffer) {
        byteBuffer.position(offset);

        ev.size = byteBuffer.getInt();
        ev.token = byteBuffer.getInt();
        ev.type = byteBuffer.getInt();
        ev.serial = ((long) byteBuffer.getInt()) & 0xFFFFFFFFl; // signed=>unsigned
        ev.ts = byteBuffer.getLong();
        ev.arrivalTs = SystemClock.elapsedRealtimeNanos();
        ev.x = byteBuffer.getFloat();
        ev.y = byteBuffer.getFloat();
        ev.z = byteBuffer.getFloat();
    }

    // parse sensors_event_t and fill information into DirectReportSensorEvent
    private static void parseSensorEvent(byte [] buf, int offset, DirectReportSensorEvent ev) {
        ByteBuffer b = ByteBuffer.wrap(buf, offset, SENSORS_EVENT_SIZE);
        b.order(NATIVE_BYTE_ORDER);

        ev.size = b.getInt();
        ev.token = b.getInt();
        ev.type = b.getInt();
        ev.serial = ((long) b.getInt()) & 0xFFFFFFFFl; // signed=>unsigned
        ev.ts = b.getLong();
        ev.arrivalTs = SystemClock.elapsedRealtimeNanos();
        ev.x = b.getFloat();
        ev.y = b.getFloat();
        ev.z = b.getFloat();
    }

    private long readAtomicCounter(int offset) {
        mByteBuffer.position(offset + ATOMIC_COUNTER_OFFSET);
        return ((long) mByteBuffer.getInt()) & 0xFFFFFFFFl; // signed => unsigned
    }

    private static long readAtomicCounter(byte [] buf, int offset) {
        ByteBuffer b = ByteBuffer.wrap(buf, offset + ATOMIC_COUNTER_OFFSET, ATOMIC_COUNTER_SIZE);
        b.order(ByteOrder.nativeOrder());

        return ((long) b.getInt()) & 0xFFFFFFFFl; // signed => unsigned
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.eventconnectionapi30.EventConnectionAPI30Test"	"testSamplingRateMicToggleOff"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/EventConnectionAPI30/src/android/sensorratepermission/cts/eventconnectionapi30/EventConnectionAPI30Test.java"	""	"public void testSamplingRateMicToggleOff() throws InterruptedException {
        // Only run this test if minDelay of the sensor is smaller than the capped min delay
        if (mUncappedMinDelayMicros >= mCappedMinDelayMicros) {
            return;
        }

        mEventConnectionTestHelper.flipAndAssertMicToggleOff(mUserID, mSensorPrivacyManager);
        List<TestSensorEvent> events = mEventConnectionTestHelper.getSensorEvents(
                true,
                NUM_EVENTS_COUNT);
        double obtainedRate = SensorRatePermissionEventConnectionTestHelper.computeAvgRate(events,
                Long.MIN_VALUE, Long.MAX_VALUE);

        Assert.assertTrue(mEventConnectionTestHelper.errorWhenBelowExpectedRate(),
                obtainedRate
                        > SensorRatePermissionEventConnectionTestHelper.CAPPED_SAMPLE_RATE_HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.eventconnectionapi30.EventConnectionAPI30Test"	"testSamplingRateMicToggleOn"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/EventConnectionAPI30/src/android/sensorratepermission/cts/eventconnectionapi30/EventConnectionAPI30Test.java"	""	"public void testSamplingRateMicToggleOn() throws InterruptedException {
        mEventConnectionTestHelper.flipAndAssertMicToggleOn(mUserID, mSensorPrivacyManager);

        List<TestSensorEvent> events = mEventConnectionTestHelper.getSensorEvents(
                true,
                NUM_EVENTS_COUNT);
        double obtainedRate = SensorRatePermissionEventConnectionTestHelper.computeAvgRate(events,
                Long.MIN_VALUE, Long.MAX_VALUE);

        Assert.assertTrue(mEventConnectionTestHelper.errorWhenExceedCappedRate(),
                obtainedRate
                        <= SensorRatePermissionEventConnectionTestHelper.CAPPED_SAMPLE_RATE_HZ);
    }

    /**
     * Test the case where a connection is ongoing while the mic toggle changes its state:
     * off -> on -> off. This test is to show that the sensor service is able to cap/uncap the
     * rate of ongoing SensorEventConnections when the state of the mic toggle changes.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.eventconnectionapi30.EventConnectionAPI30Test"	"testSamplingRateMicToggleOffOnOff"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/EventConnectionAPI30/src/android/sensorratepermission/cts/eventconnectionapi30/EventConnectionAPI30Test.java"	""	"public void testSamplingRateMicToggleOffOnOff() throws InterruptedException {
        // Only run this test if minDelay of the sensor is smaller than the capped min delay
        if (mUncappedMinDelayMicros >= mCappedMinDelayMicros) {
            return;
        }
        // Start with the mic toggle off
        mEventConnectionTestHelper.flipAndAssertMicToggleOff(mUserID, mSensorPrivacyManager);
        // Register a listener
        TestSensorEventListener listener = new TestSensorEventListener(mTestEnvironment);
        TestSensorManager testSensorManager = new TestSensorManager(mTestEnvironment);
        testSensorManager.registerListener(listener);

        // Flip the mic toggle on and clear all the events so far.
        mEventConnectionTestHelper.flipAndAssertMicToggleOn(mUserID, mSensorPrivacyManager);
        listener.clearEvents();

        // Wait for 1000 events and check the sampling rates.
        CountDownLatch eventLatch = listener.getLatchForSensorEvents(1000 /*numOfEvents*/);
        listener.waitForEvents(eventLatch, 1000 /*numOfEvents*/, false);
        List<TestSensorEvent> events = listener.getCollectedEvents();
        double rateWhenMicToggleOn =
                SensorRatePermissionEventConnectionTestHelper.computeAvgRate(events,
                        Long.MIN_VALUE, Long.MAX_VALUE);
        Assert.assertTrue(mEventConnectionTestHelper.errorWhenExceedCappedRate(),
                rateWhenMicToggleOn
                        <= SensorRatePermissionEventConnectionTestHelper.CAPPED_SAMPLE_RATE_HZ);

        // Flip the mic toggle off, clear all the events so far.
        mEventConnectionTestHelper.flipAndAssertMicToggleOff(mUserID, mSensorPrivacyManager);
        listener.clearEvents();

        // Wait for 2000 events and check the sampling rates.
        eventLatch = listener.getLatchForSensorEvents(2000 /*numOfEvents*/);
        listener.waitForEvents(eventLatch, 2000 /*numOfEvents*/, false);
        events = listener.getCollectedEvents();
        double rateWhenMicToggleOff = SensorRatePermissionEventConnectionTestHelper.computeAvgRate(
                events, Long.MIN_VALUE, Long.MAX_VALUE);
        Assert.assertTrue(mEventConnectionTestHelper.errorWhenBelowExpectedRate(),
                rateWhenMicToggleOff
                        > SensorRatePermissionEventConnectionTestHelper.CAPPED_SAMPLE_RATE_HZ);

        listener.clearEvents();
        testSensorManager.unregisterListener();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.RVCVCameraPreview"	"getDefaultDisplay"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/RVCVCameraPreview.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors;

// ----------------------------------------------------------------------

import android.content.Context;
import android.hardware.Camera;
import android.util.AttributeSet;
import android.util.Log;
import android.view.Surface;
import android.view.SurfaceHolder;
import android.view.SurfaceView;
import android.view.ViewGroup;
import android.view.WindowManager;

import java.io.IOException;
import java.lang.Math;

import com.android.cts.verifier.sensors.RVCVRecordActivity;
import com.android.cts.verifier.sensors.RVCVRecordActivity.RecordProcedureControllerCallback;

/** Camera preview class */
public class RVCVCameraPreview extends SurfaceView implements SurfaceHolder.Callback {
    private static final String TAG = ""RVCVCameraPreview"";
    private static final boolean LOCAL_LOGD = true;

    private Context mContext = null;
    private SurfaceHolder mHolder;
    private Camera mCamera;
    private float mCameraAspectRatio = 0;
    private int mCameraRotation = 0;
    private boolean mCheckStartTest = false;
    private boolean mPreviewStarted = false;

    private RVCVRecordActivity.RecordProcedureControllerCallback mRecordProcedureControllerCallback;

    /**
     * Constructor
     * @param context Activity context
     */
    public RVCVCameraPreview(Context context) {
        super(context);
        mContext = context;
        mCamera = null;
        initSurface();
    }

    /**
     * Constructor
     * @param context Activity context
     * @param attrs
     */
    public RVCVCameraPreview(Context context, AttributeSet attrs) {
        super(context, attrs);
        mContext = context;
    }

    public void init(Camera camera, float aspectRatio, int rotation)  {
        this.mCamera = camera;
        mCameraAspectRatio = aspectRatio;
        mCameraRotation = rotation;
        initSurface();
    }

    private void initSurface() {
        // Install a SurfaceHolder.Callback so we get notified when the
        // underlying surface is created and destroyed.
        mHolder = getHolder();
        mHolder.addCallback(this);

        // deprecated
        // TODO: update this code to match new API level.
        mHolder.setType(SurfaceHolder.SURFACE_TYPE_PUSH_BUFFERS);
    }

    /**
     *  SurfaceHolder.Callback
     *  Surface is created, it is OK to start the camera preview now.
     */
    public void surfaceCreated(SurfaceHolder holder) {
        // The Surface has been created, now tell the camera where to draw the preview.

        if (mCamera == null) {
            // preview camera does not exist
            return;
        }
    }
    /**
     *  SurfaceHolder.Callback
     */
    public void surfaceDestroyed(SurfaceHolder holder) {
        // empty. Take care of releasing the Camera preview in your activity.
    }

    /**
     *  SurfaceHolder.Callback
     *  Restart camera preview if surface changed
     */
    public void surfaceChanged(SurfaceHolder holder, int format, int w, int h) {

        if (mHolder.getSurface() == null || mCamera == null){
            // preview surface or camera does not exist
            return;
        }

        int totalRotation = getRequiredRotation();
        mCamera.setDisplayOrientation(totalRotation);

        if (adjustLayoutParamsIfNeeded(totalRotation)) {
            // Wait on next surfaceChanged() call before proceeding
            Log.d(TAG, ""Waiting on surface change before starting preview"");
            return;
        }

        if (mPreviewStarted) {
            Log.w(TAG, ""Re-starting camera preview"");
            if (mCheckStartTest && mRecordProcedureControllerCallback != null) {
                mRecordProcedureControllerCallback.stopRecordProcedureController();
            }
            mCamera.stopPreview();
            mPreviewStarted = false;
        }
        mCheckStartTest = false;

        try {
            mCamera.setPreviewDisplay(holder);
            mCamera.startPreview();
            mPreviewStarted = true;
            if (mRecordProcedureControllerCallback != null) {
                mCheckStartTest = true;
                mRecordProcedureControllerCallback.startRecordProcedureController();
            }
        } catch (IOException e) {
            if (LOCAL_LOGD) Log.d(TAG, ""Error when starting camera preview: "" + e.getMessage());
        }
    }

    /**
     * Determine the rotation required to display the camera's preview on the screen as large as
     * possible. This function combines the device's current rotation from its default orientation
     * and the rotation of the camera.
     */
    private int getRequiredRotation() {
        WindowManager windowManager =
                (WindowManager)mContext.getSystemService(Context.WINDOW_SERVICE);
        int deviceRotation = 0;
        if (windowManager != null) {
            switch (windowManager.getDefaultDisplay().getRotation()) {
                case Surface.ROTATION_0:
                    deviceRotation = 0;
                    break;
                case Surface.ROTATION_90:
                    deviceRotation = 270;
                    break;
                case Surface.ROTATION_180:
                    deviceRotation = 180;
                    break;
                case Surface.ROTATION_270:
                    deviceRotation = 90;
                    break;
                default:
                    deviceRotation = 0;
                    break;
            }
        } else {
            Log.w(TAG, ""Unable to get device rotation, preview may be skewed."");
        }

        return (mCameraRotation + deviceRotation) % 360;
    }

    /**
     * Resize the layout to more closely match the desired aspect ratio, if necessary.
     *
     * @return true if we updated the layout params, false if the params look good
     */
    private boolean adjustLayoutParamsIfNeeded(int totalRotation) {
        // Determine the maximum size layout that maintains the camera's preview aspect ratio
        float cameraAspect = mCameraAspectRatio;

        // Check the camera and device rotation and invert the aspect ratio if the device is not
        // rotated at 0 or 180 degrees.
        if (totalRotation % 180 != 0) {
            // The device is rotated, so the screen should be the inverse of the aspect ratio
            cameraAspect = 1.0f / mCameraAspectRatio;
        }

        // Only adjust if there is at least 1% error between the aspects
        ViewGroup.LayoutParams layoutParams = getLayoutParams();
        int curWidth = getWidth();
        int curHeight = getHeight();
        float curAspect = (float)curWidth / (float)curHeight;
        float aspectDelta = Math.abs(cameraAspect - curAspect);
        if ((aspectDelta / cameraAspect) >= 0.01) {
            if (cameraAspect > curAspect) {
                // Camera preview is wider than the current layout. Need to shorten the current layout
                layoutParams.width = curWidth;
                layoutParams.height = (int)(curWidth / cameraAspect);
            } else {
                // Camera preview taller than the current layout. Need to narrow the current layout
                layoutParams.width = (int)(curHeight * cameraAspect);
                layoutParams.height = curHeight;
            }

            if (layoutParams.height != curHeight || layoutParams.width != curWidth) {
                Log.d(TAG, String.format(""Layout (%d, %d) -> (%d, %d)"", curWidth, curHeight,
                        layoutParams.width, layoutParams.height));
                setLayoutParams(layoutParams);
                return true;
            }
        }
        return false;
    }

    public void setRecordProcedureControllerCallback(
            RVCVRecordActivity.RecordProcedureControllerCallback callback) {
        mRecordProcedureControllerCallback = callback;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensoroperations.TestSensorOperation"	"isDeviceSuspendTest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensoroperations/TestSensorOperation.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers.sensoroperations;

import java.io.IOException;
import java.util.HashSet;
import java.util.List;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

import android.hardware.cts.helpers.SensorCtsHelper;
import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.SensorTestPlatformException;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEvent;
import android.hardware.cts.helpers.TestSensorEventListener;
import android.hardware.cts.helpers.TestSensorManager;
import android.hardware.cts.helpers.SuspendStateMonitor;
import android.hardware.cts.helpers.reporting.ISensorTestNode;
import android.hardware.cts.helpers.sensorverification.EventBasicVerification;
import android.hardware.cts.helpers.sensorverification.EventGapVerification;
import android.hardware.cts.helpers.sensorverification.EventOrderingVerification;
import android.hardware.cts.helpers.sensorverification.EventTimestampSynchronizationVerification;
import android.hardware.cts.helpers.sensorverification.FrequencyVerification;
import android.hardware.cts.helpers.sensorverification.ISensorVerification;
import android.hardware.cts.helpers.sensorverification.JitterVerification;
import android.hardware.cts.helpers.sensorverification.MagnitudeVerification;
import android.hardware.cts.helpers.sensorverification.MeanVerification;
import android.hardware.cts.helpers.sensorverification.InitialValueVerification;
import android.hardware.cts.helpers.sensorverification.StandardDeviationVerification;
import android.os.Handler;
import android.os.SystemClock;
import android.os.PowerManager.WakeLock;
import android.util.Log;

import junit.framework.Assert;

/**
 * A {@link SensorOperation} used to verify that sensor events and sensor values are correct.
 * <p>
 * Provides methods to set test expectations as well as providing a set of default expectations
 * depending on sensor type.  When {{@link #execute(ISensorTestNode)} is called, the sensor will
 * collect the events and then run all the tests.
 * </p>
 */
public class TestSensorOperation extends SensorOperation {
    private static final String TAG = ""TestSensorOperation"";

    private final HashSet<ISensorVerification> mVerifications = new HashSet<>();

    private final TestSensorManager mSensorManager;
    private final TestSensorEnvironment mEnvironment;
    private final Executor mExecutor;
    private final Handler mHandler;
    private long mDeviceWakeUpTimeMs = -1;
    private long mStartTimeMs = -1;
    private long mStopTimeMs = -1;

    /**
     * An interface that defines an abstraction for operations to be performed by the
     * {@link TestSensorOperation}.
     */
    public interface Executor {
        void execute(TestSensorManager sensorManager, TestSensorEventListener listener)
                throws Exception;
    }

    /**
     * An interface that defines an abstraction for a method that allows {@link TestSensorOperation}
     * to wait for user interaction before continuing.
     */
    public interface WaitForUserOperation {
        void waitForUser() throws InterruptedException;
    }

    /**
     * Create a {@link TestSensorOperation}.
     */
    public TestSensorOperation(TestSensorEnvironment environment, Executor executor) {
        this(environment, executor, null /* handler */);
    }

    /**
     * Create a {@link TestSensorOperation}.
     */
    public TestSensorOperation(
            TestSensorEnvironment environment,
            Executor executor,
            Handler handler) {
        mEnvironment = environment;
        mExecutor = executor;
        mHandler = handler;
        mSensorManager = new TestSensorManager(mEnvironment);
    }

    /**
     * Set all of the default test expectations.
     */
    public void addDefaultVerifications() {
        addVerification(EventGapVerification.getDefault(mEnvironment));
        addVerification(EventOrderingVerification.getDefault(mEnvironment));
        addVerification(FrequencyVerification.getDefault(mEnvironment));
        addVerification(JitterVerification.getDefault(mEnvironment));
        addVerification(MagnitudeVerification.getDefault(mEnvironment));
        addVerification(MeanVerification.getDefault(mEnvironment));
        addVerification(StandardDeviationVerification.getDefault(mEnvironment));
        addVerification(EventTimestampSynchronizationVerification.getDefault(mEnvironment));
        addVerification(InitialValueVerification.getDefault(mEnvironment));
    }

    public void addVerification(ISensorVerification verification) {
        if (verification != null) {
            mVerifications.add(verification);
        }
    }

    /**
     * Collect the specified number of events from the sensor and run all enabled verifications.
     */
    @Override
    public void execute(ISensorTestNode parent) throws Exception {
        getStats().addValue(""sensor_name"", mEnvironment.getSensor().getName());
        TestSensorEventListener listener = new TestSensorEventListener(mEnvironment, mHandler);

        mStartTimeMs = SystemClock.elapsedRealtime();
        if (mEnvironment.isDeviceSuspendTest()) {
            SuspendStateMonitor suspendStateMonitor = new SuspendStateMonitor();
            // Device should go into suspend here.
            mExecutor.execute(mSensorManager, listener);
            mStopTimeMs = SystemClock.elapsedRealtime();
            // Check if the device has gone into suspend during test execution.
            mDeviceWakeUpTimeMs = suspendStateMonitor.getLastWakeUpTime();
            suspendStateMonitor.cancel();
            Assert.assertTrue(""Device did not go into suspend during test execution"",
                                       mStartTimeMs < mDeviceWakeUpTimeMs &&
                                       mDeviceWakeUpTimeMs < mStopTimeMs);
        } else {
            mExecutor.execute(mSensorManager, listener);
            mStopTimeMs = SystemClock.elapsedRealtime();
        }

        boolean failed = false;
        StringBuilder sb = new StringBuilder();
        List<TestSensorEvent> collectedEvents = listener.getCollectedEvents();
        for (ISensorVerification verification : mVerifications) {
            failed |= evaluateResults(collectedEvents, verification, sb);
        }

        trySaveCollectedEvents(parent, listener);
        if (failed) {
            String msg = SensorCtsHelper
                    .formatAssertionMessage(""VerifySensorOperation"", mEnvironment, sb.toString());
            getStats().addValue(SensorStats.ERROR, msg);
            Assert.fail(msg);
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public TestSensorOperation clone() {
        TestSensorOperation operation = new TestSensorOperation(mEnvironment, mExecutor);
        for (ISensorVerification verification : mVerifications) {
            operation.addVerification(verification.clone());
        }
        return operation;
    }

    /**
     * Evaluate the results of a test, aggregate the stats, and build the error message.
     */
    private boolean evaluateResults(
            List<TestSensorEvent> events,
            ISensorVerification verification,
            StringBuilder sb) {
        try {
            // this is an intermediate state in refactoring, at some point verifications might
            // become stateless
            verification.addSensorEvents(events);
            verification.verify(mEnvironment, getStats());
        } catch (AssertionError e) {
            if (sb.length() > 0) {
                sb.append("", "");
            }
            sb.append(e.getMessage());
            return true;
        }
        return false;
    }

    /**
     * Tries to save collected {@link TestSensorEvent}s to a file.
     *
     * NOTE: it is more important to handle verifications and its results, than failing if the file
     * cannot be created. So we silently fail if necessary.
     */
    private void trySaveCollectedEvents(ISensorTestNode parent, TestSensorEventListener listener) {
        String sanitizedFileName;
        try {
            String fileName = asTestNode(parent).getName();
            sanitizedFileName = String.format(
                    ""%s-%s-%s_%dus.txt"",
                    SensorCtsHelper.sanitizeStringForFileName(fileName),
                    SensorStats.getSanitizedSensorName(mEnvironment.getSensor()),
                    mEnvironment.getFrequencyString(),
                    mEnvironment.getMaxReportLatencyUs());
            getStats().addValue(SensorStats.EVENT_LOG_FILENAME, sanitizedFileName);
        } catch (SensorTestPlatformException e) {
            Log.w(TAG, ""Unable to generate file name to save collected events"", e);
            return;
        }

        try {
            listener.logCollectedEventsToFile(sanitizedFileName, mDeviceWakeUpTimeMs,
                    mStartTimeMs, mStopTimeMs);
        } catch (IOException e) {
            Log.w(TAG, ""Unable to save collected events to file: "" + sanitizedFileName, e);
        }
    }

    /**
     * Creates an operation that will wait for a given amount of events to arrive.
     *
     * @param environment The test environment.
     * @param eventCount The number of events to wait for.
     */
    public static TestSensorOperation createOperation(
            TestSensorEnvironment environment,
            final int eventCount) {
        Executor executor = new Executor() {
            @Override
            public void execute(TestSensorManager sensorManager, TestSensorEventListener listener)
                    throws InterruptedException {
                try {
                    CountDownLatch latch = sensorManager.registerListener(listener, eventCount);
                    listener.waitForEvents(latch, eventCount, true);
                } finally {
                    sensorManager.unregisterListener();
                }
            }
        };
        return new TestSensorOperation(environment, executor);
    }

    /**
     * Creates an operation that will wait for a given amount of events to arrive.
     *
     * After the execution of this type of test operation, the wakelock passed in will be acquired.
     * Make sure it is released at clean up.
     *
     * @param environment The test environment.
     * @param eventCount The number of events to wait for.
     */
    public static TestSensorOperation createOperation(
            final TestSensorEnvironment environment,
            final WakeLock wakeLock,
            final boolean flushBeforeAfterSuspend) {
        Executor executor = new Executor() {
            @Override
            public void execute(TestSensorManager sensorManager, TestSensorEventListener listener)
                    throws InterruptedException {
                try {
                    sensorManager.registerListener(listener);
                    if (flushBeforeAfterSuspend) {
                        int initialNumEvents1 = listener.getCollectedEvents().size();
                        SensorCtsHelper.sleep(2, TimeUnit.SECONDS);
                        CountDownLatch flushLatch1 = sensorManager.requestFlush();
                        listener.waitForFlushComplete(flushLatch1, false);
                        Assert.assertTrue(""1.No sensor events collected on calling flush "" +
                                environment.toString(),
                                listener.getCollectedEvents().size() - initialNumEvents1 > 0);
                    }
                    // acknowledge waitForFlushComplete
                    listener.releaseWakeLock();

                    Log.i(TAG, ""Collected sensor events size1="" +
                            listener.getCollectedEvents().size());
                    int initialNumEvents2 = listener.getCollectedEvents().size();

                    // allow device to go to sleep
                    if (wakeLock.isHeld()) {
                        wakeLock.release();
                    }

                    SuspendStateMonitor suspendMonitor = new SuspendStateMonitor();
                    long approxStartTimeMs = SystemClock.elapsedRealtime();
                    // Allow the device to go into suspend. Wait for wake-up.
                    suspendMonitor.waitForWakeUp(15);
                    suspendMonitor.cancel();

                    // keep device awake for processing
                    if (!wakeLock.isHeld()) {
                        wakeLock.acquire();
                    }

                    CountDownLatch flushLatch2 = sensorManager.requestFlush();
                    listener.waitForFlushComplete(flushLatch2, false);

                    Log.i(TAG, ""Collected sensor events size2="" +
                            listener.getCollectedEvents().size());

                    if (listener.getCollectedEvents().size() - initialNumEvents2 <= 0 &&
                            suspendMonitor.getLastWakeUpTime() > 0) {
                        // Fail
                        String str = String.format(""No Sensor events collected by calling flush "" +
                                ""after device wake up. Approx time after which device went into "" +
                                ""suspend %dms ,approx AP wake-up time %dms %s"",
                                approxStartTimeMs, suspendMonitor.getLastWakeUpTime(),
                                environment.toString());
                        Assert.fail(str);
                    }
                    if (flushBeforeAfterSuspend) {
                        int initialNumEvents3 = listener.getCollectedEvents().size();
                        SensorCtsHelper.sleep(2, TimeUnit.SECONDS);
                        CountDownLatch flushLatch3 = sensorManager.requestFlush();
                        listener.waitForFlushComplete(flushLatch3, false);
                        Assert.assertTrue(""3.No sensor events collected on calling flush "" +
                                environment.toString(),
                                listener.getCollectedEvents().size() - initialNumEvents3 > 0);
                    }
                    Log.i(TAG, ""Collected sensor events size3="" +
                            listener.getCollectedEvents().size());
                } finally {
                    // make sure the device can run until the test activity take over.
                    if(!wakeLock.isHeld()) {
                        wakeLock.acquire();
                    }
                    sensorManager.unregisterListener();
                }
            }
        };
        return new TestSensorOperation(environment, executor);
    }

    /**
     * Creates an operation that will wait for a given amount of time to collect events.
     *
     * @param environment The test environment.
     * @param duration The duration to wait for events.
     * @param timeUnit The time unit for {@code duration}.
     */
    public static TestSensorOperation createOperation(
            TestSensorEnvironment environment,
            final long duration,
            final TimeUnit timeUnit) {
        Executor executor = new Executor() {
            @Override
            public void execute(TestSensorManager sensorManager, TestSensorEventListener listener)
                    throws InterruptedException {
                try {
                    sensorManager.registerListener(listener);
                    listener.waitForEvents(duration, timeUnit);
                } finally {
                    sensorManager.unregisterListener();
                }
            }
        };
        return new TestSensorOperation(environment, executor);
    }

    /**
     * Creates an operation that will wait for user interaction to stop collecting events.
     *
     * @param environment The test environment.
     * @param operation Method that allows waiting for user interaction before continuing execution.
     */
    public static TestSensorOperation createOperation(
            TestSensorEnvironment environment,
            WaitForUserOperation operation) {
        Executor executor = new Executor() {
            @Override
            public void execute(TestSensorManager sensorManager, TestSensorEventListener listener)
                    throws InterruptedException {
                try {
                    sensorManager.registerListener(listener);
                    operation.waitForUser();
                } finally {
                    sensorManager.unregisterListener();
                }
            }
        };
        return new TestSensorOperation(environment, executor);
    }

    /**
     * Creates an operation that will wait for a given amount of time before calling
     * {@link TestSensorManager#requestFlush()}.
     *
     * @param environment The test environment.
     * @param duration The duration to wait before calling {@link TestSensorManager#requestFlush()}.
     * @param timeUnit The time unit for {@code duration}.
     */
    public static TestSensorOperation createFlushOperation(
            TestSensorEnvironment environment,
            final long duration,
            final TimeUnit timeUnit) {

        return createFlushOperation(environment, new int[] {(int)timeUnit.toMillis(duration)}, -1);
    }

    /**
     * Creates an operation that make a series of flush (by calling
     * {@link TestSensorManager#requestFlush()}) with predefined interval after registerListener.
     *
     * @param environment The test environment.
     * @param flushIntervalMs intervals between calls to {@link TestSensorManager#requestFlush()}.
     * @param clearEventIndex the index of interval which
     *        {@link TestSensorEventListerner#clearEvent} is called (-1 for never).
     */
    public static TestSensorOperation createFlushOperation(
            TestSensorEnvironment environment,
            final int [] flushIntervalMs,
            final int    clearEventIndex) {

        Assert.assertTrue(clearEventIndex >= -1 && flushIntervalMs.length > clearEventIndex);

        Executor executor = new Executor() {
            @Override
            public void execute(TestSensorManager sensorManager, TestSensorEventListener listener)
                    throws InterruptedException {
                try {
                    sensorManager.registerListener(listener);

                    int i = 0;
                    for (int interval: flushIntervalMs) {
                        SensorCtsHelper.sleep(interval, TimeUnit.MILLISECONDS);
                        listener.waitForFlushComplete(
                                sensorManager.requestFlush(),
                                i <= clearEventIndex);
                        ++i;
                    }
                } finally {
                    sensorManager.unregisterListener();
                }
            }
        };
        return new TestSensorOperation(environment, executor);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.EventGapVerification"	"isSensorSamplingRateOverloaded"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/EventGapVerification.java"	""	"public void testpackage android.hardware.cts.helpers.sensorverification;

import junit.framework.Assert;

import android.hardware.Sensor;
import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEvent;

import java.util.LinkedList;
import java.util.List;
import java.util.concurrent.TimeUnit;

/**
 * A {@link ISensorVerification} which verifies that there are no missing events. This is done by
 * checking the last received sensor timestamp and checking that it is within 1.8 * the expected
 * period.
 */
public class EventGapVerification extends AbstractSensorVerification {
    public static final String PASSED_KEY = ""missing_event_passed"";

    // Fail if no events are delivered within 1.8 times the expected interval
    private static final double THRESHOLD = 1.8;

    // Number of indices to print in assert message before truncating
    private static final int TRUNCATE_MESSAGE_LENGTH = 3;

    // Number of events to truncate (discard) from the initial events received
    private static final int TRUNCATE_EVENTS_COUNT = 1;

    // Number of event gaps to tolerate is 2% of total number of events received rounded up to next
    // integer or 20, whichever is smaller.
    private static final int EVENT_GAP_THRESHOLD_MAX = 20;
    private static final double EVENT_GAP_TOLERANCE = 0.02;

    private final int mExpectedDelayUs;

    private final List<IndexedEventPair> mEventGaps = new LinkedList<IndexedEventPair>();
    private TestSensorEvent mPreviousEvent = null;
    private int mEventCount = 0;

    /**
     * Construct a {@link EventGapVerification}
     *
     * @param expectedDelayUs the expected period in us.
     */
    public EventGapVerification(int expectedDelayUs) {
        mExpectedDelayUs = expectedDelayUs;
    }

    /**
     * Get the default {@link EventGapVerification}.
     *
     * @param environment the test environment
     * @return the verification or null if the verification is not a continuous mode sensor.
     */
    public static EventGapVerification getDefault(TestSensorEnvironment environment) {
        if (environment.getSensor().getReportingMode() != Sensor.REPORTING_MODE_CONTINUOUS) {
            return null;
        }
        return new EventGapVerification(environment.getExpectedSamplingPeriodUs());
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public void verify(TestSensorEnvironment environment, SensorStats stats) {
        if (environment.isSensorSamplingRateOverloaded()) {
            // the verification is not reliable on environments under load
            stats.addValue(PASSED_KEY, ""skipped (under load)"");
            return;
        }

        final int count = mEventGaps.size();
        // Ensure the threshold is rounded up.
        double eventGapThreshold =
                Math.ceil(Math.min(EVENT_GAP_THRESHOLD_MAX, mEventCount * EVENT_GAP_TOLERANCE));
        boolean pass = count <= eventGapThreshold;

        stats.addValue(PASSED_KEY, pass);
        stats.addValue(SensorStats.EVENT_GAP_COUNT_KEY, count);
        stats.addValue(SensorStats.EVENT_GAP_POSITIONS_KEY, getIndexArray(mEventGaps));

        if (!pass) {
            StringBuilder sb = new StringBuilder();
            sb.append(count).append("" events gaps: "");
            for (int i = 0; i < Math.min(count, TRUNCATE_MESSAGE_LENGTH); i++) {
                IndexedEventPair info = mEventGaps.get(i);
                sb.append(String.format(""position=%d, delta_time=%.2fms; "", info.index,
                        nanosToMillis(info.event.timestamp - info.previousEvent.timestamp)));
            }
            if (count > TRUNCATE_MESSAGE_LENGTH) {
                sb.append(count - TRUNCATE_MESSAGE_LENGTH).append("" more; "");
            }
            sb.append(String.format(""(expected <%.2fms)"",
                    (double)(THRESHOLD * mExpectedDelayUs)/1000.0));
            Assert.fail(sb.toString());
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public EventGapVerification clone() {
        return new EventGapVerification(mExpectedDelayUs);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    protected void addSensorEventInternal(TestSensorEvent event) {
        if (mEventCount >= TRUNCATE_EVENTS_COUNT) {
            if (mPreviousEvent != null) {
                long deltaNs = event.timestamp - mPreviousEvent.timestamp;
                long deltaUs = TimeUnit.MICROSECONDS.convert(deltaNs, TimeUnit.NANOSECONDS);
                if (deltaUs > mExpectedDelayUs * THRESHOLD) {
                    mEventGaps.add(new IndexedEventPair(mEventCount, event, mPreviousEvent));
                }
            }
            mPreviousEvent = event;
        }
        mEventCount++;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.devicepolicy.DeviceAndProfileOwnerTest"	"testGrantOfSensorsRelatedPermissions"	"CtsDevicePolicyManagerTestCases"	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/src/com/android/cts/devicepolicy/DeviceAndProfileOwnerTest.java"	""	"public void testGrantOfSensorsRelatedPermissions() throws Exception {
        installAppPermissionAppAsUser();
        executeDeviceTestMethod("".PermissionsTest"", ""testSensorsRelatedPermissionsCannotBeGranted"");
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.devicepolicy.DeviceAndProfileOwnerTest"	"testDenyOfSensorsRelatedPermissions"	"CtsDevicePolicyManagerTestCases"	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/src/com/android/cts/devicepolicy/DeviceAndProfileOwnerTest.java"	""	"public void testDenyOfSensorsRelatedPermissions() throws Exception {
        installAppPermissionAppAsUser();
        executeDeviceTestMethod("".PermissionsTest"", ""testSensorsRelatedPermissionsCanBeDenied"");
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.devicepolicy.DeviceAndProfileOwnerTest"	"testSensorsRelatedPermissionsNotGrantedViaPolicy"	"CtsDevicePolicyManagerTestCases"	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/src/com/android/cts/devicepolicy/DeviceAndProfileOwnerTest.java"	""	"public void testSensorsRelatedPermissionsNotGrantedViaPolicy() throws Exception {
        installAppPermissionAppAsUser();
        executeDeviceTestMethod("".PermissionsTest"",
                ""testSensorsRelatedPermissionsNotGrantedViaPolicy"");
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.devicepolicy.DeviceAndProfileOwnerTest"	"testStateOfSensorsRelatedPermissionsCannotBeRead"	"CtsDevicePolicyManagerTestCases"	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/src/com/android/cts/devicepolicy/DeviceAndProfileOwnerTest.java"	""	"public void testStateOfSensorsRelatedPermissionsCannotBeRead() throws Exception {
        installAppPermissionAppAsUser();
        executeDeviceTestMethod("".PermissionsTest"",
                ""testStateOfSensorsRelatedPermissionsCannotBeRead"");
    }

    /**
     * Require a device for tests that use the network stack. Headless Androids running in
     * data centres might need their network rules un-tampered-with in order to keep the ADB / VNC
     * connection alive.
     *
     * This is only a problem on device owner / profile owner running on USER_SYSTEM, because
     * network rules for this user will affect UID 0.
     */
    @RequiresDevice"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.devicepolicy.DeviceAndProfileOwnerTest"	"testAdminControlOverSensorPermissionGrantsDefault"	"CtsDevicePolicyManagerTestCases"	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/src/com/android/cts/devicepolicy/DeviceAndProfileOwnerTest.java"	""	"public void testAdminControlOverSensorPermissionGrantsDefault() throws Exception {
        // By default, admin should not be able to grant sensors-related permissions.
        executeDeviceTestMethod("".SensorPermissionGrantTest"",
                ""testAdminCannotGrantSensorsPermission"");
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.permission.cts.FileSystemPermissionTest"	"testAllOtherDirectoriesNotWritable"	"CtsPermissionTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/permission/src/android/permission/cts/FileSystemPermissionTest.java"	""	"public void testAllOtherDirectoriesNotWritable() throws Exception {
        File start = new File(""/"");
        Set<File> writableDirs = getWritableDirectoriesAndSubdirectoriesOf(start);

        assertTrue(""Found writable directories: "" + writableDirs.toString(),
                writableDirs.isEmpty());
    }

    private static final Set<String> OTHER_RANDOM_DIRECTORIES = new HashSet<String>(
            Arrays.asList(
                    ""/app-cache"",
                    ""/app-cache/ciq/socket"",
                    ""/cache/fotapkg"",
                    ""/cache/fotapkg/tmp"",
                    ""/data/_SamsungBnR_"",
                    ""/data/_SamsungBnR_/BR"",
                    ""/data/2nd-init"",
                    ""/data/amit"",
                    ""/data/anr"",
                    ""/data/app"",
                    ""/data/app-private"",
                    ""/data/backup"",
                    ""/data/battd"",
                    ""/data/bootlogo"",
                    ""/data/btips"",
                    ""/data/btips/TI"",
                    ""/data/btips/TI/opp"",
                    ""/data/cache"",
                    ""/data/calibration"",
                    ""/data/clipboard"",
                    ""/data/clp"",
                    ""/data/dalvik-cache"",
                    ""/data/data"",
                    ""/data/data/.drm"",
                    ""/data/data/.drm/.wmdrm"",
                    ""/data/data/cw"",
                    ""/data/data/com.android.htcprofile"",
                    ""/data/data/com.android.providers.drm/rights"",
                    ""/data/data/com.htc.android.qxdm2sd"",
                    ""/data/data/com.htc.android.qxdm2sd/bin"",
                    ""/data/data/com.htc.android.qxdm2sd/data"",
                    ""/data/data/com.htc.android.qxdm2sd/tmp"",
                    ""/data/data/com.htc.android.netlogger/data"",
                    ""/data/data/com.htc.messagecs/att"",
                    ""/data/data/com.htc.messagecs/pdu"",
                    ""/data/data/com.htc.loggers/bin"",
                    ""/data/data/com.htc.loggers/data"",
                    ""/data/data/com.htc.loggers/htclog"",
                    ""/data/data/com.htc.loggers/tmp"",
                    ""/data/data/com.htc.loggers/htcghost"",
                    ""/data/data/com.lge.ers/android"",
                    ""/data/data/com.lge.ers/arm9"",
                    ""/data/data/com.lge.ers/kernel"",
                    ""/data/data/com.lge.wmc"",
                    ""/data/data/com.redbend.vdmc/lib"",
                    ""/data/data/recovery"",
                    ""/data/data/recovery/HTCFOTA"",
                    ""/data/data/recovery/OMADM"",
                    ""/data/data/shared"",
                    ""/data/diag_logs"",
                    ""/data/dontpanic"",
                    ""/data/drm"",
                    ""/data/drm/fwdlock"",
                    ""/data/drm/IDM"",
                    ""/data/drm/IDM/HTTP"",
                    ""/data/drm/rights"",
                    ""/data/dump"",
                    ""/data/efslog"",
                    ""/data/emt"",
                    ""/data/factory"",
                    ""/data/fics"",
                    ""/data/fics/dev"",
                    ""/data/fota"",
                    ""/data/gps"",
                    ""/data/gps/log"",
                    ""/data/gps/var"",
                    ""/data/gps/var/run"",
                    ""/data/gpscfg"",
                    ""/data/hwvefs"",
                    ""/data/htcfs"",
                    ""/data/img"",
                    ""/data/install"",
                    ""/data/internal-device"",
                    ""/data/internal-device/DCIM"",
                    ""/data/last_alog"",
                    ""/data/last_klog"",
                    ""/data/local"",
                    ""/data/local/logs"",
                    ""/data/local/logs/kernel"",
                    ""/data/local/logs/logcat"",
                    ""/data/local/logs/resetlog"",
                    ""/data/local/logs/smem"",
                    ""/data/local/mono"",
                    ""/data/local/mono/pulse"",
                    ""/data/local/purple"",
                    ""/data/local/purple/sound"",
                    ""/data/local/rights"",
                    ""/data/local/rwsystag"",
                    ""/data/local/skel"",
                    ""/data/local/skel/default"",
                    ""/data/local/skel/defualt"", // Mispelled ""defualt"" is intentional
                    ""/data/local/tmp"",
                    ""/data/local/tmp/com.nuance.android.vsuite.vsuiteapp"",
                    ""/data/log"",
                    ""/data/logger"",
                    ""/data/logs"",
                    ""/data/logs/core"",
                    ""/data/lost+found"",
                    ""/data/mdl"",
                    ""/data/misc"",
                    ""/data/misc/bluetooth"",
                    ""/data/misc/bluetooth/logs"",
                    ""/data/misc/dhcp"",
                    ""/data/misc/lockscreen"",
                    ""/data/misc/sensor"",
                    ""/data/misc/webwidgets"",
                    ""/data/misc/webwidgets/chess"",
                    ""/data/misc/widgets"",
                    ""/data/misc/wifi"",
                    ""/data/misc/wifi/sockets"",
                    ""/data/misc/wimax"",
                    ""/data/misc/wimax/sockets"",
                    ""/data/misc/wminput"",
                    ""/data/misc/wpa_supplicant"",
                    ""/data/nv"",
                    ""/data/nvcam"",
                    ""/data/panic"",
                    ""/data/panicreports"",
                    ""/data/preinstall_md5"",
                    ""/data/property"",
                    ""/data/radio"",
                    ""/data/secure"",
                    ""/data/security"",
                    ""/data/sensors"",
                    ""/data/shared"",
                    ""/data/simcom"",
                    ""/data/simcom/btadd"",
                    ""/data/simcom/simlog"",
                    ""/data/system"",
                    ""/data/tmp"",
                    ""/data/tombstones"",
                    ""/data/tombstones/ramdump"",
                    ""/data/tpapi"",
                    ""/data/tpapi/etc"",
                    ""/data/tpapi/etc/tpa"",
                    ""/data/tpapi/etc/tpa/persistent"",
                    ""/data/tpapi/user.bin"",
                    ""/data/vpnch"",
                    ""/data/wapi"",
                    ""/data/wifi"",
                    ""/data/wimax"",
                    ""/data/wimax/log"",
                    ""/data/wiper"",
                    ""/data/wpstiles"",
                    ""/data/xt9"",
                    ""/dbdata/databases"",
                    ""/efs/.android"",
                    ""/mnt/sdcard"",
                    ""/mnt/usbdrive"",
                    ""/mnt_ext"",
                    ""/mnt_ext/badablk2"",
                    ""/mnt_ext/badablk3"",
                    ""/mnt_ext/cache"",
                    ""/mnt_ext/data"",
                    ""/system/etc/security/drm"",
                    ""/synthesis/hades"",
                    ""/synthesis/chimaira"",
                    ""/synthesis/shdisp"",
                    ""/synthesis/hdmi"",
                    ""/tmp""
            )
    );

    /**
     * Verify that directories not discoverable by
     * testAllOtherDirectoriesNotWritable are not writable.  An application
     * should only be able to write to it's own home directory. World
     * writable directories are a security hole because they enable a
     * number of different attacks.
     * <ul>
     *   <li><a href=""http://en.wikipedia.org/wiki/Symlink_race"">Symlink Races</a></li>
     *   <li>Data destruction by deleting or renaming files you don't own</li>
     *   <li>Data substitution by replacing trusted files with untrusted files</li>
     * </ul>
     *
     * Because /data and /data/data are not readable, we blindly try to
     * poke around in there looking for bad directories.  There has to be
     * a better way...
     */
    @LargeTest"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorTestCase"	"SensorTestCase"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorTestCase.java"	""	"public void test/*
 *.
 */

package android.hardware.cts;

import android.hardware.Sensor;
import android.hardware.cts.helpers.SensorTestStateNotSupportedException;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.reporting.ISensorTestNode;
import android.hardware.cts.helpers.sensoroperations.SensorOperation;
import android.test.AndroidTestCase;
import android.util.Log;

/**
 * Test Case class that handles gracefully sensors that are not available in the device.
 */
public abstract class SensorTestCase extends AndroidTestCase {
    // TODO: consolidate all log tags
    protected static final String LOG_TAG = ""TestRunner"";

    /**
     * Previously for L release, we had this flag to know if each sensor is running with multiple
     * listeners each requesting different data rates. Now before running CTS tests all sensors
     * are de-activated by putting SensorService in RESTRICTED mode. Only CTS tests can
     * activate/deactivate sensors in this mode. So we can default this flag value to false.
     */
    private volatile boolean mEmulateSensorUnderLoad = false;

    /**
     * By default the test class is the root of the test hierarchy.
     */
    private volatile ISensorTestNode mCurrentTestNode = new TestClassNode(getClass());

    protected SensorTestCase() {}

    @Override
    public void runBare() throws Throwable {
        try {
            super.runBare();
        } catch (SensorTestStateNotSupportedException e) {
            // the sensor state is not supported in the device, log a warning and skip the test
            Log.w(LOG_TAG, e.getMessage());
        }
    }

    public void setEmulateSensorUnderLoad(boolean value) {
        mEmulateSensorUnderLoad = value;
    }

    protected boolean shouldEmulateSensorUnderLoad() {
        return mEmulateSensorUnderLoad;
    }

    public void setCurrentTestNode(ISensorTestNode value) {
        mCurrentTestNode = value;
    }

    protected ISensorTestNode getCurrentTestNode() {
        return mCurrentTestNode;
    }

    private class TestClassNode implements ISensorTestNode {
        private final Class<?> mTestClass;

        public TestClassNode(Class<?> testClass) {
            mTestClass = testClass;
        }

        @Override
        public String getName() {
            return mTestClass.getSimpleName();
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricCryptoTests"	"testGenerateKeyWhenCredentialAndBiometricEnrolled"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricCryptoTests.java"	""	"public void testGenerateKeyWhenCredentialAndBiometricEnrolled() throws Exception {
        try (CredentialSession credentialSession = new CredentialSession()) {
            credentialSession.setCredential();

            // 1) Test biometric or credential time-based key. These should be generatable
            // regardless of biometric strength and enrollment, since credentials are enrolled.
            int authType = KeyProperties.AUTH_BIOMETRIC_STRONG
                    | KeyProperties.AUTH_DEVICE_CREDENTIAL;
            Utils.createTimeBoundSecretKey_deprecated(""credential_tb_d"", false /* useStrongBox */);
            Utils.createTimeBoundSecretKey(""credential_tb"", authType, false /* useStrongBox */);
            if (mHasStrongBox) {
                Utils.createTimeBoundSecretKey_deprecated(""credential_tb_d_sb"",
                        true /* useStrongBox */);
                Utils.createTimeBoundSecretKey(""credential_tb_sb"", authType,
                        true /* useStrongBox */);
            }

            for (SensorProperties prop : mSensorProperties) {
                final String keyPrefix = ""key"" + prop.getSensorId();
                Log.d(TAG, ""Testing sensor: "" + prop + "", key name: "" + keyPrefix);

                try (BiometricTestSession session =
                             mBiometricManager.createTestSession(prop.getSensorId())) {
                    waitForAllUnenrolled();
                    enrollForSensor(session, prop.getSensorId());

                    if (prop.getSensorStrength() == SensorProperties.STRENGTH_STRONG) {
                        // Test biometric-bound key
                        Utils.generateBiometricBoundKey(keyPrefix, false /* useStrongBox */);
                        if (mHasStrongBox) {
                            Utils.generateBiometricBoundKey(keyPrefix + ""sb"",
                                    true /* useStrongBox */);
                        }
                        // We can test initializing the key, which in this case is a Cipher.
                        // However, authenticating it and using it is not testable, since that
                        // requires a real authentication from the TEE or equivalent.
                        BiometricPrompt.CryptoObject crypto =
                                Utils.initializeCryptoObject(keyPrefix);
                    } else {
                        // 1) Test biometric auth-per-use keys
                        assertThrows(""Biometric auth-per-use key shouldn't be generatable with""
                                        + "" non-strong biometrics"",
                                InvalidAlgorithmParameterException.class,
                                () -> Utils.generateBiometricBoundKey(keyPrefix,
                                        false /* useStrongBox */));
                        if (mHasStrongBox) {
                            assertThrows(""Biometric auth-per-use strongbox-backed key shouldn't""
                                            + "" be generatable with non-strong biometrics"",
                                    InvalidAlgorithmParameterException.class,
                                    () -> Utils.generateBiometricBoundKey(keyPrefix,
                                            true /* useStrongBox */));
                        }

                        // 2) Test biometric time-based keys
                        assertThrows(""Biometric time-based key shouldn't be generatable with""
                                        + "" non-strong biometrics"",
                                Exception.class,
                                () -> Utils.createTimeBoundSecretKey(keyPrefix + ""tb"",
                                        KeyProperties.AUTH_BIOMETRIC_STRONG,
                                        false /* useStrongBox */));
                        if (mHasStrongBox) {
                            assertThrows(""Biometric time-based strongbox-backed key shouldn't be""
                                            + "" generatable with non-strong biometrics"",
                                    Exception.class,
                                    () -> Utils.createTimeBoundSecretKey(keyPrefix + ""tb"",
                                            KeyProperties.AUTH_BIOMETRIC_STRONG,
                                            true /* useStrongBox */));
                        }
                    }
                }
            }
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.MultiResolutionImageReaderTest"	"testMultiResolutionCaptureCharacteristics"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/MultiResolutionImageReaderTest.java"	""	"public void testMultiResolutionCaptureCharacteristics() {
        for (String id : mCameraIdsUnderTest) {
            if (VERBOSE) {
                Log.v(TAG, ""Testing multi-resolution capture characteristics for Camera "" + id);
            }
            StaticMetadata info = mAllStaticInfo.get(id);
            CameraCharacteristics c = info.getCharacteristics();
            StreamConfigurationMap config = c.get(
                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
            int[] outputFormats = config.getOutputFormats();
            int[] capabilities = CameraTestUtils.getValueNotNull(
                    c, CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
            boolean isLogicalCamera = CameraTestUtils.contains(capabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_LOGICAL_MULTI_CAMERA);
            boolean isUltraHighResCamera = info.isUltraHighResolutionSensor();
            Set<String> physicalCameraIds = c.getPhysicalCameraIds();

            MultiResolutionStreamConfigurationMap multiResolutionMap = c.get(
                    CameraCharacteristics.SCALER_MULTI_RESOLUTION_STREAM_CONFIGURATION_MAP);
            if (multiResolutionMap == null) {
                Log.i(TAG, ""Camera "" + id + "" doesn't support multi-resolution capture."");
                continue;
            }
            if (VERBOSE) {
                Log.v(TAG, ""MULTI_RESOLUTION_STREAM_CONFIGURATION_MAP: ""
                        + multiResolutionMap.toString());
            }

            int[] multiResolutionOutputFormats = multiResolutionMap.getOutputFormats();
            assertTrue(""Camera "" + id + "" must be a logical multi-camera or ultra high res camera ""
                    + ""to support multi-resolution capture."",
                    isLogicalCamera || isUltraHighResCamera);

            for (int format : multiResolutionOutputFormats) {
                assertTrue(String.format(""Camera %s: multi-resolution output format %d ""
                        + ""isn't a supported format"", id, format),
                        CameraTestUtils.contains(outputFormats, format));

                Collection<MultiResolutionStreamInfo> multiResolutionStreams =
                        multiResolutionMap.getOutputInfo(format);
                assertTrue(String.format(""Camera %s supports %d multi-resolution ""
                        + ""outputInfo, expected at least 2"", id,
                        multiResolutionStreams.size()),
                        multiResolutionStreams.size() >= 2);

                // Make sure that each multi-resolution output stream info has the maximum size
                // for that format.
                for (MultiResolutionStreamInfo streamInfo : multiResolutionStreams) {
                    String physicalCameraId = streamInfo.getPhysicalCameraId();
                    Size streamSize = new Size(streamInfo.getWidth(), streamInfo.getHeight());
                    if (!isLogicalCamera) {
                        assertTrue(""Camera "" + id + "" is ultra high resolution camera, but "" +
                                ""the multi-resolution stream info camera Id  "" + physicalCameraId +
                                "" doesn't match"", physicalCameraId.equals(id));
                    } else {
                        assertTrue(""Camera "" + id + ""'s multi-resolution output info "" +
                                ""physical camera id "" + physicalCameraId + "" isn't valid"",
                                physicalCameraIds.contains(physicalCameraId));
                    }

                    StaticMetadata pInfo = mAllStaticInfo.get(physicalCameraId);
                    CameraCharacteristics pChar = pInfo.getCharacteristics();
                    StreamConfigurationMap pConfig = pChar.get(
                            CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
                    Size[] sizes = pConfig.getOutputSizes(format);
                    assertTrue(String.format(""Camera %s must ""
                            + ""support at least one output size for output ""
                            + ""format %d."", physicalCameraId, format),
                             sizes != null && sizes.length > 0);

                    List<Size> maxSizes = new ArrayList<Size>();
                    maxSizes.add(CameraTestUtils.getMaxSize(sizes));
                    StreamConfigurationMap pMaxResConfig = pChar.get(CameraCharacteristics.
                            SCALER_STREAM_CONFIGURATION_MAP_MAXIMUM_RESOLUTION);
                    if (pMaxResConfig != null) {
                        Size[] maxResSizes = pMaxResConfig.getOutputSizes(format);
                        if (maxResSizes != null && maxResSizes.length > 0) {
                            maxSizes.add(CameraTestUtils.getMaxSize(maxResSizes));
                        }
                    }

                    assertTrue(String.format(""Camera %s's supported multi-resolution""
                           + "" size %s for physical camera %s is not one of the largest ""
                           + ""supported sizes %s for format %d"", id, streamSize,
                           physicalCameraId, maxSizes, format),
                           maxSizes.contains(streamSize));
                }
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.MultiResolutionImageReaderTest"	"testMultiResolutionImageReaderRaw"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/MultiResolutionImageReaderTest.java"	""	"public void testMultiResolutionImageReaderRaw() throws Exception {
        testMultiResolutionImageReaderForFormat(ImageFormat.RAW_SENSOR, /*repeating*/false);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.MultiResolutionImageReaderTest"	"testMultiResolutionImageReaderRepeatingRaw"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/MultiResolutionImageReaderTest.java"	""	"public void testMultiResolutionImageReaderRepeatingRaw() throws Exception {
        testMultiResolutionImageReaderForFormat(ImageFormat.RAW_SENSOR, /*repeating*/true);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.features.FeatureSummaryActivity"	"setPassFailButtonClickListeners"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/features/FeatureSummaryActivity.java"	""	"public void test/*
 *.
 */

/*
 * This file references fs_error.png, fs_good.png, fs_indeterminate.png,
 * and fs_warning.png which are licensed under Creative Commons 3.0
 * by fatcow.com.
 * http://www.fatcow.com/free-icons/
 * http://creativecommons.org/licenses/by/3.0/us/
 */

package com.android.cts.verifier.features;

import com.android.cts.verifier.PassFailButtons;
import com.android.cts.verifier.R;

import android.content.pm.FeatureInfo;
import android.content.pm.PackageManager;
import android.os.Build;
import android.os.Bundle;
import android.view.View;
import android.widget.ImageView;
import android.widget.SimpleAdapter;
import android.widget.TextView;

import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
import java.util.HashMap;
import java.util.LinkedHashSet;
import java.util.Set;

public class FeatureSummaryActivity extends PassFailButtons.ListActivity {
    /**
     * Simple storage class for data about an Android feature.
     */
    static class Feature {
        /**
         * The name of the feature. Should be one of the PackageManager.FEATURE*
         * constants.
         */
        public String name;

        /**
         * Indicates whether the field is present on the current device.
         */
        public boolean present;

        /**
         * Indicates whether the field is required for the current device.
         */
        public boolean required;

        /**
         * Constructor does not include 'present' because that's a detected
         * value, and not set during creation.
         *
         * @param name value for this.name
         * @param required value for this.required
         */
        public Feature(String name, boolean required) {
            this.name = name;
            this.required = required;
            this.present = false;
        }

        @Override
        public boolean equals(Object o) {
            if (this == o) {
                return true;
            } else if (o == null || !(o instanceof Feature)) {
                return false;
            } else {
                Feature feature = (Feature) o;
                return name.equals(feature.name);
            }
        }

        @Override
        public int hashCode() {
            return name.hashCode();
        }
    }

    public static final Feature[] ALL_ECLAIR_FEATURES = {
            new Feature(PackageManager.FEATURE_CAMERA, true),
            new Feature(PackageManager.FEATURE_CAMERA_AUTOFOCUS, false),
            new Feature(PackageManager.FEATURE_CAMERA_FLASH, false),
            new Feature(PackageManager.FEATURE_LIVE_WALLPAPER, false),
            new Feature(PackageManager.FEATURE_SENSOR_LIGHT, false),
            new Feature(PackageManager.FEATURE_SENSOR_PROXIMITY, false),
            new Feature(PackageManager.FEATURE_TELEPHONY, false),
            new Feature(PackageManager.FEATURE_TELEPHONY_CDMA, false),
            new Feature(PackageManager.FEATURE_TELEPHONY_GSM, false),
    };

    public static final Feature[] ALL_FROYO_FEATURES = {
            new Feature(""android.hardware.bluetooth"", true),
            new Feature(""android.hardware.location"", true),
            new Feature(""android.hardware.location.gps"", true),
            new Feature(""android.hardware.location.network"", true),
            new Feature(""android.hardware.microphone"", true),
            new Feature(""android.hardware.sensor.accelerometer"", true),
            new Feature(""android.hardware.sensor.compass"", true),
            new Feature(""android.hardware.touchscreen"", true),
            new Feature(""android.hardware.touchscreen.multitouch"", false),
            new Feature(""android.hardware.touchscreen.multitouch.distinct"", false),
            new Feature(""android.hardware.wifi"", false),
    };

    public static final Feature[] ALL_GINGERBREAD_FEATURES = {
            // Required features in prior releases that became optional in GB
            new Feature(""android.hardware.bluetooth"", false),
            new Feature(""android.hardware.camera"", false),
            new Feature(""android.hardware.location.gps"", false),
            new Feature(""android.hardware.microphone"", false),
            new Feature(""android.hardware.sensor.accelerometer"", false),
            new Feature(""android.hardware.sensor.compass"", false),

            // New features in GB
            new Feature(""android.hardware.audio.low_latency"", false),
            new Feature(""android.hardware.camera.front"", false),
            new Feature(""android.hardware.nfc"", false),
            new Feature(""android.hardware.sensor.barometer"", false),
            new Feature(""android.hardware.sensor.gyroscope"", false),
            new Feature(""android.hardware.touchscreen.multitouch.jazzhand"", false),
            new Feature(""android.software.sip"", false),
            new Feature(""android.software.sip.voip"", false),
    };

    public static final Feature[] ALL_GINGERBREAD_MR1_FEATURES = {
            new Feature(""android.hardware.usb.accessory"", false),
    };

    public static final Feature[] ALL_HONEYCOMB_FEATURES = {
            // Required features in prior releases that became optional in HC
            new Feature(""android.hardware.touchscreen"", false),

            new Feature(""android.hardware.faketouch"", true),
    };

    public static final Feature[] ALL_HONEYCOMB_MR1_FEATURES = {
            new Feature(""android.hardware.usb.host"", false),
            new Feature(""android.hardware.usb.accessory"", false),
    };

    public static final Feature[] ALL_HONEYCOMB_MR2_FEATURES = {
            new Feature(""android.hardware.faketouch.multitouch.distinct"", false),
            new Feature(""android.hardware.faketouch.multitouch.jazzhand"", false),
            new Feature(""android.hardware.screen.landscape"", false),
            new Feature(""android.hardware.screen.portrait"", false),
    };

    public static final Feature[] ALL_ICE_CREAM_SANDWICH_FEATURES = {
            new Feature(PackageManager.FEATURE_WIFI_DIRECT, false),
    };

    public static final Feature[] ALL_JELLY_BEAN_FEATURES = {
            // Required features in prior releases that became optional
            new Feature(PackageManager.FEATURE_FAKETOUCH, false),

            //new feature in JB
            new Feature(PackageManager.FEATURE_TELEVISION, false),
    };

    public static final Feature[] ALL_JELLY_BEAN_MR2_FEATURES = {
            new Feature(""android.software.app_widgets"", false),
            new Feature(""android.software.input_methods"", false),
            new Feature(""android.software.home_screen"", false),
            new Feature(""android.hardware.bluetooth_le"", false),
            new Feature(""android.hardware.camera.any"", false),
    };

    public static final Feature[] ALL_KITKAT_FEATURES = {
            new Feature(PackageManager.FEATURE_NFC_HOST_CARD_EMULATION, false),
            new Feature(PackageManager.FEATURE_CONSUMER_IR, false),
            new Feature(PackageManager.FEATURE_DEVICE_ADMIN, false),
            new Feature(PackageManager.FEATURE_SENSOR_STEP_COUNTER, false),
            new Feature(PackageManager.FEATURE_SENSOR_STEP_DETECTOR, false),
    };

    public static final Feature[] ALL_KITKAT_WATCH_FEATURES = {
            new Feature(PackageManager.FEATURE_SENSOR_HEART_RATE, false),
            new Feature(PackageManager.FEATURE_BACKUP, false),
            new Feature(PackageManager.FEATURE_PRINTING, false),
            new Feature(PackageManager.FEATURE_WATCH, false),
            new Feature(PackageManager.FEATURE_WEBVIEW, false),
            new Feature(PackageManager.FEATURE_CAMERA_EXTERNAL, false),
    };

    public static final Feature[] ALL_LOLLIPOP_FEATURES = {
            // New features in L
            new Feature(PackageManager.FEATURE_AUDIO_OUTPUT, false),
            new Feature(PackageManager.FEATURE_CAMERA_CAPABILITY_MANUAL_POST_PROCESSING, false),
            new Feature(PackageManager.FEATURE_CAMERA_CAPABILITY_MANUAL_SENSOR, false),
            new Feature(PackageManager.FEATURE_CAMERA_CAPABILITY_RAW, false),
            new Feature(PackageManager.FEATURE_CAMERA_LEVEL_FULL, false),
            new Feature(PackageManager.FEATURE_CONNECTION_SERVICE, false),
            new Feature(PackageManager.FEATURE_GAMEPAD, false),
            new Feature(PackageManager.FEATURE_LEANBACK, false),
            new Feature(PackageManager.FEATURE_LIVE_TV, false),
            new Feature(PackageManager.FEATURE_MANAGED_USERS, false),
            new Feature(PackageManager.FEATURE_OPENGLES_EXTENSION_PACK, false),
            new Feature(PackageManager.FEATURE_SECURELY_REMOVES_USERS, false),
            new Feature(PackageManager.FEATURE_SENSOR_AMBIENT_TEMPERATURE, false),
            new Feature(PackageManager.FEATURE_SENSOR_HEART_RATE_ECG, false),
            new Feature(PackageManager.FEATURE_SENSOR_RELATIVE_HUMIDITY, false),
            new Feature(PackageManager.FEATURE_VERIFIED_BOOT, false),

            // Features explicitly made optional in L
            new Feature(PackageManager.FEATURE_LOCATION_NETWORK, false),

            // New hidden features in L
            new Feature(""android.hardware.ethernet"", false),
            new Feature(""android.hardware.hdmi.cec"", false),
            new Feature(""android.software.leanback_only"", false),
            new Feature(""android.software.voice_recognizers"", false),
    };

    public static final Feature[] ALL_MNC_FEATURES = {
            new Feature(PackageManager.FEATURE_MIDI, false),
            new Feature(PackageManager.FEATURE_AUDIO_PRO, false),
            new Feature(PackageManager.FEATURE_AUTOMOTIVE, false),
            new Feature(PackageManager.FEATURE_HIFI_SENSORS, false),
            new Feature(PackageManager.FEATURE_FINGERPRINT, false),
    };

    public static final Feature[] ALL_NYC_FEATURES = {
            new Feature(PackageManager.FEATURE_VR_MODE, false),
            new Feature(PackageManager.FEATURE_VR_MODE_HIGH_PERFORMANCE, false),
            new Feature(PackageManager.FEATURE_VULKAN_HARDWARE_VERSION, false),
            new Feature(PackageManager.FEATURE_VULKAN_HARDWARE_LEVEL, false),
            new Feature(PackageManager.FEATURE_NFC_HOST_CARD_EMULATION_NFCF, false),
            new Feature(PackageManager.FEATURE_PICTURE_IN_PICTURE, false),
            new Feature(PackageManager.FEATURE_FREEFORM_WINDOW_MANAGEMENT, false),
            // FEATURE_FILE_BASED_ENCRYPTION is hide
            new Feature(""android.software.file_based_encryption"", false),
    };

    public static final Feature[] ALL_O_FEATURES = {
            new Feature(PackageManager.FEATURE_VULKAN_HARDWARE_COMPUTE, false),
            // FEATURE_TELEPHONY_CARRIERLOCK is SystemApi
            new Feature(""android.hardware.telephony.carrierlock"", false),
            new Feature(PackageManager.FEATURE_WIFI_AWARE, false),
            new Feature(PackageManager.FEATURE_EMBEDDED, false),
            new Feature(PackageManager.FEATURE_COMPANION_DEVICE_SETUP, false),
            new Feature(PackageManager.FEATURE_ACTIVITIES_ON_SECONDARY_DISPLAYS, false),
            new Feature(PackageManager.FEATURE_VR_HEADTRACKING, false),
            // FEATURE_CTS is hide
            new Feature(""android.software.cts"", false),
            new Feature(PackageManager.FEATURE_WIFI_AWARE, false),
    };

    @Override
    public void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.fs_main);
        setPassFailButtonClickListeners();
        setInfoResources(R.string.feature_summary, R.string.feature_summary_info, R.layout.fs_info);

        // some values used to detect warn-able conditions involving multiple
        // features
        boolean hasWifi = false;
        boolean hasTelephony = false;
        boolean hasBluetooth = false;
        boolean hasIllegalFeature = false;
        boolean hasTelevision = false;

        // get list of all features device thinks it has, & store in a HashMap
        // for fast lookups
        HashMap<String, String> actualFeatures = new HashMap<String, String>();
        for (FeatureInfo fi : getPackageManager().getSystemAvailableFeatures()) {
            actualFeatures.put(fi.name, fi.name);
        }

        // data structure that the SimpleAdapter will use to populate ListView
        ArrayList<HashMap<String, Object>> listViewData = new ArrayList<HashMap<String, Object>>();

        // roll over all known features & check whether device reports them
        boolean present = false;
        int statusIcon;
        Set<Feature> features = new LinkedHashSet<Feature>();

        // add features from latest to last so that the latest requirements are put in the set first
        int apiVersion = Build.VERSION.SDK_INT;
        if (apiVersion >= Build.VERSION_CODES.O) {
            Collections.addAll(features, ALL_O_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.N) {
            Collections.addAll(features, ALL_NYC_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.M) {
            Collections.addAll(features, ALL_MNC_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.LOLLIPOP) {
            Collections.addAll(features, ALL_LOLLIPOP_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.KITKAT_WATCH) {
            Collections.addAll(features, ALL_KITKAT_WATCH_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.KITKAT) {
            Collections.addAll(features, ALL_KITKAT_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.JELLY_BEAN_MR2) {
            Collections.addAll(features, ALL_JELLY_BEAN_MR2_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.JELLY_BEAN) {
            Collections.addAll(features, ALL_JELLY_BEAN_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.ICE_CREAM_SANDWICH) {
            Collections.addAll(features, ALL_ICE_CREAM_SANDWICH_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.HONEYCOMB_MR2) {
            Collections.addAll(features, ALL_HONEYCOMB_MR2_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.HONEYCOMB_MR1) {
            Collections.addAll(features, ALL_HONEYCOMB_MR1_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.HONEYCOMB) {
            Collections.addAll(features, ALL_HONEYCOMB_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.GINGERBREAD_MR1) {
            Collections.addAll(features, ALL_GINGERBREAD_MR1_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.GINGERBREAD) {
            Collections.addAll(features, ALL_GINGERBREAD_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.FROYO) {
            Collections.addAll(features, ALL_FROYO_FEATURES);
        }
        if (apiVersion >= Build.VERSION_CODES.ECLAIR_MR1) {
            Collections.addAll(features, ALL_ECLAIR_FEATURES);
        }

        hasTelevision = getPackageManager().hasSystemFeature(PackageManager.FEATURE_TELEVISION);
        for (Feature f : features) {
            HashMap<String, Object> row = new HashMap<String, Object>();
            listViewData.add(row);
            present = actualFeatures.containsKey(f.name);
            if (present) {
                // device reports it -- yay! set the happy icon
                hasWifi = hasWifi || PackageManager.FEATURE_WIFI.equals(f.name);
                hasTelephony = hasTelephony || PackageManager.FEATURE_TELEPHONY.equals(f.name);
                hasBluetooth = hasBluetooth || PackageManager.FEATURE_BLUETOOTH.equals(f.name);
                statusIcon = R.drawable.fs_good;
                actualFeatures.remove(f.name);
            } else if (!present && f.required) {
                // it's required, but device doesn't report it. Boo, set the
                // bogus icon
                statusIcon = R.drawable.fs_error;
                if (hasTelevision && PackageManager.FEATURE_LOCATION.equals(f.name)) {
                    statusIcon = R.drawable.fs_indeterminate;
                }
            } else {
                // device doesn't report it, but it's not req'd, so can't tell
                // if there's a problem
                statusIcon = R.drawable.fs_indeterminate;
            }
            row.put(""feature"", f.name);
            row.put(""icon"", statusIcon);
        }

        // now roll over any remaining features (which are non-standard)
        for (String feature : actualFeatures.keySet()) {
            if (feature == null || """".equals(feature))
                continue;
            HashMap<String, Object> row = new HashMap<String, Object>();
            listViewData.add(row);
            row.put(""feature"", feature);
            if (feature.startsWith(""android"")) { // intentionally not ""android.""
                // sorry, you're not allowed to squat in the official namespace;
                // set bogus icon
                row.put(""icon"", R.drawable.fs_error);
                hasIllegalFeature = true;
            } else {
                // non-standard features are okay, but flag them just in case
                row.put(""icon"", R.drawable.fs_warning);
            }
        }

        // sort the ListView's data to group by icon type, for easier reading by
        // humans
        final HashMap<Integer, Integer> idMap = new HashMap<Integer, Integer>();
        idMap.put(R.drawable.fs_error, 0);
        idMap.put(R.drawable.fs_warning, 1);
        idMap.put(R.drawable.fs_indeterminate, 2);
        idMap.put(R.drawable.fs_good, 3);
        Collections.sort(listViewData, new Comparator<HashMap<String, Object>>() {
            public int compare(HashMap<String, Object> left, HashMap<String, Object> right) {
                int leftId = idMap.get(left.get(""icon""));
                int rightId = idMap.get(right.get(""icon""));
                if (leftId == rightId) {
                    return ((String) left.get(""feature"")).compareTo((String) right.get(""feature""));
                }
                if (leftId < rightId)
                    return -1;
                return 1;
            }
        });

        // Set up the SimpleAdapter used to populate the ListView
        SimpleAdapter adapter = new SimpleAdapter(this, listViewData, R.layout.fs_row,
                new String[] {
                        ""feature"", ""icon""
                }, new int[] {
                        R.id.fs_feature, R.id.fs_icon
                });
        adapter.setViewBinder(new SimpleAdapter.ViewBinder() {
            public boolean setViewValue(View view, Object data, String repr) {
                try {
                    if (view instanceof ImageView) {
                        ((ImageView) view).setImageResource((Integer) data);
                    } else if (view instanceof TextView) {
                        ((TextView) view).setText((String) data);
                    } else {
                        return false;
                    }
                    return true;
                } catch (ClassCastException e) {
                    return false;
                }
            }
        });
        setListAdapter(adapter);

        // finally, check for our second-order error cases and set warning text
        // if necessary
        StringBuffer sb = new StringBuffer();
        if (hasIllegalFeature) {
            sb.append(getResources().getString(R.string.fs_disallowed)).append(""\n"");
        }

        if (!hasWifi && !hasTelephony && !hasBluetooth) {
            sb.append(getResources().getString(R.string.fs_missing_wifi_telephony)).append(""\n"");
        }

        String warnings = sb.toString().trim();
        if (warnings == null || """".equals(warnings)) {
            ((TextView) (findViewById(R.id.fs_warnings))).setVisibility(View.GONE);
        } else {
            ((TextView) (findViewById(R.id.fs_warnings))).setText(warnings);
        }
    }
}"	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.EventGapVerificationTest"	"testVerify_missing_events"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/EventGapVerificationTest.java"	""	"public void testVerify_missing_events() {
        // Timestamps in ns, expected in us
        long[] timestamps = {1000000, 2000000, 3000000, 5000000, 6000000};
        runVerification(1000, timestamps, true, new int[]{3});
    }

    private void runVerification(int expected, long[] timestamps, boolean pass,
            int[] indices) {
        SensorStats stats = new SensorStats();
        ISensorVerification verification = getVerification(expected, timestamps);
        TestSensorEnvironment environment = new TestSensorEnvironment(null, null, false, 0, 0);
        if (pass) {
            verification.verify(environment, stats);
        } else {
            boolean failed = false;
            try {
                verification.verify(environment, stats);
            } catch (AssertionError e) {
                // Expected;
                failed = true;
            }
            assertTrue(""Expected an AssertionError"", failed);
        }
        assertEquals(pass, stats.getValue(EventGapVerification.PASSED_KEY));
        assertEquals(indices.length, stats.getValue(SensorStats.EVENT_GAP_COUNT_KEY));
        assertNotNull(stats.getValue(SensorStats.EVENT_GAP_POSITIONS_KEY));
        int[] actualIndices = (int[]) stats.getValue(SensorStats.EVENT_GAP_POSITIONS_KEY);
        assertEquals(indices.length, actualIndices.length);

        for (int i = 0; i < indices.length; i++) {
            assertEquals(indices[i], actualIndices[i]);
        }
    }

    private static EventGapVerification getVerification(int expected, long ... timestamps) {
        Collection<TestSensorEvent> events = new ArrayList<>(timestamps.length);
        for (long timestamp : timestamps) {
            events.add(new TestSensorEvent(null, timestamp, 0, null));
        }
        EventGapVerification verification = new EventGapVerification(expected);
        verification.addSensorEvents(events);
        return verification;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.TestSensorManager"	"unregisterListener"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/TestSensorManager.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers;

import junit.framework.Assert;

import android.content.Context;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.util.Log;

import java.util.concurrent.CountDownLatch;

/**
 * A test class that performs the actions of {@link SensorManager} on a single sensor.
 * This class allows for a single sensor to be registered and unregistered as well as performing
 * operations such as flushing the sensor events and gathering events.
 * This class also manages performing the test verifications for the sensor manager.
 *
 * NOTE: this class is expected to mirror {@link SensorManager} operations, and perform the
 * required test verifications along with them.
 */
public class TestSensorManager {
    private static final String LOG_TAG = ""TestSensorManager"";

    private final SensorManager mSensorManager;
    private final TestSensorEnvironment mEnvironment;

    private volatile TestSensorEventListener mTestSensorEventListener;

    /**
     * @deprecated Use {@link #TestSensorManager(TestSensorEnvironment)} instead.
     */
    @Deprecated
    public TestSensorManager(
            Context context,
            int sensorType,
            int rateUs,
            int maxBatchReportLatencyUs) {
        this(new TestSensorEnvironment(context, sensorType, rateUs, maxBatchReportLatencyUs));
    }

    /**
     * Construct a {@link TestSensorManager}.
     */
    public TestSensorManager(TestSensorEnvironment environment) {
        mSensorManager =
                (SensorManager) environment.getContext().getSystemService(Context.SENSOR_SERVICE);
        mEnvironment = environment;
    }

    /**
     * Register the listener. This method will perform a no-op if the sensor is already registered.
     *
     * @throws AssertionError if there was an error registering the listener with the
     * {@link SensorManager}
     */
    public void registerListener(TestSensorEventListener listener) {
        if (mTestSensorEventListener != null) {
            Log.w(LOG_TAG, ""Listener already registered, returning."");
            return;
        }

        mTestSensorEventListener = listener;
        String message = SensorCtsHelper.formatAssertionMessage(""registerListener"", mEnvironment);

        boolean result = mSensorManager.registerListener(
                mTestSensorEventListener,
                mEnvironment.getSensor(),
                mEnvironment.getRequestedSamplingPeriodUs(),
                mEnvironment.getMaxReportLatencyUs(),
                mTestSensorEventListener.getHandler());
        Assert.assertTrue(message, result);
    }

    /**
     * Register the listener. This method will perform a no-op if the sensor is already registered.
     *
     * @return A CountDownLatch initialized with eventCount which is used to wait for sensor
     * events.
     * @throws AssertionError if there was an error registering the listener with the
     * {@link SensorManager}
     */
    public CountDownLatch registerListener(
            TestSensorEventListener listener,
            int eventCount,
            boolean specifyHandler) {
        if (mTestSensorEventListener != null) {
            Log.w(LOG_TAG, ""Listener already registered, returning."");
            return null;
        }

        CountDownLatch latch = listener.getLatchForSensorEvents(eventCount);
        mTestSensorEventListener = listener;
        String message = SensorCtsHelper.formatAssertionMessage(""registerListener"", mEnvironment);

        boolean result;
        if (specifyHandler) {
            result = mSensorManager.registerListener(
                    mTestSensorEventListener,
                    mEnvironment.getSensor(),
                    mEnvironment.getRequestedSamplingPeriodUs(),
                    mEnvironment.getMaxReportLatencyUs(),
                    mTestSensorEventListener.getHandler());
        } else {
            result = mSensorManager.registerListener(
                    mTestSensorEventListener,
                    mEnvironment.getSensor(),
                    mEnvironment.getRequestedSamplingPeriodUs(),
                    mEnvironment.getMaxReportLatencyUs());
        }
        Assert.assertTrue(message, result);
        return latch;
    }

    /**
     * Register the listener. This method will perform a no-op if the sensor is already registered.
     *
     * @return A CountDownLatch initialized with eventCount which is used to wait for sensor
     * events.
     * @throws AssertionError if there was an error registering the listener with the
     * {@link SensorManager}
     */
    public CountDownLatch registerListener(
            TestSensorEventListener listener,
            int eventCount) {
        return registerListener(listener, eventCount, true);
    }

    /**
     * Unregister the listener. This method will perform a no-op if the sensor is not registered.
     */
    public void unregisterListener() {
        if (mTestSensorEventListener == null) {
            Log.w(LOG_TAG, ""No listener registered, returning."");
            return;
        }
        mSensorManager.unregisterListener(mTestSensorEventListener, mEnvironment.getSensor());
        mTestSensorEventListener.assertEventsReceivedInHandler();
        mTestSensorEventListener.releaseWakeLock(); // clean up wakelock if it is acquired
        mTestSensorEventListener = null;
    }

    /**
     * Call {@link SensorManager#flush(SensorEventListener)} and asserts that it fails.
     */
    public void assertFlushFail() {
        if (mTestSensorEventListener == null) {
            Log.w(LOG_TAG, ""No listener registered, returning."");
            return;
        }
        Assert.assertFalse(
                SensorCtsHelper.formatAssertionMessage(
                    ""Flush succeeded unexpectedly"", mEnvironment),
                mSensorManager.flush(mTestSensorEventListener));
    }

    /**
     * Call {@link SensorManager#flush(SensorEventListener)}. This method will perform a no-op if
     * the sensor is not registered.
     *
     * @return A CountDownLatch which can be used to wait for a flush complete event.
     * @throws AssertionError if {@link SensorManager#flush(SensorEventListener)} fails.
     */
    public CountDownLatch requestFlush() {
        if (mTestSensorEventListener == null) {
            Log.w(LOG_TAG, ""No listener registered, returning."");
            return null;
        }
        CountDownLatch latch = mTestSensorEventListener.getLatchForFlushCompleteEvent();
        Assert.assertTrue(
                SensorCtsHelper.formatAssertionMessage(""Flush"", mEnvironment),
                mSensorManager.flush(mTestSensorEventListener));
        return latch;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.deviceinfo.SensorDeviceInfo"	"isWakeUpSensor"	""	"/home/gpoor/cts-12-source/cts/tools/cts-device-info/src/com/android/cts/deviceinfo/SensorDeviceInfo.java"	""	"public void test/*
 *.
 */
package com.android.cts.deviceinfo;

import android.content.Context;
import android.hardware.Sensor;
import android.hardware.SensorDirectChannel;
import android.hardware.SensorManager;
import android.os.Bundle;

import com.android.compatibility.common.deviceinfo.DeviceInfo;
import com.android.compatibility.common.util.DeviceInfoStore;

import java.lang.Exception;
import java.util.Arrays;
import java.util.ArrayList;
import java.util.List;

/**
 * Sensor device info collector.
 */
public class SensorDeviceInfo extends DeviceInfo {

    private static final String SENSOR = ""sensor"";
    private static final String REPORTING_MODE = ""reporting_mode"";
    private static final String NAME = ""name"";
    private static final String VENDOR = ""vendor"";
    private static final String TYPE = ""type"";
    private static final String VERSION = ""version"";
    private static final String MAXIMUM_RANGE = ""maximum_range"";
    private static final String RESOLUTION = ""resolution"";
    private static final String POWER = ""power"";
    private static final String MIN_DELAY = ""min_delay"";
    private static final String FIFO_RESERVED_EVENT_COUNT =
            ""fifo_reserved_event_count"";
    private static final String FIFO_MAX_EVENT_COUNT = ""fifo_max_event_count"";
    private static final String STRING_TYPE = ""string_type"";
    private static final String ID = ""id"";
    private static final String MAX_DELAY = ""max_delay"";
    private static final String IS_WAKE_UP_SENSOR = ""is_wake_up_sensor"";
    private static final String IS_DYNAMIC_SENSOR = ""is_dynamic_sensor"";
    private static final String IS_ADDITONAL_INFO_SUPPORTED =
            ""is_additional_info_supported"";
    private static final String HIGHEST_DIRECT_REPORT_RATE_LEVEL =
            ""highest_direct_report_rate_level"";
    private static final String SUPPORTED_DIRECT_CHANNEL_TYPE =
            ""supported_direct_channel_type"";
    private static final int[] CHANNEL_TYPES = new int[] {
            SensorDirectChannel.TYPE_MEMORY_FILE,
            SensorDirectChannel.TYPE_HARDWARE_BUFFER };

    @Override
    protected void collectDeviceInfo(DeviceInfoStore store) throws Exception {
        SensorManager sensorManager = (SensorManager)
                getContext().getSystemService(Context.SENSOR_SERVICE);
        List<Sensor> sensors = sensorManager.getSensorList(Sensor.TYPE_ALL);
        store.startArray(SENSOR);
        for (Sensor sensor : sensors) {
            store.startGroup();
            store.addResult(REPORTING_MODE, sensor.getReportingMode());
            store.addResult(NAME, sensor.getName());
            store.addResult(VENDOR, sensor.getVendor());
            store.addResult(TYPE, sensor.getType());
            store.addResult(VERSION, sensor.getVersion());
            store.addResult(MAXIMUM_RANGE, sensor.getMaximumRange());
            store.addResult(RESOLUTION, sensor.getResolution());
            store.addResult(POWER, sensor.getPower());
            store.addResult(MIN_DELAY, sensor.getMinDelay());
            store.addResult(FIFO_RESERVED_EVENT_COUNT,
                    sensor.getFifoReservedEventCount());
            store.addResult(FIFO_MAX_EVENT_COUNT,
                    sensor.getFifoMaxEventCount());
            store.addResult(STRING_TYPE, sensor.getStringType());
            store.addResult(ID, sensor.getId());
            store.addResult(MAX_DELAY, sensor.getMaxDelay());
            store.addResult(IS_WAKE_UP_SENSOR, sensor.isWakeUpSensor());
            store.addResult(IS_DYNAMIC_SENSOR, sensor.isDynamicSensor());
            store.addResult(IS_ADDITONAL_INFO_SUPPORTED,
                    sensor.isAdditionalInfoSupported());
            store.addResult(HIGHEST_DIRECT_REPORT_RATE_LEVEL,
                    sensor.getHighestDirectReportRateLevel());

            List<Integer> supportedChannelType = new ArrayList<>();
            for (int channelType : CHANNEL_TYPES) {
                if (sensor.isDirectChannelTypeSupported(channelType)) {
                    supportedChannelType.add(channelType);
                }
            }
            store.addArrayResult(SUPPORTED_DIRECT_CHANNEL_TYPE,
                    supportedChannelType.stream().mapToInt(i->i).toArray());
            store.endGroup();
        }
        store.endArray(); // Sensor
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.BatchArrivalVerification"	"isDeviceSuspendTest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/BatchArrivalVerification.java"	""	"public void test
package android.hardware.cts.helpers.sensorverification;

import java.util.LinkedList;
import java.util.List;
import java.util.concurrent.TimeUnit;

import android.hardware.Sensor;
import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEvent;
import android.hardware.cts.helpers.sensorverification.AbstractSensorVerification.IndexedEventPair;
import android.os.SystemClock;
import android.provider.Settings.System;

import junit.framework.Assert;

/**
 * A {@link ISensorVerification} which verifies that there are no missing events. This is done by
 * checking the last received sensor timestamp and checking that it is within 1.8 * the expected
 * period.
 */
public class BatchArrivalVerification extends AbstractSensorVerification {
    public static final String PASSED_KEY = ""missing_event_passed"";

    // Batch arrival tolerance is 5 seconds.
    private static final int BATCH_ARRIVAL_TOLERANCE_US = 5000000;

    // Number of indices to print in assert message before truncating
    private static final int TRUNCATE_MESSAGE_LENGTH = 3;

    // Number of events to truncate (discard) from the initial events received
    private static final int TRUNCATE_EVENTS_COUNT = 100;

    private final long mExpectedBatchArrivalTimeUs;

    private final List<IndexedEventPair> mFailures = new LinkedList<IndexedEventPair>();
    private TestSensorEvent mFirstEvent = null;
    private int mIndex = 0;
    private final long mEstimatedTestStartTimeMs;

    /**
     * Construct a {@link EventGapVerification}
     *
     * @param expectedDelayUs the expected period in us.
     */
    public BatchArrivalVerification(long expectedBatchArrivalTimeUs) {
         mExpectedBatchArrivalTimeUs = expectedBatchArrivalTimeUs;
         mEstimatedTestStartTimeMs = SystemClock.elapsedRealtime();
    }

    /**
     * Get the default {@link EventGapVerification}.
     *
     * @param environment the test environment
     * @return the verification or null if the verification is not a continuous mode sensor.
     */
    public static BatchArrivalVerification getDefault(TestSensorEnvironment environment) {
        if (environment.getSensor().getReportingMode() != Sensor.REPORTING_MODE_CONTINUOUS) {
            return null;
        }
        long fifoMaxEventCount = environment.getSensor().getFifoMaxEventCount();
        int maximumExpectedSamplingPeriodUs = environment.getMaximumExpectedSamplingPeriodUs();
        long reportLatencyUs = environment.getMaxReportLatencyUs();
        if (fifoMaxEventCount > 0 && maximumExpectedSamplingPeriodUs != Integer.MAX_VALUE) {
            long fifoBasedReportLatencyUs =
                    fifoMaxEventCount * maximumExpectedSamplingPeriodUs;
            // If the device goes into suspend mode during the test and the sensor under test is
            // a non wake-up sensor, the FIFO will keep overwriting itself and the reportLatency
            // of each event will be equal to the time it takes to fill up the FIFO.
            if (environment.isDeviceSuspendTest() && !environment.getSensor().isWakeUpSensor()) {
                reportLatencyUs = fifoBasedReportLatencyUs;
            } else {
                // In this case the sensor under test is either a wake-up sensor OR it
                // is a non wake-up sensor but the device does not go into suspend.
                // So the expected delay of a sensor_event is the minimum of the
                // fifoBasedReportLatencyUs and the requested latency by the application.
                reportLatencyUs = Math.min(reportLatencyUs, fifoBasedReportLatencyUs);
            }
        }
        long expectedBatchArrivalTimeUs = reportLatencyUs + SystemClock.elapsedRealtime() * 1000;
        return new BatchArrivalVerification(expectedBatchArrivalTimeUs);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public void verify(TestSensorEnvironment environment, SensorStats stats) {
        final int count = mFailures.size();
        stats.addValue(PASSED_KEY, count == 0);
        stats.addValue(SensorStats.DELAYED_BATCH_DELIVERY, count);

        if (count > 0) {
            StringBuilder sb = new StringBuilder();
            sb.append(count).append("" BatchArrivalDelayed: "");
            for (int i = 0; i < Math.min(count, TRUNCATE_MESSAGE_LENGTH); i++) {
                IndexedEventPair info = mFailures.get(i);
                sb.append(String.format(""expectedBatchArrival=%dms actualBatchArrivalTime=%dms ""+
                                        ""estimedTestStartTime=%dms diff=%dms tolerance=%dms"",
                                         (mExpectedBatchArrivalTimeUs)/1000,
                                         info.event.receivedTimestamp/(1000 * 1000),
                                         mEstimatedTestStartTimeMs,
                                         (mExpectedBatchArrivalTimeUs -
                                          info.event.receivedTimestamp/1000)/1000,
                                         BATCH_ARRIVAL_TOLERANCE_US/1000)

                          );

            }
            if (count > TRUNCATE_MESSAGE_LENGTH) {
                sb.append(count - TRUNCATE_MESSAGE_LENGTH).append("" more; "");
            }
            Assert.fail(sb.toString());
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public BatchArrivalVerification clone() {
        return new BatchArrivalVerification(mExpectedBatchArrivalTimeUs);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    protected void addSensorEventInternal(TestSensorEvent event) {
        if (mFirstEvent == null) {
            mFirstEvent = event;
        }
        if (mIndex == 1) {
            if (Math.abs(mFirstEvent.receivedTimestamp/1000 - mExpectedBatchArrivalTimeUs) >
                BATCH_ARRIVAL_TOLERANCE_US) {
                mFailures.add(new IndexedEventPair(1, mFirstEvent, null));
            }
        }
        ++mIndex;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.base.SensorCtsTestActivity"	"getTestLogger"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/base/SensorCtsTestActivity.java"	""	"public void test/*

 *.
 */

package com.android.cts.verifier.sensors.base;

import android.content.Context;
import android.hardware.cts.SensorTestCase;
import android.os.PowerManager;
import android.view.WindowManager;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.helpers.SensorTestScreenManipulator;
import com.android.cts.verifier.sensors.reporting.SensorTestDetails;

import junit.framework.Test;
import junit.framework.TestSuite;

import org.junit.internal.runners.JUnit38ClassRunner;
import org.junit.internal.runners.SuiteMethod;
import org.junit.runner.Computer;
import org.junit.runner.Description;
import org.junit.runner.JUnitCore;
import org.junit.runner.Request;
import org.junit.runner.Result;
import org.junit.runner.Runner;
import org.junit.runner.notification.Failure;
import org.junit.runner.notification.RunListener;
import org.junit.runners.model.InitializationError;
import org.junit.runners.model.RunnerBuilder;

import java.util.concurrent.TimeUnit;

/**
 * An Activity that allows Sensor CTS tests to be executed inside CtsVerifier.
 *
 * Sub-classes pass the test class as part of construction.
 * One JUnit test class is executed per Activity, the test class can still be executed outside
 * CtsVerifier.
 */
public abstract class SensorCtsTestActivity extends BaseSensorTestActivity {

    private SensorTestScreenManipulator mScreenManipulator;
    private PowerManager.WakeLock mWakeLock;

    /**
     * Constructor for a CTS test executor. It will execute a standalone CTS test class.
     *
     * @param testClass The test class to execute, it must be a subclass of {@link SensorTestCase}.
     */
    protected SensorCtsTestActivity(Class<? extends SensorTestCase> testClass) {
        super(testClass);
    }

    @Override
    protected void activitySetUp() throws InterruptedException {
        PowerManager powerManager = (PowerManager) getSystemService(Context.POWER_SERVICE);
        mWakeLock =  powerManager.newWakeLock(PowerManager.PARTIAL_WAKE_LOCK, ""SensorCtsTests"");
        mScreenManipulator = new SensorTestScreenManipulator(this);
        mScreenManipulator.initialize(this);

        SensorTestLogger logger = getTestLogger();
        logger.logInstructions(R.string.snsr_no_interaction);
        logger.logInstructions(R.string.snsr_run_automated_tests);
        waitForUserToBegin();

        // automated CTS tests run with the USB connected, so the AP doesn't go to sleep
        // here we are not connected to USB, so we need to hold a wake-lock to avoid going to sleep
        mWakeLock.acquire();

        mScreenManipulator.turnScreenOff();
    }

    @Override
    protected void activityCleanUp() {
        runOnUiThread(new Runnable() {
            @Override
            public void run() {
                getWindow().addFlags(WindowManager.LayoutParams.FLAG_DISMISS_KEYGUARD);
            }
        });
        mScreenManipulator.turnScreenOn();
        if (mWakeLock.isHeld()) {
            mWakeLock.release();
        }
    }

    @Override
    protected void onDestroy() {
        super.onDestroy();
        if (mScreenManipulator != null) {
            mScreenManipulator.releaseScreenOn();
            mScreenManipulator.close();
        }
    }

    /**
     * For reference on the implementation of this test executor see:
     *      androidx.test.runner.AndroidJUnitRunner
     */
    @Override
    protected SensorTestDetails executeTests() {
        JUnitCore testRunner = new JUnitCore();
        testRunner.addListener(new SensorRunListener());

        Computer computer = new Computer();
        RunnerBuilder runnerBuilder = new SensorRunnerBuilder();

        Runner runner;
        try {
            runner = computer.getSuite(runnerBuilder, new Class[]{ mTestClass });
        } catch (InitializationError e) {
            return new SensorTestDetails(
                    getTestClassName(),
                    SensorTestDetails.ResultCode.FAIL,
                    ""[JUnit Initialization]"" + e.getMessage());
        }

        Request request = Request.runner(runner);
        Result result = testRunner.run(request);
        return new SensorTestDetails(getApplicationContext(), getClass().getName(), result);
    }

    /**
     * A {@link RunnerBuilder} that is used to inject during execution a {@link SensorCtsTestSuite}.
     */
    private class SensorRunnerBuilder extends RunnerBuilder {
        @Override
        public Runner runnerForClass(Class<?> testClass) throws Throwable {
            TestSuite testSuite;
            if (hasSuiteMethod(testClass)) {
                Test test = SuiteMethod.testFromSuiteMethod(testClass);
                if (test instanceof TestSuite) {
                    testSuite = (TestSuite) test;
                } else {
                    throw new IllegalArgumentException(
                            testClass.getName() + ""#suite() did not return a TestSuite."");
                }
            } else {
                testSuite = new TestSuite(testClass);
            }
            SensorCtsTestSuite sensorTestSuite =
                    new SensorCtsTestSuite(getApplicationContext(), testSuite);
            return new JUnit38ClassRunner(sensorTestSuite);
        }

        private boolean hasSuiteMethod(Class<?> testClass) {
            try {
                testClass.getMethod(""suite"");
                return true;
            } catch (NoSuchMethodException e) {
                return false;
            }
        }
    }

    /**
     * Dummy {@link RunListener}.
     * It is only used to handle logging into the UI.
     */
    private class SensorRunListener extends RunListener {
        private volatile boolean mCurrentTestReported;"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.car.cts.CarSensorManagerTest"	"testRequiredSensorsForDrivingState"	"CtsCarTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/car/src/android/car/cts/CarSensorManagerTest.java"	""	"public void testRequiredSensorsForDrivingState() throws Exception {
        boolean foundSpeed =
            isSupportSensor(CarSensorManager.SENSOR_TYPE_CAR_SPEED);
        boolean foundGear = isSupportSensor(CarSensorManager.SENSOR_TYPE_GEAR);
        assertTrue(""Must support SENSOR_TYPE_CAR_SPEED"", foundSpeed);
        assertTrue(""Must support SENSOR_TYPE_GEAR"", foundGear);
    }

    @CddTest(requirement=""2.5.1"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.car.cts.CarSensorManagerTest"	"testMustSupportNightSensor"	"CtsCarTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/car/src/android/car/cts/CarSensorManagerTest.java"	""	"public void testMustSupportNightSensor() {
        boolean foundNightSensor =
            isSupportSensor(CarSensorManager.SENSOR_TYPE_NIGHT);
        assertTrue(""Must support SENSOR_TYPE_NIGHT"", foundNightSensor);
    }

    @CddTest(requirement = ""2.5.1"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.car.cts.CarSensorManagerTest"	"testMustSupportParkingBrake"	"CtsCarTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/car/src/android/car/cts/CarSensorManagerTest.java"	""	"public void testMustSupportParkingBrake() throws Exception {
        boolean foundParkingBrake =
            isSupportSensor(CarSensorManager.SENSOR_TYPE_PARKING_BRAKE);
        assertTrue(""Must support SENSOR_TYPE_PARKING_BRAKE"", foundParkingBrake);
    }

    private boolean isSupportSensor(int sensorType) {
        return IntStream.of(mSupportedSensors)
            .anyMatch(x -> x == sensorType);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.helpers.SensorTestScreenManipulator"	"isDeviceAdminInitialized"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/helpers/SensorTestScreenManipulator.java"	""	"public void test/*
 *
 */

package com.android.cts.verifier.sensors.helpers;

import com.android.cts.verifier.os.TimeoutResetActivity;
import com.android.cts.verifier.sensors.base.BaseSensorTestActivity;
import com.android.cts.verifier.sensors.base.ISensorTestStateContainer;

import android.app.Activity;
import android.app.admin.DeviceAdminInfo;
import android.app.admin.DevicePolicyManager;
import android.content.BroadcastReceiver;
import android.content.ComponentName;
import android.content.Context;
import android.content.Intent;
import android.content.IntentFilter;
import android.content.pm.PackageManager;
import android.os.PowerManager;
import android.text.TextUtils;
import android.util.Log;

import java.util.concurrent.CountDownLatch;

/**
 * A class that provides functionality to manipulate the state of the device's screen.
 *
 * The implementation uses a simple state machine with 3 states: keep-screen-off, keep-screen-on,
 * and a free-state where the class does not affect the system's state.
 *
 * The list of transitions and their handlers are:
 *      keep-screen-on --(turnScreenOff)--> keep-screen-off
 *      keep-screen-on --(releaseScreenOn)--> free-state
 *
 *      keep-screen-off --(turnScreenOn)--> keep-screen-on
 *      keep-screen-off --(wakeUpScreen)--> free-state
 *
 *      free-state --(turnScreenOff)--> keep-screen-off
 *      free-state --(turnScreenOn)--> keep-screen-on
 *
 * NOTES:
 * - the operator still can turn on/off the screen by pressing the power button
 * - this class must be used by a single client, that can manage the state of the instance, likely
 * - in a single-threaded environment
 */
public class SensorTestScreenManipulator {
    private static final String TAG = SensorTestScreenManipulator.class.getSimpleName();

    private final Activity mActivity;
    private final DevicePolicyManager mDevicePolicyManager;
    private final ComponentName mComponentName;
    private final PowerManager.WakeLock mWakeUpScreenWakeLock;
    private final PowerManager.WakeLock mKeepScreenOnWakeLock;

    private InternalBroadcastReceiver mBroadcastReceiver;
    private boolean mTurnOffScreenOnPowerDisconnected;


    public SensorTestScreenManipulator(Activity activity) {
        mActivity = activity;
        mComponentName = SensorDeviceAdminReceiver.getComponentName(activity);
        mDevicePolicyManager =
                (DevicePolicyManager) activity.getSystemService(Context.DEVICE_POLICY_SERVICE);

        int levelAndFlags = PowerManager.FULL_WAKE_LOCK
                | PowerManager.ON_AFTER_RELEASE
                | PowerManager.ACQUIRE_CAUSES_WAKEUP;
        PowerManager powerManager = (PowerManager) activity.getSystemService(Context.POWER_SERVICE);
        mWakeUpScreenWakeLock = powerManager.newWakeLock(levelAndFlags, ""SensorTestWakeUpScreen"");
        mWakeUpScreenWakeLock.setReferenceCounted(false);
        mKeepScreenOnWakeLock = powerManager.newWakeLock(levelAndFlags, ""SensorTestKeepScreenOn"");
        mKeepScreenOnWakeLock.setReferenceCounted(false);
    }

    /**
     * Initializes the current instance.
     * Initialization should usually happen inside {@link BaseSensorTestActivity#activitySetUp}.
     *
     * NOTE: Initialization will bring up an Activity to let the user activate the Device Admin,
     * this method will block until the user completes the operation.
     */
    public synchronized void initialize(ISensorTestStateContainer stateContainer)
            throws InterruptedException {
        if (hasDeviceAdminFeature() && !isDeviceAdminInitialized()) {
            Intent intent = new Intent(DevicePolicyManager.ACTION_ADD_DEVICE_ADMIN);
            intent.putExtra(DevicePolicyManager.EXTRA_DEVICE_ADMIN, mComponentName);
            int resultCode = stateContainer.executeActivity(intent);
            if (resultCode != Activity.RESULT_OK) {
                throw new IllegalStateException(
                        ""Test cannot execute without Activating the Device Administrator."");
            }
        }

        if (mBroadcastReceiver == null) {
            mBroadcastReceiver = new InternalBroadcastReceiver();
            IntentFilter intentFilter = new IntentFilter();
            intentFilter.addAction(Intent.ACTION_POWER_DISCONNECTED);
            mActivity.registerReceiver(mBroadcastReceiver, intentFilter);
        }
    }

    /**
     * Closes the current instance.
     * This operation should usually happen inside {@link BaseSensorTestActivity#activityCleanUp}.
     */
    public synchronized  void close() {
        if (mBroadcastReceiver != null) {
            mActivity.unregisterReceiver(mBroadcastReceiver);
            mBroadcastReceiver = null;
        }
    }

    /**
     * Instruct the device to turn off the screen immediately.
     */
    public synchronized void turnScreenOff() {
        ensureDeviceAdminInitialized();

        final CountDownLatch screenOffSignal = new CountDownLatch(1);
        BroadcastReceiver screenOffBroadcastReceiver = new BroadcastReceiver() {
            @Override
            public void onReceive(Context context, Intent intent) {
                mActivity.unregisterReceiver(this);
                screenOffSignal.countDown();
            }
        };
        mActivity.registerReceiver(
                screenOffBroadcastReceiver, new IntentFilter(Intent.ACTION_SCREEN_OFF));

        releaseScreenOn();
        if (hasDeviceAdminFeature()) {
            mDevicePolicyManager.lockNow();
        } else {
            TimeoutResetActivity.turnOffScreen(mActivity);
        }

        try {
            screenOffSignal.await();
        } catch (InterruptedException e) {
            Log.wtf(TAG, ""error waiting for screen off signal"", e);
        }
    }

    /**
     * Instruct the device to wake up the screen immediately, the screen will remain on for a bit,
     * but the system might turn the screen off in the near future.
     */
    public synchronized void wakeUpScreen() {
        mWakeUpScreenWakeLock.acquire();
        // release right away, the screen still remains on for a bit, but not indefinitely
        mWakeUpScreenWakeLock.release();
    }

    /**
     * Instructs the device to turn on the screen immediately.
     *
     * The screen will remain on until the client invokes {@link #releaseScreenOn()}, or the user
     * presses the device's power button.
     */
    public synchronized void turnScreenOn() {
        if (mKeepScreenOnWakeLock.isHeld()) {
            // recover from cases when we could get out of sync, this can happen because the user
            // can press the power button, and other wake-locks can prevent intents to be received
            mKeepScreenOnWakeLock.release();
        }
        mKeepScreenOnWakeLock.acquire();
    }

    /**
     * Indicates that the client does not require the screen to remain on anymore.
     *
     * See {@link #turnScreenOn()} for more information.
     */
    public synchronized void releaseScreenOn() {
        if (!mKeepScreenOnWakeLock.isHeld()) {
            return;
        }
        mKeepScreenOnWakeLock.release();
    }

    /**
     * Queues a request to turn off the screen off when the device has been disconnected from a
     * power source (usually upon USB disconnected).
     *
     * (It is useful for Sensor Power Tests, as the Power Monitor usually detaches itself from the
     * device before beginning to sample data).
     */
    public synchronized void turnScreenOffOnNextPowerDisconnect() {
        ensureDeviceAdminInitialized();
        mTurnOffScreenOnPowerDisconnected = true;
    }

    private void ensureDeviceAdminInitialized() throws IllegalStateException {
        if (hasDeviceAdminFeature() && !isDeviceAdminInitialized()) {
            throw new IllegalStateException(""Component must be initialized before it can be used."");
        }
    }

    private boolean isDeviceAdminInitialized() {
        if (!mDevicePolicyManager.isAdminActive(mComponentName)) {
            return false;
        }
        return mDevicePolicyManager
                .hasGrantedPolicy(mComponentName, DeviceAdminInfo.USES_POLICY_FORCE_LOCK);
    }

    private boolean hasDeviceAdminFeature() {
        return mActivity.getPackageManager().hasSystemFeature(PackageManager.FEATURE_DEVICE_ADMIN);
    }

    private class InternalBroadcastReceiver extends BroadcastReceiver {
        @Override
        public void onReceive(Context context, Intent intent) {
            String action = intent.getAction();

            if (TextUtils.equals(action, Intent.ACTION_POWER_DISCONNECTED)) {
                if (mTurnOffScreenOnPowerDisconnected) {
                    turnScreenOff();
                    // reset the flag after it has triggered once, we try to avoid cases when the test
                    // might leave the receiver enabled after itself,
                    // this approach still provides a way to multiplex one time requests
                    mTurnOffScreenOnPowerDisconnected = false;
                }
            }
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.TestListAdapter"	"isTest"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/TestListAdapter.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier;

import static com.android.cts.verifier.TestListActivity.sCurrentDisplayMode;
import static com.android.cts.verifier.TestListActivity.sInitialLaunch;

import android.content.ContentResolver;
import android.content.Context;
import android.content.Intent;
import android.database.ContentObserver;
import android.database.Cursor;
import android.os.AsyncTask;
import android.os.Handler;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.widget.BaseAdapter;
import android.widget.ListView;
import android.widget.TextView;

import com.android.compatibility.common.util.ReportLog;
import com.android.cts.verifier.TestListActivity.DisplayMode;

import java.io.ByteArrayInputStream;
import java.io.IOException;
import java.io.ObjectInputStream;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.atomic.AtomicBoolean;

/**
 * {@link BaseAdapter} that handles loading, refreshing, and setting test
 * results. What tests are shown can be customized by overriding
 * {@link #getRows()}. See {@link ArrayTestListAdapter} and
 * {@link ManifestTestListAdapter} for examples.
 */
public abstract class TestListAdapter extends BaseAdapter {

    /** Activities implementing {@link Intent#ACTION_MAIN} and this will appear in the list. */
    public static final String CATEGORY_MANUAL_TEST = ""android.cts.intent.category.MANUAL_TEST"";

    /** View type for a category of tests like ""Sensors"" or ""Features"" */
    private static final int CATEGORY_HEADER_VIEW_TYPE = 0;

    /** View type for an actual test like the Accelerometer test. */
    private static final int TEST_VIEW_TYPE = 1;

    /** Padding around the text views and icons. */
    private static final int PADDING = 10;

    private final Context mContext;

    /** Immutable data of tests like the test's title and launch intent. */
    private final List<TestListItem> mRows = new ArrayList<TestListItem>();

    /** Mutable test results that will change as each test activity finishes. */
    private final Map<String, Integer> mTestResults = new HashMap<String, Integer>();

    /** Map from test name to test details. */
    private final Map<String, String> mTestDetails = new HashMap<String, String>();

    /** Map from test name to {@link ReportLog}. */
    private final Map<String, ReportLog> mReportLogs = new HashMap<String, ReportLog>();

    /** Map from test name to {@link TestResultHistoryCollection}. */
    private final Map<String, TestResultHistoryCollection> mHistories = new HashMap<>();

    /** Flag to identify whether the mHistories has been loaded. */
    private final AtomicBoolean mHasLoadedResultHistory = new AtomicBoolean(false);

    private final LayoutInflater mLayoutInflater;

    /** Map from display mode to the list of {@link TestListItem}.
     *  Records the TestListItem from main view only, including unfolded mode and folded mode
     *  respectively. */
    protected Map<String, List<TestListItem>> mDisplayModesTests = new HashMap<>();

    /** Flag to identify the test data from {@link ManifestTestListAdapter}.
     *  The source of data for the adapter is various, such as ManifestTestListAdapter and
     *  ArrayTestListAdapter, and the data of foldable tests are from ManifestTestListAdapter. */
    protected static boolean adapterFromManifest;

    /** Flag to identify the test data in main view from {@link ManifestTestListAdapter}.
     *  ManifestTestListAdapter provides test data for main view and subtests.
     *  Getting foldable tests is from main view only. */
    protected static boolean hasTestParentInManifestAdapter;

    /** {@link ListView} row that is either a test category header or a test. */
    public static class TestListItem {

        /** Title shown in the {@link ListView}. */
        final String title;

        /** Test name with class and test ID to uniquely identify the test. Null for categories. */
        String testName;

        /** Intent used to launch the activity from the list. Null for categories. */
        final Intent intent;

        /** Features necessary to run this test. */
        final String[] requiredFeatures;

        /** Configs necessary to run this test. */
        final String[] requiredConfigs;

        /** Intent actions necessary to run this test. */
        final String[] requiredActions;

        /** Features such that, if any present, the test gets excluded from being shown. */
        final String[] excludedFeatures;

        /** If any of of the features are present the test is meaningful to run. */
        final String[] applicableFeatures;

        /** Configs display mode to run this test. */
        final String displayMode;

        // TODO: refactor to use a Builder approach instead

        public static TestListItem newTest(Context context, int titleResId, String testName,
            Intent intent, String[] requiredFeatures, String[] excludedFeatures,
            String[] applicableFeatures) {
            return newTest(context.getString(titleResId), testName, intent, requiredFeatures,
                excludedFeatures, applicableFeatures);
        }

        public static TestListItem newTest(Context context, int titleResId, String testName,
                Intent intent, String[] requiredFeatures, String[] excludedFeatures) {
            return newTest(context.getString(titleResId), testName, intent, requiredFeatures,
                    excludedFeatures, /* applicableFeatures= */ null);
        }

        public static TestListItem newTest(Context context, int titleResId, String testName,
                Intent intent, String[] requiredFeatures) {
            return newTest(context.getString(titleResId), testName, intent, requiredFeatures,
                    /* excludedFeatures= */ null, /* applicableFeatures= */ null);
        }

        public static TestListItem newTest(String title, String testName, Intent intent,
                String[] requiredFeatures, String[] requiredConfigs, String[] requiredActions,
                String[] excludedFeatures, String[] applicableFeatures, String displayMode) {
            return new TestListItem(title, testName, intent, requiredFeatures, requiredConfigs,
                    requiredActions, excludedFeatures, applicableFeatures, displayMode);
        }

        public static TestListItem newTest(String title, String testName, Intent intent,
            String[] requiredFeatures, String[] requiredConfigs, String[] excludedFeatures,
            String[] applicableFeatures) {
            return new TestListItem(title, testName, intent, requiredFeatures, requiredConfigs,
                    /* requiredActions = */ null, excludedFeatures, applicableFeatures,
                    /* displayMode= */ null);
        }

        public static TestListItem newTest(String title, String testName, Intent intent,
                String[] requiredFeatures, String[] excludedFeatures, String[] applicableFeatures) {
            return new TestListItem(title, testName, intent, requiredFeatures,
                    /* requiredConfigs= */ null, /* requiredActions = */ null, excludedFeatures,
                    applicableFeatures, /* displayMode= */ null);
        }

        public static TestListItem newTest(String title, String testName, Intent intent,
                String[] requiredFeatures, String[] excludedFeatures) {
            return new TestListItem(title, testName, intent, requiredFeatures,
                    /* requiredConfigs= */ null, /* requiredActions = */ null, excludedFeatures,
                    /* applicableFeatures= */ null, /* displayMode= */ null);
        }

        public static TestListItem newTest(String title, String testName, Intent intent,
                String[] requiredFeatures) {
            return new TestListItem(title, testName, intent, requiredFeatures,
                    /* requiredConfigs= */ null, /* requiredActions = */ null,
                    /* excludedFeatures= */ null, /* applicableFeatures= */ null,
                    /* displayMode= */ null);
        }

        public static TestListItem newCategory(Context context, int titleResId) {
            return newCategory(context.getString(titleResId));
        }

        public static TestListItem newCategory(String title) {
            return new TestListItem(title, /* testName= */ null, /* intent= */ null,
                    /* requiredFeatures= */ null,  /* requiredConfigs= */ null,
                    /* requiredActions = */ null, /* excludedFeatures= */ null,
                    /* applicableFeatures= */ null, /* displayMode= */ null);
        }

        protected TestListItem(String title, String testName, Intent intent,
                String[] requiredFeatures, String[] excludedFeatures, String[] applicableFeatures) {
            this(title, testName, intent, requiredFeatures, /* requiredConfigs= */ null,
                    /* requiredActions = */ null, excludedFeatures, applicableFeatures,
                    /* displayMode= */ null);
        }

        protected TestListItem(String title, String testName, Intent intent,
                String[] requiredFeatures, String[] requiredConfigs, String[] requiredActions,
                String[] excludedFeatures, String[] applicableFeatures, String displayMode) {
            this.title = title;
            if (!sInitialLaunch) {
                testName = setTestNameSuffix(sCurrentDisplayMode, testName);
            }
            this.testName = testName;
            this.intent = intent;
            this.requiredActions = requiredActions;
            this.requiredFeatures = requiredFeatures;
            this.requiredConfigs = requiredConfigs;
            this.excludedFeatures = excludedFeatures;
            this.applicableFeatures = applicableFeatures;
            this.displayMode = displayMode;
        }

        boolean isTest() {
            return intent != null;
        }
    }

    public TestListAdapter(Context context) {
        this.mContext = context;
        this.mLayoutInflater =
                (LayoutInflater) context.getSystemService(Context.LAYOUT_INFLATER_SERVICE);

        TestResultContentObserver observer = new TestResultContentObserver();
        ContentResolver resolver = context.getContentResolver();
        resolver.registerContentObserver(TestResultsProvider.getResultContentUri(context), true, observer);
    }

    public void loadTestResults() {
        new RefreshTestResultsTask().execute();
    }

    public void clearTestResults() {
        new ClearTestResultsTask().execute();
    }

    public void setTestResult(TestResult testResult) {
        String name = testResult.getName();

        // Append existing history
        TestResultHistoryCollection histories = testResult.getHistoryCollection();
        histories.merge(null, mHistories.get(name));

        new SetTestResultTask(name, testResult.getResult(),
                testResult.getDetails(), testResult.getReportLog(), histories).execute();
    }

    class RefreshTestResultsTask extends AsyncTask<Void, Void, RefreshResult> {
        @Override
        protected RefreshResult doInBackground(Void... params) {
            List<TestListItem> rows = getRows();
            // When initial launch, needs to fetch tests in the unfolded/folded mode
            // to be stored in mDisplayModesTests as the basis for the future switch.
            if (sInitialLaunch) {
                sInitialLaunch = false;
            }

            if (checkTestsFromMainView()) {
                rows = mDisplayModesTests.get(sCurrentDisplayMode);
            }else {
                rows = getRows();
            }
            return getRefreshResults(rows);
        }

        @Override
        protected void onPostExecute(RefreshResult result) {
            super.onPostExecute(result);
            mRows.clear();
            mRows.addAll(result.mItems);
            mTestResults.clear();
            mTestResults.putAll(result.mResults);
            mTestDetails.clear();
            mTestDetails.putAll(result.mDetails);
            mReportLogs.clear();
            mReportLogs.putAll(result.mReportLogs);
            mHistories.clear();
            mHistories.putAll(result.mHistories);
            mHasLoadedResultHistory.set(true);
            notifyDataSetChanged();
        }
    }

    static class RefreshResult {
        List<TestListItem> mItems;
        Map<String, Integer> mResults;
        Map<String, String> mDetails;
        Map<String, ReportLog> mReportLogs;
        Map<String, TestResultHistoryCollection> mHistories;

        RefreshResult(
                List<TestListItem> items,
                Map<String, Integer> results,
                Map<String, String> details,
                Map<String, ReportLog> reportLogs,
                Map<String, TestResultHistoryCollection> histories) {
            mItems = items;
            mResults = results;
            mDetails = details;
            mReportLogs = reportLogs;
            mHistories = histories;
        }
    }

    protected abstract List<TestListItem> getRows();

    static final String[] REFRESH_PROJECTION = {
        TestResultsProvider._ID,
        TestResultsProvider.COLUMN_TEST_NAME,
        TestResultsProvider.COLUMN_TEST_RESULT,
        TestResultsProvider.COLUMN_TEST_DETAILS,
        TestResultsProvider.COLUMN_TEST_METRICS,
        TestResultsProvider.COLUMN_TEST_RESULT_HISTORY,
    };

    RefreshResult getRefreshResults(List<TestListItem> items) {
        Map<String, Integer> results = new HashMap<String, Integer>();
        Map<String, String> details = new HashMap<String, String>();
        Map<String, ReportLog> reportLogs = new HashMap<String, ReportLog>();
        Map<String, TestResultHistoryCollection> histories = new HashMap<>();
        ContentResolver resolver = mContext.getContentResolver();
        Cursor cursor = null;
        try {
            cursor = resolver.query(TestResultsProvider.getResultContentUri(mContext), REFRESH_PROJECTION,
                    null, null, null);
            if (cursor.moveToFirst()) {
                do {
                    String testName = cursor.getString(1);
                    int testResult = cursor.getInt(2);
                    String testDetails = cursor.getString(3);
                    ReportLog reportLog = (ReportLog) deserialize(cursor.getBlob(4));
                    TestResultHistoryCollection historyCollection =
                        (TestResultHistoryCollection) deserialize(cursor.getBlob(5));
                    results.put(testName, testResult);
                    details.put(testName, testDetails);
                    reportLogs.put(testName, reportLog);
                    histories.put(testName, historyCollection);
                } while (cursor.moveToNext());
            }
        } finally {
            if (cursor != null) {
                cursor.close();
            }
        }
        return new RefreshResult(items, results, details, reportLogs, histories);
    }

    class ClearTestResultsTask extends AsyncTask<Void, Void, Void> {

        @Override
        protected Void doInBackground(Void... params) {
            ContentResolver resolver = mContext.getContentResolver();
            resolver.delete(TestResultsProvider.getResultContentUri(mContext), ""1"", null);
            return null;
        }
    }

    class SetTestResultTask extends AsyncTask<Void, Void, Void> {

        private final String mTestName;
        private final int mResult;
        private final String mDetails;
        private final ReportLog mReportLog;
        private final TestResultHistoryCollection mHistoryCollection;

        SetTestResultTask(
                String testName,
                int result,
                String details,
                ReportLog reportLog,
                TestResultHistoryCollection historyCollection) {
            mTestName = testName;
            mResult = result;
            mDetails = details;
            mReportLog = reportLog;
            mHistoryCollection = historyCollection;
        }

        @Override
        protected Void doInBackground(Void... params) {
            if (mHasLoadedResultHistory.get()) {
                mHistoryCollection.merge(null, mHistories.get(mTestName));
            } else {
                // Loads history from ContentProvider directly if it has not been loaded yet.
                ContentResolver resolver = mContext.getContentResolver();

                try (Cursor cursor = resolver.query(
                        TestResultsProvider.getTestNameUri(mContext, mTestName),
                        new String[] {TestResultsProvider.COLUMN_TEST_RESULT_HISTORY},
                        null,
                        null,
                        null)) {
                    if (cursor.moveToFirst()) {
                        do {
                            TestResultHistoryCollection historyCollection =
                                    (TestResultHistoryCollection) deserialize(cursor.getBlob(0));
                            mHistoryCollection.merge(null, historyCollection);
                        } while (cursor.moveToNext());
                    }
                }
            }
            TestResultsProvider.setTestResult(
                    mContext, mTestName, mResult, mDetails, mReportLog, mHistoryCollection);
            return null;
        }
    }

    class TestResultContentObserver extends ContentObserver {

        public TestResultContentObserver() {
            super(new Handler());
        }

        @Override
        public void onChange(boolean selfChange) {
            super.onChange(selfChange);
            loadTestResults();
        }
    }

    @Override
    public boolean areAllItemsEnabled() {
        // Section headers for test categories are not clickable.
        return false;
    }

    @Override
    public boolean isEnabled(int position) {
        return getItem(position).isTest();
    }

    @Override
    public int getItemViewType(int position) {
        return getItem(position).isTest() ? TEST_VIEW_TYPE : CATEGORY_HEADER_VIEW_TYPE;
    }

    @Override
    public int getViewTypeCount() {
        return 2;
    }

    @Override
    public int getCount() {
        if (!sInitialLaunch && checkTestsFromMainView()) {
            return mDisplayModesTests.getOrDefault(sCurrentDisplayMode, new ArrayList<>()).size();
        }
        return mRows.size();
    }

    @Override
    public TestListItem getItem(int position) {
        if (checkTestsFromMainView()) {
            return mDisplayModesTests.get(sCurrentDisplayMode).get(position);
        }
        return mRows.get(position);
    }

    @Override
    public long getItemId(int position) {
        return position;
    }

    public int getTestResult(int position) {
        TestListItem item = getItem(position);
        return mTestResults.containsKey(item.testName)
                ? mTestResults.get(item.testName)
                : TestResult.TEST_RESULT_NOT_EXECUTED;
    }

    public String getTestDetails(int position) {
        TestListItem item = getItem(position);
        return mTestDetails.containsKey(item.testName)
                ? mTestDetails.get(item.testName)
                : null;
    }

    public ReportLog getReportLog(int position) {
        TestListItem item = getItem(position);
        return mReportLogs.containsKey(item.testName)
                ? mReportLogs.get(item.testName)
                : null;
    }

    /**
     * Get test result histories.
     *
     * @param position The position of test.
     * @return A {@link TestResultHistoryCollection} object containing test result histories of tests.
     */
    public TestResultHistoryCollection getHistoryCollection(int position) {
        TestListItem item = getItem(position);
        return mHistories.containsKey(item.testName)
            ? mHistories.get(item.testName)
            : null;
    }

    /**
     * Get test item by the given display mode and position.
     *
     * @param mode The display mode.
     * @param position The position of test.
     * @return A {@link TestListItem} object containing the test item.
     */
    public TestListItem getItem(String mode, int position) {
        return mDisplayModesTests.get(mode).get(position);
    }

    /**
     * Get test item count by the given display mode.
     *
     * @param mode The display mode.
     * @return A count of test items.
     */
    public int getCount(String mode){
        return mDisplayModesTests.getOrDefault(mode, new ArrayList<>()).size();
    }

    /**
     * Get test result by the given display mode and position.
     *
     * @param mode The display mode.
     * @param position The position of test.
     * @return The test item result.
     */
    public int getTestResult(String mode, int position) {
        TestListItem item = mDisplayModesTests.get(mode).get(position);
        return mTestResults.containsKey(item.testName)
            ? mTestResults.get(item.testName)
            : TestResult.TEST_RESULT_NOT_EXECUTED;
    }

    /**
     * Get test details by the given display mode and position.
     *
     * @param mode The display mode.
     * @param position The position of test.
     * @return A string containing the test details.
     */
    public String getTestDetails(String mode, int position) {
        TestListItem item = mDisplayModesTests.get(mode).get(position);
        return mTestDetails.containsKey(item.testName)
            ? mTestDetails.get(item.testName)
            : null;
    }

    /**
     * Get test report log by the given display mode and position.
     *
     * @param mode The display mode.
     * @param position The position of test.
     * @return A {@link ReportLog} object containing the test report log of the test item.
     */
    public ReportLog getReportLog(String mode, int position) {
        TestListItem item = mDisplayModesTests.get(mode).get(position);
        return mReportLogs.containsKey(item.testName)
            ? mReportLogs.get(item.testName)
            : null;
    }

    /**
     * Get test result histories by the given display mode and position.
     *
     * @param mode The display mode.
     * @param position The position of test.
     * @return A {@link TestResultHistoryCollection} object containing the test result histories of
     *         the test item.
     */
    public TestResultHistoryCollection getHistoryCollection(String mode, int position) {
        TestListItem item = mDisplayModesTests.get(mode).get(position);
        return mHistories.containsKey(item.testName)
            ? mHistories.get(item.testName)
            : null;
    }

    public boolean allTestsPassed() {
        for (TestListItem item : mRows) {
            if (item.isTest() && (!mTestResults.containsKey(item.testName)
                    || (mTestResults.get(item.testName) != TestResult.TEST_RESULT_PASSED))) {
                return false;
            }
        }
        return true;
    }

    @Override
    public View getView(int position, View convertView, ViewGroup parent) {
        TextView textView;
        if (convertView == null) {
            int layout = getLayout(position);
            textView = (TextView) mLayoutInflater.inflate(layout, parent, false);
        } else {
            textView = (TextView) convertView;
        }

        TestListItem item = getItem(position);
        textView.setText(item.title);
        textView.setPadding(PADDING, 0, PADDING, 0);
        textView.setCompoundDrawablePadding(PADDING);

        if (item.isTest()) {
            int testResult = getTestResult(position);
            int backgroundResource = 0;
            int iconResource = 0;

            /** TODO: Remove fs_ prefix from feature icons since they are used here too. */
            switch (testResult) {
                case TestResult.TEST_RESULT_PASSED:
                    backgroundResource = R.drawable.test_pass_gradient;
                    iconResource = R.drawable.fs_good;
                    break;

                case TestResult.TEST_RESULT_FAILED:
                    backgroundResource = R.drawable.test_fail_gradient;
                    iconResource = R.drawable.fs_error;
                    break;

                case TestResult.TEST_RESULT_NOT_EXECUTED:
                    break;

                default:
                    throw new IllegalArgumentException(""Unknown test result: "" + testResult);
            }

            textView.setBackgroundResource(backgroundResource);
            textView.setCompoundDrawablesWithIntrinsicBounds(0, 0, iconResource, 0);
        }

        return textView;
    }

    private int getLayout(int position) {
        int viewType = getItemViewType(position);
        switch (viewType) {
            case CATEGORY_HEADER_VIEW_TYPE:
                return R.layout.test_category_row;
            case TEST_VIEW_TYPE:
                return android.R.layout.simple_list_item_1;
            default:
                throw new IllegalArgumentException(""Illegal view type: "" + viewType);

        }
    }

    public static Object deserialize(byte[] bytes) {
        if (bytes == null || bytes.length == 0) {
            return null;
        }
        ByteArrayInputStream byteStream = new ByteArrayInputStream(bytes);
        ObjectInputStream objectInput = null;
        try {
            objectInput = new ObjectInputStream(byteStream);
            return objectInput.readObject();
        } catch (IOException e) {
            return null;
        } catch (ClassNotFoundException e) {
            return null;
        } finally {
            try {
                if (objectInput != null) {
                    objectInput.close();
                }
                byteStream.close();
            } catch (IOException e) {
                // Ignore close exception.
            }
        }
    }

    /**
     * Sets test name suffix. In the folded mode, the suffix is [folded]; otherwise, it is empty
     * string.
     *
     * @param mode A string of current display mode.
     * @param name A string of test name.
     * @return A string of test name with suffix, [folded], in the folded mode.
     *         A string of input test name in the unfolded mode.
     */
    public static String setTestNameSuffix(String mode, String name) {
        if (name != null && mode.equals(DisplayMode.FOLDED.toString())
            && !name.endsWith(DisplayMode.FOLDED.asSuffix())){
            return name + DisplayMode.FOLDED.asSuffix();
        }
        return name;
    }

    /**
     * Checks if the tests are from main view for foldable tests.
     *
     * @return True if the tests from main view, otherwise, return false.
     */
    private static boolean checkTestsFromMainView() {
        return adapterFromManifest && !hasTestParentInManifestAdapter;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ImageReaderTest"	"testRaw"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ImageReaderTest.java"	""	"public void testRaw() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.v(TAG, ""Testing raw capture for camera "" + id);
                openDevice(id);

                bufferFormatTestByCamera(ImageFormat.RAW_SENSOR, /*repeating*/false);
            } finally {
                closeDevice(id);
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ImageReaderTest"	"testRepeatingRaw"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ImageReaderTest.java"	""	"public void testRepeatingRaw() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.v(TAG, ""Testing repeating raw capture for camera "" + id);
                openDevice(id);

                bufferFormatTestByCamera(ImageFormat.RAW_SENSOR, /*repeating*/true);
            } finally {
                closeDevice(id);
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ImageReaderTest"	"testLongProcessingRepeatingRaw"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ImageReaderTest.java"	""	"public void testLongProcessingRepeatingRaw() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.v(TAG, ""Testing long processing on repeating raw for camera "" + id);

                if (!mAllStaticInfo.get(id).isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                    continue;
                }
                openDevice(id);

                bufferFormatLongProcessingTimeTestByCamera(ImageFormat.RAW_SENSOR);
            } finally {
                closeDevice(id);
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ImageReaderTest"	"testLongProcessingRepeatingFlexibleYuv"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ImageReaderTest.java"	""	"public void testLongProcessingRepeatingFlexibleYuv() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.v(TAG, ""Testing long processing on repeating YUV for camera "" + id);

                if (!mAllStaticInfo.get(id).isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                    continue;
                }

                openDevice(id);
                bufferFormatLongProcessingTimeTestByCamera(ImageFormat.YUV_420_888);
            } finally {
                closeDevice(id);
            }
        }
    }

    /**
     * Test invalid access of image after an image is closed, further access
     * of the image will get an IllegalStateException. The basic assumption of
     * this test is that the ImageReader always gives direct byte buffer, which is always true
     * for camera case. For if the produced image byte buffer is not direct byte buffer, there
     * is no guarantee to get an ISE for this invalid access case.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ImageReaderTest"	"testYuvAndJpegWithUsageFlag"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ImageReaderTest.java"	""	"public void testYuvAndJpegWithUsageFlag() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.v(TAG, ""YUV and JPEG testing for camera "" + id);
                if (!mAllStaticInfo.get(id).isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + id +
                            "" does not support color outputs, skipping"");
                    continue;
                }
                openDevice(id);
                bufferFormatWithYuvTestByCamera(ImageFormat.JPEG, true);
            } finally {
                closeDevice(id);
            }
        }
    }

    /**
     * Test two image stream (YUV420_888 and RAW_SENSOR) capture by using ImageReader.
     *
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ImageReaderTest"	"testImageReaderYuvAndRaw"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ImageReaderTest.java"	""	"public void testImageReaderYuvAndRaw() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.v(TAG, ""YUV and RAW testing for camera "" + id);
                if (!mAllStaticInfo.get(id).isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + id +
                            "" does not support color outputs, skipping"");
                    continue;
                }
                openDevice(id);
                bufferFormatWithYuvTestByCamera(ImageFormat.RAW_SENSOR);
            } finally {
                closeDevice(id);
            }
        }
    }

    /**
     * If the camera device advertises the SECURE_IAMGE_DATA capability, test
     * ImageFormat.PRIVATE + PROTECTED usage capture by using ImageReader with the
     * ImageReader factory method that has usage flag argument, and uses a custom usage flag.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ImageReaderTest"	"testImageReaderPrivateWithProtectedUsageFlag"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ImageReaderTest.java"	""	"public void testImageReaderPrivateWithProtectedUsageFlag() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.v(TAG, ""Private format and protected usage testing for camera "" + id);
                List<String> testCameraIds = new ArrayList<>();

                if (mAllStaticInfo.get(id).isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_SECURE_IMAGE_DATA)) {
                    // Test the camera id without using physical camera
                    testCameraIds.add(null);
                }

                if (mAllStaticInfo.get(id).isLogicalMultiCamera()) {
                    Set<String> physicalIdsSet =
                        mAllStaticInfo.get(id).getCharacteristics().getPhysicalCameraIds();
                    for (String physicalId : physicalIdsSet) {
                        if (mAllStaticInfo.get(physicalId).isCapabilitySupported(
                                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_SECURE_IMAGE_DATA)) {
                            testCameraIds.add(physicalId);
                        }
                    }
                }

                if (testCameraIds.isEmpty()) {
                    Log.i(TAG, ""Camera "" + id +
                            "" does not support secure image data capability, skipping"");
                    continue;
                }
                openDevice(id);

                for (String testCameraId : testCameraIds) {
                    bufferFormatTestByCamera(ImageFormat.PRIVATE, /*setUsageFlag*/ true,
                            HardwareBuffer.USAGE_PROTECTED_CONTENT, /*repeating*/ true,
                            /*checkSession*/ true, /*validateImageData*/ false,
                            testCameraId);
                }
            } finally {
                closeDevice(id);
            }
        }
    }

    /**
     * Test two image stream (YUV420_888 and RAW_SENSOR) capture by using ImageReader with the
     * ImageReader factory method that has usage flag argument.
     *
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ImageReaderTest"	"testImageReaderYuvAndRawWithUsageFlag"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ImageReaderTest.java"	""	"public void testImageReaderYuvAndRawWithUsageFlag() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.v(TAG, ""YUV and RAW testing for camera "" + id);
                if (!mAllStaticInfo.get(id).isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + id +
                            "" does not support color outputs, skipping"");
                    continue;
                }
                openDevice(id);
                bufferFormatWithYuvTestByCamera(ImageFormat.RAW_SENSOR, true);
            } finally {
                closeDevice(id);
            }
        }
    }

    /**
     * Check that the center patches for YUV and JPEG outputs for the same frame match for each YUV
     * resolution and format supported.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ImageReaderTest"	"testUsageRespected"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ImageReaderTest.java"	""	"public void testUsageRespected() throws Exception {
        final long REQUESTED_USAGE_BITS =
                HardwareBuffer.USAGE_GPU_COLOR_OUTPUT | HardwareBuffer.USAGE_GPU_SAMPLED_IMAGE;
        ImageReader reader = ImageReader.newInstance(1, 1, PixelFormat.RGBA_8888, 1,
                REQUESTED_USAGE_BITS);
        Surface surface = reader.getSurface();
        Canvas canvas = surface.lockHardwareCanvas();
        canvas.drawColor(Color.RED);
        surface.unlockCanvasAndPost(canvas);
        Image image = null;
        for (int i = 0; i < 100; i++) {
            image = reader.acquireNextImage();
            if (image != null) break;
            Thread.sleep(10);
        }
        assertNotNull(image);
        HardwareBuffer buffer = image.getHardwareBuffer();
        assertNotNull(buffer);
        // Mask off the upper vendor bits
        int myBits = (int) (buffer.getUsage() & 0xFFFFFFF);
        assertWithMessage(""Usage bits %s did not contain requested usage bits %s"", myBits,
                REQUESTED_USAGE_BITS).that(myBits & REQUESTED_USAGE_BITS)
                        .isEqualTo(REQUESTED_USAGE_BITS);
    }

    /**
     * Convert a rectangular patch in a YUV image to an ARGB color array.
     *
     * @param w width of the patch.
     * @param h height of the patch.
     * @param wOffset offset of the left side of the patch.
     * @param hOffset offset of the top of the patch.
     * @param yuvImage a YUV image to select a patch from.
     * @return the image patch converted to RGB as an ARGB color array.
     */
    private static int[] convertPixelYuvToRgba(int w, int h, int wOffset, int hOffset,
                                               Image yuvImage) {
        final int CHANNELS = 3; // yuv
        final float COLOR_RANGE = 255f;

        assertTrue(""Invalid argument to convertPixelYuvToRgba"",
                w > 0 && h > 0 && wOffset >= 0 && hOffset >= 0);
        assertNotNull(yuvImage);

        int imageFormat = yuvImage.getFormat();
        assertTrue(""YUV image must have YUV-type format"",
                imageFormat == ImageFormat.YUV_420_888 || imageFormat == ImageFormat.YV12 ||
                        imageFormat == ImageFormat.NV21);

        int height = yuvImage.getHeight();
        int width = yuvImage.getWidth();

        Rect imageBounds = new Rect(/*left*/0, /*top*/0, /*right*/width, /*bottom*/height);
        Rect crop = new Rect(/*left*/wOffset, /*top*/hOffset, /*right*/wOffset + w,
                /*bottom*/hOffset + h);
        assertTrue(""Output rectangle"" + crop + "" must lie within image bounds "" + imageBounds,
                imageBounds.contains(crop));
        Image.Plane[] planes = yuvImage.getPlanes();

        Image.Plane yPlane = planes[0];
        Image.Plane cbPlane = planes[1];
        Image.Plane crPlane = planes[2];

        ByteBuffer yBuf = yPlane.getBuffer();
        int yPixStride = yPlane.getPixelStride();
        int yRowStride = yPlane.getRowStride();
        ByteBuffer cbBuf = cbPlane.getBuffer();
        int cbPixStride = cbPlane.getPixelStride();
        int cbRowStride = cbPlane.getRowStride();
        ByteBuffer crBuf = crPlane.getBuffer();
        int crPixStride = crPlane.getPixelStride();
        int crRowStride = crPlane.getRowStride();

        int[] output = new int[w * h];

        // TODO: Optimize this with renderscript intrinsics
        byte[] yRow = new byte[yPixStride * (w - 1) + 1];
        byte[] cbRow = new byte[cbPixStride * (w / 2 - 1) + 1];
        byte[] crRow = new byte[crPixStride * (w / 2 - 1) + 1];
        yBuf.mark();
        cbBuf.mark();
        crBuf.mark();
        int initialYPos = yBuf.position();
        int initialCbPos = cbBuf.position();
        int initialCrPos = crBuf.position();
        int outputPos = 0;
        for (int i = hOffset; i < hOffset + h; i++) {
            yBuf.position(initialYPos + i * yRowStride + wOffset * yPixStride);
            yBuf.get(yRow);
            if ((i & 1) == (hOffset & 1)) {
                cbBuf.position(initialCbPos + (i / 2) * cbRowStride + wOffset * cbPixStride / 2);
                cbBuf.get(cbRow);
                crBuf.position(initialCrPos + (i / 2) * crRowStride + wOffset * crPixStride / 2);
                crBuf.get(crRow);
            }
            for (int j = 0, yPix = 0, crPix = 0, cbPix = 0; j < w; j++, yPix += yPixStride) {
                float y = yRow[yPix] & 0xFF;
                float cb = cbRow[cbPix] & 0xFF;
                float cr = crRow[crPix] & 0xFF;

                // convert YUV -> RGB (from JFIF's ""Conversion to and from RGB"" section)
                int r = (int) Math.max(0.0f, Math.min(COLOR_RANGE, y + 1.402f * (cr - 128)));
                int g = (int) Math.max(0.0f,
                        Math.min(COLOR_RANGE, y - 0.34414f * (cb - 128) - 0.71414f * (cr - 128)));
                int b = (int) Math.max(0.0f, Math.min(COLOR_RANGE, y + 1.772f * (cb - 128)));

                // Convert to ARGB pixel color (use opaque alpha)
                output[outputPos++] = Color.rgb(r, g, b);

                if ((j & 1) == 1) {
                    crPix += crPixStride;
                    cbPix += cbPixStride;
                }
            }
        }
        yBuf.rewind();
        cbBuf.rewind();
        crBuf.rewind();

        return output;
    }

    /**
     * Test capture a given format stream with yuv stream simultaneously.
     *
     * <p>Use fixed yuv size, varies targeted format capture size. Single capture is tested.</p>
     *
     * @param format The capture format to be tested along with yuv format.
     */
    private void bufferFormatWithYuvTestByCamera(int format) throws Exception {
        bufferFormatWithYuvTestByCamera(format, false);
    }

    /**
     * Test capture a given format stream with yuv stream simultaneously.
     *
     * <p>Use fixed yuv size, varies targeted format capture size. Single capture is tested.</p>
     *
     * @param format The capture format to be tested along with yuv format.
     * @param setUsageFlag The ImageReader factory method to be used (with or without specifying
     *                     usage flag)
     */
    private void bufferFormatWithYuvTestByCamera(int format, boolean setUsageFlag)
            throws Exception {
        if (format != ImageFormat.JPEG && format != ImageFormat.RAW_SENSOR
                && format != ImageFormat.YUV_420_888) {
            throw new IllegalArgumentException(""Unsupported format: "" + format);
        }

        final int NUM_SINGLE_CAPTURE_TESTED = MAX_NUM_IMAGES - 1;
        Size maxYuvSz = mOrderedPreviewSizes.get(0);
        Size[] targetCaptureSizes = mStaticInfo.getAvailableSizesForFormatChecked(format,
                StaticMetadata.StreamDirection.Output);

        for (Size captureSz : targetCaptureSizes) {
            if (VERBOSE) {
                Log.v(TAG, ""Testing yuv size "" + maxYuvSz.toString() + "" and capture size ""
                        + captureSz.toString() + "" for camera "" + mCamera.getId());
            }

            ImageReader captureReader = null;
            ImageReader yuvReader = null;
            try {
                // Create YUV image reader
                SimpleImageReaderListener yuvListener  = new SimpleImageReaderListener();
                if (setUsageFlag) {
                    yuvReader = createImageReader(maxYuvSz, ImageFormat.YUV_420_888, MAX_NUM_IMAGES,
                            HardwareBuffer.USAGE_CPU_READ_OFTEN, yuvListener);
                } else {
                    yuvReader = createImageReader(maxYuvSz, ImageFormat.YUV_420_888, MAX_NUM_IMAGES,
                            yuvListener);
                }

                Surface yuvSurface = yuvReader.getSurface();

                // Create capture image reader
                SimpleImageReaderListener captureListener = new SimpleImageReaderListener();
                if (setUsageFlag) {
                    captureReader = createImageReader(captureSz, format, MAX_NUM_IMAGES,
                            HardwareBuffer.USAGE_CPU_READ_OFTEN, captureListener);
                } else {
                    captureReader = createImageReader(captureSz, format, MAX_NUM_IMAGES,
                            captureListener);
                }
                Surface captureSurface = captureReader.getSurface();

                // Capture images.
                List<Surface> outputSurfaces = new ArrayList<Surface>();
                outputSurfaces.add(yuvSurface);
                outputSurfaces.add(captureSurface);
                CaptureRequest.Builder request = prepareCaptureRequestForSurfaces(outputSurfaces,
                        CameraDevice.TEMPLATE_PREVIEW);
                SimpleCaptureCallback resultListener = new SimpleCaptureCallback();

                for (int i = 0; i < NUM_SINGLE_CAPTURE_TESTED; i++) {
                    startCapture(request.build(), /*repeating*/false, resultListener, mHandler);
                }

                // Verify capture result and images
                for (int i = 0; i < NUM_SINGLE_CAPTURE_TESTED; i++) {
                    resultListener.getCaptureResult(CAPTURE_WAIT_TIMEOUT_MS);
                    if (VERBOSE) {
                        Log.v(TAG, "" Got the capture result back for "" + i + ""th capture"");
                    }

                    Image yuvImage = yuvListener.getImage(CAPTURE_WAIT_TIMEOUT_MS);
                    if (VERBOSE) {
                        Log.v(TAG, "" Got the yuv image back for "" + i + ""th capture"");
                    }

                    Image captureImage = captureListener.getImage(CAPTURE_WAIT_TIMEOUT_MS);
                    if (VERBOSE) {
                        Log.v(TAG, "" Got the capture image back for "" + i + ""th capture"");
                    }

                    //Validate captured images.
                    CameraTestUtils.validateImage(yuvImage, maxYuvSz.getWidth(),
                            maxYuvSz.getHeight(), ImageFormat.YUV_420_888, /*filePath*/null);
                    CameraTestUtils.validateImage(captureImage, captureSz.getWidth(),
                            captureSz.getHeight(), format, /*filePath*/null);
                    yuvImage.close();
                    captureImage.close();
                }

                // Stop capture, delete the streams.
                stopCapture(/*fast*/false);
            } finally {
                closeImageReader(captureReader);
                captureReader = null;
                closeImageReader(yuvReader);
                yuvReader = null;
            }
        }
    }

    private void invalidAccessTestAfterClose() throws Exception {
        final int FORMAT = mStaticInfo.isColorOutputSupported() ?
            ImageFormat.YUV_420_888 : ImageFormat.DEPTH16;

        Size[] availableSizes = mStaticInfo.getAvailableSizesForFormatChecked(FORMAT,
                StaticMetadata.StreamDirection.Output);
        Image img = null;
        // Create ImageReader.
        mListener = new SimpleImageListener();
        createDefaultImageReader(availableSizes[0], FORMAT, MAX_NUM_IMAGES, mListener);

        // Start capture.
        CaptureRequest request = prepareCaptureRequest();
        SimpleCaptureCallback listener = new SimpleCaptureCallback();
        startCapture(request, /* repeating */false, listener, mHandler);

        mListener.waitForAnyImageAvailable(CAPTURE_WAIT_TIMEOUT_MS);
        img = mReader.acquireNextImage();
        Plane firstPlane = img.getPlanes()[0];
        ByteBuffer buffer = firstPlane.getBuffer();
        img.close();

        imageInvalidAccessTestAfterClose(img, firstPlane, buffer);
    }

    /**
     * Test that images captured after discarding free buffers are valid.
     */
    private void discardFreeBuffersTestByCamera() throws Exception {
        final int FORMAT = mStaticInfo.isColorOutputSupported() ?
            ImageFormat.YUV_420_888 : ImageFormat.DEPTH16;

        final Size SIZE = mStaticInfo.getAvailableSizesForFormatChecked(FORMAT,
                StaticMetadata.StreamDirection.Output)[0];
        // Create ImageReader.
        mListener = new SimpleImageListener();
        createDefaultImageReader(SIZE, FORMAT, MAX_NUM_IMAGES, mListener);

        // Start capture.
        final boolean REPEATING = true;
        final boolean SINGLE = false;
        CaptureRequest request = prepareCaptureRequest();
        SimpleCaptureCallback listener = new SimpleCaptureCallback();
        startCapture(request, REPEATING, listener, mHandler);

        // Validate images and capture results.
        validateImage(SIZE, FORMAT, NUM_FRAME_VERIFIED, REPEATING);
        validateCaptureResult(FORMAT, SIZE, listener, NUM_FRAME_VERIFIED);

        // Discard free buffers.
        mReader.discardFreeBuffers();

        // Validate images and capture resulst again.
        validateImage(SIZE, FORMAT, NUM_FRAME_VERIFIED, REPEATING);
        validateCaptureResult(FORMAT, SIZE, listener, NUM_FRAME_VERIFIED);

        // Stop repeating request in preparation for discardFreeBuffers
        mCameraSession.stopRepeating();
        mCameraSessionListener.getStateWaiter().waitForState(
                BlockingSessionCallback.SESSION_READY, SESSION_READY_TIMEOUT_MS);

        // Drain the reader queue and discard free buffers from the reader.
        Image img = mReader.acquireLatestImage();
        if (img != null) {
            img.close();
        }
        mReader.discardFreeBuffers();

        // Do a single capture for camera device to reallocate buffers
        mListener.reset();
        startCapture(request, SINGLE, listener, mHandler);
        validateImage(SIZE, FORMAT, /*captureCount*/1, SINGLE);
    }

    private void bufferFormatTestByCamera(int format, boolean repeating) throws Exception {
        bufferFormatTestByCamera(format, /*setUsageFlag*/ false,
                HardwareBuffer.USAGE_CPU_READ_OFTEN, repeating,
                /*checkSession*/ false, /*validateImageData*/ true);
    }

    private void bufferFormatTestByCamera(int format, boolean repeating, boolean checkSession)
            throws Exception {
        bufferFormatTestByCamera(format, /*setUsageFlag*/ false,
                HardwareBuffer.USAGE_CPU_READ_OFTEN,
                repeating, checkSession, /*validateImageData*/true);
    }

    private void bufferFormatTestByCamera(int format, boolean setUsageFlag, long usageFlag,
            boolean repeating, boolean checkSession, boolean validateImageData) throws Exception {
        bufferFormatTestByCamera(format, setUsageFlag, usageFlag, repeating, checkSession,
                validateImageData, /*physicalId*/null);
    }

    private void bufferFormatTestByCamera(int format, boolean setUsageFlag, long usageFlag,
            // TODO: Consider having some sort of test configuration class passed to reduce the
            //       proliferation of parameters ?
            boolean repeating, boolean checkSession, boolean validateImageData, String physicalId)
            throws Exception {
        StaticMetadata staticInfo;
        if (physicalId == null) {
            staticInfo = mStaticInfo;
        } else {
            staticInfo = mAllStaticInfo.get(physicalId);
        }

        Size[] availableSizes = staticInfo.getAvailableSizesForFormatChecked(format,
                StaticMetadata.StreamDirection.Output);

        boolean secureTest = setUsageFlag &&
                ((usageFlag & HardwareBuffer.USAGE_PROTECTED_CONTENT) != 0);
        Size secureDataSize = null;
        if (secureTest) {
            secureDataSize = staticInfo.getCharacteristics().get(
                    CameraCharacteristics.SCALER_DEFAULT_SECURE_IMAGE_SIZE);
        }

        // for each resolution, test imageReader:
        for (Size sz : availableSizes) {
            try {
                // For secure mode test only test default secure data size if HAL advertises one.
                if (secureDataSize != null && !secureDataSize.equals(sz)) {
                    continue;
                }

                if (VERBOSE) {
                    Log.v(TAG, ""Testing size "" + sz.toString() + "" format "" + format
                            + "" for camera "" + mCamera.getId());
                }

                // Create ImageReader.
                mListener  = new SimpleImageListener();
                if (setUsageFlag) {
                    createDefaultImageReader(sz, format, MAX_NUM_IMAGES, usageFlag, mListener);
                } else {
                    createDefaultImageReader(sz, format, MAX_NUM_IMAGES, mListener);
                }

                // Don't queue up images if we won't validate them
                if (!validateImageData) {
                    ImageDropperListener imageDropperListener = new ImageDropperListener();
                    mReader.setOnImageAvailableListener(imageDropperListener, mHandler);
                }

                if (checkSession) {
                    checkImageReaderSessionConfiguration(
                            ""Camera capture session validation for format: "" + format + ""failed"",
                            physicalId);
                }

                ArrayList<OutputConfiguration> outputConfigs = new ArrayList<>();
                OutputConfiguration config = new OutputConfiguration(mReader.getSurface());
                if (physicalId != null) {
                    config.setPhysicalCameraId(physicalId);
                }
                outputConfigs.add(config);
                CaptureRequest request = prepareCaptureRequestForConfigs(
                        outputConfigs, CameraDevice.TEMPLATE_PREVIEW).build();

                SimpleCaptureCallback listener = new SimpleCaptureCallback();
                startCapture(request, repeating, listener, mHandler);

                int numFrameVerified = repeating ? NUM_FRAME_VERIFIED : 1;

                if (validateImageData) {
                    // Validate images.
                    validateImage(sz, format, numFrameVerified, repeating);
                }

                // Validate capture result.
                validateCaptureResult(format, sz, listener, numFrameVerified);

                // stop capture.
                stopCapture(/*fast*/false);
            } finally {
                closeDefaultImageReader();
            }

        }
    }

    private void bufferFormatLongProcessingTimeTestByCamera(int format)
            throws Exception {

        final int TEST_SENSITIVITY_VALUE = mStaticInfo.getSensitivityClampToRange(204);
        final long TEST_EXPOSURE_TIME_NS = mStaticInfo.getExposureClampToRange(28000000);
        final long EXPOSURE_TIME_ERROR_MARGIN_NS = 100000;

        Size[] availableSizes = mStaticInfo.getAvailableSizesForFormatChecked(format,
                StaticMetadata.StreamDirection.Output);

        // for each resolution, test imageReader:
        for (Size sz : availableSizes) {
            Log.v(TAG, ""testing size "" + sz.toString());
            try {
                if (VERBOSE) {
                    Log.v(TAG, ""Testing long processing time: size "" + sz.toString() + "" format "" +
                            format + "" for camera "" + mCamera.getId());
                }

                // Create ImageReader.
                mListener  = new SimpleImageListener();
                createDefaultImageReader(sz, format, MAX_NUM_IMAGES, mListener);

                // Setting manual controls
                List<Surface> outputSurfaces = new ArrayList<Surface>();
                outputSurfaces.add(mReader.getSurface());
                CaptureRequest.Builder requestBuilder = prepareCaptureRequestForSurfaces(
                        outputSurfaces, CameraDevice.TEMPLATE_STILL_CAPTURE);

                requestBuilder.set(
                        CaptureRequest.CONTROL_MODE, CaptureRequest.CONTROL_MODE_OFF);
                requestBuilder.set(CaptureRequest.CONTROL_AE_LOCK, true);
                requestBuilder.set(CaptureRequest.CONTROL_AWB_LOCK, true);
                requestBuilder.set(CaptureRequest.CONTROL_AE_MODE,
                        CaptureRequest.CONTROL_AE_MODE_OFF);
                requestBuilder.set(CaptureRequest.CONTROL_AWB_MODE,
                        CaptureRequest.CONTROL_AWB_MODE_OFF);
                requestBuilder.set(CaptureRequest.SENSOR_SENSITIVITY, TEST_SENSITIVITY_VALUE);
                requestBuilder.set(CaptureRequest.SENSOR_EXPOSURE_TIME, TEST_EXPOSURE_TIME_NS);

                SimpleCaptureCallback listener = new SimpleCaptureCallback();
                startCapture(requestBuilder.build(), /*repeating*/true, listener, mHandler);

                for (int i = 0; i < NUM_LONG_PROCESS_TIME_FRAME_VERIFIED; i++) {
                    mListener.waitForAnyImageAvailable(CAPTURE_WAIT_TIMEOUT_MS);

                    // Verify image.
                    Image img = mReader.acquireNextImage();
                    assertNotNull(""Unable to acquire next image"", img);
                    CameraTestUtils.validateImage(img, sz.getWidth(), sz.getHeight(), format,
                            mDebugFileNameBase);

                    // Verify the exposure time and iso match the requested values.
                    CaptureResult result = listener.getCaptureResult(CAPTURE_RESULT_TIMEOUT_MS);

                    long exposureTimeDiff = TEST_EXPOSURE_TIME_NS -
                            getValueNotNull(result, CaptureResult.SENSOR_EXPOSURE_TIME);
                    int sensitivityDiff = TEST_SENSITIVITY_VALUE -
                            getValueNotNull(result, CaptureResult.SENSOR_SENSITIVITY);

                    mCollector.expectTrue(
                            String.format(""Long processing frame %d format %d size %s "" +
                                    ""exposure time was %d expecting %d."", i, format, sz.toString(),
                                    getValueNotNull(result, CaptureResult.SENSOR_EXPOSURE_TIME),
                                    TEST_EXPOSURE_TIME_NS),
                            exposureTimeDiff < EXPOSURE_TIME_ERROR_MARGIN_NS &&
                            exposureTimeDiff >= 0);

                    mCollector.expectTrue(
                            String.format(""Long processing frame %d format %d size %s "" +
                                    ""sensitivity was %d expecting %d."", i, format, sz.toString(),
                                    getValueNotNull(result, CaptureResult.SENSOR_SENSITIVITY),
                                    TEST_SENSITIVITY_VALUE),
                            sensitivityDiff >= 0);


                    // Sleep to Simulate long porcessing before closing the image.
                    Thread.sleep(LONG_PROCESS_TIME_MS);
                    img.close();
                }
                // Stop capture.
                // Drain the reader queue in case the full queue blocks
                // HAL from delivering new results
                ImageDropperListener imageDropperListener = new ImageDropperListener();
                mReader.setOnImageAvailableListener(imageDropperListener, mHandler);
                Image img = mReader.acquireLatestImage();
                if (img != null) {
                    img.close();
                }
                stopCapture(/*fast*/false);
            } finally {
                closeDefaultImageReader();
            }
        }
    }

    /**
     * Validate capture results.
     *
     * @param format The format of this capture.
     * @param size The capture size.
     * @param listener The capture listener to get capture result callbacks.
     */
    private void validateCaptureResult(int format, Size size, SimpleCaptureCallback listener,
            int numFrameVerified) {
        for (int i = 0; i < numFrameVerified; i++) {
            CaptureResult result = listener.getCaptureResult(CAPTURE_RESULT_TIMEOUT_MS);

            // TODO: Update this to use availableResultKeys once shim supports this.
            if (mStaticInfo.isCapabilitySupported(
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_READ_SENSOR_SETTINGS)) {
                Long exposureTime = getValueNotNull(result, CaptureResult.SENSOR_EXPOSURE_TIME);
                Integer sensitivity = getValueNotNull(result, CaptureResult.SENSOR_SENSITIVITY);
                mCollector.expectInRange(
                        String.format(
                                ""Capture for format %d, size %s exposure time is invalid."",
                                format, size.toString()),
                        exposureTime,
                        mStaticInfo.getExposureMinimumOrDefault(),
                        mStaticInfo.getExposureMaximumOrDefault()
                );
                mCollector.expectInRange(
                        String.format(""Capture for format %d, size %s sensitivity is invalid."",
                                format, size.toString()),
                        sensitivity,
                        mStaticInfo.getSensitivityMinimumOrDefault(),
                        mStaticInfo.getSensitivityMaximumOrDefault()
                );
            }
            // TODO: add more key validations.
        }
    }

    private final class SimpleImageListener implements ImageReader.OnImageAvailableListener {
        private final ConditionVariable imageAvailable = new ConditionVariable();
        @Override
        public void onImageAvailable(ImageReader reader) {
            if (mReader != reader) {
                return;
            }

            if (VERBOSE) Log.v(TAG, ""new image available"");
            imageAvailable.open();
        }

        public void waitForAnyImageAvailable(long timeout) {
            if (imageAvailable.block(timeout)) {
                imageAvailable.close();
            } else {
                fail(""wait for image available timed out after "" + timeout + ""ms"");
            }
        }

        public void closePendingImages() {
            Image image = mReader.acquireLatestImage();
            if (image != null) {
                image.close();
            }
        }

        public void reset() {
            imageAvailable.close();
        }
    }

    private void validateImage(Size sz, int format, int captureCount,  boolean repeating)
            throws Exception {
        // TODO: Add more format here, and wrap each one as a function.
        Image img;
        final int MAX_RETRY_COUNT = 20;
        int numImageVerified = 0;
        int reTryCount = 0;
        while (numImageVerified < captureCount) {
            assertNotNull(""Image listener is null"", mListener);
            if (VERBOSE) Log.v(TAG, ""Waiting for an Image"");
            mListener.waitForAnyImageAvailable(CAPTURE_WAIT_TIMEOUT_MS);
            if (repeating) {
                /**
                 * Acquire the latest image in case the validation is slower than
                 * the image producing rate.
                 */
                img = mReader.acquireLatestImage();
                /**
                 * Sometimes if multiple onImageAvailable callbacks being queued,
                 * acquireLatestImage will clear all buffer before corresponding callback is
                 * executed. Wait for a new frame in that case.
                 */
                if (img == null && reTryCount < MAX_RETRY_COUNT) {
                    reTryCount++;
                    continue;
                }
            } else {
                img = mReader.acquireNextImage();
            }
            assertNotNull(""Unable to acquire the latest image"", img);
            if (VERBOSE) Log.v(TAG, ""Got the latest image"");
            CameraTestUtils.validateImage(img, sz.getWidth(), sz.getHeight(), format,
                    mDebugFileNameBase);
            HardwareBuffer hwb = img.getHardwareBuffer();
            assertNotNull(""Unable to retrieve the Image's HardwareBuffer"", hwb);
            if (format == ImageFormat.DEPTH_JPEG) {
                byte [] dynamicDepthBuffer = CameraTestUtils.getDataFromImage(img);
                assertTrue(""Dynamic depth validation failed!"",
                        validateDynamicDepthNative(dynamicDepthBuffer));
            }
            if (VERBOSE) Log.v(TAG, ""finish validation of image "" + numImageVerified);
            img.close();
            numImageVerified++;
            reTryCount = 0;
        }

        // Return all pending images to the ImageReader as the validateImage may
        // take a while to return and there could be many images pending.
        mListener.closePendingImages();
    }

    /** Load dynamic depth validation jni on initialization */
    static {
        System.loadLibrary(""ctscamera2_jni"");
    }
    /**
     * Use the dynamic depth SDK to validate a dynamic depth file stored in the buffer.
     *
     * Returns false if the dynamic depth has validation errors. Validation warnings/errors
     * will be printed to logcat.
     */
    private static native boolean validateDynamicDepthNative(byte[] dynamicDepthBuffer);
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Activities.StartActivity"	"OnClickListener"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Activities/StartActivity.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Activities;

import com.android.cts.verifier.PassFailButtons;
import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.sixdof.Utils.ReportExporter;

import android.content.Context;
import android.content.Intent;
import android.os.Bundle;
import android.app.Activity;
import android.hardware.Sensor;
import android.hardware.SensorManager;
import android.view.View;
import android.widget.Button;
import android.widget.Toast;

/**
 * Launcher activity that gives brief instructions of tests.
 */
public class StartActivity extends PassFailButtons.Activity {
    private Button mBtnStart;

    // Unique code that ensures we get the result from the activity that want to get a result
    private static final int REQUEST_CODE_6DOF = 5555;

    public enum ResultCode {
        FAILED_PAUSE_AND_RESUME,
        FAILED,
        PASSED
    }

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_start);

        mBtnStart = (Button) findViewById(R.id.btnStart);
        mBtnStart.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View view) {
                startPhase1();
            }
        });

        // If there is no 6DoF sensor advertised, pass trivially.
        SensorManager sensorManager = (SensorManager) getSystemService(Context.SENSOR_SERVICE);
        if (sensorManager.getDefaultSensor(Sensor.TYPE_POSE_6DOF) == null) {
            StartActivity.this.setTestResultAndFinish(true);
        }
    }

    @Override
    protected void onResume() {
        super.onResume();
    }

    private void startPhase1() {
        Intent startPhase1 = new Intent(this, TestActivity.class);
        startActivityForResult(startPhase1, REQUEST_CODE_6DOF);
    }

    @Override
    protected void onActivityResult(int requestCode, int resultCode, Intent data) {
        // Check which request we're responding to.
        if (requestCode == REQUEST_CODE_6DOF) {
            if (resultCode == RESULT_CANCELED) {
                Toast.makeText(this, R.string.test_failed, Toast.LENGTH_SHORT).show();
            } else { // RESULT_OK
                ResultCode result = (ResultCode) data.getSerializableExtra(TestActivity.EXTRA_RESULT_ID);
                if (result == ResultCode.FAILED_PAUSE_AND_RESUME) {
                    Toast.makeText(this, R.string.failed_pause_resume, Toast.LENGTH_SHORT).show();
                } else if (result == ResultCode.FAILED) {
                    Toast.makeText(this, R.string.failed, Toast.LENGTH_SHORT).show();
                } else if (result == ResultCode.PASSED) {
                    Toast.makeText(this, R.string.passed, Toast.LENGTH_SHORT).show();
                }

                String testReport = data.getStringExtra(TestActivity.EXTRA_REPORT);
                new ReportExporter(this, testReport).execute();
            }
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.display.cts.BrightnessTest"	"testAtMostOneAppHoldsBrightnessConfigurationPermission"	"CtsDisplayTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/display/src/android/display/cts/BrightnessTest.java"	""	"public void testAtMostOneAppHoldsBrightnessConfigurationPermission() {
        assertTrue(numberOfSystemAppsWithPermission(
                    Manifest.permission.CONFIGURE_DISPLAY_BRIGHTNESS) < 2);
    }

    private void assertValidLuxData(BrightnessChangeEvent event) {
        assertNotNull(event.luxTimestamps);
        assertNotNull(event.luxValues);
        assertTrue(event.luxTimestamps.length > 0);
        assertEquals(event.luxValues.length, event.luxTimestamps.length);
        for (int i = 1; i < event.luxTimestamps.length; ++i) {
            assertTrue(event.luxTimestamps[i - 1] <= event.luxTimestamps[i]);
        }
        for (int i = 0; i < event.luxValues.length; ++i) {
            assertTrue(event.luxValues[i] >= 0.0f);
            assertTrue(event.luxValues[i] <= Float.MAX_VALUE);
            assertFalse(Float.isNaN(event.luxValues[i]));
        }
    }

    /**
     * Returns the number of system apps with the given permission.
     */
    private int numberOfSystemAppsWithPermission(String permission) {
        List<PackageInfo> packages = mContext.getPackageManager().getPackagesHoldingPermissions(
                new String[]{permission}, PackageManager.MATCH_SYSTEM_ONLY);
        packages.removeIf(packageInfo -> packageInfo.packageName.equals(""com.android.shell""));
        return packages.size();
    }

    private List<BrightnessChangeEvent> getNewEvents(int expected)
            throws InterruptedException {
        List<BrightnessChangeEvent> newEvents = new ArrayList<>();
        for (int i = 0; newEvents.size() < expected && i < 20; ++i) {
            if (i != 0) {
                Thread.sleep(100);
            }
            newEvents.addAll(getNewEvents());
        }
        return newEvents;
    }

    private List<BrightnessChangeEvent> getNewEvents() {
        List<BrightnessChangeEvent> newEvents = new ArrayList<>();
        List<BrightnessChangeEvent> events = mDisplayManager.getBrightnessEvents();
        for (BrightnessChangeEvent event : events) {
            if (!mLastReadEvents.containsKey(event.timeStamp)) {
                newEvents.add(event);
            }
        }
        mLastReadEvents = new HashMap<>();
        for (BrightnessChangeEvent event : events) {
            mLastReadEvents.put(event.timeStamp, event);
        }
        return newEvents;
    }

    private void recordSliderEvents() {
        mLastReadEvents = new HashMap<>();
        List<BrightnessChangeEvent> eventsBefore = mDisplayManager.getBrightnessEvents();
        for (BrightnessChangeEvent event : eventsBefore) {
            mLastReadEvents.put(event.timeStamp, event);
        }
    }

    private void waitForFirstSliderEvent() throws  InterruptedException {
        // Keep changing brightness until we get an event to handle devices with sensors
        // that take a while to warm up.
        int brightness = 25;
        for (int i = 0; i < 20; ++i) {
            setSystemSetting(Settings.System.SCREEN_BRIGHTNESS, brightness);
            brightness = brightness == 25 ? 80 : 25;
            Thread.sleep(100);
            if (!getNewEvents().isEmpty()) {
                return;
            }
        }
        fail(""Failed to fetch first slider event. Is the ambient brightness sensor working?"");
    }

    private int getSystemSetting(String setting) {
        return Integer.parseInt(runShellCommand(""settings get system "" + setting));
    }

    private void setSystemSetting(String setting, int value) {
        runShellCommand(""settings put system "" + setting + "" "" + Integer.toString(value));
    }

    private void grantPermission(String permission) {
        InstrumentationRegistry.getInstrumentation().getUiAutomation()
                .grantRuntimePermission(mContext.getPackageName(), permission);
    }

    private void revokePermission(String permission) {
        InstrumentationRegistry.getInstrumentation().getUiAutomation()
                .revokeRuntimePermission(mContext.getPackageName(), permission);
    }

    private String runShellCommand(String cmd) {
        UiAutomation automation = InstrumentationRegistry.getInstrumentation().getUiAutomation();
        ParcelFileDescriptor output = automation.executeShellCommand(cmd);
        String result = convertFileDescriptorToString(output.getFileDescriptor());
        return result.trim();
    }

    private String convertFileDescriptorToString(FileDescriptor desc) {
        try (Scanner s = new Scanner(new FileInputStream(desc)).useDelimiter(""\\Z"")) {
            return s.hasNext() ? s.next() : """";
        }
    }

    private static void assertInRange(float[] values, float min, float max) {
        for (int i = 0; i < values.length; i++) {
            assertFalse(Float.isNaN(values[i]));
            assertTrue(values[i] >= min);
            assertTrue(values[i] <= max);
        }
    }

    private static void assertMonotonic(float[] values, boolean strictlyIncreasing, String name) {
        if (values.length <= 1) {
            return;
        }
        float prev = values[0];
        for (int i = 1; i < values.length; i++) {
            if (prev > values[i] || (prev == values[i] && strictlyIncreasing)) {
                String condition = strictlyIncreasing ? ""strictly increasing"" : ""monotonic"";
                fail(name + "" values must be "" + condition);
            }
            prev = values[i];
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.devicepolicy.cts.DevicePolicyManagerTest"	"newlyProvisionedFullyManagedDevice_canControlSensorPermissionGrantsByDefault"	"CtsDevicePolicyTestCases"	"/home/gpoor/cts-12-source/cts/tests/devicepolicy/src/android/devicepolicy/cts/DevicePolicyManagerTest.java"	""	"@EnsureHasPermission(MANAGE_PROFILE_AND_DEVICE_OWNERS)
    public void newlyProvisionedFullyManagedDevice_canControlSensorPermissionGrantsByDefault()
            throws Exception {
        try {
            FullyManagedDeviceProvisioningParams params =
                    createDefaultManagedDeviceProvisioningParamsBuilder().build();
            resetUserSetupCompletedFlag();
            sDevicePolicyManager.provisionFullyManagedDevice(params);

            assertThat(sDevicePolicyManager.canAdminGrantSensorsPermissions()).isTrue();
        } finally {
            sDevicePolicyManager.forceRemoveActiveAdmin(
                    DEVICE_ADMIN_COMPONENT_NAME, sContext.getUserId());
            setUserSetupCompletedFlag();
        }
    }

    @RequireRunOnPrimaryUser
    @RequireFeature(PackageManager.FEATURE_DEVICE_ADMIN)"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.devicepolicy.cts.DevicePolicyManagerTest"	"newlyProvisionedFullyManagedDevice_canOptOutOfControllingSensorPermissionGrants"	"CtsDevicePolicyTestCases"	"/home/gpoor/cts-12-source/cts/tests/devicepolicy/src/android/devicepolicy/cts/DevicePolicyManagerTest.java"	""	"@EnsureHasPermission(MANAGE_PROFILE_AND_DEVICE_OWNERS)
    public void newlyProvisionedFullyManagedDevice_canOptOutOfControllingSensorPermissionGrants()
            throws Exception {
        try {
            FullyManagedDeviceProvisioningParams params =
                    createDefaultManagedDeviceProvisioningParamsBuilder()
                            .setDeviceOwnerCanGrantSensorsPermissions(false)
                            .build();
            resetUserSetupCompletedFlag();
            sDevicePolicyManager.provisionFullyManagedDevice(params);

            assertThat(sDevicePolicyManager.canAdminGrantSensorsPermissions()).isFalse();
        } finally {
            sDevicePolicyManager.forceRemoveActiveAdmin(
                    DEVICE_ADMIN_COMPONENT_NAME, sContext.getUserId());
            setUserSetupCompletedFlag();
        }
    }

    @RequireRunOnPrimaryUser
    @RequireFeature(PackageManager.FEATURE_DEVICE_ADMIN)"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Fragments.BaseUiFragment"	"isPoseProviderReady"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Fragments/BaseUiFragment.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Fragments;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.sixdof.Activities.StartActivity;
import com.android.cts.verifier.sensors.sixdof.Activities.TestActivity;
import com.android.cts.verifier.sensors.sixdof.Interfaces.BaseUiListener;
import com.android.cts.verifier.sensors.sixdof.Renderer.BaseRenderer;
import com.android.cts.verifier.sensors.sixdof.Utils.Manager;

import android.app.Activity;
import android.content.Intent;
import android.os.Handler;
import android.app.Fragment;
import android.app.AlertDialog;
import android.util.Log;
import android.view.View;
import android.widget.Button;
import android.widget.ImageButton;
import android.widget.LinearLayout;

import java.io.IOException;

/**
 * Abstract class that UI Fragments for each test inherit from,
 */
public abstract class BaseUiFragment extends Fragment implements BaseUiListener {
    private static final String TAG = ""BaseUiFragment"";
    protected static final long UI_UPDATE_DELAY = 200;

    protected static final int DIALOG_FRAGMENT = 1;

    protected Button mBtnPass;
    protected Button mBtnInfo;
    protected Button mBtnFail;
    protected ImageButton mPlaceWaypointButton;

    protected LinearLayout mLLCameraLayout;

    protected TestActivity mActivity;

    protected Handler mHandler;
    protected Runnable mUIUpdateRunnable;

    protected BaseRenderer mRenderer;

    /**
     * Called when this fragment is attached to an activity. Starts the test if the Pose service is
     * ready.
     */
    @Override
    public void onAttach(Activity context) {
        super.onAttach(context);
        mActivity = (TestActivity) getActivity();

        if (mActivity.isPoseProviderReady()) {
            onPoseProviderReady();
        }
    }

    protected void initUIHandler(Runnable uiRunnable) {
        mHandler = new Handler();
        mUIUpdateRunnable = uiRunnable;
        mHandler.postDelayed(mUIUpdateRunnable, UI_UPDATE_DELAY);
    }

    protected void setupButtons(View fragmentView, TestActivity.CTSTest currentPhase) {
        final int phaseIndex = currentPhase.ordinal();
        mBtnPass = (Button) fragmentView.findViewById(R.id.btnPass);
        mBtnInfo = (Button) fragmentView.findViewById(R.id.btnInfo);
        mBtnFail = (Button) fragmentView.findViewById(R.id.btnFail);

        mBtnInfo.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View view) {
                AlertDialog.Builder builder = new AlertDialog.Builder(getActivity());

                builder.setMessage(getResources().getStringArray(R.array.phase_descriptions)[phaseIndex])
                        .setTitle(getResources().getStringArray(R.array.phase)[phaseIndex])
                        .setPositiveButton(R.string.got_it, null);

                AlertDialog dialog = builder.create();
                dialog.show();
            }
        });

        mBtnFail.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View view) {
                Intent resultIntent = getActivity().getIntent();
                String report = ""Couldn't create test report."";
                try {
                    report = mActivity.getTestReport().getContents();
                } catch (IOException e) {
                    Log.e(TAG, report);
                }
                resultIntent.putExtra(TestActivity.EXTRA_REPORT, report);
                resultIntent.putExtra(TestActivity.EXTRA_RESULT_ID, StartActivity.ResultCode.FAILED);
                getActivity().setResult(Activity.RESULT_OK, resultIntent);
                getActivity().finish();
            }
        });
    }

    protected abstract void setupUILoop();

    protected abstract void showInitialDialog();

    protected String getObjectiveText(Manager.Lap lap, int waypointCount) {
        String currentObjective = """";
        int lapIndex = lap.ordinal();
        if (lapIndex > 1) lapIndex = 1; // Text is same for indexes 1, 2, 3

        switch (waypointCount) {
            case 0:
                currentObjective = getResources()
                        .getStringArray(R.array.initial_waypoint)[lapIndex];
                break;
            case Manager.MAX_MARKER_NUMBER - 1:
                currentObjective = getString(R.string.obj_return_to_initial_waypoint);
                break;
            case Manager.MAX_MARKER_NUMBER:
                currentObjective = """";
                mPlaceWaypointButton.setVisibility(View.INVISIBLE);
                break;
            default:
                currentObjective = getResources()
                        .getStringArray(R.array.next_waypoint)[lapIndex]
                        .replace('0', Character.forDigit(waypointCount, 10));
                break;
        }

        return currentObjective;
    }

    /**
     * Nullify activity to avoid memory leak.
     */
    @Override
    public void onDetach() {
        super.onDetach();

        mActivity = null;
        mHandler = null;
        mUIUpdateRunnable = null;
    }

    @Override
    public void onDestroyUi() {
        if (mRenderer != null) {
            mRenderer.onDestroy();
        }
    }

    @Override
    public void onPause() {
        super.onPause();
        if (mRenderer != null) {
            mRenderer.disconnectCamera();
        }
    }

    @Override
    public void onResume() {
        super.onResume();
        if (mRenderer != null) {
            mRenderer.connectCamera(mActivity.getPoseProvider(), getActivity());
        }
    }

    @Override
    public void onPoseProviderReady() {
        showInitialDialog();
        setupUILoop();
    }

    /**
     * Called when a waypoint has been successfully placed by user. Shows undo snackbar.
     */
    @Override
    public void onWaypointPlaced() {
        mPlaceWaypointButton.setVisibility(View.INVISIBLE);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensoroperations.ParallelSensorOperation"	"isEmpty"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensoroperations/ParallelSensorOperation.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers.sensoroperations;

import junit.framework.Assert;

import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.reporting.ISensorTestNode;
import android.os.SystemClock;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Future;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.ThreadPoolExecutor;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;

/**
 * A {@link SensorOperation} that executes a set of children {@link SensorOperation}s in parallel.
 * The children are run in parallel but are given an index label in the order they are added. This
 * class can be combined to compose complex {@link SensorOperation}s.
 */
public class ParallelSensorOperation extends SensorOperation {
    public static final String STATS_TAG = ""parallel"";

    private final ArrayList<SensorOperation> mOperations = new ArrayList<>();
    private final Long mTimeout;
    private final TimeUnit mTimeUnit;

    /**
     * Constructor for the {@link ParallelSensorOperation} without a timeout.
     */
    // TODO: sensor tests must always provide a timeout to prevent tests from running forever
    public ParallelSensorOperation() {
        mTimeout = null;
        mTimeUnit = null;
    }

    /**
     * Constructor for the {@link ParallelSensorOperation} with a timeout.
     */
    public ParallelSensorOperation(long timeout, TimeUnit timeUnit) {
        if (timeUnit == null) {
            throw new IllegalArgumentException(""Arguments cannot be null"");
        }
        mTimeout = timeout;
        mTimeUnit = timeUnit;
    }

    /**
     * Add a set of {@link SensorOperation}s.
     */
    public void add(SensorOperation ... operations) {
        for (SensorOperation operation : operations) {
            if (operation == null) {
                throw new IllegalArgumentException(""Arguments cannot be null"");
            }
            mOperations.add(operation);
        }
    }

    /**
     * Executes the {@link SensorOperation}s in parallel. If an exception occurs one or more
     * operations, the first exception will be thrown once all operations are completed.
     */
    @Override
    public void execute(final ISensorTestNode parent) throws InterruptedException {
        int operationsCount = mOperations.size();
        ThreadPoolExecutor executor = new ThreadPoolExecutor(
                operationsCount,
                operationsCount,
                1 /* keepAliveTime */,
                TimeUnit.SECONDS,
                new LinkedBlockingQueue<Runnable>());
        executor.allowCoreThreadTimeOut(true);
        executor.prestartAllCoreThreads();

        final ISensorTestNode currentNode = asTestNode(parent);
        ArrayList<Future<SensorOperation>> futures = new ArrayList<>();
        for (final SensorOperation operation : mOperations) {
            Future<SensorOperation> future = executor.submit(new Callable<SensorOperation>() {
                @Override
                public SensorOperation call() throws Exception {
                    operation.execute(currentNode);
                    return operation;
                }
            });
            futures.add(future);
        }

        Long executionTimeNs = null;
        if (mTimeout != null) {
            executionTimeNs = SystemClock.elapsedRealtimeNanos()
                    + TimeUnit.NANOSECONDS.convert(mTimeout, mTimeUnit);
        }

        boolean hasAssertionErrors = false;
        ArrayList<Integer> timeoutIndices = new ArrayList<>();
        ArrayList<Throwable> exceptions = new ArrayList<>();
        for (int i = 0; i < operationsCount; ++i) {
            Future<SensorOperation> future = futures.get(i);
            try {
                SensorOperation operation = getFutureResult(future, executionTimeNs);
                addSensorStats(STATS_TAG, i, operation.getStats());
            } catch (ExecutionException e) {
                // extract the exception thrown by the worker thread
                Throwable cause = e.getCause();
                hasAssertionErrors |= (cause instanceof AssertionError);
                exceptions.add(e.getCause());
                addSensorStats(STATS_TAG, i, mOperations.get(i).getStats());
            } catch (TimeoutException e) {
                // we log, but we also need to interrupt the operation to terminate cleanly
                timeoutIndices.add(i);
                future.cancel(true /* mayInterruptIfRunning */);
            } catch (InterruptedException e) {
                // clean-up after ourselves by interrupting all the worker threads, and propagate
                // the interruption status, so we stop the outer loop as well
                executor.shutdownNow();
                throw e;
            }
        }

        String summary = getSummaryMessage(exceptions, timeoutIndices);
        if (hasAssertionErrors) {
            getStats().addValue(SensorStats.ERROR, summary);
        }
        if (!exceptions.isEmpty() || !timeoutIndices.isEmpty()) {
            Assert.fail(summary);
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public ParallelSensorOperation clone() {
        ParallelSensorOperation operation = new ParallelSensorOperation();
        for (SensorOperation subOperation : mOperations) {
            operation.add(subOperation.clone());
        }
        return operation;
    }

    /**
     * Helper method that waits for a {@link Future} to complete, and returns its result.
     */
    private SensorOperation getFutureResult(Future<SensorOperation> future, Long timeoutNs)
            throws ExecutionException, TimeoutException, InterruptedException {
        if (timeoutNs == null) {
            return future.get();
        }
        // cap timeout to 1ns so that join doesn't block indefinitely
        long waitTimeNs = Math.max(timeoutNs - SystemClock.elapsedRealtimeNanos(), 1);
        return future.get(waitTimeNs, TimeUnit.NANOSECONDS);
    }

    /**
     * Helper method for joining the exception and timeout messages used in assertions.
     */
    private String getSummaryMessage(List<Throwable> exceptions, List<Integer> timeoutIndices) {
        StringBuilder sb = new StringBuilder();
        for (Throwable exception : exceptions) {
            sb.append(exception.toString()).append("", "");
        }

        if (!timeoutIndices.isEmpty()) {
            sb.append(""Operation"");
            if (timeoutIndices.size() != 1) {
                sb.append(""s"");
            }
            sb.append("" ["");
            for (Integer index : timeoutIndices) {
                sb.append(index).append("", "");
            }
            sb.append(""] timed out"");
        }

        return sb.toString();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSimpleTests"	"testEnroll"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSimpleTests.java"	""	"public void testEnroll() throws Exception {
        for (SensorProperties prop : mSensorProperties) {
            try (BiometricTestSession session =
                         mBiometricManager.createTestSession(prop.getSensorId())){
                enrollForSensor(session, prop.getSensorId());
            }
        }
    }

    /**
     * Tests that the sensorIds retrieved via {@link BiometricManager#getSensorProperties()} and
     * the dumpsys are consistent with each other.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSimpleTests"	"testSensorPropertiesAndDumpsysMatch"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSimpleTests.java"	""	"public void testSensorPropertiesAndDumpsysMatch() throws Exception {
        final BiometricServiceState state = getCurrentState();

        assertEquals(mSensorProperties.size(), state.mSensorStates.sensorStates.size());
        for (SensorProperties prop : mSensorProperties) {
            assertTrue(state.mSensorStates.sensorStates.containsKey(prop.getSensorId()));
        }
    }

    /**
     * Tests that the PackageManager features and biometric dumpsys are consistent with each other.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSimpleTests"	"testPackageManagerAndDumpsysMatch"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSimpleTests.java"	""	"public void testPackageManagerAndDumpsysMatch() throws Exception {
        final BiometricServiceState state = getCurrentState();
        if (mSensorProperties.isEmpty()) {
            assertTrue(state.mSensorStates.sensorStates.isEmpty());
        } else {
            final PackageManager pm = mContext.getPackageManager();

            assertEquals(pm.hasSystemFeature(PackageManager.FEATURE_FINGERPRINT),
                    state.mSensorStates.containsModality(SensorStateProto.FINGERPRINT));
            assertEquals(pm.hasSystemFeature(PackageManager.FEATURE_FACE),
                    state.mSensorStates.containsModality(SensorStateProto.FACE));
            assertEquals(pm.hasSystemFeature(PackageManager.FEATURE_IRIS),
                    state.mSensorStates.containsModality(SensorStateProto.IRIS));
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSimpleTests"	"testCanAuthenticate_whenNoSensors"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSimpleTests.java"	""	"public void testCanAuthenticate_whenNoSensors() {
        if (mSensorProperties.isEmpty()) {
            assertEquals(BiometricManager.BIOMETRIC_ERROR_NO_HARDWARE,
                    mBiometricManager.canAuthenticate(Authenticators.BIOMETRIC_WEAK));
            assertEquals(BiometricManager.BIOMETRIC_ERROR_NO_HARDWARE,
                    mBiometricManager.canAuthenticate(Authenticators.BIOMETRIC_STRONG));
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSimpleTests"	"testWhenCredentialNotEnrolled"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSimpleTests.java"	""	"public void testWhenCredentialNotEnrolled() throws Exception {
        // First case above
        final int result = mBiometricManager.canAuthenticate(BiometricManager
                .Authenticators.DEVICE_CREDENTIAL);
        assertEquals(BiometricManager.BIOMETRIC_ERROR_NONE_ENROLLED, result);

        // Second case above
        BiometricPrompt.AuthenticationCallback callback =
                mock(BiometricPrompt.AuthenticationCallback.class);
        showCredentialOnlyBiometricPrompt(callback, new CancellationSignal(),
                false /* shouldShow */);
        verify(callback).onAuthenticationError(
                eq(BiometricPrompt.BIOMETRIC_ERROR_NO_DEVICE_CREDENTIAL),
                any());

        // Third case above. Since the deprecated API is intended to allow credential in addition
        // to biometrics, we should be receiving BIOMETRIC_ERROR_NO_BIOMETRICS.
        final boolean noSensors = mSensorProperties.isEmpty();
        callback = mock(BiometricPrompt.AuthenticationCallback.class);
        showDeviceCredentialAllowedBiometricPrompt(callback, new CancellationSignal(),
                false /* shouldShow */);
        verify(callback).onAuthenticationError(
                eq(noSensors ? BiometricPrompt.BIOMETRIC_ERROR_NO_DEVICE_CREDENTIAL
                        : BiometricPrompt.BIOMETRIC_ERROR_NO_BIOMETRICS),
                any());
    }

    /**
     * When device credential is enrolled, check the behavior for
     * 1) BiometricManager#canAuthenticate(DEVICE_CREDENTIAL)
     * 2a) Successfully authenticating BiometricPrompt#setAllowedAuthenticators(DEVICE_CREDENTIAL)
     * 2b) Cancelling authentication for the above
     * 3a) @deprecated BiometricPrompt#setDeviceCredentialALlowed(true)
     * 3b) Cancelling authentication for the above
     * 4) Cancelling auth for options 2) and 3)
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSimpleTests"	"testSimpleBiometricAuth"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSimpleTests.java"	""	"public void testSimpleBiometricAuth() throws Exception {
        for (SensorProperties props : mSensorProperties) {

            Log.d(TAG, ""testSimpleBiometricAuth, sensor: "" + props.getSensorId());

            try (BiometricTestSession session =
                         mBiometricManager.createTestSession(props.getSensorId())) {

                final int authenticatorStrength =
                        Utils.testApiStrengthToAuthenticatorStrength(props.getSensorStrength());

                assertEquals(""Sensor: "" + props.getSensorId()
                                + "", strength: "" + props.getSensorStrength(),
                        BiometricManager.BIOMETRIC_ERROR_NONE_ENROLLED,
                        mBiometricManager.canAuthenticate(authenticatorStrength));

                enrollForSensor(session, props.getSensorId());

                assertEquals(""Sensor: "" + props.getSensorId()
                                + "", strength: "" + props.getSensorStrength(),
                        BiometricManager.BIOMETRIC_SUCCESS,
                        mBiometricManager.canAuthenticate(authenticatorStrength));

                final Random random = new Random();
                final String randomTitle = String.valueOf(random.nextInt(10000));
                final String randomSubtitle = String.valueOf(random.nextInt(10000));
                final String randomDescription = String.valueOf(random.nextInt(10000));
                final String randomNegativeButtonText = String.valueOf(random.nextInt(10000));

                CountDownLatch latch = new CountDownLatch(1);
                BiometricPrompt.AuthenticationCallback callback =
                        new BiometricPrompt.AuthenticationCallback() {
                    @Override
                    public void onAuthenticationSucceeded(
                            BiometricPrompt.AuthenticationResult result) {
                        assertEquals(""Must be TYPE_BIOMETRIC"",
                                BiometricPrompt.AUTHENTICATION_RESULT_TYPE_BIOMETRIC,
                                result.getAuthenticationType());
                        latch.countDown();
                    }
                };

                showDefaultBiometricPromptWithContents(props.getSensorId(), 0 /* userId */,
                        true /* requireConfirmation */, callback, randomTitle, randomSubtitle,
                        randomDescription, randomNegativeButtonText);

                final UiObject2 actualTitle = findView(TITLE_VIEW);
                final UiObject2 actualSubtitle = findView(SUBTITLE_VIEW);
                final UiObject2 actualDescription = findView(DESCRIPTION_VIEW);
                final UiObject2 actualNegativeButton = findView(BUTTON_ID_NEGATIVE);
                assertEquals(randomTitle, actualTitle.getText());
                assertEquals(randomSubtitle, actualSubtitle.getText());
                assertEquals(randomDescription, actualDescription.getText());
                assertEquals(randomNegativeButtonText, actualNegativeButton.getText());

                // Finish auth
                successfullyAuthenticate(session, 0 /* userId */);
                latch.await(3, TimeUnit.SECONDS);
            }
        }
    }

    /**
     * Tests that the values specified through the public APIs are shown on the BiometricPrompt UI
     * when credential auth is requested.
     *
     * Upon successful authentication, checks that the result is
     * {@link BiometricPrompt#AUTHENTICATION_RESULT_TYPE_BIOMETRIC}
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricSimpleTests"	"testBiometricCancellation"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricSimpleTests.java"	""	"public void testBiometricCancellation() throws Exception {
        for (SensorProperties props : mSensorProperties) {
            try (BiometricTestSession session =
                         mBiometricManager.createTestSession(props.getSensorId())) {
                enrollForSensor(session, props.getSensorId());

                BiometricPrompt.AuthenticationCallback callback =
                        mock(BiometricPrompt.AuthenticationCallback.class);
                CancellationSignal cancellationSignal = new CancellationSignal();

                showDefaultBiometricPrompt(props.getSensorId(), 0 /* userId */,
                        true /* requireConfirmation */, callback, cancellationSignal);

                cancelAuthentication(cancellationSignal);
                verify(callback).onAuthenticationError(eq(BiometricPrompt.BIOMETRIC_ERROR_CANCELED),
                        any());
                verifyNoMoreInteractions(callback);
            }
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricActivityTests"	"testBiometricOnly_authenticateFromForegroundActivity"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricActivityTests.java"	""	"public void testBiometricOnly_authenticateFromForegroundActivity() throws Exception {
        for (SensorProperties prop : mSensorProperties) {
            try (BiometricTestSession session =
                         mBiometricManager.createTestSession(prop.getSensorId());
                 ActivitySession activitySession =
                         new ActivitySession(this, CLASS_2_BIOMETRIC_ACTIVITY)) {
                testBiometricOnly_authenticateFromForegroundActivity_forSensor(
                        session, prop.getSensorId(), activitySession);
            }
        }
    }

    private void testBiometricOnly_authenticateFromForegroundActivity_forSensor(
            @NonNull BiometricTestSession session, int sensorId,
            @NonNull ActivitySession activitySession) throws Exception {
        Log.d(TAG, ""testBiometricOnly_authenticateFromForegroundActivity_forSensor: "" + sensorId);
        final int userId = 0;
        waitForAllUnenrolled();
        enrollForSensor(session, sensorId);
        final TestJournalProvider.TestJournal journal = TestJournalProvider.TestJournalContainer
                .get(activitySession.getComponentName());

        // Launch test activity
        launchActivityAndWaitForResumed(activitySession);

        // The sensor being tested should not be idle
        BiometricServiceState state = getCurrentState();
        assertTrue(state.toString(), state.mSensorStates.sensorStates.get(sensorId).isBusy());

        // Nothing happened yet
        BiometricCallbackHelper.State callbackState = getCallbackState(journal);
        assertEquals(callbackState.toString(), 0, callbackState.mNumAuthRejected);
        assertEquals(callbackState.toString(), 0, callbackState.mNumAuthAccepted);
        assertEquals(callbackState.toString(), 0, callbackState.mAcquiredReceived.size());
        assertEquals(callbackState.toString(), 0, callbackState.mErrorsReceived.size());

        // Auth and check again now
        successfullyAuthenticate(session, userId);

        mInstrumentation.waitForIdleSync();
        callbackState = getCallbackState(journal);
        assertTrue(callbackState.toString(), callbackState.mErrorsReceived.isEmpty());
        assertTrue(callbackState.toString(), callbackState.mAcquiredReceived.isEmpty());
        assertEquals(callbackState.toString(), 1, callbackState.mNumAuthAccepted);
        assertEquals(callbackState.toString(), 0, callbackState.mNumAuthRejected);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricActivityTests"	"testBiometricOnly_rejectThenErrorFromForegroundActivity"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricActivityTests.java"	""	"public void testBiometricOnly_rejectThenErrorFromForegroundActivity() throws Exception {
        for (SensorProperties prop : mSensorProperties) {
            try (BiometricTestSession session =
                         mBiometricManager.createTestSession(prop.getSensorId());
                 ActivitySession activitySession =
                         new ActivitySession(this, CLASS_2_BIOMETRIC_ACTIVITY)) {
                testBiometricOnly_rejectThenErrorFromForegroundActivity_forSensor(
                        session, prop.getSensorId(), activitySession);
            }
        }
    }

    private void testBiometricOnly_rejectThenErrorFromForegroundActivity_forSensor(
            @NonNull BiometricTestSession session, int sensorId,
            @NonNull ActivitySession activitySession) throws Exception {
        Log.d(TAG, ""testBiometricOnly_rejectThenErrorFromForegroundActivity_forSensor: ""
                + sensorId);
        final int userId = 0;
        waitForAllUnenrolled();
        enrollForSensor(session, sensorId);

        final TestJournalProvider.TestJournal journal =
                TestJournalProvider.TestJournalContainer.get(activitySession.getComponentName());

        // Launch test activity
        launchActivityAndWaitForResumed(activitySession);
        BiometricCallbackHelper.State callbackState = getCallbackState(journal);
        assertNotNull(callbackState);

        BiometricServiceState state = getCurrentState();
        assertTrue(state.toString(), state.mSensorStates.sensorStates.get(sensorId).isBusy());

        // Biometric rejected
        session.rejectAuthentication(userId);
        mInstrumentation.waitForIdleSync();
        callbackState = getCallbackState(journal);
        assertEquals(callbackState.toString(), 1, callbackState.mNumAuthRejected);
        assertEquals(callbackState.toString(), 0, callbackState.mNumAuthAccepted);
        assertEquals(callbackState.toString(), 0, callbackState.mAcquiredReceived.size());
        assertEquals(callbackState.toString(), 0, callbackState.mErrorsReceived.size());

        state = getCurrentState();
        Log.d(TAG, ""State after rejectAuthentication: "" + state);
        if (state.mState == STATE_AUTH_PAUSED) {
            findAndPressButton(BUTTON_ID_TRY_AGAIN);
            mInstrumentation.waitForIdleSync();
            waitForState(STATE_AUTH_STARTED_UI_SHOWING);
        }

        // Send an error
        session.notifyError(userId, BiometricPrompt.BIOMETRIC_ERROR_CANCELED);
        mInstrumentation.waitForIdleSync();
        callbackState = getCallbackState(journal);
        assertEquals(callbackState.toString(), 1, callbackState.mNumAuthRejected);
        assertEquals(callbackState.toString(), 0, callbackState.mNumAuthAccepted);
        assertEquals(callbackState.toString(), 0, callbackState.mAcquiredReceived.size());
        assertEquals(callbackState.toString(), 1, callbackState.mErrorsReceived.size());
        assertEquals(callbackState.toString(), BiometricPrompt.BIOMETRIC_ERROR_CANCELED,
                (int) callbackState.mErrorsReceived.get(0));
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricActivityTests"	"testBiometricOnly_rejectThenAuthenticate"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricActivityTests.java"	""	"public void testBiometricOnly_rejectThenAuthenticate() throws Exception {
        for (SensorProperties prop : mSensorProperties) {
            try (BiometricTestSession session =
                         mBiometricManager.createTestSession(prop.getSensorId());
                 ActivitySession activitySession =
                         new ActivitySession(this, CLASS_2_BIOMETRIC_ACTIVITY)) {
                testBiometricOnly_rejectThenAuthenticate_forSensor(
                        session, prop.getSensorId(), activitySession);
            }
        }
    }

    private void testBiometricOnly_rejectThenAuthenticate_forSensor(
            @NonNull BiometricTestSession session, int sensorId,
            @NonNull ActivitySession activitySession) throws Exception {
        Log.d(TAG, ""testBiometricOnly_rejectThenAuthenticate_forSensor: "" + sensorId);

        final int userId = 0;
        waitForAllUnenrolled();
        enrollForSensor(session, sensorId);

        final TestJournalProvider.TestJournal journal =
                TestJournalProvider.TestJournalContainer.get(activitySession.getComponentName());

        // Launch test activity
        activitySession.start();
        mWmState.waitForActivityState(activitySession.getComponentName(),
                WindowManagerState.STATE_RESUMED);
        mInstrumentation.waitForIdleSync();
        BiometricCallbackHelper.State callbackState = getCallbackState(journal);
        assertNotNull(callbackState);

        BiometricServiceState state = getCurrentState();
        assertTrue(state.toString(), state.mSensorStates.sensorStates.get(sensorId).isBusy());

        session.rejectAuthentication(userId);
        mInstrumentation.waitForIdleSync();
        callbackState = getCallbackState(journal);
        assertEquals(callbackState.toString(), 1, callbackState.mNumAuthRejected);
        assertEquals(callbackState.toString(), 0, callbackState.mNumAuthAccepted);
        assertEquals(callbackState.toString(), 0, callbackState.mAcquiredReceived.size());
        assertEquals(callbackState.toString(), 0, callbackState.mErrorsReceived.size());

        state = getCurrentState();
        Log.d(TAG, ""State after rejectAuthentication: "" + state);
        if (state.mState == STATE_AUTH_PAUSED) {
            findAndPressButton(BUTTON_ID_TRY_AGAIN);
            mInstrumentation.waitForIdleSync();
            waitForState(STATE_AUTH_STARTED_UI_SHOWING);
        }

        // Accept authentication and end
        successfullyAuthenticate(session, userId);

        mInstrumentation.waitForIdleSync();
        callbackState = getCallbackState(journal);
        assertTrue(callbackState.toString(), callbackState.mErrorsReceived.isEmpty());
        assertTrue(callbackState.toString(), callbackState.mAcquiredReceived.isEmpty());
        assertEquals(callbackState.toString(), 1, callbackState.mNumAuthAccepted);
        assertEquals(callbackState.toString(), 1, callbackState.mNumAuthRejected);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricActivityTests"	"testBiometricOnly_negativeButtonInvoked"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricActivityTests.java"	""	"public void testBiometricOnly_negativeButtonInvoked() throws Exception {
        for (SensorProperties prop : mSensorProperties) {
            try (BiometricTestSession session =
                         mBiometricManager.createTestSession(prop.getSensorId());
                 ActivitySession activitySession =
                         new ActivitySession(this, CLASS_2_BIOMETRIC_ACTIVITY)) {
                testBiometricOnly_negativeButtonInvoked_forSensor(
                        session, prop.getSensorId(), activitySession);
            }
        }
    }

    private void testBiometricOnly_negativeButtonInvoked_forSensor(
            @NonNull BiometricTestSession session, int sensorId,
            @NonNull ActivitySession activitySession) throws Exception {
        Log.d(TAG, ""testBiometricOnly_negativeButtonInvoked_forSensor: "" + sensorId);
        waitForAllUnenrolled();
        enrollForSensor(session, sensorId);
        final TestJournalProvider.TestJournal journal = TestJournalProvider.TestJournalContainer
                .get(activitySession.getComponentName());

        // Launch test activity
        launchActivityAndWaitForResumed(activitySession);
        BiometricCallbackHelper.State callbackState = getCallbackState(journal);
        assertNotNull(callbackState);

        BiometricServiceState state = getCurrentState();
        assertFalse(state.toString(), state.mSensorStates.areAllSensorsIdle());
        assertFalse(state.toString(), callbackState.mNegativeButtonPressed);

        // Press the negative button
        findAndPressButton(BUTTON_ID_NEGATIVE);

        callbackState = getCallbackState(journal);
        assertTrue(callbackState.toString(), callbackState.mNegativeButtonPressed);
        assertEquals(callbackState.toString(), 0, callbackState.mNumAuthRejected);
        assertEquals(callbackState.toString(), 0, callbackState.mNumAuthAccepted);
        assertEquals(callbackState.toString(), 0, callbackState.mAcquiredReceived.size());
        assertEquals(callbackState.toString(), 0, callbackState.mErrorsReceived.size());
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricActivityTests"	"testBiometricOrCredential_credentialButtonInvoked_biometricEnrolled"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricActivityTests.java"	""	"public void testBiometricOrCredential_credentialButtonInvoked_biometricEnrolled()
            throws Exception {
        // Test behavior for each sensor when biometrics are enrolled
        try (CredentialSession credentialSession = new CredentialSession()) {
            credentialSession.setCredential();
            for (SensorProperties prop : mSensorProperties) {
                try (BiometricTestSession session =
                             mBiometricManager.createTestSession(prop.getSensorId());
                     ActivitySession activitySession =
                             new ActivitySession(this, CLASS_2_BIOMETRIC_OR_CREDENTIAL_ACTIVITY)) {
                    testBiometricOrCredential_credentialButtonInvoked_forConfiguration(
                            session, prop.getSensorId(), true /* shouldEnrollBiometric */,
                            activitySession);
                }
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricActivityTests"	"testBiometricOrCredential_credentialButtonInvoked_biometricNotEnrolled"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricActivityTests.java"	""	"public void testBiometricOrCredential_credentialButtonInvoked_biometricNotEnrolled()
            throws Exception {
        // Test behavior for each sensor when biometrics are not enrolled
        try (CredentialSession credentialSession = new CredentialSession()) {
            credentialSession.setCredential();
            for (SensorProperties prop : mSensorProperties) {
                try (BiometricTestSession session =
                             mBiometricManager.createTestSession(prop.getSensorId());
                     ActivitySession activitySession =
                             new ActivitySession(this, CLASS_2_BIOMETRIC_OR_CREDENTIAL_ACTIVITY)) {
                    testBiometricOrCredential_credentialButtonInvoked_forConfiguration(
                            session, prop.getSensorId(), false /* shouldEnrollBiometric */,
                            activitySession);
                }
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricActivityTests"	"testBiometricOrCredential_credentialButtonInvoked_noBiometricSensor"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricActivityTests.java"	""	"public void testBiometricOrCredential_credentialButtonInvoked_noBiometricSensor()
            throws Exception {
        assumeTrue(mSensorProperties.isEmpty());
        try (CredentialSession credentialSession = new CredentialSession()) {
            credentialSession.setCredential();
            try (ActivitySession activitySession =
                         new ActivitySession(this, CLASS_2_BIOMETRIC_OR_CREDENTIAL_ACTIVITY)){
                testBiometricOrCredential_credentialButtonInvoked_forConfiguration(null,
                        0 /* sensorId */, false /* shouldEnrollBiometric */, activitySession);
            }
        }
    }

    private void testBiometricOrCredential_credentialButtonInvoked_forConfiguration(
            @Nullable BiometricTestSession session, int sensorId, boolean shouldEnrollBiometric,
            @NonNull ActivitySession activitySession)
            throws Exception {
        Log.d(TAG, ""testBiometricOrCredential_credentialButtonInvoked_forConfiguration: ""
                + ""sensorId="" + sensorId
                + "", shouldEnrollBiometric="" + shouldEnrollBiometric);
        if (shouldEnrollBiometric) {
            assertNotNull(session);
            waitForAllUnenrolled();
            enrollForSensor(session, sensorId);
        }

        final TestJournalProvider.TestJournal journal = TestJournalProvider.TestJournalContainer
                .get(activitySession.getComponentName());

        // Launch test activity
        launchActivityAndWaitForResumed(activitySession);
        BiometricCallbackHelper.State callbackState;

        BiometricServiceState state = getCurrentState();
        Log.d(TAG, ""State after launching activity: "" + state);
        if (shouldEnrollBiometric) {
            waitForState(STATE_AUTH_STARTED_UI_SHOWING);
            assertTrue(state.toString(), state.mSensorStates.sensorStates.get(sensorId).isBusy());
            // Press the credential button
            findAndPressButton(BUTTON_ID_USE_CREDENTIAL);
            callbackState = getCallbackState(journal);
            assertFalse(callbackState.toString(), callbackState.mNegativeButtonPressed);
            assertEquals(callbackState.toString(), 0, callbackState.mNumAuthRejected);
            assertEquals(callbackState.toString(), 0, callbackState.mNumAuthAccepted);
            assertEquals(callbackState.toString(), 0, callbackState.mAcquiredReceived.size());
            assertEquals(callbackState.toString(), 0, callbackState.mErrorsReceived.size());
            waitForState(STATE_SHOWING_DEVICE_CREDENTIAL);
        }

        successfullyEnterCredential();

        callbackState = getCallbackState(journal);
        assertEquals(callbackState.toString(), 0, callbackState.mNumAuthRejected);
        assertEquals(callbackState.toString(), 1, callbackState.mNumAuthAccepted);
        assertEquals(callbackState.toString(), 0, callbackState.mAcquiredReceived.size());
        assertEquals(callbackState.toString(), 0, callbackState.mErrorsReceived.size());
    }

}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.EventBasicVerification"	"isIntegrationTest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/EventBasicVerification.java"	""	"public void test/*
 *
 */

package android.hardware.cts.helpers.sensorverification;

import junit.framework.Assert;

import com.android.compatibility.common.util.ApiLevelUtil;

import android.os.Build;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEvent;
import android.os.SystemClock;

import java.util.concurrent.TimeUnit;

/**
 * A {@link ISensorVerification} which verifies if the collected sensor events have any obvious
 * problems, such as no sample, wrong sensor type, etc.
 */
public class EventBasicVerification extends AbstractSensorVerification {

    public static final String PASSED_KEY = ""event_basic_passed"";
    // allowed time from registration to sensor start sampling
    private static final long ALLOWED_SENSOR_START_DELAY_US =
            TimeUnit.MILLISECONDS.toMicros(1000);

    // allowed time for entire sensor system to send sample to test app
    private static final long ALLOWED_SENSOR_EVENT_LATENCY_US =
            TimeUnit.MILLISECONDS.toMicros(1000);

    // mercy added for recently added test. remove this mercy factor for next letter release.
    private final float NUM_EVENT_MERCY_FACTOR; // 0~1, 0 means most strict

    private final long mExpectedMinNumEvent;
    private final Object mSensor;
    private long  mNumEvent;
    private boolean mWrongSensorObserved;

    /**
     * Constructs an instance of {@link EventBasicVerification}.
     *
     * @param maximumSynchronizationErrorNs The valid threshold for timestamp synchronization.
     * @param reportLatencyNs The latency on which batching events are received
     */
    public EventBasicVerification(
            long expectedMinNumEvent,
            Sensor sensor) {
        mExpectedMinNumEvent = expectedMinNumEvent;
        mSensor = sensor;

        mNumEvent = 0;
        mWrongSensorObserved = false;

        if (ApiLevelUtil.isAfter(Build.VERSION_CODES.M)) {
            NUM_EVENT_MERCY_FACTOR = 0;
        } else {
            NUM_EVENT_MERCY_FACTOR = 0.3f;
        }
    }

    /**
     * Gets a default {@link EventBasicVerification}.
     *
     * @param environment The test environment
     * @return The verification or null if the verification is not supported in the given
     *         environment.
     */
    public static EventBasicVerification getDefault(
            TestSensorEnvironment environment,
            long testDurationUs) {

        // The calculation is still OK if sampleUs is not the actual sensor hardware
        // sample period since the actual sample period by definition only goes smaller, which
        // result in more samples.
        long sampleUs = environment.getExpectedSamplingPeriodUs();

        long askedBatchUs = environment.getMaxReportLatencyUs();

        long reservedFifoUs = sampleUs * environment.getSensor().getFifoReservedEventCount(); //>=0

        // max() prevent loop-hole if HAL specify smaller max fifo than reserved fifo.
        long maximumFifoUs = Math.max(
                sampleUs * environment.getSensor().getFifoMaxEventCount(), reservedFifoUs); //>=0

        long effectiveDurationUs = Math.max(testDurationUs -
                Math.max(ALLOWED_SENSOR_START_DELAY_US, environment.getAllowedSensorStartDelay()) -
                ALLOWED_SENSOR_EVENT_LATENCY_US, 0);

        boolean isSingleSensorTest = !environment.isIntegrationTest();

        long expectedMinUs;
        if (isSingleSensorTest) {
            // When the sensor under test is the only one active, max fifo size is assumed to be
            // available.
            long expectedBatchUs = Math.min(maximumFifoUs, askedBatchUs);
            if (expectedBatchUs > 0) {
                // This sensor should be running in batching mode.
                expectedMinUs =
                        effectiveDurationUs / expectedBatchUs * expectedBatchUs
                        - expectedBatchUs / 5;
            } else {
                // streaming, allow actual rate to be as slow as 80% of the asked rate.
                expectedMinUs = effectiveDurationUs * 4 / 5;
            }
        } else {
            // More convoluted case. Batch size can vary from reserved fifo length to max fifo size.
            long minBatchUs = Math.min(reservedFifoUs, askedBatchUs);
            long maxBatchUs = Math.min(maximumFifoUs, askedBatchUs);

            // The worst scenario happens when the sensor batch time being just above half of the
            // test time, then the test can only receive one batch which halves the expected number
            // of samples. The expected number of samples received have a lower bound like the
            // figure below.
            //
            // expected samples
            //  ^
            //  |                          ______
            //  |\                        /
            //  |  \                    /
            //  |    \                /
            //  |      \            /
            //  |        \        /
            //  |          \    /
            //  |            \/
            //  |
            //  |
            //  |
            //  |
            //  +------------+-----------+------->  actual batch size in time
            //  0   1/2*testDuration   testDuration
            //
            long worstBatchUs = effectiveDurationUs / 2 + 1;
            if ((minBatchUs > worstBatchUs) ==  (maxBatchUs > worstBatchUs)) {
                // same side
                double ratio = Math.min(Math.abs(worstBatchUs - minBatchUs),
                        Math.abs(worstBatchUs - maxBatchUs)) / (double)worstBatchUs;
                expectedMinUs = (long)((ratio + 1) / 2 * testDurationUs) * 4 / 5;
            } else {
                // the worst case is possible
                expectedMinUs = worstBatchUs * 4 / 5;
            }
        }
        long expectedMinNumEvent = expectedMinUs/sampleUs;

        return new EventBasicVerification(expectedMinNumEvent, environment.getSensor());
    }

    @Override
    public void verify(TestSensorEnvironment environment, SensorStats stats) {
        verify(stats);
    }

    /* visible to unit test */
    void verify(SensorStats stats) {

        stats.addValue(SensorStats.EVENT_COUNT_KEY, mNumEvent);
        stats.addValue(SensorStats.EVENT_COUNT_EXPECTED_KEY, mExpectedMinNumEvent);
        stats.addValue(SensorStats.WRONG_SENSOR_KEY, mWrongSensorObserved);

        boolean enoughSample = mNumEvent >= mExpectedMinNumEvent * ( 1 - NUM_EVENT_MERCY_FACTOR );
        boolean noWrongSensor = !mWrongSensorObserved;

        boolean success = enoughSample && noWrongSensor;
        stats.addValue(PASSED_KEY, success);

        if (!success) {
            Assert.fail(String.format(""Failed due to (%s%s)"",
                        enoughSample?"""":""insufficient events "" + mNumEvent + ""/"" +
                                mExpectedMinNumEvent + "", "",
                        noWrongSensor?"""":""wrong sensor observed, ""));
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public EventBasicVerification clone() {
        return new EventBasicVerification( mExpectedMinNumEvent, (Sensor)mSensor );
    }

    /**
     * {@inheritDoc}
     */
    @Override
    protected void addSensorEventInternal(TestSensorEvent event) {
        if (event.sensor == mSensor) {
            ++mNumEvent;
        } else {
            mWrongSensorObserved = true;
        }
    }

}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ImageWriterTest"	"testWriterFormatOverride"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ImageWriterTest.java"	""	"public void testWriterFormatOverride() throws Exception {
        int[] TEXTURE_TEST_FORMATS = {ImageFormat.YV12, ImageFormat.YUV_420_888};
        SurfaceTexture texture = new SurfaceTexture(/*random int*/1);
        texture.setDefaultBufferSize(640, 480);
        Surface surface = new Surface(texture);

        // Make sure that the default newInstance is still valid.
        ImageWriter defaultWriter = ImageWriter.newInstance(surface, MAX_NUM_IMAGES);
        Image defaultImage = defaultWriter.dequeueInputImage();
        defaultWriter.close();

        for (int format : TEXTURE_TEST_FORMATS) {
            // Override default buffer format of Surface texture to test format
            ImageWriter writer = ImageWriter.newInstance(surface, MAX_NUM_IMAGES, format);
            Image image = writer.dequeueInputImage();
            Log.i(TAG, ""testing format "" + format + "", got input image format "" +
                    image.getFormat());
            assertTrue(image.getFormat() == format);
            writer.close();
        }
    }

    private void readerWriterFormatTestByCamera(int format, boolean altFactoryMethod)
            throws Exception {
        List<Size> sizes = getSortedSizesForFormat(mCamera.getId(), mCameraManager, format, null);
        Size maxSize = sizes.get(0);
        if (VERBOSE) {
            Log.v(TAG, ""Testing size "" + maxSize);
        }

        // Create ImageReader for camera output.
        SimpleImageReaderListener listenerForCamera  = new SimpleImageReaderListener();
        if (altFactoryMethod) {
            createDefaultImageReader(maxSize, format, MAX_NUM_IMAGES,
                    HardwareBuffer.USAGE_CPU_READ_OFTEN, listenerForCamera);
        } else {
            createDefaultImageReader(maxSize, format, MAX_NUM_IMAGES, listenerForCamera);
        }

        if (VERBOSE) {
            Log.v(TAG, ""Created camera output ImageReader"");
        }

        // Create ImageReader for ImageWriter output
        SimpleImageReaderListener listenerForWriter  = new SimpleImageReaderListener();
        if (altFactoryMethod) {
            mReaderForWriter = createImageReader(
                    maxSize, format, MAX_NUM_IMAGES,
                    HardwareBuffer.USAGE_CPU_READ_OFTEN, listenerForWriter);
        } else {
            mReaderForWriter = createImageReader(
                    maxSize, format, MAX_NUM_IMAGES, listenerForWriter);
        }

        if (VERBOSE) {
            Log.v(TAG, ""Created ImageWriter output ImageReader"");
        }

        // Create ImageWriter
        Surface surface = mReaderForWriter.getSurface();
        assertNotNull(""Surface from ImageReader shouldn't be null"", surface);
        if (altFactoryMethod) {
            mWriter = ImageWriter.newInstance(surface, MAX_NUM_IMAGES, format);
        } else {
            mWriter = ImageWriter.newInstance(surface, MAX_NUM_IMAGES);
        }
        SimpleImageWriterListener writerImageListener = new SimpleImageWriterListener(mWriter);
        mWriter.setOnImageReleasedListener(writerImageListener, mHandler);

        // Start capture: capture 2 images.
        List<Surface> outputSurfaces = new ArrayList<Surface>();
        outputSurfaces.add(mReader.getSurface());
        CaptureRequest.Builder requestBuilder = prepareCaptureRequestForSurfaces(outputSurfaces,
                CameraDevice.TEMPLATE_PREVIEW);
        SimpleCaptureCallback captureListener = new SimpleCaptureCallback();
        // Capture 1st image.
        startCapture(requestBuilder.build(), /*repeating*/false, captureListener, mHandler);
        // Capture 2nd image.
        startCapture(requestBuilder.build(), /*repeating*/false, captureListener, mHandler);
        if (VERBOSE) {
            Log.v(TAG, ""Submitted 2 captures"");
        }

        // Image from the first ImageReader.
        Image cameraImage = null;
        // ImageWriter input image.
        Image inputImage = null;
        // Image from the second ImageReader.
        Image outputImage = null;
        assertTrue(""ImageWriter max images should be "" + MAX_NUM_IMAGES,
                mWriter.getMaxImages() == MAX_NUM_IMAGES);
        if (format == CAMERA_PRIVATE_FORMAT) {
            assertTrue(""First ImageReader format should be PRIVATE"",
                    mReader.getImageFormat() == CAMERA_PRIVATE_FORMAT);
            assertTrue(""Second ImageReader should be PRIVATE"",
                    mReaderForWriter.getImageFormat() == CAMERA_PRIVATE_FORMAT);
            assertTrue(""Format of first ImageReader should be PRIVATE"",
                    mReader.getImageFormat() == CAMERA_PRIVATE_FORMAT);
            assertTrue("" Format of second ImageReader should be PRIVATE"",
                    mReaderForWriter.getImageFormat() == CAMERA_PRIVATE_FORMAT);
            assertTrue("" Format of ImageWriter should be PRIVATE"",
                    mWriter.getFormat() == CAMERA_PRIVATE_FORMAT);

            // Validate 2 images
            validateOpaqueImages(maxSize, listenerForCamera, listenerForWriter, captureListener,
                    /*numImages*/2, writerImageListener);
        } else {
            // Test case 1: Explicit data copy, only applicable for explicit formats.

            // Get 1st image from first ImageReader, and copy the data to ImageWrtier input image
            cameraImage = listenerForCamera.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
            inputImage = mWriter.dequeueInputImage();
            inputImage.setTimestamp(cameraImage.getTimestamp());
            if (VERBOSE) {
                Log.v(TAG, ""Image is being copied"");
            }
            imageCopy(cameraImage, inputImage);
            if (VERBOSE) {
                Log.v(TAG, ""Image copy is done"");
            }
            mCollector.expectTrue(
                    ""ImageWriter 1st input image should match camera 1st output image"",
                    isImageStronglyEqual(inputImage, cameraImage));

            if (DEBUG) {
                String inputFileName = mDebugFileNameBase + ""/"" + maxSize + ""_image1_input.yuv"";
                dumpFile(inputFileName, getDataFromImage(inputImage));
            }

            // Image should be closed after queueInputImage call
            Plane closedPlane = inputImage.getPlanes()[0];
            ByteBuffer closedBuffer = closedPlane.getBuffer();
            mWriter.queueInputImage(inputImage);
            imageInvalidAccessTestAfterClose(inputImage, closedPlane, closedBuffer);

            outputImage = listenerForWriter.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
            mCollector.expectTrue(""ImageWriter 1st output image should match 1st camera image"",
                    isImageStronglyEqual(cameraImage, outputImage));
            if (DEBUG) {
                String img1FileName = mDebugFileNameBase + ""/"" + maxSize + ""_image1_camera.yuv"";
                String outputImg1FileName = mDebugFileNameBase + ""/"" + maxSize
                        + ""_image1_output.yuv"";
                dumpFile(img1FileName, getDataFromImage(cameraImage));
                dumpFile(outputImg1FileName, getDataFromImage(outputImage));
            }
            // No need to close inputImage, as it is sent to the surface after queueInputImage;
            cameraImage.close();
            outputImage.close();

            // Make sure ImageWriter listener callback is fired.
            writerImageListener.waitForImageReleased(CAPTURE_IMAGE_TIMEOUT_MS);

            // Test case 2: Directly inject the image into ImageWriter: works for all formats.

            // Get 2nd image and queue it directly to ImageWrier
            cameraImage = listenerForCamera.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
            // make a copy of image1 data, as it will be closed after queueInputImage;
            byte[] img1Data = getDataFromImage(cameraImage);
            if (DEBUG) {
                String img2FileName = mDebugFileNameBase + ""/"" + maxSize + ""_image2_camera.yuv"";
                dumpFile(img2FileName, img1Data);
            }

            // Image should be closed after queueInputImage call
            closedPlane = cameraImage.getPlanes()[0];
            closedBuffer = closedPlane.getBuffer();
            mWriter.queueInputImage(cameraImage);
            imageInvalidAccessTestAfterClose(cameraImage, closedPlane, closedBuffer);

            outputImage = listenerForWriter.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
            byte[] outputImageData = getDataFromImage(outputImage);

            mCollector.expectTrue(""ImageWriter 2nd output image should match camera ""
                    + ""2nd output image"", Arrays.equals(img1Data, outputImageData));

            if (DEBUG) {
                String outputImgFileName = mDebugFileNameBase + ""/"" + maxSize +
                        ""_image2_output.yuv"";
                dumpFile(outputImgFileName, outputImageData);
            }
            // No need to close inputImage, as it is sent to the surface after queueInputImage;
            outputImage.close();

            // Make sure ImageWriter listener callback is fired.
            writerImageListener.waitForImageReleased(CAPTURE_IMAGE_TIMEOUT_MS);
        }

        stopCapture(/*fast*/false);
        mReader.close();
        mReader = null;
        mReaderForWriter.close();
        mReaderForWriter = null;
        mWriter.close();
        mWriter = null;
    }

    private void validateOpaqueImages(Size maxSize, SimpleImageReaderListener listenerForCamera,
            SimpleImageReaderListener listenerForWriter, SimpleCaptureCallback captureListener,
            int numImages, SimpleImageWriterListener writerListener) throws Exception {
        Image cameraImage;
        Image outputImage;
        for (int i = 0; i < numImages; i++) {
            cameraImage = listenerForCamera.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
            CaptureResult result = captureListener.getCaptureResult(CAPTURE_IMAGE_TIMEOUT_MS);
            validateOpaqueImage(cameraImage, ""Opaque image "" + i + ""from camera: "", maxSize,
                    result);
            mWriter.queueInputImage(cameraImage);
            // Image should be closed after queueInputImage
            imageInvalidAccessTestAfterClose(cameraImage,
                    /*closedPlane*/null, /*closedBuffer*/null);
            outputImage = listenerForWriter.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
            validateOpaqueImage(outputImage, ""First Opaque image output by ImageWriter: "",
                    maxSize, result);
            outputImage.close();
            writerListener.waitForImageReleased(CAPTURE_IMAGE_TIMEOUT_MS);
        }
    }

    private void validateOpaqueImage(Image image, String msg, Size imageSize,
            CaptureResult result) {
        assertNotNull(""Opaque image Capture result should not be null"", result != null);
        mCollector.expectImageProperties(msg + ""Opaque "", image, CAMERA_PRIVATE_FORMAT,
                imageSize, result.get(CaptureResult.SENSOR_TIMESTAMP));
        mCollector.expectTrue(msg + ""Opaque image number planes should be zero"",
                image.getPlanes().length == 0);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.SensorStats"	"isExternalStorageWritable"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/SensorStats.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers;

import android.content.Context;
import android.hardware.Sensor;
import android.hardware.cts.helpers.sensoroperations.SensorOperation;
import android.os.Environment;
import android.util.Log;

import java.io.BufferedWriter;
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;

/**
 * Class used to store stats related to {@link SensorOperation}s. Sensor stats may be linked
 * together so that they form a tree.
 */
public class SensorStats {
    private static final String TAG = ""SensorStats"";
    public static final String DELIMITER = ""__"";

    public static final String ERROR = ""error"";
    public static final String EVENT_FIFO_LENGTH = ""event_fifo_length_observed"";
    public static final String EVENT_GAP_COUNT_KEY = ""event_gap_count"";
    public static final String EVENT_GAP_POSITIONS_KEY = ""event_gap_positions"";
    public static final String EVENT_OUT_OF_ORDER_COUNT_KEY = ""event_out_of_order_count"";
    public static final String EVENT_OUT_OF_ORDER_POSITIONS_KEY = ""event_out_of_order_positions"";
    public static final String EVENT_TIME_SYNCHRONIZATION_COUNT_KEY =
            ""event_time_synchronization_count"";
    public static final String EVENT_TIME_SYNCHRONIZATION_POSITIONS_KEY =
            ""event_time_synchronization_positions"";
    public static final String EVENT_TIME_WRONG_CLOCKSOURCE_COUNT_KEY =
            ""event_time_wrong_clocksource_count"";
    public static final String EVENT_TIME_WRONG_CLOCKSOURCE_POSITIONS_KEY =
            ""event_time_wrong_clocksource_positions"";
    public static final String EVENT_COUNT_KEY = ""event_count"";
    public static final String EVENT_COUNT_EXPECTED_KEY = ""event_count_expected"";
    public static final String EVENT_NOT_SANITIZED_KEY = ""event_not_sanitized"";
    public static final String EVENT_LOG_FILENAME = ""event_log_filename"";
    public static final String WRONG_SENSOR_KEY = ""wrong_sensor_observed"";
    public static final String FREQUENCY_KEY = ""frequency"";
    public static final String JITTER_95_PERCENTILE_PERCENT_KEY = ""jitter_95_percentile_percent"";
    public static final String MEAN_KEY = ""mean"";
    public static final String STANDARD_DEVIATION_KEY = ""standard_deviation"";
    public static final String MAGNITUDE_KEY = ""magnitude"";
    public static final String DELAYED_BATCH_DELIVERY = ""delayed_batch_delivery"";
    public static final String INITIAL_MEAN_KEY = ""initial_mean"";
    public static final String LATER_MEAN_KEY = ""later_mean"";

    private final Map<String, Object> mValues = new HashMap<>();
    private final Map<String, SensorStats> mSensorStats = new HashMap<>();

    /**
     * Add a value.
     *
     * @param key the key.
     * @param value the value as an {@link Object}.
     */
    public synchronized void addValue(String key, Object value) {
        if (value == null) {
            return;
        }
        mValues.put(key, value);
    }

    /**
     * Add a nested {@link SensorStats}. This is useful for keeping track of stats in a
     * {@link SensorOperation} tree.
     *
     * @param key the key
     * @param stats the sub {@link SensorStats} object.
     */
    public synchronized void addSensorStats(String key, SensorStats stats) {
        if (stats == null) {
            return;
        }
        mSensorStats.put(key, stats);
    }

    /**
     * Get the keys from the values table. Will not get the keys from the nested
     * {@link SensorStats}.
     */
    public synchronized Set<String> getKeys() {
        return mValues.keySet();
    }

    /**
     * Get a value from the values table. Will not attempt to get values from nested
     * {@link SensorStats}.
     */
    public synchronized Object getValue(String key) {
        return mValues.get(key);
    }

    /**
     * Flattens the map and all sub {@link SensorStats} objects. Keys will be flattened using
     * {@value #DELIMITER}. For example, if a sub {@link SensorStats} is added with key
     * {@code ""key1""} containing the key value pair {@code \(""key2"", ""value""\)}, the flattened map
     * will contain the entry {@code \(""key1__key2"", ""value""\)}.
     *
     * @return a {@link Map} containing all stats from the value and sub {@link SensorStats}.
     */
    public synchronized Map<String, Object> flatten() {
        final Map<String, Object> flattenedMap = new HashMap<>(mValues);
        for (Entry<String, SensorStats> statsEntry : mSensorStats.entrySet()) {
            for (Entry<String, Object> valueEntry : statsEntry.getValue().flatten().entrySet()) {
                String key = statsEntry.getKey() + DELIMITER + valueEntry.getKey();
                flattenedMap.put(key, valueEntry.getValue());
            }
        }
        return flattenedMap;
    }

    /**
     * Utility method to log the stats to the logcat.
     */
    public void log(String tag) {
        final Map<String, Object> flattened = flatten();
        for (String key : getSortedKeys(flattened)) {
            Object value = flattened.get(key);
            Log.v(tag, String.format(""%s: %s"", key, getValueString(value)));
        }
    }

    /* Checks if external storage is available for read and write */
    private boolean isExternalStorageWritable() {
        String state = Environment.getExternalStorageState();
        return Environment.MEDIA_MOUNTED.equals(state);
    }

    /**
     * Utility method to log the stats to a file. Will overwrite the file if it already exists.
     */
    public void logToFile(Context context, String fileName) throws IOException {
        if (!isExternalStorageWritable()) {
            Log.w(TAG,
                ""External storage unavailable, skipping log to file: "" + fileName);
            return;
        }

        try {
            // Only log to file if currently not an Instant App since Instant Apps do not have access to
            // external storage.
            if (!context.getPackageManager().isInstantApp()) {
                File statsDirectory = SensorCtsHelper.getSensorTestDataDirectory(""stats/"");
                File logFile = new File(statsDirectory, fileName);
                final Map<String, Object> flattened = flatten();
                FileWriter fileWriter = new FileWriter(logFile, false /* append */);
                try (BufferedWriter writer = new BufferedWriter(fileWriter)) {
                    for (String key : getSortedKeys(flattened)) {
                        Object value = flattened.get(key);
                        writer.write(String.format(""%s: %s\n"", key, getValueString(value)));
                    }
                }
            }
        } catch(IOException e) {
            Log.w(TAG, ""Unable to write to file: "" + fileName, e);
        }
    }

    /**
     * Provides a sanitized sensor name, that can be used in file names.
     * See {@link #logToFile(String)}.
     */
    public static String getSanitizedSensorName(Sensor sensor) throws SensorTestPlatformException {
        return SensorCtsHelper.sanitizeStringForFileName(sensor.getStringType());
    }

    private static List<String> getSortedKeys(Map<String, Object> flattenedStats) {
        List<String> keys = new ArrayList<>(flattenedStats.keySet());
        Collections.sort(keys);
        return keys;
    }

    private static String getValueString(Object value) {
        if (value == null) {
            return """";
        } else if (value instanceof boolean[]) {
            return Arrays.toString((boolean[]) value);
        } else if (value instanceof byte[]) {
            return Arrays.toString((byte[]) value);
        } else if (value instanceof char[]) {
            return Arrays.toString((char[]) value);
        } else if (value instanceof double[]) {
            return Arrays.toString((double[]) value);
        } else if (value instanceof float[]) {
            return Arrays.toString((float[]) value);
        } else if (value instanceof int[]) {
            return Arrays.toString((int[]) value);
        } else if (value instanceof long[]) {
            return Arrays.toString((long[]) value);
        } else if (value instanceof short[]) {
            return Arrays.toString((short[]) value);
        } else if (value instanceof Object[]) {
            return Arrays.toString((Object[]) value);
        } else {
            return value.toString();
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.helpers.PowerTestHostLink"	"PowerTestResult"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/helpers/PowerTestHostLink.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors.helpers;

import com.android.cts.verifier.sensors.reporting.SensorTestDetails;

import android.content.Context;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.hardware.cts.helpers.SensorCtsHelper;
import android.net.LocalServerSocket;
import android.net.LocalSocket;
import android.util.Log;

import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.util.List;
import java.util.StringTokenizer;

/**
 * This class handles communication with the host to respond to commands.
 * The command/response link is through a TCP socket on the host side, forwarded via adb to a local
 * socket on the device. The system uses a standard ""accept-read_command-send_response-close"" to
 * execute commands sent from the host.
 *
 * CAUTION: The local socket name (SOCKET_NAME below) must match that used by the host to set up
 * the adb-forwarding.
 */
public class PowerTestHostLink {
    private static final String TAG = ""PowerTestHostLink"";

    /**
     * Host-to-device bridge will use a Listener instance to drive the test via the CtsVerifier
     * running on the device.
     */
    public interface HostToDeviceInterface {
        void logTestResult(SensorTestDetails testDetails);
        void raiseError(String testName, String message) throws Exception;
        void waitForUserAcknowledgement(String message) throws InterruptedException;
        void logText(String text);
        void turnScreenOff();
    }

    /** This is a data-only message to communicate result of a power test */
    public class PowerTestResult{
        public int passedCount = 0;
        public int skippedCount = 0;
        public int failedCount = 0;
    }

    /**
     * Standard response types back to host. Host-side code must match these definitions.
     */
    private final static String RESPONSE_OK = ""OK"";
    private final static String RESPONSE_ERR = ""ERR"";
    private final static String RESPONSE_UNAVAILABLE = ""UNAVAILABLE"";

    /**
     * Socket name for host adb forwarded communications. Must match naem in host-side code.
     */
    public final static String SOCKET_NAME = ""/android/cts/powertest"";

    private volatile boolean mStopThread;
    private final SensorManager mSensorManager;
    private final HostToDeviceInterface mHostToDeviceExecutor;
    private final PowerTestResult mTestResult = new PowerTestResult();

    public PowerTestHostLink(Context context, HostToDeviceInterface listener) {
        Log.d(TAG, "" +++ Begin of localSocketServer() +++ "");
        mHostToDeviceExecutor = listener;
        mSensorManager = (SensorManager) context.getSystemService(Context.SENSOR_SERVICE);
    }

    /**
     * Ensure connection to host is closed; stop accepting requests.
     **/
    public void close() {
        mStopThread = true;
    }

    /**
     * Run the suite of tests via the host, responding to host requests.
     *
     * @return number of failed test cases
     * @throws Exception
     */
    public PowerTestResult run() throws Exception {
        // define buffer to receive data from host
        final int BUFFER_SIZE = 4096;
        byte[] buffer = new byte[BUFFER_SIZE];

        LocalServerSocket serverSocket = createSocket();
        if (null == serverSocket) {
            mStopThread = true;
        }

        InputStream streamIn;
        OutputStream streamOut;
        LocalSocket receiverSocket;
        while (!mStopThread) {

            try {
                Log.d(TAG, ""localSocketServer accept..."");
                receiverSocket = serverSocket.accept();
                Log.d(TAG, ""Got new connection"");
            } catch (IOException e) {
                Log.d(TAG, ""localSocketServer accept() failed !!!"", e);
                continue;
            }

            try {
                streamIn = receiverSocket.getInputStream();
            } catch (IOException e) {
                Log.d(TAG, ""getInputStream() failed !!!"", e);
                continue;
            }

            try {
                streamOut = receiverSocket.getOutputStream();
            } catch (IOException e) {
                Log.e(TAG, ""getOutputStream() failed"", e);
                continue;
            }

            Log.d(TAG, ""The client connected to LocalServerSocket"");

            try {
                int total = 0;
                // command and response handshake, so read all data
                while (streamIn.available() > 0 || total == 0) {
                    if (total < BUFFER_SIZE) {
                        int bytesRead = streamIn.read(buffer, total,
                                (BUFFER_SIZE - total));
                        if (bytesRead > 0) {
                            total += bytesRead;
                        }
                    } else {
                        Log.e(TAG, ""Message too long: truncating"");
                    }
                }
                String clientRequest = new String(buffer);
                clientRequest = clientRequest.substring(0, total);
                if (clientRequest.length() > 0) {

                    Log.d(TAG, ""Client requested: "" + clientRequest);
                    try {
                        String response = processClientRequest(clientRequest);
                        if (response != null) {
                            Log.d(TAG, ""Sending response "" + response);
                            streamOut.write(response.getBytes(), 0, response.length());
                        }
                        // null response means response is deferred awaiting user response
                    } catch (Exception e) {
                        Log.e(TAG, ""Error executing "" + clientRequest, e);
                        streamOut.write(RESPONSE_ERR.getBytes(), 0, RESPONSE_ERR.length());
                    }
                }
                receiverSocket.close();
            } catch (IOException e) {
                Log.e(TAG, ""There is an exception when reading from or writing to socket"", e);
                break;
            }
        }
        Log.d(TAG, ""The LocalSocketServer thread is going to stop !!!"");

        if (serverSocket != null) {
            try {
                serverSocket.close();
            } catch (IOException e) {
                Log.d(TAG, ""Exception on close of server socket"", e);
            }
        }
        mHostToDeviceExecutor.logText(""Device disconnected."");
        Log.d(TAG, ""Returning "" + mTestResult.passedCount + ""passed "" + mTestResult.skippedCount +
                ""skipped "" + mTestResult.failedCount + ""failed."");
        return mTestResult;
    }

    private  String processClientRequest(String request) throws Exception {
        // the following constants need to match the definitions in execute_power_tests.py
        final String REQUEST_EXTERNAL_STORAGE = ""EXTERNAL STORAGE?"";
        final String REQUEST_EXIT = ""EXIT"";
        final String REQUEST_RAISE = ""RAISE "";
        final String REQUEST_USER_RESPONSE = ""USER RESPONSE "";
        final String REQUEST_SET_TEST_RESULT = ""SET TEST RESULT "";
        final String REQUEST_SENSOR_ON = ""SENSOR ON "";
        final String REQUEST_SENSOR_OFF = ""SENSOR OFF"";
        final String REQUEST_SENSOR_AVAILABILITY = ""SENSOR? "";
        final String REQUEST_SCREEN_OFF = ""SCREEN OFF"";
        final String REQUEST_SHOW_MESSAGE = ""MESSAGE "";

        String response = RESPONSE_ERR;
        // Queries must appear first and then commands to direct actions after in these statements
        if (request.startsWith(REQUEST_SENSOR_AVAILABILITY)) {
            final String sensor = request.substring(REQUEST_SENSOR_AVAILABILITY.length());
            final int sensorId = getSensorId(sensor);
            if (mSensorManager.getDefaultSensor(sensorId) == null) {
                response = RESPONSE_UNAVAILABLE;
            } else {
                response = RESPONSE_OK;
            }
        } else if (request.startsWith(REQUEST_EXTERNAL_STORAGE)){
            response = SensorCtsHelper.getSensorTestDataDirectory(""power/"").getAbsolutePath();
            Log.d(TAG,""External storage is "" + response);
        } else if (request.startsWith(REQUEST_SCREEN_OFF)) {
            try {
                mHostToDeviceExecutor.turnScreenOff();
                response = RESPONSE_OK;
            } catch (SecurityException e) {
                Log.e(TAG, ""Error Turning screen off"", e);
                response = RESPONSE_ERR;
            }
        } else if (request.startsWith(REQUEST_SENSOR_ON)) {
            String sensorList = request.substring(REQUEST_SENSOR_ON.length()).trim();
            response = handleSensorSwitchCommand(sensorList, true);
        } else if (request.startsWith(REQUEST_SENSOR_OFF)) {
            String sensorList = request.substring(REQUEST_SENSOR_ON.length()).trim();
            response = handleSensorSwitchCommand(sensorList, false);
        } else if (request.startsWith(REQUEST_SHOW_MESSAGE)) {
            final String message = request.substring(REQUEST_SHOW_MESSAGE.length());
            mHostToDeviceExecutor.logText(message);
            response = RESPONSE_OK;
        } else if (request.startsWith(REQUEST_USER_RESPONSE)) {
            String message = request.substring(REQUEST_USER_RESPONSE.length());
            mHostToDeviceExecutor.waitForUserAcknowledgement(message);
            response = RESPONSE_OK;
        } else if (request.startsWith(REQUEST_SET_TEST_RESULT)) {
            String testResult = request.substring(REQUEST_SET_TEST_RESULT.length());
            response = handleSetTestResultCmd(testResult);
        } else if (request.startsWith(REQUEST_RAISE)) {
            String command = request.substring(REQUEST_RAISE.length());
            StringTokenizer tokenizer = new StringTokenizer(command);
            try {
                final String testName = tokenizer.nextToken();
                final String message = request.substring(7 + testName.length());
                mHostToDeviceExecutor.raiseError(testName, message);
                response = RESPONSE_OK;
            } catch (Exception e) {
                Log.e(TAG, ""Invalid RAISE command received (bad arguments): "" + request);
                response = RESPONSE_ERR;
            }
        } else if (request.startsWith(REQUEST_EXIT)) {
            mStopThread = true;
            response = RESPONSE_OK;
        } else {
            Log.e(TAG, ""Unknown request: "" + request);
        }
        return response;
    }

    private String handleSetTestResultCmd(final String request) {
        String response;
        StringTokenizer tokenizer = new StringTokenizer(request, "" "");
        String testName = """";
        SensorTestDetails.ResultCode resultCode = SensorTestDetails.ResultCode.FAIL;
        String message = """";

        try {
            testName = tokenizer.nextToken();
            final String resultToken = tokenizer.nextToken();

            if (resultToken.equals(""PASS"")) {
                resultCode = SensorTestDetails.ResultCode.PASS;
                ++mTestResult.passedCount;
                message = ""PASSED: "";
                response = RESPONSE_OK;
            } else if (resultToken.equals(""FAIL"")) {
                resultCode = SensorTestDetails.ResultCode.FAIL;
                ++mTestResult.failedCount;
                message = ""FAILED: "";
                response = RESPONSE_OK;
            } else if (resultToken.equals(""SKIPPED"")) {
                resultCode = SensorTestDetails.ResultCode.SKIPPED;
                ++mTestResult.skippedCount;
                message = ""SKIPPED: "";
                response = RESPONSE_OK;
            } else {
                response = RESPONSE_ERR;
            }
            while (tokenizer.hasMoreTokens()) {
                message += tokenizer.nextToken() + "" "";
            }
            Log.i(TAG, message);
        } catch (Exception e) {
            Log.e(TAG, ""Improperly formatted command received: "" + request, e);
            response = RESPONSE_ERR;
        }
        String fullMessage = testName + "" "" + message;
        mHostToDeviceExecutor.logTestResult(
                new SensorTestDetails(testName, resultCode, fullMessage));
        return response;
    }

    private String handleSensorSwitchCommand(String sensorList, boolean switchOn) {
        String response;
        try {
            StringTokenizer tokenizer = new StringTokenizer(sensorList, "" "");
            int n = tokenizer.countTokens();
            if (n == 0) {
                response = switchAllSensors(switchOn);
            } else {
                String sensorName = tokenizer.nextToken();
                String requestRate = """";
                if (n > 1) {
                    requestRate = tokenizer.nextToken();
                }
                if (sensorName.equals(""ALL"")) {
                    response = switchAllSensors(switchOn);
                } else {
                    int sensorId = getSensorId(sensorName);
                    if (sensorId >= 0) {
                        response = switchSensor(sensorId, switchOn, requestRate);
                    } else {
                        Log.e(TAG, ""Unknown sensor in request: "" + sensorName);
                        response = RESPONSE_UNAVAILABLE;
                    }
                }
            }
        } catch (Exception e) {
            Log.e(TAG, ""Improperly formatted command received on setting sensor state"");
            response = RESPONSE_ERR;
        }
        return response;
    }

    private static int getSensorId(String sensorName) {
        int sensorId = -1;

        if (sensorName.compareToIgnoreCase(""ACCELEROMETER"") == 0) {
            sensorId = Sensor.TYPE_ACCELEROMETER;
        } else if (sensorName.compareToIgnoreCase(""AMBIENT_TEMPERATURE"") == 0) {
            sensorId = Sensor.TYPE_AMBIENT_TEMPERATURE;
        } else if (sensorName.compareToIgnoreCase(""GAME_ROTATION_VECTOR"") == 0) {
            sensorId = Sensor.TYPE_GAME_ROTATION_VECTOR;
        } else if (sensorName.compareToIgnoreCase(""GEOMAGNETIC_ROTATION_VECTOR"") == 0) {
            sensorId = Sensor.TYPE_GEOMAGNETIC_ROTATION_VECTOR;
        } else if (sensorName.compareToIgnoreCase(""GRAVITY"") == 0) {
            sensorId = Sensor.TYPE_GRAVITY;
        } else if (sensorName.compareToIgnoreCase(""GYROSCOPE"") == 0) {
            sensorId = Sensor.TYPE_GYROSCOPE;
        } else if (sensorName.compareToIgnoreCase(""LIGHT"") == 0) {
            sensorId = Sensor.TYPE_LIGHT;
        } else if (sensorName.compareToIgnoreCase(""MAGNETIC_FIELD"") == 0) {
            sensorId = Sensor.TYPE_MAGNETIC_FIELD;
        } else if (sensorName.compareToIgnoreCase(""PRESSURE"") == 0) {
            sensorId = Sensor.TYPE_PRESSURE;
        } else if (sensorName.compareToIgnoreCase(""PROXIMITY"") == 0) {
            sensorId = Sensor.TYPE_PROXIMITY;
        } else if (sensorName.compareToIgnoreCase(""RELATIVE_HUMIDITY"") == 0) {
            sensorId = Sensor.TYPE_RELATIVE_HUMIDITY;
        } else if (sensorName.compareToIgnoreCase(""ROTATION_VECTOR"") == 0) {
            sensorId = Sensor.TYPE_ROTATION_VECTOR;
        } else if (sensorName.compareToIgnoreCase(""SIGNIFICANT_MOTION"") == 0) {
            sensorId = Sensor.TYPE_SIGNIFICANT_MOTION;
        } else if (sensorName.compareToIgnoreCase(""STEP_COUNTER"") == 0) {
            sensorId = Sensor.TYPE_STEP_COUNTER;
        } else if (sensorName.compareToIgnoreCase(""STEP_DETECTOR"") == 0) {
            sensorId = Sensor.TYPE_STEP_DETECTOR;
        }

        return sensorId;
    }

    private String switchSensor(int sensorId, boolean switchOn) {
        return switchSensor(sensorId, switchOn, ""SENSOR_DELAY_NORMAL"");
    }

    private String switchSensor(int sensorId, boolean switchOn, String requestFrequency) {
        String response;
        int rateUs = SensorManager.SENSOR_DELAY_NORMAL;

        if (requestFrequency.compareToIgnoreCase(""SENSOR_DELAY_FASTEST"") == 0) {
            rateUs = SensorManager.SENSOR_DELAY_FASTEST;
        } else if (requestFrequency.compareToIgnoreCase(""SENSOR_DELAY_GAME"") == 0) {
            rateUs = SensorManager.SENSOR_DELAY_GAME;
        } else if (requestFrequency.compareToIgnoreCase(""SENSOR_DELAY_UI"") == 0) {
            rateUs = SensorManager.SENSOR_DELAY_UI;
        }

        if (switchOn) {
            mSensorManager.registerListener(mSensorEventListener,
                    mSensorManager.getDefaultSensor(sensorId), rateUs);
            response = RESPONSE_OK;
            Log.v(TAG, ""Switching ON "" + String.valueOf(sensorId) + "" | "" + String.valueOf(rateUs));
        } else {
            mSensorManager.unregisterListener(mSensorEventListener,
                    mSensorManager.getDefaultSensor(sensorId));
            response = RESPONSE_OK;
            Log.v(TAG, ""Switching  OFF "" + String.valueOf(sensorId));
        }

        return response;
    }

    private String switchAllSensors(boolean on) {
        List<Sensor> allSensors = mSensorManager.getSensorList(Sensor.TYPE_ALL);
        String response = RESPONSE_OK;
        for (Sensor sensor : allSensors) {
            if (sensor.getType() >= Sensor.TYPE_DEVICE_PRIVATE_BASE) {
                continue;
            }
            response = switchSensor(sensor.getType(), on);
            if (response == null) {
                response = RESPONSE_ERR;
            }
        }
        return response;
    }

    private LocalServerSocket createSocket() {
        try {
            return new LocalServerSocket(SOCKET_NAME);
        } catch (IOException e) {
            Log.e(TAG, ""LocalSocketServer creation failure."", e);
            return null;
        }
    }

    private SensorEventListener mSensorEventListener = new SensorEventListener() {
        @Override
        public void onAccuracyChanged(Sensor sensor, int accuracy) {}

        @Override
        public void onSensorChanged(SensorEvent event) {}
    };
}"	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.TimestampClockSourceVerificationTest"	"uptimeMillis"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/TimestampClockSourceVerificationTest.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers.sensorverification;

import junit.framework.TestCase;

import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEvent;
import android.os.SystemClock;

import java.util.ArrayList;
import java.util.Collection;

import android.util.Log;

/**
 * Tests for {@link TimestampClockSourceVerification}.
 */
public class TimestampClockSourceVerificationTest extends TestCase {
    private final String TAG = ""TimestampClockSourceVerificationTest"";

    private final int MIN_DELTA_BETWEEN_CLOCKS_MS = 2000;
    private boolean mAdjustUptime = false;

    private long getValidTimestamp() {
        return SystemClock.elapsedRealtimeNanos();
    }

    private long getInvalidTimestamp() {
        long ms = SystemClock.uptimeMillis();
        if (mAdjustUptime == true) {
            ms -= MIN_DELTA_BETWEEN_CLOCKS_MS;
        }
        return (ms * 1000000);
    }

    private void verifyClockDelta() throws Throwable {
        long uptimeMs = SystemClock.uptimeMillis();
        long realtimeNs = SystemClock.elapsedRealtimeNanos();
        long deltaMs = (realtimeNs/1000000 - uptimeMs);
        if (deltaMs < MIN_DELTA_BETWEEN_CLOCKS_MS) {
            Log.i(TAG, ""Device has not slept, will use different clock source for test purposes"");
            mAdjustUptime = true;
        } else {
            mAdjustUptime = false;
            Log.i(TAG, ""CLOCK_MONOTONIC=""+uptimeMs*1000000+"", CLOCK_BOOTTIME=""+realtimeNs+"", delta="" + deltaMs + "" mS"");
        }
    }


    /**
     * Test that the verification passes when there are not missing events.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.TimestampClockSourceVerificationTest"	"testVerify_no_events_fail"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/TimestampClockSourceVerificationTest.java"	""	"public void testVerify_no_events_fail() throws Throwable {
        try {
            verifyClockDelta();
            // Timestamps in ns, expected in us
            runVerification(MIN_DELTA_BETWEEN_CLOCKS_MS*1000, new long[]{}, false, new int[]{});
        } finally {
        }
    }

    private void runVerification(int expectedUs, long[] timestamps, boolean pass,
            int[] indices) {
        SensorStats stats = new SensorStats();
        ISensorVerification verification = getVerification(expectedUs, timestamps);
        TestSensorEnvironment environment = new TestSensorEnvironment(null, null, false, 0, 0);
        if (pass) {
            verification.verify(environment, stats);
        } else {
            boolean failed = false;
            try {
                verification.verify(environment, stats);
            } catch (AssertionError e) {
                // Expected;
                failed = true;
            }
            assertTrue(""Expected an AssertionError"", failed);
        }

        assertEquals(pass, stats.getValue(TimestampClockSourceVerification.PASSED_KEY));
        assertEquals(indices.length, stats.getValue(SensorStats.EVENT_TIME_WRONG_CLOCKSOURCE_COUNT_KEY));
        if (0 != (Integer) stats.getValue(SensorStats.EVENT_TIME_WRONG_CLOCKSOURCE_COUNT_KEY)) {
            assertNotNull(stats.getValue(SensorStats.EVENT_TIME_WRONG_CLOCKSOURCE_POSITIONS_KEY));
        }
        try {
            int[] actualIndices = (int[]) stats.getValue(SensorStats.EVENT_TIME_WRONG_CLOCKSOURCE_POSITIONS_KEY);
            assertEquals(indices.length, actualIndices.length);

            for (int i = 0; i < indices.length; i++) {
                assertEquals(indices[i], actualIndices[i]);
            }
        } catch (Exception t) {
        }
    }

    private static TimestampClockSourceVerification getVerification(int expectedUs, long ... timestamps) {
        Collection<TestSensorEvent> events = new ArrayList<>(timestamps.length);
        long expectedNs = expectedUs * 1000;
        long now = SystemClock.elapsedRealtimeNanos();
        long receiveTime;
        for (long timestamp : timestamps) {
            //receiveTime = now - (expectedNs * count);
            receiveTime = SystemClock.elapsedRealtimeNanos();
            events.add(new TestSensorEvent(null, timestamp, receiveTime, 0, null));
        }
        TimestampClockSourceVerification verification = new TimestampClockSourceVerification(expectedUs);
        verification.addSensorEvents(events);
        return verification;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.camera.cts.api25test.EnableZslTest"	"getCameraIdList"	"CtsCameraApi25TestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/api25test/src/android/camera/cts/api25test/EnableZslTest.java"	""	"public void test/*
 *.
 */

package android.camera.cts.api25test;

import android.content.Context;
import android.hardware.camera2.CameraDevice;
import android.hardware.camera2.CameraManager;
import android.hardware.camera2.CaptureRequest;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.cts.CameraTestUtils;
import android.hardware.camera2.cts.helpers.CameraErrorCollector;
import android.hardware.camera2.cts.helpers.StaticMetadata;
import android.hardware.camera2.cts.helpers.StaticMetadata.CheckLevel;
import android.os.Handler;
import android.os.HandlerThread;
import android.test.AndroidTestCase;
import android.util.Log;

import java.lang.reflect.Field;
import java.lang.reflect.Modifier;
import java.lang.reflect.ParameterizedType;
import java.lang.reflect.Type;
import java.util.Set;
import java.util.HashSet;

public class EnableZslTest extends AndroidTestCase {
    private static final String TAG = ""EnableZslTest"";
    private static final boolean VERBOSE = Log.isLoggable(TAG, Log.VERBOSE);

    private CameraManager mCameraManager;
    private String[] mCameraIds;
    private Handler mHandler;
    private HandlerThread mHandlerThread;
    private StaticMetadata mStaticInfo;
    private CameraErrorCollector mCollector;

    private static int[] sTemplates = new int[] {
            CameraDevice.TEMPLATE_MANUAL,
            CameraDevice.TEMPLATE_PREVIEW,
            CameraDevice.TEMPLATE_RECORD,
            CameraDevice.TEMPLATE_STILL_CAPTURE,
            CameraDevice.TEMPLATE_VIDEO_SNAPSHOT,
            CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG,
    };

    // Request templates that are unsupported by LEGACY mode.
    private static Set<Integer> sLegacySkipTemplates = new HashSet<>();
    static {
        sLegacySkipTemplates.add(CameraDevice.TEMPLATE_VIDEO_SNAPSHOT);
        sLegacySkipTemplates.add(CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG);
        sLegacySkipTemplates.add(CameraDevice.TEMPLATE_MANUAL);
    }

    @Override
    public void setContext(Context context) {
        super.setContext(context);
        mCameraManager = (CameraManager) context.getSystemService(Context.CAMERA_SERVICE);
        assertNotNull(""Can't connect to camera manager!"", mCameraManager);
    }

    @Override
    protected void setUp() throws Exception {
        super.setUp();

        mCameraIds = mCameraManager.getCameraIdList();
        assertNotNull(""Camera ids shouldn't be null"", mCameraIds);

        mHandlerThread = new HandlerThread(TAG);
        mHandlerThread.start();
        mHandler = new Handler(mHandlerThread.getLooper());

        mCollector = new CameraErrorCollector();
    }

    @Override
    protected void tearDown() throws Exception {
        mHandlerThread.quitSafely();
        mHandler = null;

        try {
            mCollector.verify();
        } catch (Throwable e) {
            // When new Exception(e) is used, exception info will be printed twice.
            throw new Exception(e.getMessage());
        } finally {
            super.tearDown();
        }
    }

    // Get android.control.enableZsl value from the request. Note that android.control.enableZsl
    // is not a public key in API 25 so reflect is used to get the value.
    private Boolean getEnableZslValue(CaptureRequest.Builder request) throws Exception {
        Field[] allFields = CaptureRequest.class.getDeclaredFields();
        for (Field field : allFields) {
            if (Modifier.isStatic(field.getModifiers()) &&
                    field.getType() == CaptureRequest.Key.class &&
                    field.getGenericType() instanceof ParameterizedType) {
                ParameterizedType paramType = (ParameterizedType)field.getGenericType();
                Type[] argTypes = paramType.getActualTypeArguments();
                if (argTypes.length > 0) {
                    CaptureRequest.Key key = (CaptureRequest.Key)field.get(request);
                    if (key.getName().equals(""android.control.enableZsl"")) {
                        return (Boolean)request.get(key);
                    }
                }
            }
        }

        return null;
    }

    // Verify CaptureRequest.CONTROL_ENABLE_ZSL values for a camera.
    private void testEnableZslValueByCamera(String cameraId) throws Exception {
        CameraDevice camera = CameraTestUtils.openCamera(mCameraManager, cameraId,
                /*listener*/null, mHandler);

        StaticMetadata staticInfo = new StaticMetadata(
                mCameraManager.getCameraCharacteristics(cameraId), CheckLevel.ASSERT,
                mCollector);

        for (int i = 0; i < sTemplates.length; i++) {
            try {
                CaptureRequest.Builder request = camera.createCaptureRequest(sTemplates[i]);
                Boolean enableZsl = getEnableZslValue(request);
                if (enableZsl != null) {
                    if (VERBOSE) {
                        Log.v(TAG, ""enableZsl is "" + enableZsl + "" for template "" + sTemplates[i]);
                    }

                    mCollector.expectTrue(""CaptureRequest.CONTROL_ENABLE_ZSL should be false."",
                            !enableZsl);
                }
            } catch (IllegalArgumentException e) {
                if (sTemplates[i] == CameraDevice.TEMPLATE_MANUAL &&
                        !staticInfo.isCapabilitySupported(CameraCharacteristics.
                                REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                    // OK
                } else if (sTemplates[i] == CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG &&
                        !staticInfo.isCapabilitySupported(CameraCharacteristics.
                                REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING) &&
                        !staticInfo.isCapabilitySupported(CameraCharacteristics.
                                REQUEST_AVAILABLE_CAPABILITIES_YUV_REPROCESSING)) {
                   // OK.
                } else if (sLegacySkipTemplates.contains(sTemplates[i]) &&
                        staticInfo.isHardwareLevelLegacy()) {
                   // OK
                } else if (sTemplates[i] != CameraDevice.TEMPLATE_PREVIEW &&
                        !staticInfo.isColorOutputSupported()) {
                   // OK, depth-only devices need only support PREVIEW template
                } else {
                   throw e; // rethrow
                }
            }
        }
        camera.close();
    }

    /**
     * Verify CaptureRequest.CONTROL_ENABLE_ZSL values.
     * <p>Verify CaptureRequest.CONTROL_ENABLE_ZSL is false if available in all templates.</p>
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity"	"executeTests"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/base/SensorCtsVerifierTestActivity.java"	""	"public void test/*

 *.
 */

package com.android.cts.verifier.sensors.base;

import android.hardware.cts.helpers.reporting.ISensorTestNode;

import com.android.cts.verifier.sensors.reporting.SensorTestDetails;
import com.android.cts.verifier.sensors.reporting.SensorTestDetails.ResultCode;

import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;
import java.lang.reflect.Modifier;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;

/**
 * An Activity that provides a test execution engine for Sensor CtsVerifier tests. The tests are
 * able to interact with an operator.
 *
 * Sub-classes reuse its own class definition to 'load' tests at runtime through reflection.
 */
public abstract class SensorCtsVerifierTestActivity extends BaseSensorTestActivity {
    private volatile int mTestPassedCounter;
    private volatile int mTestSkippedCounter;
    private volatile int mTestFailedCounter;
    private volatile ISensorTestNode mCurrentTestNode;
    private volatile boolean mEnableRetry = false;

    /**
     * {@inheritDoc}
     */
    protected SensorCtsVerifierTestActivity(
            Class<? extends SensorCtsVerifierTestActivity> testClass) {
        super(testClass);
    }

    /**
     * {@inheritDoc}
     * Constructor to be used by subclasses.
     *
     * @param testClass   The class that contains the tests. It is dependant on test executor
     *                    implemented by subclasses.
     * @param enableRetry Subclass can enable retry mechanism for subtests.
     */
    protected SensorCtsVerifierTestActivity(
        Class<? extends SensorCtsVerifierTestActivity> testClass, boolean enableRetry) {
        super(testClass);
        mEnableRetry = enableRetry;
    }

    /**
     * Executes Semi-automated Sensor tests.
     * Execution is driven by this class, and allows discovery of tests using reflection.
     */
    @Override
    protected SensorTestDetails executeTests() throws InterruptedException {
        // TODO: use reporting to log individual test results
        Iterator<Method> testMethodIt = findTestMethods().iterator();
        while (testMethodIt.hasNext()) {
            Method testMethod = testMethodIt.next();
            boolean isLastSubtest = !testMethodIt.hasNext();
            getTestLogger().logTestStart(testMethod.getName());
            SensorTestDetails testDetails = executeTest(testMethod);
            getTestLogger().logTestDetails(testDetails);

            // If tests enable retry and get failed result, trigger the retry process.
            while (mEnableRetry && testDetails.getResultCode().equals(ResultCode.FAIL)) {
                if (isLastSubtest) {
                    waitForUserToFinish();
                } else {
                    waitForUserToRetry();
                }
                if (!getShouldRetry()) {
                    break;
                }
                mTestFailedCounter--;
                testDetails = executeTest(testMethod);
                getTestLogger().logTestDetails(testDetails);
            }
        }
        return new SensorTestDetails(
                getApplicationContext(),
                getTestClassName(),
                mTestPassedCounter,
                mTestSkippedCounter,
                mTestFailedCounter);
    }

    protected ISensorTestNode getCurrentTestNode() {
        return mCurrentTestNode;
    }

    private List<Method> findTestMethods() {
        ArrayList<Method> testMethods = new ArrayList<>();
        for (Method method : mTestClass.getDeclaredMethods()) {
            if (Modifier.isPublic(method.getModifiers())
                    && method.getParameterTypes().length == 0
                    && method.getName().startsWith(""test"")
                    && method.getReturnType().equals(String.class)) {
                testMethods.add(method);
            }
        }
        return testMethods;
    }

    private SensorTestDetails executeTest(Method testMethod) throws InterruptedException {
        String testMethodName = testMethod.getName();
        String testName = String.format(""%s#%s"", getTestClassName(), testMethodName);
        mCurrentTestNode = new TestNode(testMethod);

        SensorTestDetails testDetails;
        try {
            String testSummary = (String) testMethod.invoke(this);
            testDetails =
                    new SensorTestDetails(testName, SensorTestDetails.ResultCode.PASS, testSummary);
        } catch (InvocationTargetException e) {
            // get the inner exception, because we use reflection APIs to execute the test
            testDetails = new SensorTestDetails(testName, ""TestExecution"", e.getCause());
        } catch (Throwable e) {
            testDetails = new SensorTestDetails(testName, ""TestInfrastructure"", e);
        }

        SensorTestDetails.ResultCode resultCode = testDetails.getResultCode();
        switch(resultCode) {
            case PASS:
            // Warning should still be treated as a pass, but with more detail to the test runner.
            case WARNING:
                ++mTestPassedCounter;
                break;
            case SKIPPED:
                ++mTestSkippedCounter;
                break;
            case INTERRUPTED:
                throw new InterruptedException();
            case FAIL:
                ++mTestFailedCounter;
                break;
            default:
                throw new IllegalStateException(""Unknown ResultCode: "" + resultCode);
        }

        return testDetails;
    }

    private class TestNode implements ISensorTestNode {
        private final Method mTestMethod;

        public TestNode(Method testMethod) {
            mTestMethod = testMethod;
        }

        @Override
        public String getName() {
            return mTestClass.getSimpleName() + ""_"" + mTestMethod.getName();
        }
    }

    /**
     * Show the instruction for the first time execution and wait for user to begin the test.
     *
     * @param descriptionResId The description for the first time execution.
     */
    protected void setFirstExecutionInstruction(int ... descriptionResId) throws Throwable {
        if (!getShouldRetry()) {
            SensorTestLogger logger = getTestLogger();
            for (int id : descriptionResId) {
                logger.logInstructions(id);
            }
            waitForUserToBegin();
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Renderer.AccuracyRenderer"	"doTestSpecificRendering"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Renderer/AccuracyRenderer.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Renderer;

import android.content.Context;

/**
 * Renderer for the Accuracy test.
 */
public class AccuracyRenderer extends BaseRenderer {
    public AccuracyRenderer(Context context) {
        super(context);
    }

    @Override
    protected void doPreRenderingSetup() {
        // Set view and projection matrix to orthogonal so that camera preview fills the screen.
        mViewMatrix = mOrthogonalViewMatrix;
        mProjectionMatrix = mOrthogonalProjectionMatrix;
    }

    @Override
    protected void doTestSpecificRendering() {
        // Update the texture with the latest camera frame if there is an update pending.
        updateCameraTexture();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.RVCVXCheckTestActivity"	"RVCVXCheckTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/RVCVXCheckTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import android.app.AlertDialog;
import android.content.Context;
import android.content.DialogInterface;
import android.content.Intent;
import android.content.res.Resources;
import android.hardware.cts.helpers.SensorTestStateNotSupportedException;
import android.os.Bundle;
import android.os.PowerManager;
import android.text.method.LinkMovementMethod;
import android.text.Html;
import android.util.Log;
import android.view.View;
import android.view.View.OnClickListener;
import android.view.ViewGroup;
import android.view.ViewGroup.LayoutParams;
import android.widget.Button;
import android.widget.CheckBox;
import android.widget.CompoundButton;
import android.widget.TextView;

import com.android.compatibility.common.util.ReportLog;
import com.android.compatibility.common.util.ResultType;
import com.android.compatibility.common.util.ResultUnit;
import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;
import com.android.cts.verifier.sensors.helpers.OpenCVLibrary;

import junit.framework.Assert;
import java.io.IOException;
import java.io.InputStream;
import java.util.concurrent.CountDownLatch;

/**
 * This test (Rotation Vector - Computer Vision Cross Check, or RXCVXCheck for short) verifies that
 * mobile device can detect the orientation of itself in a relatively accurate manner.
 *
 * Currently only ROTATION_VECTOR sensor is used.
 *
 */
public class RVCVXCheckTestActivity
        extends SensorCtsVerifierTestActivity {
    public RVCVXCheckTestActivity() {
        super(RVCVXCheckTestActivity.class);
    }

    CountDownLatch mRecordActivityFinishedSignal = null;

    private static final int REQ_CODE_TXCVRECORD = 0x012345678;
    private static final boolean TEST_USING_DEBUGGING_DATA = false;
    private static final String PATH_DEBUGGING_DATA = ""/sdcard/RXCVRecData/150313-014443/"";

    private String mRecPath;

    RVCVXCheckAnalyzer.AnalyzeReport mReport = null;

    private boolean mRecordSuccessful = false;
    private boolean mOpenCVLoadSuccessful = false;
    private boolean mFlipAxes = false;

    private static class Criterion {
        public static final float roll_rms_error = 0.15f;
        public static final float pitch_rms_error = 0.15f;
        public static final float yaw_rms_error = 0.25f;

        public static final float roll_max_error = 0.35f;
        public static final float pitch_max_error = 0.35f;
        public static final float yaw_max_error = 0.5f;

        public static final float sensor_period_stdev = 0.25e-3f;
    };


    /**
     * The activity setup collects all the required data for test cases.
     * This approach allows to test all sensors at once.
     */
    @Override
    protected void activitySetUp() throws InterruptedException {

        mRecPath = """";

        // Test result is fail by default.
        getReportLog().setSummary(
                ""Initialize failed"", 0, ResultType.NEUTRAL, ResultUnit.NONE);

        showDetailedTutorialLink();

        showUserMessage(""Loading OpenCV Library..."");

        if (!OpenCVLibrary.load(this,
                false /*allowLocal*/, true/*allowPackage*/, false/*allowInstall*/)) {
            // cannot load opencv library
            showUserMessage(""Cannot load OpenCV library! Please follow instruction and install "" +
                    ""OpenCV Manager 3.0.0 and start this test again."");
            waitForUserToContinue();
            clearText();
            return;
        }
        showUserMessage(""OpenCV Library Successfully Loaded."");
        showOpenCVLibaryLicenseDisplayButton();

        mOpenCVLoadSuccessful = true;

        if (TEST_USING_DEBUGGING_DATA) {
            mRecPath = PATH_DEBUGGING_DATA;

            // assume the data is there already
            mRecordSuccessful = true;
        } else {
            showUserMessage(""Take the test as instructed below:\n"" +
                ""1. Print out the test pattern and place it on a ""+
                   ""horizontal surface.\n"" +
                ""2. Start the test and align the yellow square on the screen ""+
                   ""roughly to the yellow sqaure.\n"" +
                ""3. Follow the prompt to orbit the device around the test "" +
                   ""pattern while aiming the field of view at the test pattern"" +
                   ""at the same time.\n"" +
                ""4. Wait patiently for the analysis to finish."");

            showAxesToggle();
            waitForUserToContinue();

            // prepare sync signal
            mRecordActivityFinishedSignal = new CountDownLatch(1);

            // record both sensor and camera
            Intent intent = new Intent(this, RVCVRecordActivity.class);
            startActivityForResult(intent, REQ_CODE_TXCVRECORD);

            // wait for record finish
            mRecordActivityFinishedSignal.await();

            if ("""".equals(mRecPath)) {
                showUserMessage(""Recording failed or exited prematurely."");
                waitForUserToContinue();
            } else {
                showUserMessage(""Recording is done!"");
                showUserMessage(""Result are in path: "" + mRecPath);
                mRecordSuccessful = true;
            }
        }


        if (!mRecordSuccessful) {
            getReportLog().setSummary(
                    ""Record failed"", 0, ResultType.NEUTRAL, ResultUnit.NONE);
        } else {
            showUserMessage(""Please wait for the analysis ... \n""+
                            ""It may take a few minutes, you will be noted when ""+
                            ""its finished by sound and vibration. "");

            // Analysis of recorded video and sensor data using RVCXAnalyzer
            RVCVXCheckAnalyzer analyzer = new RVCVXCheckAnalyzer(mRecPath, mFlipAxes);

            // acquire a partial wake lock just in case CPU fall asleep
            PowerManager pm = (PowerManager) getSystemService(Context.POWER_SERVICE);
            PowerManager.WakeLock wl = pm.newWakeLock(PowerManager.FULL_WAKE_LOCK,
                    ""RVCVXCheckAnalyzer"");

            wl.acquire();
            mReport = analyzer.processDataSet();
            wl.release();

            playSound();
            vibrate(500);

            if (mReport == null) {
                showUserMessage(""Analysis failed due to unknown reason!"");
            } else {
                if (mReport.error) {
                    getReportLog().setSummary(""Analysis failed: ""+mReport.reason, 0,
                            ResultType.NEUTRAL, ResultUnit.NONE);

                    showUserMessage(""Analysis failed: "" + mReport.reason);
                } else {
                    getReportLog().setSummary(
                            ""Analysis succeed"", 1, ResultType.NEUTRAL, ResultUnit.NONE);

                    getReportLog().addValue(""Roll error RMS"", mReport.roll_rms_error,
                            ResultType.LOWER_BETTER, ResultUnit.RADIAN);
                    getReportLog().addValue(""Pitch error RMS"", mReport.pitch_rms_error,
                            ResultType.LOWER_BETTER, ResultUnit.RADIAN);
                    getReportLog().addValue(""Yaw error RMS"", mReport.yaw_rms_error,
                            ResultType.LOWER_BETTER, ResultUnit.RADIAN);

                    getReportLog().addValue(""Roll error MAX"", mReport.roll_max_error,
                            ResultType.LOWER_BETTER, ResultUnit.RADIAN);
                    getReportLog().addValue(""Pitch error MAX"", mReport.pitch_max_error,
                            ResultType.LOWER_BETTER, ResultUnit.RADIAN);
                    getReportLog().addValue(""Yaw error MAX"", mReport.yaw_max_error,
                            ResultType.LOWER_BETTER, ResultUnit.RADIAN);

                    getReportLog().addValue(""Number of frames"", mReport.n_of_frame,
                            ResultType.NEUTRAL, ResultUnit.COUNT);
                    getReportLog().addValue(""Number of valid frames"", mReport.n_of_valid_frame,
                            ResultType.NEUTRAL, ResultUnit.COUNT);

                    getReportLog().addValue(""Sensor period mean"", mReport.sensor_period_avg*1000,
                            ResultType.NEUTRAL, ResultUnit.MS);
                    getReportLog().addValue(""Sensor period stdev"", mReport.sensor_period_stdev*1000,
                            ResultType.NEUTRAL, ResultUnit.MS);
                    getReportLog().addValue(""Time offset"", mReport.optimal_delta_t*1000,
                            ResultType.NEUTRAL, ResultUnit.MS);
                    getReportLog().addValue(""Yaw offset"", mReport.yaw_offset,
                            ResultType.NEUTRAL, ResultUnit.RADIAN);

                    showUserMessage(String.format(""Analysis finished!\n"" +
                                    ""Roll error (Rms, max) = %4.3f, %4.3f rad\n"" +
                                    ""Pitch error (Rms, max) = %4.3f, %4.3f rad\n"" +
                                    ""Yaw error (Rms, max) = %4.3f, %4.3f rad\n"" +
                                    ""N of Frame (valid, total) = %d, %d\n"" +
                                    ""Sensor period (mean, stdev) = %4.3f, %4.3f ms\n"" +
                                    ""Time offset: %4.3f s \n"" +
                                    ""Yaw offset: %4.3f rad \n\n"",
                            mReport.roll_rms_error, mReport.roll_max_error,
                            mReport.pitch_rms_error, mReport.pitch_max_error,
                            mReport.yaw_rms_error, mReport.yaw_max_error,
                            mReport.n_of_valid_frame, mReport.n_of_frame,
                            mReport.sensor_period_avg * 1000.0, mReport.sensor_period_stdev*1000.0,
                            mReport.optimal_delta_t, mReport.yaw_offset));
                    showUserMessage(""Please click next after details reviewed."");
                    waitForUserToContinue();
                }
            }
        }
        clearText();
    }

    /**
    Receiving the results from the RVCVRecordActivity, which is a patch where the recorded
    video and sensor data is stored.
    */
    @Override
    protected void onActivityResult(int requestCode, int resultCode, Intent data) {
        // Check which request we're responding to
        if (requestCode == REQ_CODE_TXCVRECORD) {
            // Make sure the request was successful

            if (resultCode == RESULT_OK) {
                mRecPath = data.getData().getPath();
            }

            // notify it is finished
            mRecordActivityFinishedSignal.countDown();
        }
        super.onActivityResult(requestCode, resultCode, data);
    }

    /**
     * Test cases.
     *
     * Test cases is numbered to make sure they are executed in the right order.
     */

    public String test00OpenCV() throws Throwable {

        String message = ""OpenCV is loaded"";
        Assert.assertTrue(""OpenCV library cannot be loaded. If OpenCV Manager is just installed, "" +
                          ""please restart this test."", mOpenCVLoadSuccessful);
        return message;
    }


    public String test01Recording() throws Throwable {

        loadOpenCVSuccessfulOrSkip();

        String message = ""Record is successful."";
        Assert.assertTrue(""Record is not successful."", mRecordSuccessful);
        return message;
    }

    public String test02Analysis() throws Throwable {

        loadOpenCVSuccessfulOrSkip();
        recordSuccessfulOrSkip();

        String message = ""Analysis result: "" + mReport.reason;
        Assert.assertTrue(message, (mReport!=null && !mReport.error));
        return message;
    }

    public String test1RollAxis() throws Throwable {

        loadOpenCVSuccessfulOrSkip();
        recordSuccessfulOrSkip();
        analyzeSuccessfulOrSkip();

        String message = ""Test Roll Axis Accuracy"";

        assertLessThan(""Roll RMS error"", mReport.roll_rms_error, Criterion.roll_rms_error);
        assertLessThan(""Roll max error"", mReport.roll_max_error, Criterion.roll_max_error);
        return message;
    }

    public String test2PitchAxis() throws Throwable {

        loadOpenCVSuccessfulOrSkip();
        recordSuccessfulOrSkip();
        analyzeSuccessfulOrSkip();

        String message = ""Test Pitch Axis Accuracy"";

        assertLessThan(""Pitch RMS error"", mReport.pitch_rms_error, Criterion.pitch_rms_error);
        assertLessThan(""Pitch max error"", mReport.pitch_max_error, Criterion.pitch_max_error);
        return message;
    }

    public String test3YawAxis() throws Throwable {

        loadOpenCVSuccessfulOrSkip();
        recordSuccessfulOrSkip();
        analyzeSuccessfulOrSkip();

        String message = ""Test Yaw Axis Accuracy"";

        assertLessThan(""Yaw RMS error"", mReport.yaw_rms_error, Criterion.yaw_rms_error);
        assertLessThan(""Yaw max error"", mReport.yaw_max_error, Criterion.yaw_max_error);
        return message;
    }

    private void assertLessThan(String message, double lhs, double rhs) {
        Assert.assertTrue(String.format(""%s - expected %.4f < %.4f"", message, lhs, rhs),
                lhs < rhs);
    }

    private void loadOpenCVSuccessfulOrSkip() throws SensorTestStateNotSupportedException {
        if (!mOpenCVLoadSuccessful)
            throw new SensorTestStateNotSupportedException(""Skipped due to OpenCV cannot be loaded"");
    }

    private void recordSuccessfulOrSkip() throws SensorTestStateNotSupportedException {
        if (!mRecordSuccessful)
            throw new SensorTestStateNotSupportedException(""Skipped due to record failure."");
    }

    private void analyzeSuccessfulOrSkip() throws SensorTestStateNotSupportedException {
        if (mReport == null || mReport.error)
            throw new SensorTestStateNotSupportedException(""Skipped due to CV Analysis failure."");
    }

    /*
     *  This function serves as a proxy as appendText is marked to be deprecated.
     *  When appendText is removed, this function will have a different implementation.
     *
     */
    private void showUserMessage(String s) {
        appendText(s);
    }

    private void showDetailedTutorialLink() {
        TextView textView = new TextView(this);
        textView.setText(Html.fromHtml(
                    ""Detailed test instructions can be found at "" +
                    ""<A href=\""http://goo.gl/xTwB4d\"">http://goo.gl/xTwB4d</a><br>""));
        textView.setMovementMethod(LinkMovementMethod.getInstance());
        textView.setPadding(10, 0, 0, 0);
        getTestLogger().logCustomView(textView);
    }

    private void showOpenCVLibaryLicenseDisplayButton() {
        Button btnLicense = new Button(this);
        btnLicense.setText(""View OpenCV Library BSD License Agreement"");
        // Avoid default all cap text on button.
        btnLicense.setTransformationMethod(null);
        btnLicense.setLayoutParams(new LayoutParams(
                        ViewGroup.LayoutParams.WRAP_CONTENT,
                                    ViewGroup.LayoutParams.WRAP_CONTENT));

        // load
        Resources res = getResources();
        InputStream rawStream = res.openRawResource(R.raw.opencv_library_license);
        byte[] byteArray;
        try {
            byteArray = new byte[rawStream.available()];
            rawStream.read(byteArray);
        } catch (IOException e) {
            e.printStackTrace();
            byteArray = ""Unable to load license text."".getBytes();
        }
        final String licenseText = new String(byteArray);

        btnLicense.setOnClickListener(new OnClickListener() {
            public void onClick(View v) {
                AlertDialog dialog =
                    new AlertDialog.Builder(RVCVXCheckTestActivity.this)
                        .setTitle(""OpenCV Library BSD License"")
                        .setMessage(licenseText)
                        .setPositiveButton(""Acknowledged"", new DialogInterface.OnClickListener() {
                                public void onClick(DialogInterface dialog, int id) {
                                    dialog.dismiss();
                                }
                            })
                        .show();

                TextView textView = (TextView) dialog.findViewById(android.R.id.message);
                textView.setTextSize(9);
            }
        });
        getTestLogger().logCustomView(btnLicense);
    }

    private void showAxesToggle() {
        CheckBox checkBox = new CheckBox(this);

        checkBox.setText(Html.fromHtml(
            ""<b>Flip axes</b>: Only enable this setting if this device has a combination  ""+
            ""front/rear camera, and the sensor's positive Z axis is aligned with the camera's "" +
            ""field of view""));
        checkBox.setOnCheckedChangeListener(new CompoundButton.OnCheckedChangeListener() {
            @Override
            public void onCheckedChanged(CompoundButton buttonView,
                                         boolean isChecked) {
                mFlipAxes = isChecked;
            }
        });

        getTestLogger().logCustomView(checkBox);
    }

    @Override
    protected void onCreate(Bundle savedInstanceState) {

        super.onCreate(savedInstanceState);

        // GlSurfaceView is not necessary for this test
        closeGlSurfaceView();
    }

    @Override
    protected void onPause() {
        super.onPause();
    }

    @Override
    protected void onResume() {
        super.onResume();

    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.HingeAngleTestActivity"	"HingeAngleTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/HingeAngleTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;

import android.content.Context;
import android.hardware.Sensor;
import android.hardware.SensorManager;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.sensoroperations.TestSensorOperation;
import android.hardware.cts.helpers.sensorverification.HingeAngleVerification;

public class HingeAngleTestActivity extends SensorCtsVerifierTestActivity {
    private SensorManager mSensorManager;

    public HingeAngleTestActivity() {
        super(HingeAngleTestActivity.class, true /* enableRetry */);
    }

    @Override
    protected void activitySetUp() throws InterruptedException {
        mSensorManager = (SensorManager) getSystemService(Context.SENSOR_SERVICE);

        getTestLogger().logInstructions(R.string.snsr_hinge_angle_test_instructions);
        waitForUserToContinue();
    }

    public String testExerciseHinge() throws Throwable {
        return verifyMeasurements(R.string.snsr_hinge_angle_test_exercise_hinge);
    }

    /**
     * Helper method that verifies hinge sensor measurements meet the following criteria:
     *  - Maximum range of the sensor isn't exceeded.
     *  - Sensor resolution is respected
     *  - Duplicate values are not seen back-to-back.
     */
    private String verifyMeasurements(int instructionsResId) throws Throwable {
        Sensor wakeUpSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_HINGE_ANGLE);
        TestSensorEnvironment environment = new TestSensorEnvironment(
                getApplicationContext(),
                wakeUpSensor,
                0, /* samplingPeriod */
                SensorManager.SENSOR_DELAY_FASTEST);

        TestSensorOperation sensorOperation = TestSensorOperation
                .createOperation(environment, () -> waitForUser(instructionsResId));

        HingeAngleVerification verification = new HingeAngleVerification();
        sensorOperation.addVerification(verification);
        sensorOperation.execute(getCurrentTestNode());

        return null;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Renderer.RobustnessRenderer"	"doTestSpecificRendering"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Renderer/RobustnessRenderer.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Renderer;

import android.content.Context;

import com.android.cts.verifier.sensors.sixdof.Renderer.Renderable.RectangleRenderable;

import javax.microedition.khronos.egl.EGLConfig;
import javax.microedition.khronos.opengles.GL10;

/**
 * Renderer for the robustness test
 */
public class RobustnessRenderer extends BaseRenderer {

    private float[] mRectanglePositionData;
    private RectangleRenderable mRectangle;

    public RobustnessRenderer(Context context) {
        super(context);
    }

    @Override
    public void onSurfaceCreated(GL10 glUnused, EGLConfig config) {
        super.onSurfaceCreated(glUnused, config);
        mRectangle = new RectangleRenderable();
    }

    @Override
    public void onSurfaceChanged(GL10 glUnused, int width, int height) {
        super.onSurfaceChanged(glUnused, width, height);
        mRectangle.initialiseRectangle(mRectanglePositionData);
        mProjectionMatrix = mFrustrumProjectionMatrix;
    }

    public void setLineColor(float[] newColor) {
        if (mIsValid) {
            mRectangle.setLineColor(newColor);
        }
    }

    public void updateCurrentAngle(float newAngle) {
        if (mIsValid) {
            mRectangle.setRotationAngle(newAngle);
        }
    }

    public void updateTargetAngle(float newAngle) {
        if (mIsValid) {
            mCameraPreview.setRotationAngle(newAngle);
        }
    }

    @Override
    protected void doPreRenderingSetup() {
        // Set view matrix to one that doesn't move.
        mViewMatrix = mOrthogonalViewMatrix;
        // Set projection matrix to show camera preview slightly set back.
        mProjectionMatrix = mFrustrumProjectionMatrix;
    }

    @Override
    protected void doTestSpecificRendering() {
        // Update the texture with the latest camera frame if there is an update pending.
        updateCameraTexture();

        mDrawParameters.update(mViewMatrix, mProjectionMatrix);
        mRectangle.draw(mDrawParameters);
    }

    @Override
    protected float[] getCameraCoordinates(float left, float right, float bottom, float top) {
        // Set rectangle coordinates to be the exact same as the camera preview.
        mRectanglePositionData = new float[]{
                2 * left, 2 * top, 0.0f,
                2 * left, 2 * bottom, 0.0f,

                2 * left, 2 * bottom, 0.0f,
                2 * right, 2 * bottom, 0.0f,

                2 * right, 2 * bottom, 0.0f,
                2 * right, 2 * top, 0.0f,

                2 * right, 2 * top, 0.0f,
                2 * left, 2 * top, 0.0f,
        };

        return new float[]{
                2 * left, 2 * top, 0.0f,
                2 * left, 2 * bottom, 0.0f,
                2 * right, 2 * top, 0.0f,
                2 * left, 2 * bottom, 0.0f,
                2 * right, 2 * bottom, 0.0f,
                2 * right, 2 * top, 0.0f,
        };
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.SuspendStateMonitor"	"uptimeMillis"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/SuspendStateMonitor.java"	""	"public void testpackage android.hardware.cts.helpers;

import java.util.ArrayList;
import java.util.List;
import java.util.Timer;
import java.util.TimerTask;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

import android.hardware.Sensor;
import android.hardware.TriggerEvent;
import android.hardware.TriggerEventListener;
import android.os.Handler;
import android.os.SystemClock;
import android.util.Log;

import junit.framework.Assert;

public class SuspendStateMonitor extends TimerTask {
    private final double firstRealTimeMillis;
    private final double firstUpTimeMillis;
    private double lastSleepTimeSeconds = 0;
    private volatile long lastWakeUpTime = 0;
    Timer sleepMonitoringTimer = new Timer();
    private final List<CountDownLatch> mWaitForWakeUpLatch = new ArrayList<>();
    private final String TAG = ""SensorCTSDeviceSuspendMonitor"";

    /**
     * Returns the time the device slept since the start of the application,
     * in seconds.
     */
    public double getSleepTimeSeconds() {
        double totalSinceStart = android.os.SystemClock.elapsedRealtime() - firstRealTimeMillis;
        double upTimeSinceStart = android.os.SystemClock.uptimeMillis() - firstUpTimeMillis;
        return (totalSinceStart - upTimeSinceStart) / 1000;
    }

    public long getLastWakeUpTime() {
        return lastWakeUpTime;
    }


    public void waitForWakeUp(int numSeconds) throws InterruptedException {
        CountDownLatch latch = new CountDownLatch(1);
        synchronized(mWaitForWakeUpLatch) {
            mWaitForWakeUpLatch.add(latch);
        }
        if (numSeconds == -1) {
            // Wait indefinitely.
            latch.await();
        } else {
            // Wait for the specified number of seconds.
            boolean countZero = latch.await(numSeconds, TimeUnit.SECONDS);
            if (!countZero) {
               Log.e(TAG, ""Device did not enter suspend state."");
            }
        }
    }

    /**
     * Run every 100ms inside the TimerTask.
     */
    @Override
    public void run() {
        if (getSleepTimeSeconds() - lastSleepTimeSeconds > 0.1) {
            lastSleepTimeSeconds = getSleepTimeSeconds();
            lastWakeUpTime = SystemClock.elapsedRealtime();
            // If any client is waiting for wake-up, call countDown to unblock it.
            synchronized(mWaitForWakeUpLatch) {
                for (CountDownLatch latch : mWaitForWakeUpLatch) {
                    latch.countDown();
                }
            }
        }
    }

    public SuspendStateMonitor() {
        firstRealTimeMillis = android.os.SystemClock.elapsedRealtime();
        firstUpTimeMillis = android.os.SystemClock.uptimeMillis();
        // Every 100 miliseconds, check whether the device has slept.
        sleepMonitoringTimer.schedule(this, 0, 100);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.MeanVerificationTest"	"testVerify"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/MeanVerificationTest.java"	""	"public void testVerify() {
        float[][] values = {
                {0, 1, 0},
                {1, 2, 1},
                {2, 3, 4},
                {3, 4, 9},
                {4, 5, 16},
        };

        float[] expected = {2.0f, 3.0f, 6.0f};
        float[] upperThresholds = {0.3f, 0.3f, 0.3f};
        float[] lowerThresholds = {0.1f, 0.1f, 0.1f};
        SensorStats stats = new SensorStats();
        MeanVerification verification =
            getVerification(expected, upperThresholds, lowerThresholds, values);
        verification.verify(stats);
        verifyStats(stats, true, MEANS);

        // Test the lower threshold
        expected = new float[]{2.4f, 3.3f, 6.4f};
        lowerThresholds = new float[]{0.6f, 0.6f, 0.6f};
        stats = new SensorStats();
        verification = getVerification(expected, upperThresholds, lowerThresholds, values);
        verification.verify(stats);
        verifyStats(stats, true, MEANS);

        lowerThresholds = new float[]{0.1f, 0.6f, 0.6f};
        stats = new SensorStats();
        verification = getVerification(expected, upperThresholds, lowerThresholds, values);
        try {
            verification.verify(stats);
            throw new Error(""Expected an AssertionError"");
        } catch (AssertionError e) {
            // Expected;
        }
        verifyStats(stats, false, MEANS);

        lowerThresholds = new float[]{0.6f, 0.1f, 0.6f};
        stats = new SensorStats();
        verification = getVerification(expected, upperThresholds, lowerThresholds, values);
        try {
            verification.verify(stats);
            throw new Error(""Expected an AssertionError"");
        } catch (AssertionError e) {
            // Expected;
        }
        verifyStats(stats, false, MEANS);

        lowerThresholds = new float[]{0.6f, 0.6f, 0.1f};
        stats = new SensorStats();
        verification = getVerification(expected, upperThresholds, lowerThresholds, values);
        try {
            verification.verify(stats);
            throw new Error(""Expected an AssertionError"");
        } catch (AssertionError e) {
            // Expected;
        }
        verifyStats(stats, false, MEANS);

        // Test the upper threshold
        expected = new float[]{1.5f, 2.8f, 5.7f};
        upperThresholds = new float[]{0.6f, 0.6f, 0.6f};
        lowerThresholds = new float[]{0.1f, 0.1f, 0.1f};
        stats = new SensorStats();
        verification = getVerification(expected, upperThresholds, lowerThresholds, values);
        verification.verify(stats);
        verifyStats(stats, true, MEANS);

        upperThresholds = new float[]{0.1f, 0.6f, 0.6f};
        stats = new SensorStats();
        verification = getVerification(expected, upperThresholds, lowerThresholds, values);
        try {
            verification.verify(stats);
            throw new Error(""Expected an AssertionError"");
        } catch (AssertionError e) {
            // Expected;
        }
        verifyStats(stats, false, MEANS);

        upperThresholds = new float[]{0.6f, 0.1f, 0.6f};
        stats = new SensorStats();
        verification = getVerification(expected, upperThresholds, lowerThresholds, values);
        try {
            verification.verify(stats);
            throw new Error(""Expected an AssertionError"");
        } catch (AssertionError e) {
            // Expected;
        }
        verifyStats(stats, false, MEANS);

        upperThresholds = new float[]{0.6f, 0.6f, 0.1f};
        stats = new SensorStats();
        verification = getVerification(expected, upperThresholds, lowerThresholds, values);
        try {
            verification.verify(stats);
            throw new Error(""Expected an AssertionError"");
        } catch (AssertionError e) {
            // Expected;
        }
        verifyStats(stats, false, MEANS);
    }

    private static MeanVerification getVerification(float[] expected, float[] upperThresholds,
            float[] lowerThresholds, float[] ... values) {
        Collection<TestSensorEvent> events = new ArrayList<>(values.length);
        for (float[] value : values) {
            events.add(new TestSensorEvent(null, 0, 0, value));
        }
        MeanVerification verification =
            new MeanVerification(expected, upperThresholds, lowerThresholds);
        verification.addSensorEvents(events);
        return verification;
    }

    private void verifyStats(SensorStats stats, boolean passed, float[] means) {
        assertEquals(passed, stats.getValue(MeanVerification.PASSED_KEY));
        float[] actual = (float[]) stats.getValue(SensorStats.MEAN_KEY);
        assertEquals(means.length, actual.length);
        for (int i = 0; i < means.length; i++) {
            assertEquals(means[i], actual[i], 0.1);
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorParameterRangeTest"	"testProximityFifoLength"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorParameterRangeTest.java"	""	"public void testProximityFifoLength() throws Throwable {
        if (!mHasHifiSensors || !mHasProximitySensor) return;
        checkMinFifoLength(Sensor.TYPE_PROXIMITY, PROXIMITY_SENSOR_MIN_FIFO_LENGTH);
    }"	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorParameterRangeTest"	"testAccelerometerRange"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorParameterRangeTest.java"	""	"public void testAccelerometerRange() {
        double hifiMaxFrequency = ApiLevelUtil.isAtLeast(Build.VERSION_CODES.N) ?
                ACCELEROMETER_HIFI_MAX_FREQUENCY :
                ACCELEROMETER_HIFI_MAX_FREQUENCY_BEFORE_N;

        double accelerometerMaxFrequency = mIsAutomotive ?
                ACCELEROMETER_AUTOMOTIVE_MAX_FREQUENCY :
                ACCELEROMETER_MAX_FREQUENCY;

        checkSensorRangeAndFrequency(
                Sensor.TYPE_ACCELEROMETER,
                ACCELEROMETER_MAX_RANGE,
                accelerometerMaxFrequency,
                ACCELEROMETER_HIFI_MAX_RANGE,
                ACCELEROMETER_HIFI_MIN_FREQUENCY,
                hifiMaxFrequency);
    }

    @AppModeFull(reason = ""Instant apps cannot have HIGH_SAMPLING_RATE_SENSORS permission."")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorParameterRangeTest"	"testGyroscopeRange"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorParameterRangeTest.java"	""	"public void testGyroscopeRange() {
        double hifiMaxFrequency = ApiLevelUtil.isAtLeast(Build.VERSION_CODES.N) ?
                GYRO_HIFI_MAX_FREQUENCY :
                GYRO_HIFI_MAX_FREQUENCY_BEFORE_N;

        double gyroMaxRange = mIsAutomotive &&
                ApiLevelUtil.isAtLeast(Build.VERSION_CODES.Q) ?
                GYRO_AUTOMOTIVE_MAX_RANGE :
                GYRO_MAX_RANGE;

        double gyroMaxFrequency = mIsAutomotive ?
                GYRO_AUTOMOTIVE_MAX_FREQUENCY :
                GYRO_MAX_FREQUENCY;

        checkSensorRangeAndFrequency(
                Sensor.TYPE_GYROSCOPE,
                gyroMaxRange,
                gyroMaxFrequency,
                GYRO_HIFI_MAX_RANGE,
                GYRO_HIFI_MIN_FREQUENCY,
                hifiMaxFrequency);
    }

    @AppModeFull(reason = ""Instant apps cannot have HIGH_SAMPLING_RATE_SENSORS permission."")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorParameterRangeTest"	"testMagnetometerRange"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorParameterRangeTest.java"	""	"public void testMagnetometerRange() {
        checkSensorRangeAndFrequency(
                Sensor.TYPE_MAGNETIC_FIELD,
                MAGNETOMETER_MAX_RANGE,
                MAGNETOMETER_MAX_FREQUENCY,
                MAGNETOMETER_HIFI_MAX_RANGE,
                MAGNETOMETER_HIFI_MIN_FREQUENCY,
                MAGNETOMETER_HIFI_MAX_FREQUENCY);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorParameterRangeTest"	"testPressureRange"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorParameterRangeTest.java"	""	"public void testPressureRange() {
        checkSensorRangeAndFrequency(
                Sensor.TYPE_PRESSURE,
                PRESSURE_MAX_RANGE,
                PRESSURE_MAX_FREQUENCY,
                PRESSURE_HIFI_MAX_RANGE,
                PRESSURE_HIFI_MIN_FREQUENCY,
                PRESSURE_HIFI_MAX_FREQUENCY);
    }

    private void checkSensorRangeAndFrequency(
            int sensorType, double maxRange, double maxFrequency, double hifiMaxRange,
            double hifiMinFrequency, double hifiMaxFrequency) {
        boolean mustMeetHiFi = mHasHifiSensors;

        // CDD 7.9.2/C-1-21: High Performance VR must meet accel, gyro, and mag HiFi requirements
        if (mVrModeHighPerformance && (sensorType == Sensor.TYPE_ACCELEROMETER ||
                sensorType == Sensor.TYPE_GYROSCOPE || sensorType == Sensor.TYPE_MAGNETIC_FIELD)) {
            mustMeetHiFi = true;
        }

        Sensor sensor = mSensorManager.getDefaultSensor(sensorType);
        if (sensor == null) {
            if (mustMeetHiFi) {
                fail(String.format(""Must support sensor type %d"", sensorType));
            } else {
                // Sensor is not required
                return;
            }
        }

        double range = mustMeetHiFi ? hifiMaxRange : maxRange;
        double frequency = mustMeetHiFi ? hifiMaxFrequency : maxFrequency;

        assertTrue(String.format(""%s Range actual=%.2f expected=%.2f %s"",
                    sensor.getName(), sensor.getMaximumRange(), range,
                    SensorCtsHelper.getUnitsForSensor(sensor)),
                sensor.getMaximumRange() >= (range - 0.1));
        double actualMaxFrequency = SensorCtsHelper.getFrequency(sensor.getMinDelay(),
                TimeUnit.MICROSECONDS);
        assertTrue(String.format(""%s Max Frequency actual=%.2f expected=%.2fHz"",
                    sensor.getName(), actualMaxFrequency, frequency), actualMaxFrequency >=
                frequency - 0.1);

        if (mustMeetHiFi) {
            double actualMinFrequency = SensorCtsHelper.getFrequency(sensor.getMaxDelay(),
                    TimeUnit.MICROSECONDS);
            assertTrue(String.format(""%s Min Frequency actual=%.2f expected=%.2fHz"",
                        sensor.getName(), actualMinFrequency, hifiMinFrequency),
                    actualMinFrequency <=  hifiMinFrequency + 0.1);
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorParameterRangeTest"	"testAccelerometerFifoLength"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorParameterRangeTest.java"	""	"public void testAccelerometerFifoLength() throws Throwable {
        if (!mHasHifiSensors) return;
        checkMinFifoLength(Sensor.TYPE_ACCELEROMETER, ACCELEROMETER_MIN_FIFO_LENGTH);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorParameterRangeTest"	"testUncalMagnetometerFifoLength"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorParameterRangeTest.java"	""	"public void testUncalMagnetometerFifoLength() throws Throwable {
        if (!mHasHifiSensors) return;
        checkMinFifoLength(
                Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED,
                UNCAL_MAGNETOMETER_MIN_FIFO_LENGTH);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorParameterRangeTest"	"testPressureFifoLength"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorParameterRangeTest.java"	""	"public void testPressureFifoLength() throws Throwable {
        if (!mHasHifiSensors) return;
        checkMinFifoLength(Sensor.TYPE_PRESSURE, PRESSURE_MIN_FIFO_LENGTH);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorParameterRangeTest"	"testStepDetectorFifoLength"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorParameterRangeTest.java"	""	"public void testStepDetectorFifoLength() throws Throwable {
        if (!mHasHifiSensors) return;
        checkMinFifoLength(Sensor.TYPE_STEP_DETECTOR, STEP_DETECTOR_MIN_FIFO_LENGTH);
    }

    private void checkMinFifoLength(int sensorType, int minRequiredLength) {
        Sensor sensor = mSensorManager.getDefaultSensor(sensorType);
        assertTrue(String.format(""sensor of type=%d (null)"", sensorType), sensor != null);
        int reservedLength = sensor.getFifoReservedEventCount();
        assertTrue(String.format(""Sensor=%s, min required fifo length=%d actual=%d"",
                    sensor.getName(), minRequiredLength, reservedLength),
                    reservedLength >= minRequiredLength);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorParameterRangeTest"	"testStaticSensorId"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorParameterRangeTest.java"	""	"public void testStaticSensorId() {
        // all static sensors should have id of 0
        List<Sensor> sensors = mSensorManager.getSensorList(Sensor.TYPE_ALL);
        List<String> errors = new ArrayList<>();
        for (Sensor s : sensors) {
            int id = s.getId();
            if (id != 0) {
                errors.add(String.format(""sensor \""%s\"" has id %d"", s.getName(), id));
            }
        }
        if (errors.size() > 0) {
            String message = ""Static sensors should have id of 0, violations: < "" +
                    TextUtils.join("", "", errors) + "" >"";
            fail(message);
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.PerformanceTest"	"testSingleCapture"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/PerformanceTest.java"	""	"public void testSingleCapture() throws Exception {
        int[] JPEG_FORMAT = {ImageFormat.JPEG};
        testSingleCaptureForFormat(JPEG_FORMAT, ""jpeg"", /*addPreviewDelay*/ true);
        if (!mTestRule.isPerfMeasure()) {
            int[] YUV_FORMAT = {ImageFormat.YUV_420_888};
            testSingleCaptureForFormat(YUV_FORMAT, null, /*addPreviewDelay*/ false);
            int[] PRIVATE_FORMAT = {ImageFormat.PRIVATE};
            testSingleCaptureForFormat(PRIVATE_FORMAT, ""private"", /*addPreviewDelay*/ true);
            int[] RAW_FORMAT = {ImageFormat.RAW_SENSOR};
            testSingleCaptureForFormat(RAW_FORMAT, ""raw"", /*addPreviewDelay*/ true);
            int[] RAW_JPEG_FORMATS = {ImageFormat.RAW_SENSOR, ImageFormat.JPEG};
            testSingleCaptureForFormat(RAW_JPEG_FORMATS, ""raw_jpeg"", /*addPreviewDelay*/ true);
        }
    }

    private String appendFormatDescription(String message, String formatDescription) {
        if (message == null) {
            return null;
        }

        String ret = message;
        if (formatDescription != null) {
            ret = String.format(ret + ""_%s"", formatDescription);
        }

        return ret;
    }

    private void testSingleCaptureForFormat(int[] formats, String formatDescription,
            boolean addPreviewDelay) throws Exception {
        double[] avgResultTimes = new double[mTestRule.getCameraIdsUnderTest().length];
        double[] avgCaptureTimes = new double[mTestRule.getCameraIdsUnderTest().length];

        int counter = 0;
        for (String id : mTestRule.getCameraIdsUnderTest()) {
            // Do NOT move these variables to outer scope
            // They will be passed to DeviceReportLog and their references will be stored
            String streamName = appendFormatDescription(""test_single_capture"", formatDescription);
            mReportLog = new DeviceReportLog(REPORT_LOG_NAME, streamName);
            mReportLog.addValue(""camera_id"", id, ResultType.NEUTRAL, ResultUnit.NONE);
            double[] captureTimes = new double[NUM_TEST_LOOPS];
            double[] getPartialTimes = new double[NUM_TEST_LOOPS];
            double[] getResultTimes = new double[NUM_TEST_LOOPS];
            ImageReader[] readers = null;
            try {
                if (!mTestRule.getAllStaticInfo().get(id).isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + id + "" does not support color outputs, skipping"");
                    continue;
                }

                StreamConfigurationMap configMap = mTestRule.getAllStaticInfo().get(
                        id).getCharacteristics().get(
                        CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
                boolean formatsSupported = true;
                for (int format : formats) {
                    if (!configMap.isOutputSupportedFor(format)) {
                        Log.i(TAG, ""Camera "" + id + "" does not support output format: "" + format +
                                "" skipping"");
                        formatsSupported = false;
                        break;
                    }
                }
                if (!formatsSupported) {
                    continue;
                }

                mTestRule.openDevice(id);

                boolean partialsExpected = mTestRule.getStaticInfo().getPartialResultCount() > 1;
                long startTimeMs;
                boolean isPartialTimingValid = partialsExpected;
                for (int i = 0; i < NUM_TEST_LOOPS; i++) {

                    // setup builders and listeners
                    CaptureRequest.Builder previewBuilder =
                            mTestRule.getCamera().createCaptureRequest(
                                    CameraDevice.TEMPLATE_PREVIEW);
                    CaptureRequest.Builder captureBuilder =
                            mTestRule.getCamera().createCaptureRequest(
                                    CameraDevice.TEMPLATE_STILL_CAPTURE);
                    SimpleCaptureCallback previewResultListener =
                            new SimpleCaptureCallback();
                    SimpleTimingResultListener captureResultListener =
                            new SimpleTimingResultListener();
                    SimpleImageListener[] imageListeners = new SimpleImageListener[formats.length];
                    Size[] imageSizes = new Size[formats.length];
                    for (int j = 0; j < formats.length; j++) {
                        Size sizeBound = mTestRule.isPerfClassTest() ? new Size(1920, 1080) : null;
                        imageSizes[j] = CameraTestUtils.getSortedSizesForFormat(
                                id,
                                mTestRule.getCameraManager(),
                                formats[j],
                                sizeBound).get(0);
                        imageListeners[j] = new SimpleImageListener();
                    }

                    readers = prepareStillCaptureAndStartPreview(id, previewBuilder, captureBuilder,
                            mTestRule.getOrderedPreviewSizes().get(0), imageSizes, formats,
                            previewResultListener, NUM_MAX_IMAGES, imageListeners,
                            false /*isHeic*/);

                    if (addPreviewDelay) {
                        Thread.sleep(500);
                    }

                    // Capture an image and get image data
                    startTimeMs = SystemClock.elapsedRealtime();
                    CaptureRequest request = captureBuilder.build();
                    mTestRule.getCameraSession().capture(
                            request, captureResultListener, mTestRule.getHandler());

                    Pair<CaptureResult, Long> partialResultNTime = null;
                    if (partialsExpected) {
                        partialResultNTime = captureResultListener.getPartialResultNTimeForRequest(
                                request, NUM_RESULTS_WAIT);
                        // Even if maxPartials > 1, may not see partials for some devices
                        if (partialResultNTime == null) {
                            partialsExpected = false;
                            isPartialTimingValid = false;
                        }
                    }
                    Pair<CaptureResult, Long> captureResultNTime =
                            captureResultListener.getCaptureResultNTimeForRequest(
                                    request, NUM_RESULTS_WAIT);

                    double [] imageTimes = new double[formats.length];
                    for (int j = 0; j < formats.length; j++) {
                        imageListeners[j].waitForImageAvailable(
                                CameraTestUtils.CAPTURE_IMAGE_TIMEOUT_MS);
                        imageTimes[j] = imageListeners[j].getTimeReceivedImage();
                    }

                    captureTimes[i] = Stat.getAverage(imageTimes) - startTimeMs;
                    if (partialsExpected) {
                        getPartialTimes[i] = partialResultNTime.second - startTimeMs;
                        if (getPartialTimes[i] < 0) {
                            isPartialTimingValid = false;
                        }
                    }
                    getResultTimes[i] = captureResultNTime.second - startTimeMs;

                    // simulate real scenario (preview runs a bit)
                    CameraTestUtils.waitForNumResults(previewResultListener, NUM_RESULTS_WAIT,
                            WAIT_FOR_RESULT_TIMEOUT_MS);

                    blockingStopRepeating();

                    CameraTestUtils.closeImageReaders(readers);
                    readers = null;
                }
                String message = appendFormatDescription(""camera_capture_latency"",
                        formatDescription);
                mReportLog.addValues(message, captureTimes, ResultType.LOWER_BETTER, ResultUnit.MS);
                // If any of the partial results do not contain AE and AF state, then no report
                if (isPartialTimingValid) {
                    message = appendFormatDescription(""camera_partial_result_latency"",
                            formatDescription);
                    mReportLog.addValues(message, getPartialTimes, ResultType.LOWER_BETTER,
                            ResultUnit.MS);
                }
                message = appendFormatDescription(""camera_capture_result_latency"",
                        formatDescription);
                mReportLog.addValues(message, getResultTimes, ResultType.LOWER_BETTER,
                        ResultUnit.MS);

                avgResultTimes[counter] = Stat.getAverage(getResultTimes);
                avgCaptureTimes[counter] = Stat.getAverage(captureTimes);
            }
            finally {
                CameraTestUtils.closeImageReaders(readers);
                readers = null;
                mTestRule.closeDevice(id);
                closePreviewSurface();
            }
            counter++;
            mReportLog.submit(mInstrumentation);
        }

        // Result will not be reported in CTS report if no summary is printed.
        if (mTestRule.getCameraIdsUnderTest().length != 0) {
            String streamName = appendFormatDescription(""test_single_capture_average"",
                    formatDescription);
            mReportLog = new DeviceReportLog(REPORT_LOG_NAME, streamName);
            // In performance measurement mode, capture the buffer latency rather than result
            // latency.
            if (mTestRule.isPerfMeasure()) {
                String message = appendFormatDescription(
                        ""camera_capture_average_latency_for_all_cameras"", formatDescription);
                mReportLog.setSummary(message, Stat.getAverage(avgCaptureTimes),
                        ResultType.LOWER_BETTER, ResultUnit.MS);
            } else {
                String message = appendFormatDescription(
                        ""camera_capture_result_average_latency_for_all_cameras"", formatDescription);
                mReportLog.setSummary(message, Stat.getAverage(avgResultTimes),
                        ResultType.LOWER_BETTER, ResultUnit.MS);
            }
            mReportLog.submit(mInstrumentation);
        }
    }

    /**
     * Test multiple capture KPI for YUV_420_888 format: the average time duration
     * between sending out image capture requests and receiving capture results.
     * <p>
     * It measures capture latency, which is the time between sending out the capture
     * request and getting the full capture result, and the frame duration, which is the timestamp
     * gap between results.
     * </p>
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.PerformanceTest"	"testMultipleCapture"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/PerformanceTest.java"	""	"public void testMultipleCapture() throws Exception {
        double[] avgResultTimes = new double[mTestRule.getCameraIdsUnderTest().length];
        double[] avgDurationMs = new double[mTestRule.getCameraIdsUnderTest().length];

        // A simple CaptureSession StateCallback to handle onCaptureQueueEmpty
        class MultipleCaptureStateCallback extends CameraCaptureSession.StateCallback {
            private ConditionVariable captureQueueEmptyCond = new ConditionVariable();
            private int captureQueueEmptied = 0;

            @Override
            public void onConfigured(CameraCaptureSession session) {
                // Empty implementation
            }

            @Override
            public void onConfigureFailed(CameraCaptureSession session) {
                // Empty implementation
            }

            @Override
            public void onCaptureQueueEmpty(CameraCaptureSession session) {
                captureQueueEmptied++;
                if (VERBOSE) {
                    Log.v(TAG, ""onCaptureQueueEmpty received. captureQueueEmptied = ""
                            + captureQueueEmptied);
                }

                captureQueueEmptyCond.open();
            }

            /* Wait for onCaptureQueueEmpty, return immediately if an onCaptureQueueEmpty was
             * already received, otherwise, wait for one to arrive. */
            public void waitForCaptureQueueEmpty(long timeout) {
                if (captureQueueEmptied > 0) {
                    captureQueueEmptied--;
                    return;
                }

                if (captureQueueEmptyCond.block(timeout)) {
                    captureQueueEmptyCond.close();
                    captureQueueEmptied = 0;
                } else {
                    throw new TimeoutRuntimeException(""Unable to receive onCaptureQueueEmpty after ""
                            + timeout + ""ms"");
                }
            }
        }

        final MultipleCaptureStateCallback sessionListener = new MultipleCaptureStateCallback();

        int counter = 0;
        for (String id : mTestRule.getCameraIdsUnderTest()) {
            // Do NOT move these variables to outer scope
            // They will be passed to DeviceReportLog and their references will be stored
            String streamName = ""test_multiple_capture"";
            mReportLog = new DeviceReportLog(REPORT_LOG_NAME, streamName);
            mReportLog.addValue(""camera_id"", id, ResultType.NEUTRAL, ResultUnit.NONE);
            long[] startTimes = new long[NUM_MAX_IMAGES];
            double[] getResultTimes = new double[NUM_MAX_IMAGES];
            double[] frameDurationMs = new double[NUM_MAX_IMAGES-1];
            try {
                StaticMetadata staticMetadata = mTestRule.getAllStaticInfo().get(id);
                if (!staticMetadata.isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + id + "" does not support color outputs, skipping"");
                    continue;
                }
                boolean useSessionKeys = isFpsRangeASessionKey(staticMetadata.getCharacteristics());

                mTestRule.openDevice(id);
                for (int i = 0; i < NUM_TEST_LOOPS; i++) {

                    // setup builders and listeners
                    CaptureRequest.Builder previewBuilder =
                            mTestRule.getCamera().createCaptureRequest(
                                    CameraDevice.TEMPLATE_PREVIEW);
                    CaptureRequest.Builder captureBuilder =
                            mTestRule.getCamera().createCaptureRequest(
                                    CameraDevice.TEMPLATE_STILL_CAPTURE);
                    SimpleCaptureCallback previewResultListener =
                            new SimpleCaptureCallback();
                    SimpleTimingResultListener captureResultListener =
                            new SimpleTimingResultListener();
                    SimpleImageReaderListener imageListener =
                            new SimpleImageReaderListener(/*asyncMode*/true, NUM_MAX_IMAGES);

                    Size maxYuvSize = CameraTestUtils.getSortedSizesForFormat(
                            id, mTestRule.getCameraManager(),
                            ImageFormat.YUV_420_888, /*bound*/null).get(0);
                    // Find minimum frame duration for YUV_420_888
                    StreamConfigurationMap config =
                            mTestRule.getStaticInfo().getCharacteristics().get(
                            CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);

                    final long minStillFrameDuration =
                            config.getOutputMinFrameDuration(ImageFormat.YUV_420_888, maxYuvSize);
                    if (minStillFrameDuration > 0) {
                        Range<Integer> targetRange =
                                CameraTestUtils.getSuitableFpsRangeForDuration(id,
                                        minStillFrameDuration, mTestRule.getStaticInfo());
                        previewBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, targetRange);
                        captureBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, targetRange);
                    }

                    prepareCaptureAndStartPreview(previewBuilder, captureBuilder,
                            mTestRule.getOrderedPreviewSizes().get(0), maxYuvSize,
                            ImageFormat.YUV_420_888, previewResultListener,
                            sessionListener, NUM_MAX_IMAGES, imageListener,
                            useSessionKeys);

                    // Converge AE
                    CameraTestUtils.waitForAeStable(previewResultListener,
                            NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY, mTestRule.getStaticInfo(),
                            WAIT_FOR_RESULT_TIMEOUT_MS, NUM_RESULTS_WAIT_TIMEOUT);

                    if (mTestRule.getStaticInfo().isAeLockSupported()) {
                        // Lock AE if possible to improve stability
                        previewBuilder.set(CaptureRequest.CONTROL_AE_LOCK, true);
                        mTestRule.getCameraSession().setRepeatingRequest(previewBuilder.build(),
                                previewResultListener, mTestRule.getHandler());
                        if (mTestRule.getStaticInfo().isHardwareLevelAtLeastLimited()) {
                            // Legacy mode doesn't output AE state
                            CameraTestUtils.waitForResultValue(previewResultListener,
                                    CaptureResult.CONTROL_AE_STATE,
                                    CaptureResult.CONTROL_AE_STATE_LOCKED,
                                    NUM_RESULTS_WAIT_TIMEOUT, WAIT_FOR_RESULT_TIMEOUT_MS);
                        }
                    }

                    // Capture NUM_MAX_IMAGES images based on onCaptureQueueEmpty callback
                    for (int j = 0; j < NUM_MAX_IMAGES; j++) {

                        // Capture an image and get image data
                        startTimes[j] = SystemClock.elapsedRealtime();
                        CaptureRequest request = captureBuilder.build();
                        mTestRule.getCameraSession().capture(
                                request, captureResultListener, mTestRule.getHandler());

                        // Wait for capture queue empty for the current request
                        sessionListener.waitForCaptureQueueEmpty(
                                CameraTestUtils.CAPTURE_IMAGE_TIMEOUT_MS);
                    }

                    // Acquire the capture result time and frame duration
                    long prevTimestamp = -1;
                    for (int j = 0; j < NUM_MAX_IMAGES; j++) {
                        Pair<CaptureResult, Long> captureResultNTime =
                                captureResultListener.getCaptureResultNTime(
                                        CameraTestUtils.CAPTURE_RESULT_TIMEOUT_MS);

                        getResultTimes[j] +=
                                (double)(captureResultNTime.second - startTimes[j])/NUM_TEST_LOOPS;

                        // Collect inter-frame timestamp
                        long timestamp = captureResultNTime.first.get(
                                CaptureResult.SENSOR_TIMESTAMP);
                        if (prevTimestamp != -1) {
                            frameDurationMs[j-1] +=
                                    (double)(timestamp - prevTimestamp)/(
                                            NUM_TEST_LOOPS * 1000000.0);
                        }
                        prevTimestamp = timestamp;
                    }

                    // simulate real scenario (preview runs a bit)
                    CameraTestUtils.waitForNumResults(previewResultListener, NUM_RESULTS_WAIT,
                            WAIT_FOR_RESULT_TIMEOUT_MS);

                    stopRepeating();
                }

                for (int i = 0; i < getResultTimes.length; i++) {
                    Log.v(TAG, ""Camera "" + id + "" result time["" + i + ""] is "" +
                            getResultTimes[i] + "" ms"");
                }
                for (int i = 0; i < NUM_MAX_IMAGES-1; i++) {
                    Log.v(TAG, ""Camera "" + id + "" frame duration time["" + i + ""] is "" +
                            frameDurationMs[i] + "" ms"");
                }

                mReportLog.addValues(""camera_multiple_capture_result_latency"", getResultTimes,
                        ResultType.LOWER_BETTER, ResultUnit.MS);
                mReportLog.addValues(""camera_multiple_capture_frame_duration"", frameDurationMs,
                        ResultType.LOWER_BETTER, ResultUnit.MS);


                avgResultTimes[counter] = Stat.getAverage(getResultTimes);
                avgDurationMs[counter] = Stat.getAverage(frameDurationMs);
            }
            finally {
                mTestRule.closeDefaultImageReader();
                mTestRule.closeDevice(id);
                closePreviewSurface();
            }
            counter++;
            mReportLog.submit(mInstrumentation);
        }

        // Result will not be reported in CTS report if no summary is printed.
        if (mTestRule.getCameraIdsUnderTest().length != 0) {
            String streamName = ""test_multiple_capture_average"";
            mReportLog = new DeviceReportLog(REPORT_LOG_NAME, streamName);
            mReportLog.setSummary(""camera_multiple_capture_result_average_latency_for_all_cameras"",
                    Stat.getAverage(avgResultTimes), ResultType.LOWER_BETTER, ResultUnit.MS);
            mReportLog.submit(mInstrumentation);
            mReportLog = new DeviceReportLog(REPORT_LOG_NAME, streamName);
            mReportLog.setSummary(""camera_multiple_capture_frame_duration_average_for_all_cameras"",
                    Stat.getAverage(avgDurationMs), ResultType.LOWER_BETTER, ResultUnit.MS);
            mReportLog.submit(mInstrumentation);
        }
    }

    /**
     * Test reprocessing shot-to-shot latency with default NR and edge options, i.e., from the time
     * a reprocess request is issued to the time the reprocess image is returned.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.PerformanceTest"	"testReprocessingCaptureStall"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/PerformanceTest.java"	""	"public void testReprocessingCaptureStall() throws Exception {
        for (String id : mTestRule.getCameraIdsUnderTest()) {
            for (int format : REPROCESS_FORMATS) {
                if (!isReprocessSupported(id, format)) {
                    continue;
                }

                try {
                    mTestRule.openDevice(id);
                    String streamName = ""test_reprocessing_capture_stall"";
                    mReportLog = new DeviceReportLog(REPORT_LOG_NAME, streamName);
                    mReportLog.addValue(""camera_id"", id, ResultType.NEUTRAL, ResultUnit.NONE);
                    mReportLog.addValue(""format"", format, ResultType.NEUTRAL, ResultUnit.NONE);
                    reprocessingCaptureStallTestByCamera(format);
                } finally {
                    closeReaderWriters();
                    mTestRule.closeDevice(id);
                    closePreviewSurface();
                    mReportLog.submit(mInstrumentation);
                }
            }
        }
    }

    private void reprocessingCaptureStallTestByCamera(int reprocessInputFormat) throws Exception {
        prepareReprocessCapture(reprocessInputFormat);

        // Let it stream for a while before reprocessing
        startZslStreaming();
        waitForFrames(NUM_RESULTS_WAIT);

        final int NUM_REPROCESS_TESTED = MAX_REPROCESS_IMAGES / 2;
        // Prepare several reprocessing request
        Image[] inputImages = new Image[NUM_REPROCESS_TESTED];
        CaptureRequest.Builder[] reprocessReqs = new CaptureRequest.Builder[MAX_REPROCESS_IMAGES];
        for (int i = 0; i < NUM_REPROCESS_TESTED; i++) {
            inputImages[i] =
                    mCameraZslImageListener.getImage(CameraTestUtils.CAPTURE_IMAGE_TIMEOUT_MS);
            TotalCaptureResult zslResult =
                    mZslResultListener.getCaptureResult(
                            WAIT_FOR_RESULT_TIMEOUT_MS, inputImages[i].getTimestamp());
            reprocessReqs[i] = mTestRule.getCamera().createReprocessCaptureRequest(zslResult);
            reprocessReqs[i].addTarget(mJpegReader.getSurface());
            reprocessReqs[i].set(CaptureRequest.NOISE_REDUCTION_MODE,
                    CaptureRequest.NOISE_REDUCTION_MODE_HIGH_QUALITY);
            reprocessReqs[i].set(CaptureRequest.EDGE_MODE,
                    CaptureRequest.EDGE_MODE_HIGH_QUALITY);
            mWriter.queueInputImage(inputImages[i]);
        }

        double[] maxCaptureGapsMs = new double[NUM_REPROCESS_TESTED];
        double[] averageFrameDurationMs = new double[NUM_REPROCESS_TESTED];
        Arrays.fill(averageFrameDurationMs, 0.0);
        final int MAX_REPROCESS_RETURN_FRAME_COUNT = 20;
        SimpleCaptureCallback reprocessResultListener = new SimpleCaptureCallback();
        for (int i = 0; i < NUM_REPROCESS_TESTED; i++) {
            mZslResultListener.drain();
            CaptureRequest reprocessRequest = reprocessReqs[i].build();
            mTestRule.getCameraSession().capture(
                    reprocessRequest, reprocessResultListener, mTestRule.getHandler());
            // Wait for reprocess output jpeg and result come back.
            reprocessResultListener.getCaptureResultForRequest(reprocessRequest,
                    CameraTestUtils.CAPTURE_RESULT_TIMEOUT_MS);
            mJpegListener.getImage(CameraTestUtils.CAPTURE_IMAGE_TIMEOUT_MS).close();
            long numFramesMaybeStalled = mZslResultListener.getTotalNumFrames();
            assertTrue(""Reprocess capture result should be returned in ""
                            + MAX_REPROCESS_RETURN_FRAME_COUNT + "" frames"",
                    numFramesMaybeStalled <= MAX_REPROCESS_RETURN_FRAME_COUNT);

            // Need look longer time, as the stutter could happen after the reprocessing
            // output frame is received.
            long[] timestampGap = new long[MAX_REPROCESS_RETURN_FRAME_COUNT + 1];
            Arrays.fill(timestampGap, 0);
            CaptureResult[] results = new CaptureResult[timestampGap.length];
            long[] frameDurationsNs = new long[timestampGap.length];
            for (int j = 0; j < results.length; j++) {
                results[j] = mZslResultListener.getCaptureResult(
                        CameraTestUtils.CAPTURE_IMAGE_TIMEOUT_MS);
                if (j > 0) {
                    timestampGap[j] = results[j].get(CaptureResult.SENSOR_TIMESTAMP) -
                            results[j - 1].get(CaptureResult.SENSOR_TIMESTAMP);
                    assertTrue(""Time stamp should be monotonically increasing"",
                            timestampGap[j] > 0);
                }
                frameDurationsNs[j] = results[j].get(CaptureResult.SENSOR_FRAME_DURATION);
            }

            if (VERBOSE) {
                Log.i(TAG, ""timestampGap: "" + Arrays.toString(timestampGap));
                Log.i(TAG, ""frameDurationsNs: "" + Arrays.toString(frameDurationsNs));
            }

            // Get the number of candidate results, calculate the average frame duration
            // and max timestamp gap.
            Arrays.sort(timestampGap);
            double maxTimestampGapMs = timestampGap[timestampGap.length - 1] / 1000000.0;
            for (int m = 0; m < frameDurationsNs.length; m++) {
                averageFrameDurationMs[i] += (frameDurationsNs[m] / 1000000.0);
            }
            averageFrameDurationMs[i] /= frameDurationsNs.length;

            maxCaptureGapsMs[i] = maxTimestampGapMs;
        }

        blockingStopRepeating();

        String reprocessType = ""YUV reprocessing"";
        if (reprocessInputFormat == ImageFormat.PRIVATE) {
            reprocessType = ""opaque reprocessing"";
        }
        mReportLog.addValue(""reprocess_type"", reprocessType, ResultType.NEUTRAL, ResultUnit.NONE);
        mReportLog.addValues(""max_capture_timestamp_gaps"", maxCaptureGapsMs,
                ResultType.LOWER_BETTER, ResultUnit.MS);
        mReportLog.addValues(""capture_average_frame_duration"", averageFrameDurationMs,
                ResultType.LOWER_BETTER, ResultUnit.MS);
        mReportLog.setSummary(""camera_reprocessing_average_max_capture_timestamp_gaps"",
                Stat.getAverage(maxCaptureGapsMs), ResultType.LOWER_BETTER, ResultUnit.MS);

        // The max timestamp gap should be less than (captureStall + 1) x average frame
        // duration * (1 + error margin).
        int maxCaptureStallFrames = mTestRule.getStaticInfo().getMaxCaptureStallOrDefault();
        for (int i = 0; i < maxCaptureGapsMs.length; i++) {
            double stallDurationBound = averageFrameDurationMs[i] *
                    (maxCaptureStallFrames + 1) * (1 + REPROCESS_STALL_MARGIN);
            assertTrue(""max capture stall duration should be no larger than "" + stallDurationBound,
                    maxCaptureGapsMs[i] <= stallDurationBound);
        }
    }

    private void reprocessingPerformanceTestByCamera(int reprocessInputFormat, boolean asyncMode,
            boolean requireHighQuality)
            throws Exception {
        // Prepare the reprocessing capture
        prepareReprocessCapture(reprocessInputFormat);

        // Start ZSL streaming
        startZslStreaming();
        waitForFrames(NUM_RESULTS_WAIT);

        CaptureRequest.Builder[] reprocessReqs = new CaptureRequest.Builder[MAX_REPROCESS_IMAGES];
        Image[] inputImages = new Image[MAX_REPROCESS_IMAGES];
        double[] getImageLatenciesMs = new double[MAX_REPROCESS_IMAGES];
        long startTimeMs;
        for (int i = 0; i < MAX_REPROCESS_IMAGES; i++) {
            inputImages[i] =
                    mCameraZslImageListener.getImage(CameraTestUtils.CAPTURE_IMAGE_TIMEOUT_MS);
            TotalCaptureResult zslResult =
                    mZslResultListener.getCaptureResult(
                            WAIT_FOR_RESULT_TIMEOUT_MS, inputImages[i].getTimestamp());
            reprocessReqs[i] = mTestRule.getCamera().createReprocessCaptureRequest(zslResult);
            if (requireHighQuality) {
                // Reprocessing should support high quality for NR and edge modes.
                reprocessReqs[i].set(CaptureRequest.NOISE_REDUCTION_MODE,
                        CaptureRequest.NOISE_REDUCTION_MODE_HIGH_QUALITY);
                reprocessReqs[i].set(CaptureRequest.EDGE_MODE,
                        CaptureRequest.EDGE_MODE_HIGH_QUALITY);
            }
            reprocessReqs[i].addTarget(mJpegReader.getSurface());
        }

        if (asyncMode) {
            // async capture: issue all the reprocess requests as quick as possible, then
            // check the throughput of the output jpegs.
            for (int i = 0; i < MAX_REPROCESS_IMAGES; i++) {
                // Could be slow for YUV reprocessing, do it in advance.
                mWriter.queueInputImage(inputImages[i]);
            }

            // Submit the requests
            for (int i = 0; i < MAX_REPROCESS_IMAGES; i++) {
                mTestRule.getCameraSession().capture(reprocessReqs[i].build(), null, null);
            }

            // Get images
            startTimeMs = SystemClock.elapsedRealtime();
            Image jpegImages[] = new Image[MAX_REPROCESS_IMAGES];
            for (int i = 0; i < MAX_REPROCESS_IMAGES; i++) {
                jpegImages[i] = mJpegListener.getImage(CameraTestUtils.CAPTURE_IMAGE_TIMEOUT_MS);
                getImageLatenciesMs[i] = SystemClock.elapsedRealtime() - startTimeMs;
                startTimeMs = SystemClock.elapsedRealtime();
            }
            for (Image i : jpegImages) {
                i.close();
            }
        } else {
            // sync capture: issue reprocess request one by one, only submit next one when
            // the previous capture image is returned. This is to test the back to back capture
            // performance.
            Image jpegImages[] = new Image[MAX_REPROCESS_IMAGES];
            for (int i = 0; i < MAX_REPROCESS_IMAGES; i++) {
                startTimeMs = SystemClock.elapsedRealtime();
                mWriter.queueInputImage(inputImages[i]);
                mTestRule.getCameraSession().capture(reprocessReqs[i].build(), null, null);
                jpegImages[i] = mJpegListener.getImage(CameraTestUtils.CAPTURE_IMAGE_TIMEOUT_MS);
                getImageLatenciesMs[i] = SystemClock.elapsedRealtime() - startTimeMs;
            }
            for (Image i : jpegImages) {
                i.close();
            }
        }

        blockingStopRepeating();

        String reprocessType = ""YUV reprocessing"";
        if (reprocessInputFormat == ImageFormat.PRIVATE) {
            reprocessType = ""opaque reprocessing"";
        }

        // Report the performance data
        String captureMsg;
        if (asyncMode) {
            captureMsg = ""capture latency"";
            if (requireHighQuality) {
                captureMsg += "" for High Quality noise reduction and edge modes"";
            }
            mReportLog.addValue(""reprocess_type"", reprocessType, ResultType.NEUTRAL,
                    ResultUnit.NONE);
            mReportLog.addValue(""capture_message"", captureMsg, ResultType.NEUTRAL,
                    ResultUnit.NONE);
            mReportLog.addValues(""latency"", getImageLatenciesMs, ResultType.LOWER_BETTER,
                    ResultUnit.MS);
            mReportLog.setSummary(""camera_reprocessing_average_latency"",
                    Stat.getAverage(getImageLatenciesMs), ResultType.LOWER_BETTER, ResultUnit.MS);
        } else {
            captureMsg = ""shot to shot latency"";
            if (requireHighQuality) {
                captureMsg += "" for High Quality noise reduction and edge modes"";
            }
            mReportLog.addValue(""reprocess_type"", reprocessType, ResultType.NEUTRAL,
                    ResultUnit.NONE);
            mReportLog.addValue(""capture_message"", captureMsg, ResultType.NEUTRAL,
                    ResultUnit.NONE);
            mReportLog.addValues(""latency"", getImageLatenciesMs, ResultType.LOWER_BETTER,
                    ResultUnit.MS);
            mReportLog.setSummary(""camera_reprocessing_shot_to_shot_average_latency"",
                    Stat.getAverage(getImageLatenciesMs), ResultType.LOWER_BETTER, ResultUnit.MS);
        }
    }

    /**
     * Start preview and ZSL streaming
     */
    private void startZslStreaming() throws Exception {
        CaptureRequest.Builder zslBuilder =
                mTestRule.getCamera().createCaptureRequest(CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG);
        zslBuilder.addTarget(mPreviewSurface);
        zslBuilder.addTarget(mCameraZslReader.getSurface());
        mTestRule.getCameraSession().setRepeatingRequest(
                zslBuilder.build(), mZslResultListener, mTestRule.getHandler());
    }

    /**
     * Wait for a certain number of frames, the images and results will be drained from the
     * listeners to make sure that next reprocessing can get matched results and images.
     *
     * @param numFrameWait The number of frames to wait before return, 0 means that
     *      this call returns immediately after streaming on.
     */
    private void waitForFrames(int numFrameWait) throws Exception {
        if (numFrameWait < 0) {
            throw new IllegalArgumentException(""numFrameWait "" + numFrameWait +
                    "" should be non-negative"");
        }

        for (int i = 0; i < numFrameWait; i++) {
            mCameraZslImageListener.getImage(CameraTestUtils.CAPTURE_IMAGE_TIMEOUT_MS).close();
        }
    }

    private void closeReaderWriters() {
        mCameraZslImageListener.drain();
        CameraTestUtils.closeImageReader(mCameraZslReader);
        mCameraZslReader = null;
        mJpegListener.drain();
        CameraTestUtils.closeImageReader(mJpegReader);
        mJpegReader = null;
        CameraTestUtils.closeImageWriter(mWriter);
        mWriter = null;
    }

    private void prepareReprocessCapture(int inputFormat)
            throws CameraAccessException {
        // 1. Find the right preview and capture sizes.
        Size maxPreviewSize = mTestRule.getOrderedPreviewSizes().get(0);
        Size[] supportedInputSizes =
                mTestRule.getStaticInfo().getAvailableSizesForFormatChecked(inputFormat,
                        StaticMetadata.StreamDirection.Input);
        Size maxInputSize = CameraTestUtils.getMaxSize(supportedInputSizes);
        Size maxJpegSize = mTestRule.getOrderedStillSizes().get(0);
        updatePreviewSurface(maxPreviewSize);
        mZslResultListener = new SimpleCaptureCallback();

        // 2. Create camera output ImageReaders.
        // YUV/Opaque output, camera should support output with input size/format
        mCameraZslImageListener = new SimpleImageReaderListener(
                /*asyncMode*/true, MAX_ZSL_IMAGES - MAX_REPROCESS_IMAGES);
        mCameraZslReader = CameraTestUtils.makeImageReader(
                maxInputSize, inputFormat, MAX_ZSL_IMAGES,
                mCameraZslImageListener, mTestRule.getHandler());
        // Jpeg reprocess output
        mJpegListener = new SimpleImageReaderListener();
        mJpegReader = CameraTestUtils.makeImageReader(
                maxJpegSize, ImageFormat.JPEG, MAX_JPEG_IMAGES,
                mJpegListener, mTestRule.getHandler());

        // create camera reprocess session
        List<Surface> outSurfaces = new ArrayList<Surface>();
        outSurfaces.add(mPreviewSurface);
        outSurfaces.add(mCameraZslReader.getSurface());
        outSurfaces.add(mJpegReader.getSurface());
        InputConfiguration inputConfig = new InputConfiguration(maxInputSize.getWidth(),
                maxInputSize.getHeight(), inputFormat);
        mTestRule.setCameraSessionListener(new BlockingSessionCallback());
        mTestRule.setCameraSession(CameraTestUtils.configureReprocessableCameraSession(
                mTestRule.getCamera(), inputConfig, outSurfaces,
                mTestRule.getCameraSessionListener(), mTestRule.getHandler()));

        // 3. Create ImageWriter for input
        mWriter = CameraTestUtils.makeImageWriter(
                mTestRule.getCameraSession().getInputSurface(), MAX_INPUT_IMAGES,
                /*listener*/null, /*handler*/null);
    }

    /**
     * Stop repeating requests for current camera and waiting for it to go back to idle, resulting
     * in an idle device.
     */
    private void blockingStopRepeating() throws Exception {
        stopRepeating();
        mTestRule.getCameraSessionListener().getStateWaiter().waitForState(
                BlockingSessionCallback.SESSION_READY, CameraTestUtils.CAMERA_IDLE_TIMEOUT_MS);
    }

    private void blockingStartPreview(String id, CaptureCallback listener,
            CaptureRequest previewRequest, SimpleImageListener imageListener)
            throws Exception {
        mTestRule.getCameraSession().setRepeatingRequest(
                previewRequest, listener, mTestRule.getHandler());
        imageListener.waitForImageAvailable(CameraTestUtils.CAPTURE_IMAGE_TIMEOUT_MS);
    }

    /**
     * Setup still capture configuration and start preview.
     *
     * @param id The camera id under test
     * @param previewBuilder The capture request builder to be used for preview
     * @param stillBuilder The capture request builder to be used for still capture
     * @param previewSz Preview size
     * @param captureSizes Still capture sizes
     * @param formats The single capture image formats
     * @param resultListener Capture result listener
     * @param maxNumImages The max number of images set to the image reader
     * @param imageListeners The single capture capture image listeners
     * @param isHeic Capture HEIC image if true, JPEG image if false
     */
    private ImageReader[] prepareStillCaptureAndStartPreview(String id,
            CaptureRequest.Builder previewBuilder, CaptureRequest.Builder stillBuilder,
            Size previewSz, Size[] captureSizes, int[] formats, CaptureCallback resultListener,
            int maxNumImages, ImageReader.OnImageAvailableListener[] imageListeners,
            boolean isHeic)
            throws Exception {

        if ((captureSizes == null) || (formats == null) || (imageListeners == null) &&
                (captureSizes.length != formats.length) ||
                (formats.length != imageListeners.length)) {
            throw new IllegalArgumentException(""Invalid capture sizes/formats or image listeners!"");
        }

        if (VERBOSE) {
            Log.v(TAG, String.format(""Prepare still capture and preview (%s)"",
                    previewSz.toString()));
        }

        // Update preview size.
        updatePreviewSurface(previewSz);

        ImageReader[] readers = new ImageReader[captureSizes.length];
        List<Surface> outputSurfaces = new ArrayList<Surface>();
        outputSurfaces.add(mPreviewSurface);
        for (int i = 0; i < captureSizes.length; i++) {
            readers[i] = CameraTestUtils.makeImageReader(captureSizes[i], formats[i], maxNumImages,
                    imageListeners[i], mTestRule.getHandler());
            outputSurfaces.add(readers[i].getSurface());
        }

        // Configure the requests.
        previewBuilder.addTarget(mPreviewSurface);
        stillBuilder.addTarget(mPreviewSurface);
        for (int i = 0; i < readers.length; i++) {
            stillBuilder.addTarget(readers[i].getSurface());
        }

        // Update target fps based on the min frame duration of preview.
        CameraCharacteristics ch = mTestRule.getStaticInfo().getCharacteristics();
        StreamConfigurationMap config = ch.get(
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
        long minFrameDuration = Math.max(FRAME_DURATION_NS_30FPS, config.getOutputMinFrameDuration(
                SurfaceTexture.class, previewSz));
        Range<Integer> targetRange =
                CameraTestUtils.getSuitableFpsRangeForDuration(id,
                minFrameDuration, mTestRule.getStaticInfo());
        previewBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, targetRange);
        stillBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, targetRange);

        CaptureRequest previewRequest = previewBuilder.build();
        mTestRule.setCameraSessionListener(new BlockingSessionCallback());
        boolean useSessionKeys = isFpsRangeASessionKey(ch);
        configureAndSetCameraSession(outputSurfaces, useSessionKeys, previewRequest);

        // Start preview.
        mTestRule.getCameraSession().setRepeatingRequest(
                previewRequest, resultListener, mTestRule.getHandler());

        return readers;
    }

    /**
     * Helper function to check if TARGET_FPS_RANGE is a session parameter
     */
    private boolean isFpsRangeASessionKey(CameraCharacteristics ch) {
        List<CaptureRequest.Key<?>> sessionKeys = ch.getAvailableSessionKeys();
        return sessionKeys != null &&
                sessionKeys.contains(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE);
    }

    /**
     * Helper function to configure camera session using parameters provided.
     */
    private void configureAndSetCameraSession(List<Surface> surfaces,
            boolean useInitialRequest, CaptureRequest initialRequest)
            throws CameraAccessException {
        CameraCaptureSession cameraSession;
        if (useInitialRequest) {
            cameraSession = CameraTestUtils.configureCameraSessionWithParameters(
                mTestRule.getCamera(), surfaces,
                mTestRule.getCameraSessionListener(), mTestRule.getHandler(),
                initialRequest);
        } else {
            cameraSession = CameraTestUtils.configureCameraSession(
                mTestRule.getCamera(), surfaces,
                mTestRule.getCameraSessionListener(), mTestRule.getHandler());
        }
        mTestRule.setCameraSession(cameraSession);
    }

    /**
     * Setup single capture configuration and start preview.
     *
     * @param previewBuilder The capture request builder to be used for preview
     * @param stillBuilder The capture request builder to be used for still capture
     * @param previewSz Preview size
     * @param captureSz Still capture size
     * @param format The single capture image format
     * @param resultListener Capture result listener
     * @param sessionListener Session listener
     * @param maxNumImages The max number of images set to the image reader
     * @param imageListener The single capture capture image listener
     * @param useSessionKeys Create capture session using session keys from previewRequest
     */
    private void prepareCaptureAndStartPreview(CaptureRequest.Builder previewBuilder,
            CaptureRequest.Builder stillBuilder, Size previewSz, Size captureSz, int format,
            CaptureCallback resultListener, CameraCaptureSession.StateCallback sessionListener,
            int maxNumImages, ImageReader.OnImageAvailableListener imageListener,
            boolean  useSessionKeys) throws Exception {
        if ((captureSz == null) || (imageListener == null)) {
            throw new IllegalArgumentException(""Invalid capture size or image listener!"");
        }

        if (VERBOSE) {
            Log.v(TAG, String.format(""Prepare single capture (%s) and preview (%s)"",
                    captureSz.toString(), previewSz.toString()));
        }

        // Update preview size.
        updatePreviewSurface(previewSz);

        // Create ImageReader.
        mTestRule.createDefaultImageReader(captureSz, format, maxNumImages, imageListener);

        // Configure output streams with preview and jpeg streams.
        List<Surface> outputSurfaces = new ArrayList<Surface>();
        outputSurfaces.add(mPreviewSurface);
        outputSurfaces.add(mTestRule.getReaderSurface());
        if (sessionListener == null) {
            mTestRule.setCameraSessionListener(new BlockingSessionCallback());
        } else {
            mTestRule.setCameraSessionListener(new BlockingSessionCallback(sessionListener));
        }

        // Configure the requests.
        previewBuilder.addTarget(mPreviewSurface);
        stillBuilder.addTarget(mPreviewSurface);
        stillBuilder.addTarget(mTestRule.getReaderSurface());
        CaptureRequest previewRequest = previewBuilder.build();

        configureAndSetCameraSession(outputSurfaces, useSessionKeys, previewRequest);

        // Start preview.
        mTestRule.getCameraSession().setRepeatingRequest(
                previewRequest, resultListener, mTestRule.getHandler());
    }

    /**
     * Update the preview surface size.
     *
     * @param size The preview size to be updated.
     */
    private void updatePreviewSurface(Size size) {
        if ((mPreviewSurfaceTexture != null ) || (mPreviewSurface != null)) {
            closePreviewSurface();
        }

        mPreviewSurfaceTexture = new SurfaceTexture(/*random int*/ 1);
        mPreviewSurfaceTexture.setDefaultBufferSize(size.getWidth(), size.getHeight());
        mPreviewSurface = new Surface(mPreviewSurfaceTexture);
    }

    /**
     * Release preview surface and corresponding surface texture.
     */
    private void closePreviewSurface() {
        if (mPreviewSurface != null) {
            mPreviewSurface.release();
            mPreviewSurface = null;
        }

        if (mPreviewSurfaceTexture != null) {
            mPreviewSurfaceTexture.release();
            mPreviewSurfaceTexture = null;
        }
    }

    private boolean isReprocessSupported(String cameraId, int format)
            throws CameraAccessException {
        if (format != ImageFormat.YUV_420_888 && format != ImageFormat.PRIVATE) {
            throw new IllegalArgumentException(
                    ""format "" + format + "" is not supported for reprocessing"");
        }

        StaticMetadata info = new StaticMetadata(
                mTestRule.getCameraManager().getCameraCharacteristics(cameraId), CheckLevel.ASSERT,
                /*collector*/ null);
        int cap = CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_YUV_REPROCESSING;
        if (format == ImageFormat.PRIVATE) {
            cap = CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING;
        }
        return info.isCapabilitySupported(cap);
    }

    /**
     * Stop the repeating requests of current camera.
     * Does _not_ wait for the device to go idle
     */
    private void stopRepeating() throws Exception {
        // Stop repeat, wait for captures to complete, and disconnect from surfaces
        if (mTestRule.getCameraSession() != null) {
            if (VERBOSE) Log.v(TAG, ""Stopping preview"");
            mTestRule.getCameraSession().stopRepeating();
        }
    }

    /**
     * Configure reader and preview outputs and wait until done.
     *
     * @return The preview capture request
     */
    private CaptureRequest configureReaderAndPreviewOutputs(
            String id, boolean isColorOutputSupported)
            throws Exception {
        if (mPreviewSurface == null || mTestRule.getReaderSurface() == null) {
            throw new IllegalStateException(""preview and reader surface must be initilized first"");
        }

        // Create previewBuilder
        CaptureRequest.Builder previewBuilder =
                mTestRule.getCamera().createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        if (isColorOutputSupported) {
            previewBuilder.addTarget(mPreviewSurface);
        }
        previewBuilder.addTarget(mTestRule.getReaderSurface());


        // Figure out constant target FPS range no larger than 30fps
        CameraCharacteristics ch = mTestRule.getStaticInfo().getCharacteristics();
        StreamConfigurationMap config =
                ch.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
        long minFrameDuration = Math.max(FRAME_DURATION_NS_30FPS,
                config.getOutputMinFrameDuration(mImageReaderFormat, mPreviewSize));

        List<Surface> outputSurfaces = new ArrayList<>();
        outputSurfaces.add(mTestRule.getReaderSurface());
        if (isColorOutputSupported) {
            outputSurfaces.add(mPreviewSurface);
            minFrameDuration = Math.max(minFrameDuration,
                    config.getOutputMinFrameDuration(SurfaceTexture.class, mPreviewSize));
        }
        Range<Integer> targetRange =
                CameraTestUtils.getSuitableFpsRangeForDuration(id,
                        minFrameDuration, mTestRule.getStaticInfo());
        previewBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, targetRange);

        // Create capture session
        boolean useSessionKeys = isFpsRangeASessionKey(ch);
        CaptureRequest previewRequest = previewBuilder.build();
        mTestRule.setCameraSessionListener(new BlockingSessionCallback());
        configureAndSetCameraSession(outputSurfaces, useSessionKeys, previewRequest);

        return previewRequest;
    }

    /**
     * Initialize the ImageReader instance and preview surface.
     * @param cameraId The camera to be opened.
     * @param format The format used to create ImageReader instance.
     */
    private void initializeImageReader(String cameraId, int format) throws Exception {
        mTestRule.setOrderedPreviewSizes(CameraTestUtils.getSortedSizesForFormat(
                cameraId, mTestRule.getCameraManager(), format,
                CameraTestUtils.getPreviewSizeBound(mTestRule.getWindowManager(),
                        CameraTestUtils.PREVIEW_SIZE_BOUND)));
        mPreviewSize = mTestRule.getOrderedPreviewSizes().get(0);
        mImageReaderFormat = format;
        mTestRule.createDefaultImageReader(
                mPreviewSize, format, NUM_MAX_IMAGES, /*listener*/null);
        updatePreviewSurface(mPreviewSize);
    }

    private void simpleOpenCamera(String cameraId) throws Exception {
        mTestRule.setCamera(CameraTestUtils.openCamera(
                mTestRule.getCameraManager(), cameraId,
                mTestRule.getCameraListener(), mTestRule.getHandler()));
        mTestRule.getCollector().setCameraId(cameraId);
        mTestRule.setStaticInfo(new StaticMetadata(
                mTestRule.getCameraManager().getCameraCharacteristics(cameraId),
                CheckLevel.ASSERT, /*collector*/null));
    }

    /**
     * Simple image listener that can be used to time the availability of first image.
     *
     */
    private static class SimpleImageListener implements ImageReader.OnImageAvailableListener {
        private ConditionVariable imageAvailable = new ConditionVariable();
        private boolean imageReceived = false;
        private long mTimeReceivedImage = 0;

        @Override
        public void onImageAvailable(ImageReader reader) {
            Image image = null;
            if (!imageReceived) {
                if (VERBOSE) {
                    Log.v(TAG, ""First image arrives"");
                }
                imageReceived = true;
                mTimeReceivedImage = SystemClock.elapsedRealtime();
                imageAvailable.open();
            }
            image = reader.acquireNextImage();
            if (image != null) {
                image.close();
            }
        }

        /**
         * Wait for image available, return immediately if the image was already
         * received, otherwise wait until an image arrives.
         */
        public void waitForImageAvailable(long timeout) {
            if (imageReceived) {
                imageReceived = false;
                return;
            }

            if (imageAvailable.block(timeout)) {
                imageAvailable.close();
                imageReceived = true;
            } else {
                throw new TimeoutRuntimeException(""Unable to get the first image after ""
                        + CameraTestUtils.CAPTURE_IMAGE_TIMEOUT_MS + ""ms"");
            }
        }

        public long getTimeReceivedImage() {
            return mTimeReceivedImage;
        }
    }

    private static class SimpleTimingResultListener
            extends CameraCaptureSession.CaptureCallback {
        private final LinkedBlockingQueue<Pair<CaptureResult, Long> > mPartialResultQueue =
                new LinkedBlockingQueue<Pair<CaptureResult, Long> >();
        private final LinkedBlockingQueue<Pair<CaptureResult, Long> > mResultQueue =
                new LinkedBlockingQueue<Pair<CaptureResult, Long> > ();

        @Override
        public void onCaptureCompleted(CameraCaptureSession session, CaptureRequest request,
                TotalCaptureResult result) {
            try {
                Long time = SystemClock.elapsedRealtime();
                mResultQueue.put(new Pair<CaptureResult, Long>(result, time));
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(
                        ""Can't handle InterruptedException in onCaptureCompleted"");
            }
        }

        @Override
        public void onCaptureProgressed(CameraCaptureSession session, CaptureRequest request,
                CaptureResult partialResult) {
            try {
                // check if AE and AF state exists
                Long time = -1L;
                if (partialResult.get(CaptureResult.CONTROL_AE_STATE) != null &&
                        partialResult.get(CaptureResult.CONTROL_AF_STATE) != null) {
                    time = SystemClock.elapsedRealtime();
                }
                mPartialResultQueue.put(new Pair<CaptureResult, Long>(partialResult, time));
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(
                        ""Can't handle InterruptedException in onCaptureProgressed"");
            }
        }

        public Pair<CaptureResult, Long> getPartialResultNTime(long timeout) {
            try {
                Pair<CaptureResult, Long> result =
                        mPartialResultQueue.poll(timeout, TimeUnit.MILLISECONDS);
                return result;
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(""Unhandled interrupted exception"", e);
            }
        }

        public Pair<CaptureResult, Long> getCaptureResultNTime(long timeout) {
            try {
                Pair<CaptureResult, Long> result =
                        mResultQueue.poll(timeout, TimeUnit.MILLISECONDS);
                assertNotNull(""Wait for a capture result timed out in "" + timeout + ""ms"", result);
                return result;
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(""Unhandled interrupted exception"", e);
            }
        }

        public Pair<CaptureResult, Long> getPartialResultNTimeForRequest(CaptureRequest myRequest,
                int numResultsWait) {
            if (numResultsWait < 0) {
                throw new IllegalArgumentException(""numResultsWait must be no less than 0"");
            }

            Pair<CaptureResult, Long> result;
            int i = 0;
            do {
                result = getPartialResultNTime(CameraTestUtils.CAPTURE_RESULT_TIMEOUT_MS);
                // The result may be null if no partials are produced on this particular path, so
                // stop trying
                if (result == null) break;
                if (result.first.getRequest().equals(myRequest)) {
                    return result;
                }
            } while (i++ < numResultsWait);

            // No partials produced - this may not be an error, since a given device may not
            // produce any partials on this testing path
            return null;
        }

        public Pair<CaptureResult, Long> getCaptureResultNTimeForRequest(CaptureRequest myRequest,
                int numResultsWait) {
            if (numResultsWait < 0) {
                throw new IllegalArgumentException(""numResultsWait must be no less than 0"");
            }

            Pair<CaptureResult, Long> result;
            int i = 0;
            do {
                result = getCaptureResultNTime(CameraTestUtils.CAPTURE_RESULT_TIMEOUT_MS);
                if (result.first.getRequest().equals(myRequest)) {
                    return result;
                }
            } while (i++ < numResultsWait);

            throw new TimeoutRuntimeException(""Unable to get the expected capture result after ""
                    + ""waiting for "" + numResultsWait + "" results"");
        }

    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.CameraDeviceTest"	"testCameraDevicePreviewTemplate"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/CameraDeviceTest.java"	""	"public void testCameraDevicePreviewTemplate() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            captureTemplateTestByCamera(mCameraIdsUnderTest[i], CameraDevice.TEMPLATE_PREVIEW);
        }

        // TODO: test the frame rate sustainability in preview use case test.
    }

    /**
     * <p>
     * Test camera capture request still capture template.
     * </p>
     *
     * <p>
     * The request template returned by the camera device must include a
     * necessary set of metadata keys, and their values must be set correctly.
     * It mainly requires below settings:
     * </p>
     * <ul>
     * <li>All 3A settings are auto.</li>
     * <li>All sensor settings are not null.</li>
     * <li>All ISP processing settings should be non-manual, and the camera
     * device should make sure the high quality takes priority to the stable
     * frame rate for the given settings.</li>
     * </ul>
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.CameraDeviceTest"	"testCameraDeviceCreateCaptureBuilder"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/CameraDeviceTest.java"	""	"public void testCameraDeviceCreateCaptureBuilder() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                openDevice(mCameraIdsUnderTest[i], mCameraMockListener);
                /**
                 * Test: that each template type is supported, and that its required fields are
                 * present.
                 */
                for (int j = 0; j < sTemplates.length; j++) {
                    // Skip video snapshots for LEGACY mode
                    if (mStaticInfo.isHardwareLevelLegacy() &&
                            sTemplates[j] == CameraDevice.TEMPLATE_VIDEO_SNAPSHOT) {
                        continue;
                    }
                    // Skip non-PREVIEW templates for non-color output
                    if (!mStaticInfo.isColorOutputSupported() &&
                            sTemplates[j] != CameraDevice.TEMPLATE_PREVIEW) {
                        continue;
                    }
                    CaptureRequest.Builder capReq = mCamera.createCaptureRequest(sTemplates[j]);
                    assertNotNull(""Failed to create capture request"", capReq);
                    if (mStaticInfo.areKeysAvailable(CaptureRequest.SENSOR_EXPOSURE_TIME)) {
                        assertNotNull(""Missing field: SENSOR_EXPOSURE_TIME"",
                                capReq.get(CaptureRequest.SENSOR_EXPOSURE_TIME));
                    }
                    if (mStaticInfo.areKeysAvailable(CaptureRequest.SENSOR_SENSITIVITY)) {
                        assertNotNull(""Missing field: SENSOR_SENSITIVITY"",
                                capReq.get(CaptureRequest.SENSOR_SENSITIVITY));
                    }
                }

                /**
                 * Test: creating capture requests with an invalid template ID should throw
                 * IllegalArgumentException.
                 */
                for (int j = 0; j < sInvalidTemplates.length; j++) {
                    try {
                        CaptureRequest.Builder capReq =
                                mCamera.createCaptureRequest(sInvalidTemplates[j]);
                        fail(""Should get IllegalArgumentException due to an invalid template ID."");
                    } catch (IllegalArgumentException e) {
                        // Expected exception.
                    }
                }
            }
            finally {
                try {
                    closeSession();
                } finally {
                    closeDevice(mCameraIdsUnderTest[i], mCameraMockListener);
                }
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.CameraDeviceTest"	"testSessionParametersStateLeak"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/CameraDeviceTest.java"	""	"public void testSessionParametersStateLeak() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                if (!mAllStaticInfo.get(mCameraIdsUnderTest[i]).isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support color outputs, skipping"");
                    continue;
                }
                openDevice(mCameraIdsUnderTest[i], mCameraMockListener);
                waitForDeviceState(STATE_OPENED, CAMERA_OPEN_TIMEOUT_MS);

                testSessionParametersStateLeakByCamera(mCameraIdsUnderTest[i]);
            }
            finally {
                closeDevice(mCameraIdsUnderTest[i], mCameraMockListener);
            }
        }
    }

    /**
     * Check for any state leakage in case of internal re-configure
     */
    private void testSessionParametersStateLeakByCamera(String cameraId)
            throws Exception {
        int outputFormat = ImageFormat.YUV_420_888;
        Size outputSize = mOrderedPreviewSizes.get(0);

        CameraCharacteristics characteristics = mCameraManager.getCameraCharacteristics(cameraId);
        StreamConfigurationMap config = characteristics.get(
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
        List <CaptureRequest.Key<?>> sessionKeys = characteristics.getAvailableSessionKeys();
        if (sessionKeys == null) {
            return;
        }

        if (config.isOutputSupportedFor(outputFormat)) {
            outputSize = config.getOutputSizes(outputFormat)[0];
        } else {
            return;
        }

        ImageReader imageReader = ImageReader.newInstance(outputSize.getWidth(),
                outputSize.getHeight(), outputFormat, /*maxImages*/3);

        class OnReadyCaptureStateCallback extends CameraCaptureSession.StateCallback {
            private ConditionVariable onReadyTriggeredCond = new ConditionVariable();
            private boolean onReadyTriggered = false;

            @Override
            public void onConfigured(CameraCaptureSession session) {
            }

            @Override
            public void onConfigureFailed(CameraCaptureSession session) {
            }

            @Override
            public synchronized void onReady(CameraCaptureSession session) {
                onReadyTriggered = true;
                onReadyTriggeredCond.open();
            }

            public void waitForOnReady(long timeout) {
                synchronized (this) {
                    if (onReadyTriggered) {
                        onReadyTriggered = false;
                        onReadyTriggeredCond.close();
                        return;
                    }
                }

                if (onReadyTriggeredCond.block(timeout)) {
                    synchronized (this) {
                        onReadyTriggered = false;
                        onReadyTriggeredCond.close();
                    }
                } else {
                    throw new TimeoutRuntimeException(""Unable to receive onReady after ""
                        + timeout + ""ms"");
                }
            }
        }

        OnReadyCaptureStateCallback sessionListener = new OnReadyCaptureStateCallback();

        try {
            mSessionMockListener = spy(new BlockingSessionCallback(sessionListener));
            mSessionWaiter = mSessionMockListener.getStateWaiter();
            List<OutputConfiguration> outputs = new ArrayList<>();
            outputs.add(new OutputConfiguration(imageReader.getSurface()));
            SessionConfiguration sessionConfig = new SessionConfiguration(
                    SessionConfiguration.SESSION_REGULAR, outputs,
                    new HandlerExecutor(mHandler), mSessionMockListener);

            CaptureRequest.Builder builder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
            builder.addTarget(imageReader.getSurface());
            CaptureRequest request = builder.build();

            sessionConfig.setSessionParameters(request);
            mCamera.createCaptureSession(sessionConfig);

            mSession = mSessionMockListener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);
            sessionListener.waitForOnReady(SESSION_CONFIGURE_TIMEOUT_MS);

            SimpleCaptureCallback captureListener = new SimpleCaptureCallback();
            ImageDropperListener imageListener = new ImageDropperListener();
            imageReader.setOnImageAvailableListener(imageListener, mHandler);

            // To check the state leak condition, we need a capture request that has
            // at least one session pararameter value difference from the initial session
            // parameters configured above. Scan all available template types for the
            // required delta.
            CaptureRequest.Builder requestBuilder = null;
            ArrayList<CaptureRequest.Builder> builders = new ArrayList<CaptureRequest.Builder> ();
            if (mStaticInfo.isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                builders.add(mCamera.createCaptureRequest(CameraDevice.TEMPLATE_MANUAL));
            }
            if (mStaticInfo.isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING)
                    || mStaticInfo.isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_YUV_REPROCESSING)) {
                builders.add(mCamera.createCaptureRequest(CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG));
            }
            builders.add(mCamera.createCaptureRequest(CameraDevice.TEMPLATE_VIDEO_SNAPSHOT));
            builders.add(mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW));
            builders.add(mCamera.createCaptureRequest(CameraDevice.TEMPLATE_RECORD));
            for (CaptureRequest.Key<?> key : sessionKeys) {
                Object sessionValue = builder.get(key);
                for (CaptureRequest.Builder newBuilder : builders) {
                    Object currentValue = newBuilder.get(key);
                    if ((sessionValue == null) && (currentValue == null)) {
                        continue;
                    }

                    if (((sessionValue == null) && (currentValue != null)) ||
                            ((sessionValue != null) && (currentValue == null)) ||
                            (!sessionValue.equals(currentValue))) {
                        requestBuilder = newBuilder;
                        break;
                    }
                }

                if (requestBuilder != null) {
                    break;
                }
            }

            if (requestBuilder != null) {
                requestBuilder.addTarget(imageReader.getSurface());
                request = requestBuilder.build();
                mSession.setRepeatingRequest(request, captureListener, mHandler);
                try {
                    sessionListener.waitForOnReady(SESSION_CONFIGURE_TIMEOUT_MS);
                    fail(""Camera shouldn't switch to ready state when session parameters are "" +
                            ""modified"");
                } catch (TimeoutRuntimeException e) {
                    //expected
                }
            }
        } finally {
            imageReader.close();
            mSession.close();
        }
    }

    /**
     * Verify creating a session with additional parameters.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.CameraDeviceTest"	"testCreateSessionWithParameters"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/CameraDeviceTest.java"	""	"public void testCreateSessionWithParameters() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                if (!mAllStaticInfo.get(mCameraIdsUnderTest[i]).isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support color outputs, skipping"");
                    continue;
                }
                openDevice(mCameraIdsUnderTest[i], mCameraMockListener);
                waitForDeviceState(STATE_OPENED, CAMERA_OPEN_TIMEOUT_MS);

                testCreateSessionWithParametersByCamera(mCameraIdsUnderTest[i], /*reprocessable*/false);
                testCreateSessionWithParametersByCamera(mCameraIdsUnderTest[i], /*reprocessable*/true);
            }
            finally {
                closeDevice(mCameraIdsUnderTest[i], mCameraMockListener);
            }
        }
    }

    /**
     * Verify creating a session with additional parameters works
     */
    private void testCreateSessionWithParametersByCamera(String cameraId, boolean reprocessable)
            throws Exception {
        final int SESSION_TIMEOUT_MS = 1000;
        final int CAPTURE_TIMEOUT_MS = 3000;
        int inputFormat = ImageFormat.YUV_420_888;
        int outputFormat = inputFormat;
        Size outputSize = mOrderedPreviewSizes.get(0);
        Size inputSize = outputSize;
        InputConfiguration inputConfig = null;

        if (VERBOSE) {
            Log.v(TAG, ""Testing creating session with parameters for camera "" + cameraId);
        }

        CameraCharacteristics characteristics = mCameraManager.getCameraCharacteristics(cameraId);
        StreamConfigurationMap config = characteristics.get(
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);

        if (reprocessable) {
            //Pick a supported i/o format and size combination.
            //Ideally the input format should match the output.
            boolean found = false;
            int inputFormats [] = config.getInputFormats();
            if (inputFormats.length == 0) {
                return;
            }

            for (int inFormat : inputFormats) {
                int outputFormats [] = config.getValidOutputFormatsForInput(inFormat);
                for (int outFormat : outputFormats) {
                    if (inFormat == outFormat) {
                        inputFormat = inFormat;
                        outputFormat = outFormat;
                        found = true;
                        break;
                    }
                }
                if (found) {
                    break;
                }
            }

            //In case the above combination doesn't exist, pick the first first supported
            //pair.
            if (!found) {
                inputFormat = inputFormats[0];
                int outputFormats [] = config.getValidOutputFormatsForInput(inputFormat);
                assertTrue(""No output formats supported for input format: "" + inputFormat,
                        (outputFormats.length > 0));
                outputFormat = outputFormats[0];
            }

            Size inputSizes[] = config.getInputSizes(inputFormat);
            Size outputSizes[] = config.getOutputSizes(outputFormat);
            assertTrue(""No valid sizes supported for input format: "" + inputFormat,
                    (inputSizes.length > 0));
            assertTrue(""No valid sizes supported for output format: "" + outputFormat,
                    (outputSizes.length > 0));

            inputSize = inputSizes[0];
            outputSize = outputSizes[0];
            inputConfig = new InputConfiguration(inputSize.getWidth(),
                    inputSize.getHeight(), inputFormat);
        } else {
            if (config.isOutputSupportedFor(outputFormat)) {
                outputSize = config.getOutputSizes(outputFormat)[0];
            } else {
                return;
            }
        }

        ImageReader imageReader = ImageReader.newInstance(outputSize.getWidth(),
                outputSize.getHeight(), outputFormat, /*maxImages*/1);

        try {
            mSessionMockListener = spy(new BlockingSessionCallback());
            mSessionWaiter = mSessionMockListener.getStateWaiter();
            List<OutputConfiguration> outputs = new ArrayList<>();
            outputs.add(new OutputConfiguration(imageReader.getSurface()));
            SessionConfiguration sessionConfig = new SessionConfiguration(
                    SessionConfiguration.SESSION_REGULAR, outputs,
                    new HandlerExecutor(mHandler), mSessionMockListener);

            CaptureRequest.Builder builder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
            builder.addTarget(imageReader.getSurface());
            CaptureRequest request = builder.build();

            sessionConfig.setInputConfiguration(inputConfig);
            sessionConfig.setSessionParameters(request);
            mCamera.createCaptureSession(sessionConfig);

            mSession = mSessionMockListener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);

            // Verify we can capture a frame with the session.
            SimpleCaptureCallback captureListener = new SimpleCaptureCallback();
            SimpleImageReaderListener imageListener = new SimpleImageReaderListener();
            imageReader.setOnImageAvailableListener(imageListener, mHandler);

            mSession.capture(request, captureListener, mHandler);
            captureListener.getCaptureResultForRequest(request, CAPTURE_TIMEOUT_MS);
            imageListener.getImage(CAPTURE_TIMEOUT_MS).close();
        } finally {
            imageReader.close();
            mSession.close();
        }
    }

    /**
     * Verify creating sessions back to back and only the last one is valid for
     * submitting requests.
     */
    private void testCreateSessionsByCamera(String cameraId) throws Exception {
        final int NUM_SESSIONS = 3;
        final int SESSION_TIMEOUT_MS = 1000;
        final int CAPTURE_TIMEOUT_MS = 3000;

        if (VERBOSE) {
            Log.v(TAG, ""Testing creating sessions for camera "" + cameraId);
        }

        Size yuvSize = getSortedSizesForFormat(cameraId, mCameraManager, ImageFormat.YUV_420_888,
                /*bound*/null).get(0);
        Size jpegSize = getSortedSizesForFormat(cameraId, mCameraManager, ImageFormat.JPEG,
                /*bound*/null).get(0);

        // Create a list of image readers. JPEG for last one and YUV for the rest.
        List<ImageReader> imageReaders = new ArrayList<>();
        List<CameraCaptureSession> allSessions = new ArrayList<>();

        try {
            for (int i = 0; i < NUM_SESSIONS - 1; i++) {
                imageReaders.add(ImageReader.newInstance(yuvSize.getWidth(), yuvSize.getHeight(),
                        ImageFormat.YUV_420_888, /*maxImages*/1));
            }
            imageReaders.add(ImageReader.newInstance(jpegSize.getWidth(), jpegSize.getHeight(),
                    ImageFormat.JPEG, /*maxImages*/1));

            // Create multiple sessions back to back.
            MultipleSessionCallback sessionListener =
                    new MultipleSessionCallback(/*failOnConfigureFailed*/true);
            for (int i = 0; i < NUM_SESSIONS; i++) {
                List<Surface> outputs = new ArrayList<>();
                outputs.add(imageReaders.get(i).getSurface());
                mCamera.createCaptureSession(outputs, sessionListener, mHandler);
            }

            // Verify we get onConfigured() for all sessions.
            allSessions = sessionListener.getAllSessions(NUM_SESSIONS,
                    SESSION_TIMEOUT_MS * NUM_SESSIONS);
            assertEquals(String.format(""Got %d sessions but configured %d sessions"",
                    allSessions.size(), NUM_SESSIONS), allSessions.size(), NUM_SESSIONS);

            // Verify all sessions except the last one are closed.
            for (int i = 0; i < NUM_SESSIONS - 1; i++) {
                sessionListener.waitForSessionClose(allSessions.get(i), SESSION_TIMEOUT_MS);
            }

            // Verify we can capture a frame with the last session.
            CameraCaptureSession session = allSessions.get(allSessions.size() - 1);
            SimpleCaptureCallback captureListener = new SimpleCaptureCallback();
            ImageReader reader = imageReaders.get(imageReaders.size() - 1);
            SimpleImageReaderListener imageListener = new SimpleImageReaderListener();
            reader.setOnImageAvailableListener(imageListener, mHandler);

            CaptureRequest.Builder builder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
            builder.addTarget(reader.getSurface());
            CaptureRequest request = builder.build();

            session.capture(request, captureListener, mHandler);
            captureListener.getCaptureResultForRequest(request, CAPTURE_TIMEOUT_MS);
            imageListener.getImage(CAPTURE_TIMEOUT_MS).close();
        } finally {
            for (ImageReader reader : imageReaders) {
                reader.close();
            }
            for (CameraCaptureSession session : allSessions) {
                session.close();
            }
        }
    }

    private void prepareTestByCamera() throws Exception {
        final int PREPARE_TIMEOUT_MS = 10000;

        mSessionMockListener = spy(new BlockingSessionCallback());

        SurfaceTexture output1 = new SurfaceTexture(1);
        Surface output1Surface = new Surface(output1);
        SurfaceTexture output2 = new SurfaceTexture(2);
        Surface output2Surface = new Surface(output2);

        ArrayList<OutputConfiguration> outConfigs = new ArrayList<OutputConfiguration> ();
        outConfigs.add(new OutputConfiguration(output1Surface));
        outConfigs.add(new OutputConfiguration(output2Surface));
        SessionConfiguration sessionConfig = new SessionConfiguration(
                SessionConfiguration.SESSION_REGULAR, outConfigs,
                new HandlerExecutor(mHandler), mSessionMockListener);
        CaptureRequest.Builder r = mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        sessionConfig.setSessionParameters(r.build());
        mCamera.createCaptureSession(sessionConfig);

        mSession = mSessionMockListener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);

        // Try basic prepare

        mSession.prepare(output1Surface);

        verify(mSessionMockListener, timeout(PREPARE_TIMEOUT_MS).times(1))
                .onSurfacePrepared(eq(mSession), eq(output1Surface));

        // Should not complain if preparing already prepared stream

        mSession.prepare(output1Surface);

        verify(mSessionMockListener, timeout(PREPARE_TIMEOUT_MS).times(2))
                .onSurfacePrepared(eq(mSession), eq(output1Surface));

        // Check surface not included in session

        SurfaceTexture output3 = new SurfaceTexture(3);
        Surface output3Surface = new Surface(output3);
        try {
            mSession.prepare(output3Surface);
            // Legacy camera prepare always succeed
            if (mStaticInfo.isHardwareLevelAtLeastLimited()) {
                fail(""Preparing surface not part of session must throw IllegalArgumentException"");
            }
        } catch (IllegalArgumentException e) {
            // expected
        }

        // Ensure second prepare also works

        mSession.prepare(output2Surface);

        verify(mSessionMockListener, timeout(PREPARE_TIMEOUT_MS).times(1))
                .onSurfacePrepared(eq(mSession), eq(output2Surface));

        // Use output1

        r = mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        r.addTarget(output1Surface);

        mSession.capture(r.build(), null, null);

        try {
            mSession.prepare(output1Surface);
            // Legacy camera prepare always succeed
            if (mStaticInfo.isHardwareLevelAtLeastLimited()) {
                fail(""Preparing already-used surface must throw IllegalArgumentException"");
            }
        } catch (IllegalArgumentException e) {
            // expected
        }

        // Create new session with outputs 1 and 3, ensure output1Surface still can't be prepared
        // again

        mSessionMockListener = spy(new BlockingSessionCallback());

        ArrayList<Surface> outputSurfaces = new ArrayList<Surface>(
            Arrays.asList(output1Surface, output3Surface));
        mCamera.createCaptureSession(outputSurfaces, mSessionMockListener, mHandler);

        mSession = mSessionMockListener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);

        try {
            mSession.prepare(output1Surface);
            // Legacy camera prepare always succeed
            if (mStaticInfo.isHardwareLevelAtLeastLimited()) {
                fail(""Preparing surface used in previous session must throw "" +
                        ""IllegalArgumentException"");
            }
        } catch (IllegalArgumentException e) {
            // expected
        }

        // Use output3, wait for result, then make sure prepare still doesn't work

        r = mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        r.addTarget(output3Surface);

        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        mSession.capture(r.build(), resultListener, mHandler);

        resultListener.getCaptureResult(CAPTURE_RESULT_TIMEOUT_MS);

        try {
            mSession.prepare(output3Surface);
            // Legacy camera prepare always succeed
            if (mStaticInfo.isHardwareLevelAtLeastLimited()) {
                fail(""Preparing already-used surface must throw IllegalArgumentException"");
            }
        } catch (IllegalArgumentException e) {
            // expected
        }

        // Create new session with outputs 1 and 2, ensure output2Surface can be prepared again

        mSessionMockListener = spy(new BlockingSessionCallback());

        outputSurfaces = new ArrayList<>(
            Arrays.asList(output1Surface, output2Surface));
        mCamera.createCaptureSession(outputSurfaces, mSessionMockListener, mHandler);

        mSession = mSessionMockListener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);

        mSession.prepare(output2Surface);

        verify(mSessionMockListener, timeout(PREPARE_TIMEOUT_MS).times(1))
                .onSurfacePrepared(eq(mSession), eq(output2Surface));

        try {
            mSession.prepare(output1Surface);
            // Legacy camera prepare always succeed
            if (mStaticInfo.isHardwareLevelAtLeastLimited()) {
                fail(""Preparing surface used in previous session must throw "" +
                        ""IllegalArgumentException"");
            }
        } catch (IllegalArgumentException e) {
            // expected
        }

        output1.release();
        output2.release();
        output3.release();
    }

    private void prepareTestForSharedSurfacesByCamera() throws Exception {
        final int PREPARE_TIMEOUT_MS = 10000;

        mSessionMockListener = spy(new BlockingSessionCallback());

        SurfaceTexture output1 = new SurfaceTexture(1);
        Surface output1Surface = new Surface(output1);
        SurfaceTexture output2 = new SurfaceTexture(2);
        Surface output2Surface = new Surface(output2);

        List<Surface> outputSurfaces = new ArrayList<>(
            Arrays.asList(output1Surface, output2Surface));
        OutputConfiguration surfaceSharedConfig = new OutputConfiguration(
            OutputConfiguration.SURFACE_GROUP_ID_NONE, output1Surface);
        surfaceSharedConfig.enableSurfaceSharing();
        surfaceSharedConfig.addSurface(output2Surface);

        List<OutputConfiguration> outputConfigurations = new ArrayList<>();
        outputConfigurations.add(surfaceSharedConfig);
        mCamera.createCaptureSessionByOutputConfigurations(
                outputConfigurations, mSessionMockListener, mHandler);

        mSession = mSessionMockListener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);

        // Try prepare on output1Surface
        mSession.prepare(output1Surface);

        verify(mSessionMockListener, timeout(PREPARE_TIMEOUT_MS).times(1))
                .onSurfacePrepared(eq(mSession), eq(output1Surface));
        verify(mSessionMockListener, timeout(PREPARE_TIMEOUT_MS).times(1))
                .onSurfacePrepared(eq(mSession), eq(output2Surface));

        // Try prepare on output2Surface
        mSession.prepare(output2Surface);

        verify(mSessionMockListener, timeout(PREPARE_TIMEOUT_MS).times(2))
                .onSurfacePrepared(eq(mSession), eq(output1Surface));
        verify(mSessionMockListener, timeout(PREPARE_TIMEOUT_MS).times(2))
                .onSurfacePrepared(eq(mSession), eq(output2Surface));

        // Try prepare on output1Surface again
        mSession.prepare(output1Surface);

        verify(mSessionMockListener, timeout(PREPARE_TIMEOUT_MS).times(3))
                .onSurfacePrepared(eq(mSession), eq(output1Surface));
        verify(mSessionMockListener, timeout(PREPARE_TIMEOUT_MS).times(3))
                .onSurfacePrepared(eq(mSession), eq(output2Surface));
    }

    private void invalidRequestCaptureTestByCamera() throws Exception {
        if (VERBOSE) Log.v(TAG, ""invalidRequestCaptureTestByCamera"");

        List<CaptureRequest> emptyRequests = new ArrayList<CaptureRequest>();
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        CaptureRequest unConfiguredRequest = requestBuilder.build();
        List<CaptureRequest> unConfiguredRequests = new ArrayList<CaptureRequest>();
        unConfiguredRequests.add(unConfiguredRequest);

        try {
            // Test: CameraCaptureSession capture should throw IAE for null request.
            mSession.capture(/*request*/null, /*listener*/null, mHandler);
            mCollector.addMessage(
                    ""Session capture should throw IllegalArgumentException for null request"");
        } catch (IllegalArgumentException e) {
            // Pass.
        }

        try {
            // Test: CameraCaptureSession capture should throw IAE for request
            // without surface configured.
            mSession.capture(unConfiguredRequest, /*listener*/null, mHandler);
            mCollector.addMessage(""Session capture should throw "" +
                    ""IllegalArgumentException for request without surface configured"");
        } catch (IllegalArgumentException e) {
            // Pass.
        }

        try {
            // Test: CameraCaptureSession setRepeatingRequest should throw IAE for null request.
            mSession.setRepeatingRequest(/*request*/null, /*listener*/null, mHandler);
            mCollector.addMessage(""Session setRepeatingRequest should throw "" +
                    ""IllegalArgumentException for null request"");
        } catch (IllegalArgumentException e) {
            // Pass.
        }

        try {
            // Test: CameraCaptureSession setRepeatingRequest should throw IAE for for request
            // without surface configured.
            mSession.setRepeatingRequest(unConfiguredRequest, /*listener*/null, mHandler);
            mCollector.addMessage(""Capture zero burst should throw IllegalArgumentException "" +
                    ""for request without surface configured"");
        } catch (IllegalArgumentException e) {
            // Pass.
        }

        try {
            // Test: CameraCaptureSession captureBurst should throw IAE for null request list.
            mSession.captureBurst(/*requests*/null, /*listener*/null, mHandler);
            mCollector.addMessage(""Session captureBurst should throw "" +
                    ""IllegalArgumentException for null request list"");
        } catch (IllegalArgumentException e) {
            // Pass.
        }

        try {
            // Test: CameraCaptureSession captureBurst should throw IAE for empty request list.
            mSession.captureBurst(emptyRequests, /*listener*/null, mHandler);
            mCollector.addMessage(""Session captureBurst should throw "" +
                    "" IllegalArgumentException for empty request list"");
        } catch (IllegalArgumentException e) {
            // Pass.
        }

        try {
            // Test: CameraCaptureSession captureBurst should throw IAE for request
            // without surface configured.
            mSession.captureBurst(unConfiguredRequests, /*listener*/null, mHandler);
            fail(""Session captureBurst should throw IllegalArgumentException "" +
                    ""for null request list"");
        } catch (IllegalArgumentException e) {
            // Pass.
        }

        try {
            // Test: CameraCaptureSession setRepeatingBurst should throw IAE for null request list.
            mSession.setRepeatingBurst(/*requests*/null, /*listener*/null, mHandler);
            mCollector.addMessage(""Session setRepeatingBurst should throw "" +
                    ""IllegalArgumentException for null request list"");
        } catch (IllegalArgumentException e) {
            // Pass.
        }

        try {
            // Test: CameraCaptureSession setRepeatingBurst should throw IAE for empty request list.
            mSession.setRepeatingBurst(emptyRequests, /*listener*/null, mHandler);
            mCollector.addMessage(""Session setRepeatingBurst should throw "" +
                    ""IllegalArgumentException for empty request list"");
        } catch (IllegalArgumentException e) {
            // Pass.
        }

        try {
            // Test: CameraCaptureSession setRepeatingBurst should throw IAE for request
            // without surface configured.
            mSession.setRepeatingBurst(unConfiguredRequests, /*listener*/null, mHandler);
            mCollector.addMessage(""Session setRepeatingBurst should throw "" +
                    ""IllegalArgumentException for request without surface configured"");
        } catch (IllegalArgumentException e) {
            // Pass.
        }
    }

    private class IsCaptureResultNotEmpty
            implements ArgumentMatcher<TotalCaptureResult> {
        @Override
        public boolean matches(TotalCaptureResult result) {
            /**
             * Do the simple verification here. Only verify the timestamp for now.
             * TODO: verify more required capture result metadata fields.
             */
            Long timeStamp = result.get(CaptureResult.SENSOR_TIMESTAMP);
            if (timeStamp != null && timeStamp.longValue() > 0L) {
                return true;
            }
            return false;
        }
    }

    /**
     * Run capture test with different test configurations.
     *
     * @param burst If the test uses {@link CameraCaptureSession#captureBurst} or
     * {@link CameraCaptureSession#setRepeatingBurst} to capture the burst.
     * @param repeating If the test uses {@link CameraCaptureSession#setRepeatingBurst} or
     * {@link CameraCaptureSession#setRepeatingRequest} for repeating capture.
     * @param abort If the test uses {@link CameraCaptureSession#abortCaptures} to stop the
     * repeating capture.  It has no effect if repeating is false.
     * @param useExecutor If the test uses {@link java.util.concurrent.Executor} instead of
     * {@link android.os.Handler} for callback invocation.
     */
    private void runCaptureTest(boolean burst, boolean repeating, boolean abort,
            boolean useExecutor) throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                openDevice(mCameraIdsUnderTest[i], mCameraMockListener);
                waitForDeviceState(STATE_OPENED, CAMERA_OPEN_TIMEOUT_MS);

                prepareCapture();

                if (!burst) {
                    // Test: that a single capture of each template type succeeds.
                    for (int j = 0; j < sTemplates.length; j++) {
                        // Skip video snapshots for LEGACY mode
                        if (mStaticInfo.isHardwareLevelLegacy() &&
                                sTemplates[j] == CameraDevice.TEMPLATE_VIDEO_SNAPSHOT) {
                            continue;
                        }
                        // Skip non-PREVIEW templates for non-color output
                        if (!mStaticInfo.isColorOutputSupported() &&
                                sTemplates[j] != CameraDevice.TEMPLATE_PREVIEW) {
                            continue;
                        }

                        captureSingleShot(mCameraIdsUnderTest[i], sTemplates[j], repeating, abort,
                                useExecutor);
                    }
                }
                else {
                    // Test: burst of one shot
                    captureBurstShot(mCameraIdsUnderTest[i], sTemplates, 1, repeating, abort, useExecutor);

                    int template = mStaticInfo.isColorOutputSupported() ?
                        CameraDevice.TEMPLATE_STILL_CAPTURE :
                        CameraDevice.TEMPLATE_PREVIEW;
                    int[] templates = new int[] {
                        template,
                        template,
                        template,
                        template,
                        template
                    };

                    // Test: burst of 5 shots of the same template type
                    captureBurstShot(mCameraIdsUnderTest[i], templates, templates.length, repeating, abort,
                            useExecutor);

                    if (mStaticInfo.isColorOutputSupported()) {
                        // Test: burst of 6 shots of different template types
                        captureBurstShot(mCameraIdsUnderTest[i], sTemplates, sTemplates.length, repeating,
                                abort, useExecutor);
                    }
                }
                verify(mCameraMockListener, never())
                        .onError(
                                any(CameraDevice.class),
                                anyInt());
            } catch (Exception e) {
                mCollector.addError(e);
            } finally {
                try {
                    closeSession();
                } catch (Exception e) {
                    mCollector.addError(e);
                }finally {
                    closeDevice(mCameraIdsUnderTest[i], mCameraMockListener);
                }
            }
        }
    }

    private void captureSingleShot(
            String id,
            int template,
            boolean repeating, boolean abort, boolean useExecutor) throws Exception {

        assertEquals(""Bad initial state for preparing to capture"",
                mLatestSessionState, SESSION_READY);

        final Executor executor = useExecutor ? new HandlerExecutor(mHandler) : null;
        CaptureRequest.Builder requestBuilder = mCamera.createCaptureRequest(template);
        assertNotNull(""Failed to create capture request"", requestBuilder);
        requestBuilder.addTarget(mReaderSurface);
        CameraCaptureSession.CaptureCallback mockCaptureCallback =
                mock(CameraCaptureSession.CaptureCallback.class);

        if (VERBOSE) {
            Log.v(TAG, String.format(""Capturing shot for device %s, template %d"",
                    id, template));
        }

        if (executor != null) {
            startCapture(requestBuilder.build(), repeating, mockCaptureCallback, executor);
        } else {
            startCapture(requestBuilder.build(), repeating, mockCaptureCallback, mHandler);
        }
        waitForSessionState(SESSION_ACTIVE, SESSION_ACTIVE_TIMEOUT_MS);

        int expectedCaptureResultCount = repeating ? REPEATING_CAPTURE_EXPECTED_RESULT_COUNT : 1;
        verifyCaptureResults(mockCaptureCallback, expectedCaptureResultCount);

        if (repeating) {
            if (abort) {
                mSession.abortCaptures();
                // Have to make sure abort and new requests aren't interleave together.
                waitForSessionState(SESSION_READY, SESSION_READY_TIMEOUT_MS);

                // Capture a single capture, and verify the result.
                SimpleCaptureCallback resultCallback = new SimpleCaptureCallback();
                CaptureRequest singleRequest = requestBuilder.build();
                if (executor != null) {
                    mSession.captureSingleRequest(singleRequest, executor, resultCallback);
                } else {
                    mSession.capture(singleRequest, resultCallback, mHandler);
                }
                resultCallback.getCaptureResultForRequest(singleRequest, CAPTURE_RESULT_TIMEOUT_MS);

                // Resume the repeating, and verify that results are returned.
                if (executor != null) {
                    mSession.setSingleRepeatingRequest(singleRequest, executor, resultCallback);
                } else {
                    mSession.setRepeatingRequest(singleRequest, resultCallback, mHandler);
                }
                for (int i = 0; i < REPEATING_CAPTURE_EXPECTED_RESULT_COUNT; i++) {
                    resultCallback.getCaptureResult(CAPTURE_RESULT_TIMEOUT_MS);
                }
            }
            mSession.stopRepeating();
        }
        waitForSessionState(SESSION_READY, SESSION_READY_TIMEOUT_MS);
    }

    private void captureBurstShot(
            String id,
            int[] templates,
            int len,
            boolean repeating,
            boolean abort, boolean useExecutor) throws Exception {

        assertEquals(""Bad initial state for preparing to capture"",
                mLatestSessionState, SESSION_READY);

        assertTrue(""Invalid args to capture function"", len <= templates.length);
        List<CaptureRequest> requests = new ArrayList<CaptureRequest>();
        List<CaptureRequest> postAbortRequests = new ArrayList<CaptureRequest>();
        final Executor executor = useExecutor ? new HandlerExecutor(mHandler) : null;
        for (int i = 0; i < len; i++) {
            // Skip video snapshots for LEGACY mode
            if (mStaticInfo.isHardwareLevelLegacy() &&
                    templates[i] == CameraDevice.TEMPLATE_VIDEO_SNAPSHOT) {
                continue;
            }
            // Skip non-PREVIEW templates for non-color outpu
            if (!mStaticInfo.isColorOutputSupported() &&
                    templates[i] != CameraDevice.TEMPLATE_PREVIEW) {
                continue;
            }

            CaptureRequest.Builder requestBuilder = mCamera.createCaptureRequest(templates[i]);
            assertNotNull(""Failed to create capture request"", requestBuilder);
            requestBuilder.addTarget(mReaderSurface);
            requests.add(requestBuilder.build());
            if (abort) {
                postAbortRequests.add(requestBuilder.build());
            }
        }
        CameraCaptureSession.CaptureCallback mockCaptureCallback =
                mock(CameraCaptureSession.CaptureCallback.class);

        if (VERBOSE) {
            Log.v(TAG, String.format(""Capturing burst shot for device %s"", id));
        }

        if (!repeating) {
            if (executor != null) {
                mSession.captureBurstRequests(requests, executor, mockCaptureCallback);
            } else {
                mSession.captureBurst(requests, mockCaptureCallback, mHandler);
            }
        }
        else {
            if (executor != null) {
                mSession.setRepeatingBurstRequests(requests, executor, mockCaptureCallback);
            } else {
                mSession.setRepeatingBurst(requests, mockCaptureCallback, mHandler);
            }
        }
        waitForSessionState(SESSION_ACTIVE, SESSION_READY_TIMEOUT_MS);

        int expectedResultCount = requests.size();
        if (repeating) {
            expectedResultCount *= REPEATING_CAPTURE_EXPECTED_RESULT_COUNT;
        }

        verifyCaptureResults(mockCaptureCallback, expectedResultCount);

        if (repeating) {
            if (abort) {
                mSession.abortCaptures();
                // Have to make sure abort and new requests aren't interleave together.
                waitForSessionState(SESSION_READY, SESSION_READY_TIMEOUT_MS);

                // Capture a burst of captures, and verify the results.
                SimpleCaptureCallback resultCallback = new SimpleCaptureCallback();
                if (executor != null) {
                    mSession.captureBurstRequests(postAbortRequests, executor, resultCallback);
                } else {
                    mSession.captureBurst(postAbortRequests, resultCallback, mHandler);
                }
                // Verify that the results are returned.
                for (int i = 0; i < postAbortRequests.size(); i++) {
                    resultCallback.getCaptureResultForRequest(
                            postAbortRequests.get(i), CAPTURE_RESULT_TIMEOUT_MS);
                }

                // Resume the repeating, and verify that results are returned.
                if (executor != null) {
                    mSession.setRepeatingBurstRequests(requests, executor, resultCallback);
                } else {
                    mSession.setRepeatingBurst(requests, resultCallback, mHandler);
                }
                for (int i = 0; i < REPEATING_CAPTURE_EXPECTED_RESULT_COUNT; i++) {
                    resultCallback.getCaptureResult(CAPTURE_RESULT_TIMEOUT_MS);
                }
            }
            mSession.stopRepeating();
        }
        waitForSessionState(SESSION_READY, SESSION_READY_TIMEOUT_MS);
    }

    /**
     * Precondition: Device must be in known OPENED state (has been waited for).
     *
     * <p>Creates a new capture session and waits until it is in the {@code SESSION_READY} state.
     * </p>
     *
     * <p>Any existing capture session will be closed as a result of calling this.</p>
     * */
    private void prepareCapture() throws Exception {
        if (VERBOSE) Log.v(TAG, ""prepareCapture"");

        assertTrue(""Bad initial state for preparing to capture"",
                mLatestDeviceState == STATE_OPENED);

        if (mSession != null) {
            if (VERBOSE) Log.v(TAG, ""prepareCapture - closing existing session"");
            closeSession();
        }

        // Create a new session listener each time, it's not reusable across cameras
        mSessionMockListener = spy(new BlockingSessionCallback());
        mSessionWaiter = mSessionMockListener.getStateWaiter();

        if (!mStaticInfo.isColorOutputSupported()) {
            createDefaultImageReader(getMaxDepthSize(mCamera.getId(), mCameraManager),
                    ImageFormat.DEPTH16, MAX_NUM_IMAGES, new ImageDropperListener());
        } else {
            createDefaultImageReader(DEFAULT_CAPTURE_SIZE, ImageFormat.YUV_420_888, MAX_NUM_IMAGES,
                    new ImageDropperListener());
        }

        List<Surface> outputSurfaces = new ArrayList<>(Arrays.asList(mReaderSurface));
        mCamera.createCaptureSession(outputSurfaces, mSessionMockListener, mHandler);

        mSession = mSessionMockListener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);
        waitForSessionState(SESSION_CONFIGURED, SESSION_CONFIGURE_TIMEOUT_MS);
        waitForSessionState(SESSION_READY, SESSION_READY_TIMEOUT_MS);
    }

    private void waitForDeviceState(int state, long timeoutMs) {
        mCameraMockListener.waitForState(state, timeoutMs);
        mLatestDeviceState = state;
    }

    private void waitForSessionState(int state, long timeoutMs) {
        mSessionWaiter.waitForState(state, timeoutMs);
        mLatestSessionState = state;
    }

    private void verifyCaptureResults(
            CameraCaptureSession.CaptureCallback mockListener,
            int expectResultCount) {
        final int TIMEOUT_PER_RESULT_MS = 2000;
        // Should receive expected number of capture results.
        verify(mockListener,
                timeout(TIMEOUT_PER_RESULT_MS * expectResultCount).atLeast(expectResultCount))
                        .onCaptureCompleted(
                                eq(mSession),
                                isA(CaptureRequest.class),
                                argThat(new IsCaptureResultNotEmpty()));
        // Should not receive any capture failed callbacks.
        verify(mockListener, never())
                        .onCaptureFailed(
                                eq(mSession),
                                isA(CaptureRequest.class),
                                isA(CaptureFailure.class));
        // Should receive expected number of capture shutter calls
        verify(mockListener,
                atLeast(expectResultCount))
                        .onCaptureStarted(
                               eq(mSession),
                               isA(CaptureRequest.class),
                               anyLong(),
                               anyLong());
    }

    private void checkFpsRange(CaptureRequest.Builder request, int template,
            CameraCharacteristics props) {
        CaptureRequest.Key<Range<Integer>> fpsRangeKey = CONTROL_AE_TARGET_FPS_RANGE;
        Range<Integer> fpsRange;
        if ((fpsRange = mCollector.expectKeyValueNotNull(request, fpsRangeKey)) == null) {
            return;
        }

        int minFps = fpsRange.getLower();
        int maxFps = fpsRange.getUpper();
        Range<Integer>[] availableFpsRange = props
                .get(CameraCharacteristics.CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES);
        boolean foundRange = false;
        for (int i = 0; i < availableFpsRange.length; i += 1) {
            if (minFps == availableFpsRange[i].getLower()
                    && maxFps == availableFpsRange[i].getUpper()) {
                foundRange = true;
                break;
            }
        }
        if (!foundRange) {
            mCollector.addMessage(String.format(""Unable to find the fps range (%d, %d)"",
                    minFps, maxFps));
            return;
        }


        if (template != CameraDevice.TEMPLATE_MANUAL &&
                template != CameraDevice.TEMPLATE_STILL_CAPTURE) {
            if (maxFps < MIN_FPS_REQUIRED_FOR_STREAMING) {
                mCollector.addMessage(""Max fps should be at least ""
                        + MIN_FPS_REQUIRED_FOR_STREAMING);
                return;
            }

            // Relax framerate constraints on legacy mode
            if (mStaticInfo.isHardwareLevelAtLeastLimited()) {
                // Need give fixed frame rate for video recording template.
                if (template == CameraDevice.TEMPLATE_RECORD) {
                    if (maxFps != minFps) {
                        mCollector.addMessage(""Video recording frame rate should be fixed"");
                    }
                }
            }
        }
    }

    private void checkAfMode(CaptureRequest.Builder request, int template,
            CameraCharacteristics props) {
        boolean hasFocuser = props.getKeys().contains(CameraCharacteristics.
                LENS_INFO_MINIMUM_FOCUS_DISTANCE) &&
                (props.get(CameraCharacteristics.LENS_INFO_MINIMUM_FOCUS_DISTANCE) > 0f);

        if (!hasFocuser) {
            return;
        }

        int targetAfMode = CaptureRequest.CONTROL_AF_MODE_AUTO;
        int[] availableAfMode = props.get(CameraCharacteristics.CONTROL_AF_AVAILABLE_MODES);
        if (template == CameraDevice.TEMPLATE_PREVIEW ||
                template == CameraDevice.TEMPLATE_STILL_CAPTURE ||
                template == CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG) {
            // Default to CONTINUOUS_PICTURE if it is available, otherwise AUTO.
            for (int i = 0; i < availableAfMode.length; i++) {
                if (availableAfMode[i] == CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE) {
                    targetAfMode = CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE;
                    break;
                }
            }
        } else if (template == CameraDevice.TEMPLATE_RECORD ||
                template == CameraDevice.TEMPLATE_VIDEO_SNAPSHOT) {
            // Default to CONTINUOUS_VIDEO if it is available, otherwise AUTO.
            for (int i = 0; i < availableAfMode.length; i++) {
                if (availableAfMode[i] == CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_VIDEO) {
                    targetAfMode = CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_VIDEO;
                    break;
                }
            }
        } else if (template == CameraDevice.TEMPLATE_MANUAL) {
            targetAfMode = CaptureRequest.CONTROL_AF_MODE_OFF;
        }

        mCollector.expectKeyValueEquals(request, CONTROL_AF_MODE, targetAfMode);
        if (mStaticInfo.areKeysAvailable(CaptureRequest.LENS_FOCUS_DISTANCE)) {
            mCollector.expectKeyValueNotNull(request, LENS_FOCUS_DISTANCE);
        }
    }

    private void checkAntiBandingMode(CaptureRequest.Builder request, int template) {
        if (template == CameraDevice.TEMPLATE_MANUAL) {
            return;
        }

        if (!mStaticInfo.isColorOutputSupported()) return;

        List<Integer> availableAntiBandingModes =
                Arrays.asList(toObject(mStaticInfo.getAeAvailableAntiBandingModesChecked()));

        if (availableAntiBandingModes.contains(CameraMetadata.CONTROL_AE_ANTIBANDING_MODE_AUTO)) {
            mCollector.expectKeyValueEquals(request, CONTROL_AE_ANTIBANDING_MODE,
                    CameraMetadata.CONTROL_AE_ANTIBANDING_MODE_AUTO);
        } else {
            mCollector.expectKeyValueIsIn(request, CONTROL_AE_ANTIBANDING_MODE,
                    CameraMetadata.CONTROL_AE_ANTIBANDING_MODE_50HZ,
                    CameraMetadata.CONTROL_AE_ANTIBANDING_MODE_60HZ);
        }
    }

    /**
     * <p>Check if 3A metering settings are ""up to HAL"" in request template</p>
     *
     * <p>This function doesn't fail the test immediately, it updates the
     * test pass/fail status and appends the failure message to the error collector each key.</p>
     *
     * @param regions The metering rectangles to be checked
     */
    private void checkMeteringRect(MeteringRectangle[] regions) {
        if (regions == null) {
            return;
        }
        mCollector.expectNotEquals(""Number of metering region should not be 0"", 0, regions.length);
        for (int i = 0; i < regions.length; i++) {
            mCollector.expectEquals(""Default metering regions should have all zero weight"",
                    0, regions[i].getMeteringWeight());
        }
    }

    /**
     * <p>Check if the request settings are suitable for a given request template.</p>
     *
     * <p>This function doesn't fail the test immediately, it updates the
     * test pass/fail status and appends the failure message to the error collector each key.</p>
     *
     * @param request The request to be checked.
     * @param template The capture template targeted by this request.
     * @param props The CameraCharacteristics this request is checked against with.
     */
    private void checkRequestForTemplate(CaptureRequest.Builder request, int template,
            CameraCharacteristics props) {
        Integer hwLevel = props.get(CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL);
        boolean isExternalCamera = (hwLevel ==
                CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_EXTERNAL);

        // 3A settings--AE/AWB/AF.
        Integer maxRegionsAeVal = props.get(CameraCharacteristics.CONTROL_MAX_REGIONS_AE);
        int maxRegionsAe = maxRegionsAeVal != null ? maxRegionsAeVal : 0;
        Integer maxRegionsAwbVal = props.get(CameraCharacteristics.CONTROL_MAX_REGIONS_AWB);
        int maxRegionsAwb = maxRegionsAwbVal != null ? maxRegionsAwbVal : 0;
        Integer maxRegionsAfVal = props.get(CameraCharacteristics.CONTROL_MAX_REGIONS_AF);
        int maxRegionsAf = maxRegionsAfVal != null ? maxRegionsAfVal : 0;

        checkFpsRange(request, template, props);

        checkAfMode(request, template, props);
        checkAntiBandingMode(request, template);

        if (template == CameraDevice.TEMPLATE_MANUAL) {
            mCollector.expectKeyValueEquals(request, CONTROL_MODE, CaptureRequest.CONTROL_MODE_OFF);
            mCollector.expectKeyValueEquals(request, CONTROL_AE_MODE,
                    CaptureRequest.CONTROL_AE_MODE_OFF);
            mCollector.expectKeyValueEquals(request, CONTROL_AWB_MODE,
                    CaptureRequest.CONTROL_AWB_MODE_OFF);
        } else {
            mCollector.expectKeyValueEquals(request, CONTROL_MODE,
                    CaptureRequest.CONTROL_MODE_AUTO);
            if (mStaticInfo.isColorOutputSupported()) {
                mCollector.expectKeyValueEquals(request, CONTROL_AE_MODE,
                        CaptureRequest.CONTROL_AE_MODE_ON);
                mCollector.expectKeyValueEquals(request, CONTROL_AE_EXPOSURE_COMPENSATION, 0);
                mCollector.expectKeyValueEquals(request, CONTROL_AE_PRECAPTURE_TRIGGER,
                        CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_IDLE);
                // if AE lock is not supported, expect the control key to be non-exist or false
                if (mStaticInfo.isAeLockSupported() || request.get(CONTROL_AE_LOCK) != null) {
                    mCollector.expectKeyValueEquals(request, CONTROL_AE_LOCK, false);
                }

                mCollector.expectKeyValueEquals(request, CONTROL_AF_TRIGGER,
                        CaptureRequest.CONTROL_AF_TRIGGER_IDLE);

                mCollector.expectKeyValueEquals(request, CONTROL_AWB_MODE,
                        CaptureRequest.CONTROL_AWB_MODE_AUTO);
                // if AWB lock is not supported, expect the control key to be non-exist or false
                if (mStaticInfo.isAwbLockSupported() || request.get(CONTROL_AWB_LOCK) != null) {
                    mCollector.expectKeyValueEquals(request, CONTROL_AWB_LOCK, false);
                }

                // Check 3A regions.
                if (VERBOSE) {
                    Log.v(TAG, String.format(""maxRegions is: {AE: %s, AWB: %s, AF: %s}"",
                                    maxRegionsAe, maxRegionsAwb, maxRegionsAf));
                }
                if (maxRegionsAe > 0) {
                    mCollector.expectKeyValueNotNull(request, CONTROL_AE_REGIONS);
                    MeteringRectangle[] aeRegions = request.get(CONTROL_AE_REGIONS);
                    checkMeteringRect(aeRegions);
                }
                if (maxRegionsAwb > 0) {
                    mCollector.expectKeyValueNotNull(request, CONTROL_AWB_REGIONS);
                    MeteringRectangle[] awbRegions = request.get(CONTROL_AWB_REGIONS);
                    checkMeteringRect(awbRegions);
                }
                if (maxRegionsAf > 0) {
                    mCollector.expectKeyValueNotNull(request, CONTROL_AF_REGIONS);
                    MeteringRectangle[] afRegions = request.get(CONTROL_AF_REGIONS);
                    checkMeteringRect(afRegions);
                }
            }
        }

        // Sensor settings.

        mCollector.expectEquals(""Lens aperture must be present in request if available apertures "" +
                        ""are present in metadata, and vice-versa."",
                mStaticInfo.areKeysAvailable(CameraCharacteristics.LENS_INFO_AVAILABLE_APERTURES),
                mStaticInfo.areKeysAvailable(CaptureRequest.LENS_APERTURE));
        if (mStaticInfo.areKeysAvailable(CameraCharacteristics.LENS_INFO_AVAILABLE_APERTURES)) {
            float[] availableApertures =
                    props.get(CameraCharacteristics.LENS_INFO_AVAILABLE_APERTURES);
            if (availableApertures.length > 1) {
                mCollector.expectKeyValueNotNull(request, LENS_APERTURE);
            }
        }

        mCollector.expectEquals(""Lens filter density must be present in request if available "" +
                        ""filter densities are present in metadata, and vice-versa."",
                mStaticInfo.areKeysAvailable(CameraCharacteristics.
                        LENS_INFO_AVAILABLE_FILTER_DENSITIES),
                mStaticInfo.areKeysAvailable(CaptureRequest.LENS_FILTER_DENSITY));
        if (mStaticInfo.areKeysAvailable(CameraCharacteristics.
                LENS_INFO_AVAILABLE_FILTER_DENSITIES)) {
            float[] availableFilters =
                    props.get(CameraCharacteristics.LENS_INFO_AVAILABLE_FILTER_DENSITIES);
            if (availableFilters.length > 1) {
                mCollector.expectKeyValueNotNull(request, LENS_FILTER_DENSITY);
            }
        }


        if (!isExternalCamera) {
            float[] availableFocalLen =
                    props.get(CameraCharacteristics.LENS_INFO_AVAILABLE_FOCAL_LENGTHS);
            if (availableFocalLen.length > 1) {
                mCollector.expectKeyValueNotNull(request, LENS_FOCAL_LENGTH);
            }
        }


        mCollector.expectEquals(""Lens optical stabilization must be present in request if "" +
                        ""available optical stabilizations are present in metadata, and vice-versa."",
                mStaticInfo.areKeysAvailable(CameraCharacteristics.
                        LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION),
                mStaticInfo.areKeysAvailable(CaptureRequest.LENS_OPTICAL_STABILIZATION_MODE));
        if (mStaticInfo.areKeysAvailable(CameraCharacteristics.
                LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION)) {
            int[] availableOIS =
                    props.get(CameraCharacteristics.LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION);
            if (availableOIS.length > 1) {
                mCollector.expectKeyValueNotNull(request, LENS_OPTICAL_STABILIZATION_MODE);
            }
        }

        if (mStaticInfo.areKeysAvailable(SENSOR_TEST_PATTERN_MODE)) {
            mCollector.expectKeyValueEquals(request, SENSOR_TEST_PATTERN_MODE,
                    CaptureRequest.SENSOR_TEST_PATTERN_MODE_OFF);
        }

        if (mStaticInfo.areKeysAvailable(BLACK_LEVEL_LOCK)) {
            mCollector.expectKeyValueEquals(request, BLACK_LEVEL_LOCK, false);
        }

        if (mStaticInfo.areKeysAvailable(SENSOR_FRAME_DURATION)) {
            mCollector.expectKeyValueNotNull(request, SENSOR_FRAME_DURATION);
        }

        if (mStaticInfo.areKeysAvailable(SENSOR_EXPOSURE_TIME)) {
            mCollector.expectKeyValueNotNull(request, SENSOR_EXPOSURE_TIME);
        }

        if (mStaticInfo.areKeysAvailable(SENSOR_SENSITIVITY)) {
            mCollector.expectKeyValueNotNull(request, SENSOR_SENSITIVITY);
        }

        // ISP-processing settings.
        if (mStaticInfo.isColorOutputSupported()) {
            mCollector.expectKeyValueEquals(
                    request, STATISTICS_FACE_DETECT_MODE,
                    CaptureRequest.STATISTICS_FACE_DETECT_MODE_OFF);
            mCollector.expectKeyValueEquals(request, FLASH_MODE, CaptureRequest.FLASH_MODE_OFF);
        }

        List<Integer> availableCaps = mStaticInfo.getAvailableCapabilitiesChecked();
        if (mStaticInfo.areKeysAvailable(STATISTICS_LENS_SHADING_MAP_MODE)) {
            // If the device doesn't support RAW, all template should have OFF as default.
            if (!availableCaps.contains(REQUEST_AVAILABLE_CAPABILITIES_RAW)) {
                mCollector.expectKeyValueEquals(
                        request, STATISTICS_LENS_SHADING_MAP_MODE,
                        CaptureRequest.STATISTICS_LENS_SHADING_MAP_MODE_OFF);
            }
        }

        boolean supportReprocessing =
                availableCaps.contains(REQUEST_AVAILABLE_CAPABILITIES_YUV_REPROCESSING) ||
                availableCaps.contains(REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING);


        if (template == CameraDevice.TEMPLATE_STILL_CAPTURE) {

            // Ok with either FAST or HIGH_QUALITY
            if (mStaticInfo.areKeysAvailable(COLOR_CORRECTION_MODE)) {
                mCollector.expectKeyValueNotEquals(
                        request, COLOR_CORRECTION_MODE,
                        CaptureRequest.COLOR_CORRECTION_MODE_TRANSFORM_MATRIX);
            }

            // Edge enhancement, noise reduction and aberration correction modes.
            mCollector.expectEquals(""Edge mode must be present in request if "" +
                            ""available edge modes are present in metadata, and vice-versa."",
                    mStaticInfo.areKeysAvailable(CameraCharacteristics.
                            EDGE_AVAILABLE_EDGE_MODES),
                    mStaticInfo.areKeysAvailable(CaptureRequest.EDGE_MODE));
            if (mStaticInfo.areKeysAvailable(EDGE_MODE)) {
                List<Integer> availableEdgeModes =
                        Arrays.asList(toObject(mStaticInfo.getAvailableEdgeModesChecked()));
                // Don't need check fast as fast or high quality must be both present or both not.
                if (availableEdgeModes.contains(CaptureRequest.EDGE_MODE_HIGH_QUALITY)) {
                    mCollector.expectKeyValueEquals(request, EDGE_MODE,
                            CaptureRequest.EDGE_MODE_HIGH_QUALITY);
                } else {
                    mCollector.expectKeyValueEquals(request, EDGE_MODE,
                            CaptureRequest.EDGE_MODE_OFF);
                }
            }
            if (mStaticInfo.areKeysAvailable(SHADING_MODE)) {
                List<Integer> availableShadingModes =
                        Arrays.asList(toObject(mStaticInfo.getAvailableShadingModesChecked()));
                mCollector.expectKeyValueEquals(request, SHADING_MODE,
                        CaptureRequest.SHADING_MODE_HIGH_QUALITY);
            }

            mCollector.expectEquals(""Noise reduction mode must be present in request if "" +
                            ""available noise reductions are present in metadata, and vice-versa."",
                    mStaticInfo.areKeysAvailable(CameraCharacteristics.
                            NOISE_REDUCTION_AVAILABLE_NOISE_REDUCTION_MODES),
                    mStaticInfo.areKeysAvailable(CaptureRequest.NOISE_REDUCTION_MODE));
            if (mStaticInfo.areKeysAvailable(
                    CameraCharacteristics.NOISE_REDUCTION_AVAILABLE_NOISE_REDUCTION_MODES)) {
                List<Integer> availableNoiseReductionModes =
                        Arrays.asList(toObject(mStaticInfo.getAvailableNoiseReductionModesChecked()));
                // Don't need check fast as fast or high quality must be both present or both not.
                if (availableNoiseReductionModes
                        .contains(CaptureRequest.NOISE_REDUCTION_MODE_HIGH_QUALITY)) {
                    mCollector.expectKeyValueEquals(
                            request, NOISE_REDUCTION_MODE,
                            CaptureRequest.NOISE_REDUCTION_MODE_HIGH_QUALITY);
                } else {
                    mCollector.expectKeyValueEquals(
                            request, NOISE_REDUCTION_MODE, CaptureRequest.NOISE_REDUCTION_MODE_OFF);
                }
            }

            mCollector.expectEquals(""Hot pixel mode must be present in request if "" +
                            ""available hot pixel modes are present in metadata, and vice-versa."",
                    mStaticInfo.areKeysAvailable(CameraCharacteristics.
                            HOT_PIXEL_AVAILABLE_HOT_PIXEL_MODES),
                    mStaticInfo.areKeysAvailable(CaptureRequest.HOT_PIXEL_MODE));

            if (mStaticInfo.areKeysAvailable(HOT_PIXEL_MODE)) {
                List<Integer> availableHotPixelModes =
                        Arrays.asList(toObject(
                                mStaticInfo.getAvailableHotPixelModesChecked()));
                if (availableHotPixelModes
                        .contains(CaptureRequest.HOT_PIXEL_MODE_HIGH_QUALITY)) {
                    mCollector.expectKeyValueEquals(
                            request, HOT_PIXEL_MODE,
                            CaptureRequest.HOT_PIXEL_MODE_HIGH_QUALITY);
                } else {
                    mCollector.expectKeyValueEquals(
                            request, HOT_PIXEL_MODE, CaptureRequest.HOT_PIXEL_MODE_OFF);
                }
            }

            boolean supportAvailableAberrationModes = mStaticInfo.areKeysAvailable(
                    CameraCharacteristics.COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES);
            boolean supportAberrationRequestKey = mStaticInfo.areKeysAvailable(
                    CaptureRequest.COLOR_CORRECTION_ABERRATION_MODE);
            mCollector.expectEquals(""Aberration correction mode must be present in request if "" +
                    ""available aberration correction reductions are present in metadata, and ""
                    + ""vice-versa."", supportAvailableAberrationModes, supportAberrationRequestKey);
            if (supportAberrationRequestKey) {
                List<Integer> availableAberrationModes = Arrays.asList(
                        toObject(mStaticInfo.getAvailableColorAberrationModesChecked()));
                // Don't need check fast as fast or high quality must be both present or both not.
                if (availableAberrationModes
                        .contains(CaptureRequest.COLOR_CORRECTION_ABERRATION_MODE_HIGH_QUALITY)) {
                    mCollector.expectKeyValueEquals(
                            request, COLOR_CORRECTION_ABERRATION_MODE,
                            CaptureRequest.COLOR_CORRECTION_ABERRATION_MODE_HIGH_QUALITY);
                } else {
                    mCollector.expectKeyValueEquals(
                            request, COLOR_CORRECTION_ABERRATION_MODE,
                            CaptureRequest.COLOR_CORRECTION_ABERRATION_MODE_OFF);
                }
            }
        } else if (template == CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG && supportReprocessing) {
            mCollector.expectKeyValueEquals(request, EDGE_MODE,
                    CaptureRequest.EDGE_MODE_ZERO_SHUTTER_LAG);
            mCollector.expectKeyValueEquals(request, NOISE_REDUCTION_MODE,
                    CaptureRequest.NOISE_REDUCTION_MODE_ZERO_SHUTTER_LAG);
        } else if (template == CameraDevice.TEMPLATE_PREVIEW ||
                template == CameraDevice.TEMPLATE_RECORD) {

            // Ok with either FAST or HIGH_QUALITY
            if (mStaticInfo.areKeysAvailable(COLOR_CORRECTION_MODE)) {
                mCollector.expectKeyValueNotEquals(
                        request, COLOR_CORRECTION_MODE,
                        CaptureRequest.COLOR_CORRECTION_MODE_TRANSFORM_MATRIX);
            }

            if (mStaticInfo.areKeysAvailable(EDGE_MODE)) {
                List<Integer> availableEdgeModes =
                        Arrays.asList(toObject(mStaticInfo.getAvailableEdgeModesChecked()));
                if (availableEdgeModes.contains(CaptureRequest.EDGE_MODE_FAST)) {
                    mCollector.expectKeyValueEquals(request, EDGE_MODE,
                            CaptureRequest.EDGE_MODE_FAST);
                } else {
                    mCollector.expectKeyValueEquals(request, EDGE_MODE,
                            CaptureRequest.EDGE_MODE_OFF);
                }
            }

            if (mStaticInfo.areKeysAvailable(SHADING_MODE)) {
                List<Integer> availableShadingModes =
                        Arrays.asList(toObject(mStaticInfo.getAvailableShadingModesChecked()));
                mCollector.expectKeyValueEquals(request, SHADING_MODE,
                        CaptureRequest.SHADING_MODE_FAST);
            }

            if (mStaticInfo.areKeysAvailable(NOISE_REDUCTION_MODE)) {
                List<Integer> availableNoiseReductionModes =
                        Arrays.asList(toObject(
                                mStaticInfo.getAvailableNoiseReductionModesChecked()));
                if (availableNoiseReductionModes
                        .contains(CaptureRequest.NOISE_REDUCTION_MODE_FAST)) {
                    mCollector.expectKeyValueEquals(
                            request, NOISE_REDUCTION_MODE,
                            CaptureRequest.NOISE_REDUCTION_MODE_FAST);
                } else {
                    mCollector.expectKeyValueEquals(
                            request, NOISE_REDUCTION_MODE, CaptureRequest.NOISE_REDUCTION_MODE_OFF);
                }
            }

            if (mStaticInfo.areKeysAvailable(HOT_PIXEL_MODE)) {
                List<Integer> availableHotPixelModes =
                        Arrays.asList(toObject(
                                mStaticInfo.getAvailableHotPixelModesChecked()));
                if (availableHotPixelModes
                        .contains(CaptureRequest.HOT_PIXEL_MODE_FAST)) {
                    mCollector.expectKeyValueEquals(
                            request, HOT_PIXEL_MODE,
                            CaptureRequest.HOT_PIXEL_MODE_FAST);
                } else {
                    mCollector.expectKeyValueEquals(
                            request, HOT_PIXEL_MODE, CaptureRequest.HOT_PIXEL_MODE_OFF);
                }
            }

            if (mStaticInfo.areKeysAvailable(COLOR_CORRECTION_ABERRATION_MODE)) {
                List<Integer> availableAberrationModes = Arrays.asList(
                        toObject(mStaticInfo.getAvailableColorAberrationModesChecked()));
                if (availableAberrationModes
                        .contains(CaptureRequest.COLOR_CORRECTION_ABERRATION_MODE_FAST)) {
                    mCollector.expectKeyValueEquals(
                            request, COLOR_CORRECTION_ABERRATION_MODE,
                            CaptureRequest.COLOR_CORRECTION_ABERRATION_MODE_FAST);
                } else {
                    mCollector.expectKeyValueEquals(
                            request, COLOR_CORRECTION_ABERRATION_MODE,
                            CaptureRequest.COLOR_CORRECTION_ABERRATION_MODE_OFF);
                }
            }
        } else {
            if (mStaticInfo.areKeysAvailable(EDGE_MODE)) {
                mCollector.expectKeyValueNotNull(request, EDGE_MODE);
            }

            if (mStaticInfo.areKeysAvailable(NOISE_REDUCTION_MODE)) {
                mCollector.expectKeyValueNotNull(request, NOISE_REDUCTION_MODE);
            }

            if (mStaticInfo.areKeysAvailable(COLOR_CORRECTION_ABERRATION_MODE)) {
                mCollector.expectKeyValueNotNull(request, COLOR_CORRECTION_ABERRATION_MODE);
            }
        }

        // Tone map and lens shading modes.
        if (template == CameraDevice.TEMPLATE_STILL_CAPTURE) {
            mCollector.expectEquals(""Tonemap mode must be present in request if "" +
                            ""available tonemap modes are present in metadata, and vice-versa."",
                    mStaticInfo.areKeysAvailable(CameraCharacteristics.
                            TONEMAP_AVAILABLE_TONE_MAP_MODES),
                    mStaticInfo.areKeysAvailable(CaptureRequest.TONEMAP_MODE));
            if (mStaticInfo.areKeysAvailable(
                    CameraCharacteristics.TONEMAP_AVAILABLE_TONE_MAP_MODES)) {
                List<Integer> availableToneMapModes =
                        Arrays.asList(toObject(mStaticInfo.getAvailableToneMapModesChecked()));
                if (availableToneMapModes.contains(CaptureRequest.TONEMAP_MODE_HIGH_QUALITY)) {
                    mCollector.expectKeyValueEquals(request, TONEMAP_MODE,
                            CaptureRequest.TONEMAP_MODE_HIGH_QUALITY);
                } else {
                    mCollector.expectKeyValueEquals(request, TONEMAP_MODE,
                            CaptureRequest.TONEMAP_MODE_FAST);
                }
            }

            // Still capture template should have android.statistics.lensShadingMapMode ON when
            // RAW capability is supported.
            if (mStaticInfo.areKeysAvailable(STATISTICS_LENS_SHADING_MAP_MODE) &&
                    availableCaps.contains(REQUEST_AVAILABLE_CAPABILITIES_RAW)) {
                    mCollector.expectKeyValueEquals(request, STATISTICS_LENS_SHADING_MAP_MODE,
                            STATISTICS_LENS_SHADING_MAP_MODE_ON);
            }
        } else {
            if (mStaticInfo.areKeysAvailable(TONEMAP_MODE)) {
                mCollector.expectKeyValueNotEquals(request, TONEMAP_MODE,
                        CaptureRequest.TONEMAP_MODE_CONTRAST_CURVE);
                mCollector.expectKeyValueNotEquals(request, TONEMAP_MODE,
                        CaptureRequest.TONEMAP_MODE_GAMMA_VALUE);
                mCollector.expectKeyValueNotEquals(request, TONEMAP_MODE,
                        CaptureRequest.TONEMAP_MODE_PRESET_CURVE);
            }
            if (mStaticInfo.areKeysAvailable(STATISTICS_LENS_SHADING_MAP_MODE)) {
                mCollector.expectKeyValueEquals(request, STATISTICS_LENS_SHADING_MAP_MODE,
                        CaptureRequest.STATISTICS_LENS_SHADING_MAP_MODE_OFF);
            }
            if (mStaticInfo.areKeysAvailable(STATISTICS_HOT_PIXEL_MAP_MODE)) {
                mCollector.expectKeyValueEquals(request, STATISTICS_HOT_PIXEL_MAP_MODE,
                        false);
            }
        }

        // Enable ZSL
        if (template != CameraDevice.TEMPLATE_STILL_CAPTURE) {
            if (mStaticInfo.areKeysAvailable(CONTROL_ENABLE_ZSL)) {
                    mCollector.expectKeyValueEquals(request, CONTROL_ENABLE_ZSL, false);
            }
        }

        int[] outputFormats = mStaticInfo.getAvailableFormats(
                StaticMetadata.StreamDirection.Output);
        boolean supportRaw = false;
        for (int format : outputFormats) {
            if (format == ImageFormat.RAW_SENSOR || format == ImageFormat.RAW10 ||
                    format == ImageFormat.RAW12 || format == ImageFormat.RAW_PRIVATE) {
                supportRaw = true;
                break;
            }
        }
        if (supportRaw) {
            mCollector.expectKeyValueEquals(request,
                    CONTROL_POST_RAW_SENSITIVITY_BOOST,
                    DEFAULT_POST_RAW_SENSITIVITY_BOOST);
        }

        switch(template) {
            case CameraDevice.TEMPLATE_PREVIEW:
                mCollector.expectKeyValueEquals(request, CONTROL_CAPTURE_INTENT,
                        CameraCharacteristics.CONTROL_CAPTURE_INTENT_PREVIEW);
                break;
            case CameraDevice.TEMPLATE_STILL_CAPTURE:
                mCollector.expectKeyValueEquals(request, CONTROL_CAPTURE_INTENT,
                        CameraCharacteristics.CONTROL_CAPTURE_INTENT_STILL_CAPTURE);
                break;
            case CameraDevice.TEMPLATE_RECORD:
                mCollector.expectKeyValueEquals(request, CONTROL_CAPTURE_INTENT,
                        CameraCharacteristics.CONTROL_CAPTURE_INTENT_VIDEO_RECORD);
                break;
            case CameraDevice.TEMPLATE_VIDEO_SNAPSHOT:
                mCollector.expectKeyValueEquals(request, CONTROL_CAPTURE_INTENT,
                        CameraCharacteristics.CONTROL_CAPTURE_INTENT_VIDEO_SNAPSHOT);
                break;
            case CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG:
                mCollector.expectKeyValueEquals(request, CONTROL_CAPTURE_INTENT,
                        CameraCharacteristics.CONTROL_CAPTURE_INTENT_ZERO_SHUTTER_LAG);
                break;
            case CameraDevice.TEMPLATE_MANUAL:
                mCollector.expectKeyValueEquals(request, CONTROL_CAPTURE_INTENT,
                        CameraCharacteristics.CONTROL_CAPTURE_INTENT_MANUAL);
                break;
            default:
                // Skip unknown templates here
        }

        // Check distortion correction mode
        if (mStaticInfo.isDistortionCorrectionSupported()) {
            mCollector.expectKeyValueNotEquals(request, DISTORTION_CORRECTION_MODE,
                    CaptureRequest.DISTORTION_CORRECTION_MODE_OFF);
        }

        // Scaler settings
        if (mStaticInfo.areKeysAvailable(
                CameraCharacteristics.SCALER_AVAILABLE_ROTATE_AND_CROP_MODES)) {
            List<Integer> rotateAndCropModes = Arrays.asList(toObject(
                props.get(CameraCharacteristics.SCALER_AVAILABLE_ROTATE_AND_CROP_MODES)));
            if (rotateAndCropModes.contains(SCALER_ROTATE_AND_CROP_AUTO)) {
                mCollector.expectKeyValueEquals(request, SCALER_ROTATE_AND_CROP,
                        CaptureRequest.SCALER_ROTATE_AND_CROP_AUTO);
            }
        }

        // Check JPEG quality
        if (mStaticInfo.isColorOutputSupported()) {
            mCollector.expectKeyValueNotNull(request, JPEG_QUALITY);
        }

        // TODO: use the list of keys from CameraCharacteristics to avoid expecting
        //       keys which are not available by this CameraDevice.
    }

    private void captureTemplateTestByCamera(String cameraId, int template) throws Exception {
        try {
            openDevice(cameraId, mCameraMockListener);

            assertTrue(""Camera template "" + template + "" is out of range!"",
                    template >= CameraDevice.TEMPLATE_PREVIEW
                            && template <= CameraDevice.TEMPLATE_MANUAL);

            mCollector.setCameraId(cameraId);

            try {
                CaptureRequest.Builder request = mCamera.createCaptureRequest(template);
                assertNotNull(""Failed to create capture request for template "" + template, request);

                CameraCharacteristics props = mStaticInfo.getCharacteristics();
                checkRequestForTemplate(request, template, props);
            } catch (IllegalArgumentException e) {
                if (template == CameraDevice.TEMPLATE_MANUAL &&
                        !mStaticInfo.isCapabilitySupported(CameraCharacteristics.
                                REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                    // OK
                } else if (template == CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG &&
                        !mStaticInfo.isCapabilitySupported(CameraCharacteristics.
                                REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING)) {
                    // OK.
                } else if (sLegacySkipTemplates.contains(template) &&
                        mStaticInfo.isHardwareLevelLegacy()) {
                    // OK
                } else if (template != CameraDevice.TEMPLATE_PREVIEW &&
                        mStaticInfo.isDepthOutputSupported() &&
                        !mStaticInfo.isColorOutputSupported()) {
                    // OK, depth-only devices need only support PREVIEW template
                } else {
                    throw e; // rethrow
                }
            }
        }
        finally {
            try {
                closeSession();
            } finally {
                closeDevice(cameraId, mCameraMockListener);
            }
        }
    }

    /**
     * Start capture with given {@link #CaptureRequest}.
     *
     * @param request The {@link #CaptureRequest} to be captured.
     * @param repeating If the capture is single capture or repeating.
     * @param listener The {@link #CaptureCallback} camera device used to notify callbacks.
     * @param handler The handler camera device used to post callbacks.
     */
    @Override
    protected void startCapture(CaptureRequest request, boolean repeating,
            CameraCaptureSession.CaptureCallback listener, Handler handler)
                    throws CameraAccessException {
        if (VERBOSE) Log.v(TAG, ""Starting capture from session"");

        if (repeating) {
            mSession.setRepeatingRequest(request, listener, handler);
        } else {
            mSession.capture(request, listener, handler);
        }
    }

    /**
     * Start capture with given {@link #CaptureRequest}.
     *
     * @param request The {@link #CaptureRequest} to be captured.
     * @param repeating If the capture is single capture or repeating.
     * @param listener The {@link #CaptureCallback} camera device used to notify callbacks.
     * @param executor The executor used to invoke callbacks.
     */
    protected void startCapture(CaptureRequest request, boolean repeating,
            CameraCaptureSession.CaptureCallback listener, Executor executor)
                    throws CameraAccessException {
        if (VERBOSE) Log.v(TAG, ""Starting capture from session"");

        if (repeating) {
            mSession.setSingleRepeatingRequest(request, executor, listener);
        } else {
            mSession.captureSingleRequest(request, executor, listener);
        }
    }

    /**
     * Close a {@link #CameraCaptureSession capture session}; blocking until
     * the close finishes with a transition to {@link CameraCaptureSession.StateCallback#onClosed}.
     */
    protected void closeSession() {
        if (mSession == null) {
            return;
        }

        mSession.close();
        waitForSessionState(SESSION_CLOSED, SESSION_CLOSE_TIMEOUT_MS);
        mSession = null;

        mSessionMockListener = null;
        mSessionWaiter = null;
    }

    /**
     * A camera capture session listener that keeps all the configured and closed sessions.
     */
    private class MultipleSessionCallback extends CameraCaptureSession.StateCallback {
        public static final int SESSION_CONFIGURED = 0;
        public static final int SESSION_CLOSED = 1;

        final List<CameraCaptureSession> mSessions = new ArrayList<>();
        final Map<CameraCaptureSession, Integer> mSessionStates = new HashMap<>();
        CameraCaptureSession mCurrentConfiguredSession = null;

        final ReentrantLock mLock = new ReentrantLock();
        final Condition mNewStateCond = mLock.newCondition();

        final boolean mFailOnConfigureFailed;

        /**
         * If failOnConfigureFailed is true, it calls fail() when onConfigureFailed() is invoked
         * for any session.
         */
        public MultipleSessionCallback(boolean failOnConfigureFailed) {
            mFailOnConfigureFailed = failOnConfigureFailed;
        }

        @Override
        public void onClosed(CameraCaptureSession session) {
            mLock.lock();
            mSessionStates.put(session, SESSION_CLOSED);
            mNewStateCond.signal();
            mLock.unlock();
        }

        @Override
        public void onConfigured(CameraCaptureSession session) {
            mLock.lock();
            mSessions.add(session);
            mSessionStates.put(session, SESSION_CONFIGURED);
            mNewStateCond.signal();
            mLock.unlock();
        }

        @Override
        public void onConfigureFailed(CameraCaptureSession session) {
            if (mFailOnConfigureFailed) {
                fail(""Configuring a session failed"");
            }
        }

        /**
         * Get a number of sessions that have been configured.
         */
        public List<CameraCaptureSession> getAllSessions(int numSessions, int timeoutMs)
                throws Exception {
            long remainingTime = timeoutMs;
            mLock.lock();
            try {
                while (mSessions.size() < numSessions) {
                    long startTime = SystemClock.elapsedRealtime();
                    boolean ret = mNewStateCond.await(remainingTime, TimeUnit.MILLISECONDS);
                    remainingTime -= (SystemClock.elapsedRealtime() - startTime);
                    ret &= remainingTime > 0;

                    assertTrue(""Get "" + numSessions + "" sessions timed out after "" + timeoutMs +
                            ""ms"", ret);
                }

                return mSessions;
            } finally {
                mLock.unlock();
            }
        }

        /**
         * Wait until a previously-configured sessoin is closed or it times out.
         */
        public void waitForSessionClose(CameraCaptureSession session, int timeoutMs) throws Exception {
            long remainingTime = timeoutMs;
            mLock.lock();
            try {
                while (mSessionStates.get(session).equals(SESSION_CLOSED) == false) {
                    long startTime = SystemClock.elapsedRealtime();
                    boolean ret = mNewStateCond.await(remainingTime, TimeUnit.MILLISECONDS);
                    remainingTime -= (SystemClock.elapsedRealtime() - startTime);
                    ret &= remainingTime > 0;

                    assertTrue(""Wait for session close timed out after "" + timeoutMs + ""ms"", ret);
                }
            } finally {
                mLock.unlock();
            }
        }
    }

    /**
     * Verify audio restrictions are set properly for single CameraDevice usage
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.SurfaceViewPreviewTest"	"testPreparePerformance"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/SurfaceViewPreviewTest.java"	""	"public void testPreparePerformance() throws Throwable {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                if (!mAllStaticInfo.get(mCameraIdsUnderTest[i]).isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support color outputs, skipping"");
                    continue;
                }
                openDevice(mCameraIdsUnderTest[i]);
                preparePerformanceTestByCamera(mCameraIdsUnderTest[i]);
            }
            finally {
                closeDevice();
            }
        }
    }

    private void preparePerformanceTestByCamera(String cameraId) throws Exception {
        final int MAX_IMAGES_TO_PREPARE = 10;
        final int UNKNOWN_LATENCY_RESULT_WAIT = 5;
        final int MAX_RESULTS_TO_WAIT = 10;
        final int FRAMES_FOR_AVERAGING = 100;
        final float PREPARE_FRAME_RATE_BOUNDS = 0.05f; // fraction allowed difference
        final float PREPARE_PEAK_RATE_BOUNDS = 0.5f; // fraction allowed difference

        Size maxYuvSize = getSupportedPreviewSizes(cameraId, mCameraManager, null).get(0);
        Size maxPreviewSize = mOrderedPreviewSizes.get(0);

        // Don't need image data, just drop it right away to minimize overhead
        ImageDropperListener imageListener = new ImageDropperListener();

        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();

        CaptureRequest.Builder previewRequest =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);

        // Configure outputs and session

        updatePreviewSurface(maxPreviewSize);

        createImageReader(maxYuvSize, ImageFormat.YUV_420_888, MAX_IMAGES_TO_PREPARE, imageListener);
        HashMap<Size, Long> yuvMinFrameDurations =
                mStaticInfo.getAvailableMinFrameDurationsForFormatChecked(ImageFormat.YUV_420_888);
        Long readerMinFrameDuration = yuvMinFrameDurations.get(maxYuvSize);

        List<Surface> outputSurfaces = new ArrayList<Surface>();
        outputSurfaces.add(mPreviewSurface);
        outputSurfaces.add(mReaderSurface);

        CameraCaptureSession.StateCallback mockSessionListener =
                mock(CameraCaptureSession.StateCallback.class);

        mSession = configureCameraSession(mCamera, outputSurfaces, mockSessionListener, mHandler);

        previewRequest.addTarget(mPreviewSurface);
        Range<Integer> maxFpsTarget = mStaticInfo.getAeMaxTargetFpsRange();
        previewRequest.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, maxFpsTarget);

        mSession.setRepeatingRequest(previewRequest.build(), resultListener, mHandler);

        // Converge AE
        waitForAeStable(resultListener, UNKNOWN_LATENCY_RESULT_WAIT);

        if (mStaticInfo.isAeLockSupported()) {
            // Lock AE if possible to improve stability
            previewRequest.set(CaptureRequest.CONTROL_AE_LOCK, true);
            mSession.setRepeatingRequest(previewRequest.build(), resultListener, mHandler);
            if (mStaticInfo.isHardwareLevelAtLeastLimited()) {
                // Legacy mode doesn't output AE state
                waitForResultValue(resultListener, CaptureResult.CONTROL_AE_STATE,
                        CaptureResult.CONTROL_AE_STATE_LOCKED, MAX_RESULTS_TO_WAIT);
            }
        }

        // Measure frame rate for a bit
        Pair<Long, Long> frameDurationStats =
                measureMeanFrameInterval(resultListener, FRAMES_FOR_AVERAGING, /*prevTimestamp*/ 0);

        Log.i(TAG, String.format(""Frame interval avg during normal preview: %f ms, peak %f ms"",
                        frameDurationStats.first / 1e6, frameDurationStats.second / 1e6));

        // Drain results, do prepare
        resultListener.drain();

        mSession.prepare(mReaderSurface);

        verify(mockSessionListener,
                timeout(PREPARE_TIMEOUT_MS).times(1)).
                onSurfacePrepared(eq(mSession), eq(mReaderSurface));

        resultListener.drain();

        // Get at least one more preview result without prepared target
        CaptureResult result = resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
        long prevTimestamp = result.get(CaptureResult.SENSOR_TIMESTAMP);

        // Now use the prepared stream and ensure there are no hiccups from using it
        previewRequest.addTarget(mReaderSurface);

        mSession.setRepeatingRequest(previewRequest.build(), resultListener, mHandler);

        Pair<Long, Long> preparedFrameDurationStats =
                measureMeanFrameInterval(resultListener, MAX_IMAGES_TO_PREPARE*2, prevTimestamp);

        Log.i(TAG, String.format(""Frame interval with prepared stream added avg: %f ms, peak %f ms"",
                        preparedFrameDurationStats.first / 1e6,
                        preparedFrameDurationStats.second / 1e6));

        if (mStaticInfo.isHardwareLevelAtLeastLimited()) {
            mCollector.expectTrue(
                String.format(""Camera %s: Preview peak frame interval affected by use of new "" +
                        "" stream: preview avg frame duration: %f ms, peak with new stream: %f ms"",
                        cameraId,
                        frameDurationStats.first / 1e6, preparedFrameDurationStats.second / 1e6),
                (preparedFrameDurationStats.second <=
                        Math.max(frameDurationStats.first, readerMinFrameDuration) *
                        (1 + PREPARE_PEAK_RATE_BOUNDS)));
            mCollector.expectTrue(
                String.format(""Camera %s: Preview average frame interval affected by use of new "" +
                        ""stream: preview avg frame duration: %f ms, with new stream: %f ms"",
                        cameraId,
                        frameDurationStats.first / 1e6, preparedFrameDurationStats.first / 1e6),
                (preparedFrameDurationStats.first <=
                        Math.max(frameDurationStats.first, readerMinFrameDuration) *
                        (1 + PREPARE_FRAME_RATE_BOUNDS)));
        }
    }

    /**
     * Test to verify correct behavior with the same Surface object being used repeatedly with
     * different native internals, and multiple Surfaces pointing to the same actual consumer object
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.SurfaceViewPreviewTest"	"testDeferredSurfaces"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/SurfaceViewPreviewTest.java"	""	"public void testDeferredSurfaces() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                StaticMetadata staticInfo = mAllStaticInfo.get(mCameraIdsUnderTest[i]);
                if (staticInfo.isHardwareLevelLegacy()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] + "" is legacy, skipping"");
                    continue;
                }
                if (!staticInfo.isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support color outputs, skipping"");
                    continue;
                }

                openDevice(mCameraIdsUnderTest[i]);
                testDeferredSurfacesByCamera(mCameraIdsUnderTest[i]);
            }
            finally {
                closeDevice();
            }
        }
    }

    private void testDeferredSurfacesByCamera(String cameraId) throws Exception {
        Size maxPreviewSize = m1080pBoundedOrderedPreviewSizes.get(0);

        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();

        // Create a SurfaceTexture for a second output
        SurfaceTexture sharedOutputTexture = new SurfaceTexture(/*random texture ID*/ 5);
        sharedOutputTexture.setDefaultBufferSize(maxPreviewSize.getWidth(),
                maxPreviewSize.getHeight());
        Surface sharedOutputSurface1 = new Surface(sharedOutputTexture);

        class TextureAvailableListener implements SurfaceTexture.OnFrameAvailableListener {
            @Override
            public void onFrameAvailable(SurfaceTexture t) {
                mGotFrame = true;
            }
            public boolean gotFrame() { return mGotFrame; }

            private volatile boolean mGotFrame = false;
        }
        TextureAvailableListener textureAvailableListener = new TextureAvailableListener();

        sharedOutputTexture.setOnFrameAvailableListener(textureAvailableListener, mHandler);

        updatePreviewSurface(maxPreviewSize);

        // Create deferred outputs for surface view and surface texture
        OutputConfiguration surfaceViewOutput = new OutputConfiguration(maxPreviewSize,
                SurfaceHolder.class);
        OutputConfiguration surfaceTextureOutput = new OutputConfiguration(maxPreviewSize,
                SurfaceTexture.class);

        List<OutputConfiguration> outputSurfaces = new ArrayList<>();
        outputSurfaces.add(surfaceViewOutput);
        outputSurfaces.add(surfaceTextureOutput);

        // Create non-deferred ImageReader output (JPEG for LIMITED-level compatibility)
        ImageDropperListener imageListener = new ImageDropperListener();
        createImageReader(mOrderedStillSizes.get(0), ImageFormat.JPEG, /*maxImages*/ 3,
                imageListener);
        OutputConfiguration jpegOutput =
                new OutputConfiguration(OutputConfiguration.SURFACE_GROUP_ID_NONE, mReaderSurface);
        outputSurfaces.add(jpegOutput);

        // Confirm that other surface types aren't supported for OutputConfiguration
        Class[] unsupportedClasses =
                {android.media.ImageReader.class, android.media.MediaCodec.class,
                 android.renderscript.Allocation.class, android.media.MediaRecorder.class};

        for (Class klass : unsupportedClasses) {
            try {
                OutputConfiguration bad = new OutputConfiguration(maxPreviewSize, klass);
                fail(""OutputConfiguration allowed use of unsupported class "" + klass);
            } catch (IllegalArgumentException e) {
                // expected
            }
        }

        // Confirm that zero surface size isn't supported for OutputConfiguration
        Size[] sizeZeros = { new Size(0, 0), new Size(1, 0), new Size(0, 1) };
        for (Size size : sizeZeros) {
            try {
                OutputConfiguration bad = new OutputConfiguration(size, SurfaceHolder.class);
                fail(""OutputConfiguration allowed use of zero surfaceSize"");
            } catch (IllegalArgumentException e) {
                //expected
            }
        }

        // Check whether session configuration is supported
        CameraTestUtils.checkSessionConfigurationSupported(mCamera, mHandler, outputSurfaces,
                /*inputConfig*/ null, SessionConfiguration.SESSION_REGULAR,
                /*defaultSupport*/ true, ""Deferred session configuration query failed"");

        // Create session

        BlockingSessionCallback sessionListener =
                new BlockingSessionCallback();

        mSession = configureCameraSessionWithConfig(mCamera, outputSurfaces, sessionListener,
                mHandler);
        sessionListener.getStateWaiter().waitForState(BlockingSessionCallback.SESSION_READY,
                SESSION_CONFIGURE_TIMEOUT_MS);

        // Submit JPEG requests

        CaptureRequest.Builder request = mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        request.addTarget(mReaderSurface);

        final int SOME_FRAMES = 10;
        for (int i = 0; i < SOME_FRAMES; i++) {
            mSession.capture(request.build(), resultListener, mHandler);
        }

        // Wait to get some frames out to ensure we can operate just the one expected surface
        waitForNumResults(resultListener, SOME_FRAMES);
        assertTrue(""No images received"", imageListener.getImageCount() > 0);

        // Ensure we can't use the deferred surfaces yet
        request.addTarget(sharedOutputSurface1);
        try {
            mSession.capture(request.build(), resultListener, mHandler);
            fail(""Should have received IAE for trying to use a deferred target "" +
                    ""that's not yet configured"");
        } catch (IllegalArgumentException e) {
            // expected
        }

        // Add deferred surfaces to their configurations
        surfaceViewOutput.addSurface(mPreviewSurface);
        surfaceTextureOutput.addSurface(sharedOutputSurface1);

        // Verify bad inputs to addSurface
        try {
            surfaceViewOutput.addSurface(null);
            fail(""No error from setting a null deferred surface"");
        } catch (NullPointerException e) {
            // expected
        }
        try {
            surfaceViewOutput.addSurface(mPreviewSurface);
            fail(""Shouldn't be able to set deferred surface twice"");
        } catch (IllegalStateException e) {
            // expected
        }

        // Add first deferred surface to session
        List<OutputConfiguration> deferredSurfaces = new ArrayList<>();
        deferredSurfaces.add(surfaceTextureOutput);

        mSession.finalizeOutputConfigurations(deferredSurfaces);

        // Try a second time, this should error

        try {
            mSession.finalizeOutputConfigurations(deferredSurfaces);
            fail(""Should have received ISE for trying to finish a deferred output twice"");
        } catch (IllegalArgumentException e) {
            // expected
        }

        // Use new deferred surface for a bit
        imageListener.resetImageCount();
        for (int i = 0; i < SOME_FRAMES; i++) {
            mSession.capture(request.build(), resultListener, mHandler);
        }
        waitForNumResults(resultListener, SOME_FRAMES);
        assertTrue(""No images received"", imageListener.getImageCount() > 0);
        assertTrue(""No texture update received"", textureAvailableListener.gotFrame());

        // Ensure we can't use the last deferred surface yet
        request.addTarget(mPreviewSurface);
        try {
            mSession.capture(request.build(), resultListener, mHandler);
            fail(""Should have received IAE for trying to use a deferred target that's"" +
                    "" not yet configured"");
        } catch (IllegalArgumentException e) {
            // expected
        }

        // Add final deferred surface
        deferredSurfaces.clear();
        deferredSurfaces.add(surfaceViewOutput);

        mSession.finalizeOutputConfigurations(deferredSurfaces);

        // Use final deferred surface for a bit
        imageListener.resetImageCount();
        for (int i = 0; i < SOME_FRAMES; i++) {
            mSession.capture(request.build(), resultListener, mHandler);
        }
        waitForNumResults(resultListener, SOME_FRAMES);
        assertTrue(""No images received"", imageListener.getImageCount() > 0);
        // Can't check GL output since we don't have a context to call updateTexImage on, and
        // the callback only fires once per updateTexImage call.
        // And there's no way to verify data is going to a SurfaceView

        // Check for invalid output configurations being handed to a session
        OutputConfiguration badConfig =
                new OutputConfiguration(maxPreviewSize, SurfaceTexture.class);
        deferredSurfaces.clear();
        try {
            mSession.finalizeOutputConfigurations(deferredSurfaces);
            fail(""No error for empty list passed to finalizeOutputConfigurations"");
        } catch (IllegalArgumentException e) {
            // expected
        }

        deferredSurfaces.add(badConfig);
        try {
            mSession.finalizeOutputConfigurations(deferredSurfaces);
            fail(""No error for invalid output config being passed to finalizeOutputConfigurations"");
        } catch (IllegalArgumentException e) {
            // expected
        }

    }

    /**
     * Measure the inter-frame interval based on SENSOR_TIMESTAMP for frameCount frames from the
     * provided capture listener.  If prevTimestamp is positive, it is used for the first interval
     * calculation; otherwise, the first result is used to establish the starting time.
     *
     * Returns the mean interval in the first pair entry, and the largest interval in the second
     * pair entry
     */
    Pair<Long, Long> measureMeanFrameInterval(SimpleCaptureCallback resultListener, int frameCount,
            long prevTimestamp) throws Exception {
        long summedIntervals = 0;
        long maxInterval = 0;
        int measurementCount = frameCount - ((prevTimestamp > 0) ? 0 : 1);

        for (int i = 0; i < frameCount; i++) {
            CaptureResult result = resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
            long timestamp = result.get(CaptureResult.SENSOR_TIMESTAMP);
            if (prevTimestamp > 0) {
                long interval = timestamp - prevTimestamp;
                if (interval > maxInterval) maxInterval = interval;
                summedIntervals += interval;
            }
            prevTimestamp = timestamp;
        }
        return new Pair<Long, Long>(summedIntervals / measurementCount, maxInterval);
    }


    /**
     * Test preview fps range for all supported ranges. The exposure time are frame duration are
     * validated.
     */
    private void previewFpsRangeTestByCamera() throws Exception {
        Size maxPreviewSz;
        Range<Integer>[] fpsRanges = getDescendingTargetFpsRanges(mStaticInfo);
        boolean antiBandingOffIsSupported = mStaticInfo.isAntiBandingOffModeSupported();
        Range<Integer> fpsRange;
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();

        for (int i = 0; i < fpsRanges.length; i += 1) {
            fpsRange = fpsRanges[i];
            if (mStaticInfo.isHardwareLevelLegacy()) {
                // Legacy devices don't report minimum frame duration for preview sizes. The FPS
                // range should be valid for any supported preview size.
                maxPreviewSz = mOrderedPreviewSizes.get(0);
            } else {
                maxPreviewSz = getMaxPreviewSizeForFpsRange(fpsRange);
            }

            requestBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, fpsRange);
            // Turn off auto antibanding to avoid exposure time and frame duration interference
            // from antibanding algorithm.
            if (antiBandingOffIsSupported) {
                requestBuilder.set(CaptureRequest.CONTROL_AE_ANTIBANDING_MODE,
                        CaptureRequest.CONTROL_AE_ANTIBANDING_MODE_OFF);
            } else {
                // The device doesn't implement the OFF mode, test continues. It need make sure
                // that the antibanding algorithm doesn't interfere with the fps range control.
                Log.i(TAG, ""OFF antibanding mode is not supported, the camera device output must"" +
                        "" satisfy the specified fps range regardless of its current antibanding"" +
                        "" mode"");
            }

            startPreview(requestBuilder, maxPreviewSz, resultListener);
            resultListener = new SimpleCaptureCallback();
            mSession.setRepeatingRequest(requestBuilder.build(), resultListener, mHandler);

            waitForSettingsApplied(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

            verifyPreviewTargetFpsRange(resultListener, NUM_FRAMES_VERIFIED, fpsRange,
                    maxPreviewSz);
            stopPreview();
            resultListener.drain();
        }
    }

    private void verifyPreviewTargetFpsRange(SimpleCaptureCallback resultListener,
            int numFramesVerified, Range<Integer> fpsRange, Size previewSz) {
        CaptureResult result = resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
        List<Integer> capabilities = mStaticInfo.getAvailableCapabilitiesChecked();

        if (capabilities.contains(CaptureRequest.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
            long frameDuration = getValueNotNull(result, CaptureResult.SENSOR_FRAME_DURATION);
            long[] frameDurationRange =
                    new long[]{(long) (1e9 / fpsRange.getUpper()), (long) (1e9 / fpsRange.getLower())};
            mCollector.expectInRange(
                    ""Frame duration must be in the range of "" + Arrays.toString(frameDurationRange),
                    frameDuration, (long) (frameDurationRange[0] * (1 - FRAME_DURATION_ERROR_MARGIN)),
                    (long) (frameDurationRange[1] * (1 + FRAME_DURATION_ERROR_MARGIN)));
            long expTime = getValueNotNull(result, CaptureResult.SENSOR_EXPOSURE_TIME);
            mCollector.expectTrue(String.format(""Exposure time %d must be no larger than frame""
                    + ""duration %d"", expTime, frameDuration), expTime <= frameDuration);

            Long minFrameDuration = mMinPreviewFrameDurationMap.get(previewSz);
            boolean findDuration = mCollector.expectTrue(""Unable to find minFrameDuration for size ""
                    + previewSz.toString(), minFrameDuration != null);
            if (findDuration) {
                mCollector.expectTrue(""Frame duration "" + frameDuration + "" must be no smaller than""
                        + "" minFrameDuration "" + minFrameDuration, frameDuration >= minFrameDuration);
            }
        } else {
            Log.i(TAG, ""verifyPreviewTargetFpsRange - MANUAL_SENSOR control is not supported,"" +
                    "" skipping duration and exposure time check."");
        }
    }

    /**
     * Test all supported preview sizes for a camera device
     *
     * @throws Exception
     */
    private void previewTestByCamera() throws Exception {
        List<Size> previewSizes = getSupportedPreviewSizes(
                mCamera.getId(), mCameraManager, PREVIEW_SIZE_BOUND);

        for (final Size sz : previewSizes) {
            if (VERBOSE) {
                Log.v(TAG, ""Testing camera preview size: "" + sz.toString());
            }

            // TODO: vary the different settings like crop region to cover more cases.
            CaptureRequest.Builder requestBuilder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
            CaptureCallback mockCaptureCallback =
                    mock(CameraCaptureSession.CaptureCallback.class);

            startPreview(requestBuilder, sz, mockCaptureCallback);
            verifyCaptureResults(mSession, mockCaptureCallback, NUM_FRAMES_VERIFIED,
                    NUM_FRAMES_VERIFIED * FRAME_TIMEOUT_MS);
            stopPreview();
        }
    }

    private void previewTestPatternTestByCamera() throws Exception {
        Size maxPreviewSize = mOrderedPreviewSizes.get(0);
        int[] testPatternModes = mStaticInfo.getAvailableTestPatternModesChecked();
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        CaptureCallback mockCaptureCallback;

        final int[] TEST_PATTERN_DATA = {0, 0xFFFFFFFF, 0xFFFFFFFF, 0}; // G:100%, RB:0.
        for (int mode : testPatternModes) {
            if (VERBOSE) {
                Log.v(TAG, ""Test pattern mode: "" + mode);
            }
            requestBuilder.set(CaptureRequest.SENSOR_TEST_PATTERN_MODE, mode);
            if (mode == CaptureRequest.SENSOR_TEST_PATTERN_MODE_SOLID_COLOR) {
                // Assign color pattern to SENSOR_TEST_PATTERN_MODE_DATA
                requestBuilder.set(CaptureRequest.SENSOR_TEST_PATTERN_DATA, TEST_PATTERN_DATA);
            }
            mockCaptureCallback = mock(CaptureCallback.class);
            startPreview(requestBuilder, maxPreviewSize, mockCaptureCallback);
            verifyCaptureResults(mSession, mockCaptureCallback, NUM_TEST_PATTERN_FRAMES_VERIFIED,
                    NUM_TEST_PATTERN_FRAMES_VERIFIED * FRAME_TIMEOUT_MS);
        }

        stopPreview();
    }

    private void surfaceSetTestByCamera(String cameraId) throws Exception {
        final int MAX_SURFACE_GROUP_ID = 10;
        Size maxPreviewSz = mOrderedPreviewSizes.get(0);
        Size yuvSizeBound = maxPreviewSz; // Default case: legacy device
        if (mStaticInfo.isHardwareLevelLimited()) {
            yuvSizeBound = mOrderedVideoSizes.get(0);
        } else if (mStaticInfo.isHardwareLevelAtLeastFull()) {
            yuvSizeBound = null;
        }
        Size maxYuvSize = getSupportedPreviewSizes(cameraId, mCameraManager, yuvSizeBound).get(0);

        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        ImageDropperListener imageListener = new ImageDropperListener();

        updatePreviewSurface(maxPreviewSz);
        createImageReader(maxYuvSize, ImageFormat.YUV_420_888, MAX_READER_IMAGES, imageListener);
        List<OutputConfiguration> outputConfigs = new ArrayList<OutputConfiguration>();
        OutputConfiguration previewConfig = new OutputConfiguration(mPreviewSurface);
        OutputConfiguration yuvConfig = new OutputConfiguration(mReaderSurface);
        assertEquals(OutputConfiguration.SURFACE_GROUP_ID_NONE, previewConfig.getSurfaceGroupId());
        assertEquals(OutputConfiguration.SURFACE_GROUP_ID_NONE, yuvConfig.getSurfaceGroupId());
        assertEquals(mPreviewSurface, previewConfig.getSurface());
        assertEquals(mReaderSurface, yuvConfig.getSurface());
        outputConfigs.add(previewConfig);
        outputConfigs.add(yuvConfig);
        requestBuilder.addTarget(mPreviewSurface);
        requestBuilder.addTarget(mReaderSurface);

        // Test different stream set ID.
        for (int surfaceGroupId = OutputConfiguration.SURFACE_GROUP_ID_NONE;
                surfaceGroupId < MAX_SURFACE_GROUP_ID; surfaceGroupId++) {
            if (VERBOSE) {
                Log.v(TAG, ""test preview with surface group id: "");
            }

            previewConfig = new OutputConfiguration(surfaceGroupId, mPreviewSurface);
            yuvConfig = new OutputConfiguration(surfaceGroupId, mReaderSurface);
            outputConfigs.clear();
            outputConfigs.add(previewConfig);
            outputConfigs.add(yuvConfig);

            for (OutputConfiguration config : outputConfigs) {
                assertEquals(surfaceGroupId, config.getSurfaceGroupId());
            }

            CameraCaptureSession.StateCallback mockSessionListener =
                    mock(CameraCaptureSession.StateCallback.class);

            mSession = configureCameraSessionWithConfig(mCamera, outputConfigs,
                    mockSessionListener, mHandler);


            mSession.prepare(mPreviewSurface);
            verify(mockSessionListener,
                    timeout(PREPARE_TIMEOUT_MS).times(1)).
                    onSurfacePrepared(eq(mSession), eq(mPreviewSurface));

            mSession.prepare(mReaderSurface);
            verify(mockSessionListener,
                    timeout(PREPARE_TIMEOUT_MS).times(1)).
                    onSurfacePrepared(eq(mSession), eq(mReaderSurface));

            CaptureRequest request = requestBuilder.build();
            CaptureCallback mockCaptureCallback =
                    mock(CameraCaptureSession.CaptureCallback.class);
            mSession.setRepeatingRequest(request, mockCaptureCallback, mHandler);
            verifyCaptureResults(mSession, mockCaptureCallback, NUM_FRAMES_VERIFIED,
                    NUM_FRAMES_VERIFIED * FRAME_TIMEOUT_MS);
        }
    }

    private class IsCaptureResultValid implements ArgumentMatcher<TotalCaptureResult> {
        @Override
        public boolean matches(TotalCaptureResult obj) {
            TotalCaptureResult result = obj;
            Long timeStamp = result.get(CaptureResult.SENSOR_TIMESTAMP);
            if (timeStamp != null && timeStamp.longValue() > 0L) {
                return true;
            }
            return false;
        }
    }

    private void verifyCaptureResults(
            CameraCaptureSession session,
            CaptureCallback mockListener,
            int expectResultCount,
            int timeOutMs) {
        // Should receive expected number of onCaptureStarted callbacks.
        ArgumentCaptor<Long> timestamps = ArgumentCaptor.forClass(Long.class);
        ArgumentCaptor<Long> frameNumbers = ArgumentCaptor.forClass(Long.class);
        verify(mockListener,
                timeout(timeOutMs).atLeast(expectResultCount))
                        .onCaptureStarted(
                                eq(session),
                                isA(CaptureRequest.class),
                                timestamps.capture(),
                                frameNumbers.capture());

        // Validate timestamps: all timestamps should be larger than 0 and monotonically increase.
        long timestamp = 0;
        for (Long nextTimestamp : timestamps.getAllValues()) {
            assertNotNull(""Next timestamp is null!"", nextTimestamp);
            assertTrue(""Captures are out of order"", timestamp < nextTimestamp);
            timestamp = nextTimestamp;
        }

        // Validate framenumbers: all framenumbers should be consecutive and positive
        long frameNumber = -1;
        for (Long nextFrameNumber : frameNumbers.getAllValues()) {
            assertNotNull(""Next frame number is null!"", nextFrameNumber);
            assertTrue(""Captures are out of order"",
                    (frameNumber == -1) || (frameNumber + 1 == nextFrameNumber));
            frameNumber = nextFrameNumber;
        }

        // Should receive expected number of capture results.
        verify(mockListener,
                timeout(timeOutMs).atLeast(expectResultCount))
                        .onCaptureCompleted(
                                eq(session),
                                isA(CaptureRequest.class),
                                argThat(new IsCaptureResultValid()));

        // Should not receive any capture failed callbacks.
        verify(mockListener, never())
                        .onCaptureFailed(
                                eq(session),
                                isA(CaptureRequest.class),
                                isA(CaptureFailure.class));
    }

}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.TestSensorEventListener"	"TestSensorEventListener"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/TestSensorEventListener.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers;

import junit.framework.Assert;

import android.content.Context;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener2;
import android.os.Handler;
import android.os.Looper;
import android.os.SystemClock;
import android.os.PowerManager;
import android.os.PowerManager.WakeLock;
import android.util.Log;

import java.io.BufferedWriter;
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * A {@link SensorEventListener2} which performs operations such as waiting for a specific number of
 * events or for a specific time, or waiting for a flush to complete. This class performs
 * verifications and will throw {@link AssertionError}s if there are any errors. It may also wrap
 * another {@link SensorEventListener2}.
 */
public class TestSensorEventListener implements SensorEventListener2 {
    public static final String LOG_TAG = ""TestSensorEventListener"";

    private static final long EVENT_TIMEOUT_US = TimeUnit.SECONDS.toMicros(5);
    private static final long FLUSH_TIMEOUT_US = TimeUnit.SECONDS.toMicros(10);

    private final ArrayList<TestSensorEvent> mCollectedEvents = new ArrayList<>();
    private final ArrayList<Long> mTimeStampFlushCompleteEvents = new ArrayList<>();
    private final List<CountDownLatch> mEventLatches = new ArrayList<>();
    private final List<CountDownLatch> mFlushLatches = new ArrayList<>();
    private final AtomicInteger mEventsReceivedOutsideHandler = new AtomicInteger();

    private final Handler mHandler;
    private final TestSensorEnvironment mEnvironment;

    // Wakelock for keeping the system running after terminate criterion is met.
    // Useful for CtsVerifier test cases in which cpu can sleep if usb is not connected.
    private final PowerManager.WakeLock mTestSensorEventListenerWakeLock;

    /**
     * @deprecated Use {@link TestSensorEventListener(TestSensorEnvironment)}.
     */
    @Deprecated
    public TestSensorEventListener() {
        this(null /* environment */);
    }

    /**
     * Construct a {@link TestSensorEventListener}.
     */
    public TestSensorEventListener(TestSensorEnvironment environment) {
        this(environment, null /* handler */);
    }

    /**
     * Construct a {@link TestSensorEventListener}.
     */
    public TestSensorEventListener(TestSensorEnvironment environment, Handler handler) {
        mEnvironment = environment;
        mHandler = handler;
        PowerManager pm = (PowerManager) environment.getContext().getSystemService(
                Context.POWER_SERVICE);
        mTestSensorEventListenerWakeLock = pm.newWakeLock(PowerManager.PARTIAL_WAKE_LOCK,
                                                ""TestSensorEventListenerWakeLock"");
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public void onSensorChanged(SensorEvent event) {
        long timestampNs = SystemClock.elapsedRealtimeNanos();
        checkHandler();
        synchronized (mCollectedEvents) {
            mCollectedEvents.add(new TestSensorEvent(event, timestampNs));
        }
        synchronized (mEventLatches) {
            for (CountDownLatch latch : mEventLatches) {
                latch.countDown();
                if (latch.getCount() == 0 && !mTestSensorEventListenerWakeLock.isHeld()) {
                    mTestSensorEventListenerWakeLock.acquire();
                }
            }
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public void onAccuracyChanged(Sensor sensor, int accuracy) {
        checkHandler();
    }

    /**
     * @param eventCount
     * @return A CountDownLatch initialzed with eventCount and decremented as sensor events arrive
     * for this listerner.
     */
    public CountDownLatch getLatchForSensorEvents(int eventCount) {
        CountDownLatch latch = new CountDownLatch(eventCount);
        synchronized (mEventLatches) {
            mEventLatches.add(latch);
        }
        return latch;
    }

    /**
     * @return A CountDownLatch initialzed with 1 and decremented as a flush complete arrives
     * for this listerner.
     */
    public CountDownLatch getLatchForFlushCompleteEvent() {
        CountDownLatch latch = new CountDownLatch(1);
        synchronized (mFlushLatches) {
            mFlushLatches.add(latch);
        }
        return latch;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public void onFlushCompleted(Sensor sensor) {
        checkHandler();
        long timestampNs = SystemClock.elapsedRealtimeNanos();
        synchronized (mTimeStampFlushCompleteEvents) {
           mTimeStampFlushCompleteEvents.add(timestampNs);
        }
        synchronized (mFlushLatches) {
            for (CountDownLatch latch : mFlushLatches) {
                latch.countDown();
            }
        }
    }

    /**
     * @return The handler (if any) associated with the instance.
     */
    public Handler getHandler() {
        return mHandler;
    }

    /**
     * @return A list of {@link TestSensorEvent}s collected by the listener.
     */
    public List<TestSensorEvent> getCollectedEvents() {
        synchronized (mCollectedEvents){
            return Collections.unmodifiableList((List<TestSensorEvent>) mCollectedEvents.clone());
        }
    }

    /**
     * Clears the internal list of collected {@link TestSensorEvent}s.
     */
    public void clearEvents() {
        synchronized (mCollectedEvents) {
            mCollectedEvents.clear();
        }
    }


    /**
     * Utility method to log the collected events to a file.
     * It will overwrite the file if it already exists, the file is created in a relative directory
     * named 'events' under the sensor test directory (part of external storage).
     */
    public void logCollectedEventsToFile(String fileName, long deviceWakeUpTimeMs,
            long testStartTimeMs, long testStopTimeMs)
        throws IOException {
        StringBuilder builder = new StringBuilder();
        builder.append(""Sensor='"").append(mEnvironment.getSensor()).append(""', "");
        builder.append(""SamplingRateOverloaded="")
                .append(mEnvironment.isSensorSamplingRateOverloaded()).append("", "");
        builder.append(""RequestedSamplingPeriod="")
                .append(mEnvironment.getRequestedSamplingPeriodUs()).append(""us, "");
        builder.append(""MaxReportLatency="")
                .append(mEnvironment.getMaxReportLatencyUs()).append(""us, "");
        builder.append(""StartedTimestamp="")
                .append(testStartTimeMs).append(""ms, "");
        builder.append(""StoppedTimestamp="")
                .append(testStopTimeMs).append(""ms"");
        synchronized (mCollectedEvents) {
            int i = 0, j = 0;
            while (i < mCollectedEvents.size() && j < mTimeStampFlushCompleteEvents.size()) {
                if (mCollectedEvents.get(i).receivedTimestamp <
                        mTimeStampFlushCompleteEvents.get(j)) {
                    TestSensorEvent event = mCollectedEvents.get(i);
                    if (deviceWakeUpTimeMs != -1 && deviceWakeUpTimeMs <
                            event.receivedTimestamp/1000000) {
                        builder.append(""\n"");
                        builder.append(""AP wake-up time="").append(deviceWakeUpTimeMs).append(""ms"");
                        deviceWakeUpTimeMs = -1;
                    }
                    builder.append(""\n"");
                    builder.append(""Timestamp="").append(event.timestamp/1000).append(""us, "");
                    builder.append(""ReceivedTimestamp="").append(event.receivedTimestamp/1000).
                        append(""us, "");
                    builder.append(""Accuracy="").append(event.accuracy).append("", "");
                    builder.append(""Values="").append(Arrays.toString(event.values));
                    ++i;
                } else {
                    builder.append(""\n"");
                    builder.append(""ReceivedTimestamp="")
                    .append(mTimeStampFlushCompleteEvents.get(j)/1000)
                    .append(""us Flush complete Event"");
                    ++j;
                }
            }
            for (;i < mCollectedEvents.size(); ++i) {
                TestSensorEvent event = mCollectedEvents.get(i);
                if (deviceWakeUpTimeMs != -1 && deviceWakeUpTimeMs <
                        event.receivedTimestamp/1000000) {
                    builder.append(""\n"");
                    builder.append(""AP wake-up time="").append(deviceWakeUpTimeMs).append(""ms"");
                    deviceWakeUpTimeMs = -1;
                }
                builder.append(""\n"");
                builder.append(""Timestamp="").append(event.timestamp/1000).append(""us, "");
                builder.append(""ReceivedTimestamp="").append(event.receivedTimestamp/1000).
                    append(""us, "");
                builder.append(""Accuracy="").append(event.accuracy).append("", "");
                builder.append(""Values="").append(Arrays.toString(event.values));
            }
            for (;j < mTimeStampFlushCompleteEvents.size(); ++j) {
                builder.append(""\n"");
                builder.append(""ReceivedTimestamp="")
                    .append(mTimeStampFlushCompleteEvents.get(j)/1000)
                    .append(""us Flush complete Event"");
            }
        }

        File eventsDirectory = SensorCtsHelper.getSensorTestDataDirectory(""events/"");
        File logFile = new File(eventsDirectory, fileName);
        FileWriter fileWriter = new FileWriter(logFile, false /* append */);
        try (BufferedWriter writer = new BufferedWriter(fileWriter)) {
            writer.write(builder.toString());
        }
    }

    /**
     * Wait for {@link #onFlushCompleted(Sensor)} to be called.
     *
     * A wake lock may be acquired at the return if operation is successful. Do
     * {@link releaseWakeLock()} if the wakelock is not necessary.
     *
     * @throws AssertionError if there was a timeout after {@link #FLUSH_TIMEOUT_US} &micro;s
     */
    public void waitForFlushComplete(CountDownLatch latch,
                                      boolean clearCollectedEvents) throws InterruptedException {
        if (clearCollectedEvents) {
            clearEvents();
        }
        try {
            String message = SensorCtsHelper.formatAssertionMessage(
                    ""WaitForFlush"",
                    mEnvironment,
                    ""timeout=%dus"",
                    FLUSH_TIMEOUT_US);
            Assert.assertTrue(message, latch.await(FLUSH_TIMEOUT_US, TimeUnit.MICROSECONDS));
        } finally {
            synchronized (mFlushLatches) {
                mFlushLatches.remove(latch);
            }
        }
    }

    /**
     * Collect a specific number of {@link TestSensorEvent}s.
     *
     * A wake lock may be acquired at the return if operation is successful. Do
     * {@link releaseWakeLock()} if the wakelock is not necessary.
     *
     * @throws AssertionError if there was a timeout after {@link #FLUSH_TIMEOUT_US} &micro;s
     */
    public void waitForEvents(CountDownLatch latch, int eventCount,
                               boolean clearCollectedEvents) throws InterruptedException {
        if (clearCollectedEvents) {
            clearEvents();
        }
        try {
            long samplingPeriodUs = mEnvironment.getMaximumExpectedSamplingPeriodUs();
            // timeout is 2 * event count * expected period + batch timeout + default wait
            // we multiply by two as not to raise an error in this function even if the events are
            // streaming at a lower rate than expected, as long as it's not streaming twice as slow
            // as expected
            long timeoutUs = (2 * eventCount * samplingPeriodUs)
                    + mEnvironment.getMaxReportLatencyUs()
                    + EVENT_TIMEOUT_US;
            boolean success = latch.await(timeoutUs, TimeUnit.MICROSECONDS);
            if (!success) {
                String message = SensorCtsHelper.formatAssertionMessage(
                        ""WaitForEvents"",
                        mEnvironment,
                        ""requested=%d, received=%d, timeout=%dus"",
                        eventCount,
                        eventCount - latch.getCount(),
                        timeoutUs);
                Assert.fail(message);
            }
        } finally {
            synchronized (mEventLatches) {
                mEventLatches.remove(latch);
            }
        }
    }

    /**
     * Collect {@link TestSensorEvent} for a specific duration.
     */
    public void waitForEvents(long duration, TimeUnit timeUnit) throws InterruptedException {
        SensorCtsHelper.sleep(duration, timeUnit);
    }

    /**
     * Asserts that sensor events arrived in the proper thread if a {@link Handler} was associated
     * with the current instance.
     *
     * If no events were received this assertion will be evaluated to {@code true}.
     */
    public void assertEventsReceivedInHandler() {
        int eventsOutsideHandler = mEventsReceivedOutsideHandler.get();
        String message = String.format(
                ""Events arrived outside the associated Looper. Expected=0, Found=%d"",
                eventsOutsideHandler);
        Assert.assertEquals(message, 0 /* expected */, eventsOutsideHandler);
    }

    public void releaseWakeLock() {
        if (mTestSensorEventListenerWakeLock.isHeld()) {
            mTestSensorEventListenerWakeLock.release();
        }
    }

    /**
     * Keeps track of the number of events that arrived in a different {@link Looper} than the one
     * associated with the {@link TestSensorEventListener}.
     */
    private void checkHandler() {
        if (mHandler != null && mHandler.getLooper() != Looper.myLooper()) {
            mEventsReceivedOutsideHandler.incrementAndGet();
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.MagnitudeVerificationTest"	"testVerify"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/MagnitudeVerificationTest.java"	""	"public void testVerify() {
        float[][] values = {
                {0, 3, 4},
                {4, 0, 3},
                {3, 4, 0},
                {0, 0, 4},
                {6, 0, 0},
        };

        runStats(5.0f, 0.1f, values, true, 5.0f);
        runStats(4.5f, 0.6f, values, true, 5.0f);
        runStats(5.5f, 0.6f, values, true, 5.0f);
        runStats(4.5f, 0.1f, values, false, 5.0f);
        runStats(5.5f, 0.1f, values, false, 5.0f);
    }

    private void runStats(float expected, float threshold, float[][] values, boolean pass, float magnitude) {
        SensorStats stats = new SensorStats();
        MagnitudeVerification verification = getVerification(expected, threshold, values);
        if (pass) {
            verification.verify(stats);
        } else {
            try {
                verification.verify(stats);
                throw new Error(""Expected an AssertionError"");
            } catch (AssertionError e) {
                // Expected;
            }
        }
        assertEquals(pass, stats.getValue(MagnitudeVerification.PASSED_KEY));
        assertEquals(magnitude, (Float) stats.getValue(SensorStats.MAGNITUDE_KEY), 0.01);
    }

    private static MagnitudeVerification getVerification(float expected, float threshold,
            float[] ... values) {
        Collection<TestSensorEvent> events = new ArrayList<>(values.length);
        for (float[] value : values) {
            events.add(new TestSensorEvent(null, 0, 0, value));
        }
        MagnitudeVerification verification = new MagnitudeVerification(expected, threshold);
        verification.addSensorEvents(events);
        return verification;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.debuggableapi31.DebuggableAPI31Test"	"testRegisterListener"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/DebuggableAPI31/src/android/sensorratepermission/cts/debuggableapi31/DebuggableAPI31Test.java"	""	"public void testRegisterListener() {
        try {
            Sensor sensor = mSensorManager.getDefaultSensor(sensorType);
            if (sensor == null) {
                return;
            }
            TestSensorEnvironment testSensorEnvironment = new TestSensorEnvironment(
                    mContext,
                    sensor,
                    SensorManager.SENSOR_DELAY_FASTEST,
                    (int) TimeUnit.SECONDS.toMicros(5));
            TestSensorEventListener listener = new TestSensorEventListener(testSensorEnvironment);
            boolean res = mSensorManager.registerListener(
                    listener,
                    sensor,
                    testSensorEnvironment.getRequestedSamplingPeriodUs(),
                    testSensorEnvironment.getMaxReportLatencyUs());
            fail(""Should have thrown a SecurityException!"");
        } catch (Exception e) {
            // Expected
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.debuggableapi31.DebuggableAPI31Test"	"testDirectChannel"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/DebuggableAPI31/src/android/sensorratepermission/cts/debuggableapi31/DebuggableAPI31Test.java"	""	"public void testDirectChannel() {
        try {
            Sensor s = mSensorManager.getDefaultSensor(sensorType);
            if (s == null) {
                return;
            }
            if (!s.isDirectChannelTypeSupported(SensorDirectChannel.TYPE_HARDWARE_BUFFER)
                    || s.getHighestDirectReportRateLevel() <= SensorDirectChannel.RATE_FAST) {
                return;
            }
            int rateLevel = SensorDirectChannel.RATE_VERY_FAST;
            HardwareBuffer hardwareBuffer = HardwareBuffer.create(
                    1000, 1, HardwareBuffer.BLOB, 1,
                    HardwareBuffer.USAGE_CPU_READ_OFTEN | HardwareBuffer.USAGE_GPU_DATA_BUFFER
                            | HardwareBuffer.USAGE_SENSOR_DIRECT_DATA);
            SensorDirectChannel channel = mSensorManager.createDirectChannel(hardwareBuffer);
            channel.configure(s, rateLevel);
            hardwareBuffer.close();
            fail(""Should have thrown a SecurityException"");
        } catch (SecurityException e) {
            // Expected
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorAdditionalInfoTest"	"testSensorAdditionalInfo"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorAdditionalInfoTest.java"	""	"public void testSensorAdditionalInfo() {
        if (mSensorManager == null) {
            return;
        }

        List<Sensor> list = mSensorManager.getSensorList(Sensor.TYPE_ALL);
        List<String> errors = new ArrayList<String>();
        for (Sensor s : list) {
            // Only test sensor additional info for Accelerometer, Gyroscope and Magnetometer.
            if (s.getType() != Sensor.TYPE_ACCELEROMETER &&
                    s.getType() != Sensor.TYPE_GYROSCOPE &&
                    s.getType() != Sensor.TYPE_MAGNETIC_FIELD) {
                continue;
            }
            if (!s.isAdditionalInfoSupported()) {
                // check SensorAdditionalInfo is supported for Automotive sensors.
                if (getContext().getPackageManager().hasSystemFeature(
                        PackageManager.FEATURE_AUTOMOTIVE)) {
                    errors.add(""Sensor: "" + s.getName() +
                        "", error: AdditionalSensorInfo not supported for Automotive sensor."");
                }
                continue;
            }

            try {
                runSensorAdditionalInfoTest(s);
            } catch (AssertionError e) {
                errors.add(""Sensor: "" + s.getName() + "", error: "" + e.getMessage());
            }
        }
        if (errors.size() > 0) {
            StringBuilder sb = new StringBuilder();
            sb.append(""Failed for following reasons: ["");
            int i = 0;
            for (String error : errors) {
                sb.append(String.format(""%d. %s; "", i++, error));
            }
            sb.append(""]"");
            fail(sb.toString());
        }
    }

    private void runSensorAdditionalInfoTest(Sensor s) throws AssertionError {
        waitBeforeTestStarts();

        AdditionalInfoVerifier verifier = new AdditionalInfoVerifier(s);
        verifier.reset(false /*flushPending*/);

        assertTrue(String.format(""Register sensor listener for %s failed."", s.getName()),
                mSensorManager.registerListener(verifier, s, SensorManager.SENSOR_DELAY_NORMAL));
        try {
            assertTrue(""Missing additional info at registration: ("" + verifier.getState() + "")"",
                    verifier.verify());

            assertFalse(""Duplicate TYPE_FRAME_BEGIN at: ("" +
                    verifier.getState() + "")"", verifier.beginFrameDuplicate());

            if (verifier.internalTemperature()) {
                assertFalse(""Duplicate TYPE_INTERNAL_TEMPERATURE at: ("" +
                        verifier.getState() + "")"", verifier.internalTemperatureDuplicate());
            }

            if (verifier.sampling()) {
                assertFalse(""Duplicate TYPE_SAMPLING_TEMPERATURE at: ("" +
                        verifier.getState() + "")"", verifier.samplingDuplicate());
            }

            // verify TYPE_SENSOR_PLACEMENT for Automotive.
            if (getContext().getPackageManager().
                    hasSystemFeature(PackageManager.FEATURE_AUTOMOTIVE)) {
                assertTrue(""Missing TYPE_SENSOR_PLACEMENT at: ("" + verifier.getState() + "")"",
                        verifier.sensorPlacement());

            }
            if(verifier.sensorPlacement()) {
                assertFalse(""Duplicate TYPE_SENSOR_PLACEMENT at: ("" +
                        verifier.getState() + "")"", verifier.sensorPlacementDuplicate());

                assertTrue(""Incorrect size of TYPE_SENSOR_PLACEMENT at: ("" +
                        verifier.getState() + "")"", verifier.sensorPlacementSizeValid());

                if (verifier.sensorPlacementSizeValid()) {
                    assertTrue(""Incorrect rotation matrix of TYPE_SENSOR_PLACEMENT at: ("" +
                            verifier.getState() + "")"", verifier.sensorPlacementRotationValid());
                }
            }

            if (verifier.untrackedDelay()) {
                assertFalse(""Duplicate TYPE_UNTRACKED_DELAY at: ("" +
                        verifier.getState() + "")"", verifier.untrackedDelayDuplicate());
            }

            if (verifier.vec3Calibration()) {
                assertFalse(""Duplicate TYPE_VEC3_CALIBRATION at: ("" +
                        verifier.getState() + "")"", verifier.vec3CalibrationDuplicate());
            }

            verifier.reset(true /*flushPending*/);
            assertTrue(""Flush sensor failed."", mSensorManager.flush(verifier));
            assertTrue(""Missing additional info after flushing: ("" + verifier.getState() + "")"",
                    verifier.verify());
        } finally {
            mSensorManager.unregisterListener(verifier);
        }
    }

    private void waitBeforeTestStarts() {
        // wait for sensor system to come to a rest after previous test to avoid flakiness.
        try {
            SensorCtsHelper.sleep(REST_PERIOD_BEFORE_TEST_SEC, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }

    private class AdditionalInfoVerifier extends SensorEventCallback {
        private boolean mBeginFrame = false;
        private boolean mBeginFrameDuplicate = false;
        private boolean mEndFrame = false;
        private boolean mFlushPending = false;
        private boolean mInternalTemperature = false;
        private boolean mInternalTemperatureDuplicate = false;
        private boolean mSampling = false;
        private boolean mSamplingDuplicate = false;
        private boolean mSensorPlacement = false;
        private boolean mSensorPlacementDuplicate = false;
        private boolean mIsSensorPlacementSizeValid = false;
        private boolean mIsSensorPlacementRotationValid = false;
        private boolean mUntrackedDelay = false;
        private boolean mUntrackedDelayDuplicate = false;
        private boolean mVec3Calibration = false;
        private boolean mVec3CalibrationDuplicate = false;
        private CountDownLatch mDone;
        private final Sensor mSensor;

        public AdditionalInfoVerifier(Sensor s) {
            mSensor = s;
        }

        @Override
        public void onFlushCompleted(Sensor sensor) {
            if (sensor == mSensor) {
                mFlushPending = false;
            }
        }

        @Override
        public void onSensorAdditionalInfo(SensorAdditionalInfo info) {
            if (info.sensor == mSensor && !mFlushPending) {
                if (info.type == SensorAdditionalInfo.TYPE_FRAME_BEGIN) {
                    if (mBeginFrame) {
                        mBeginFrameDuplicate = true;
                        return;
                    }
                    mBeginFrame = true;
                } else if (mBeginFrame &&
                            info.type == SensorAdditionalInfo.TYPE_INTERNAL_TEMPERATURE) {
                    if (mInternalTemperature) {
                        mInternalTemperatureDuplicate = true;
                        return;
                    }
                    mInternalTemperature = true;
                } else if (mBeginFrame && info.type == SensorAdditionalInfo.TYPE_SAMPLING) {
                    if (mSampling) {
                        mSamplingDuplicate = true;
                        return;
                    }
                    mSampling = true;
                } else if (mBeginFrame && info.type == SensorAdditionalInfo.TYPE_SENSOR_PLACEMENT) {
                    if (mSensorPlacement) {
                        mSensorPlacementDuplicate = true;
                        return;
                    }
                    mSensorPlacement = true;
                    verifySensorPlacementData(info.floatValues);
                } else if (mBeginFrame && info.type == SensorAdditionalInfo.TYPE_UNTRACKED_DELAY) {
                    if (mUntrackedDelay) {
                        mUntrackedDelayDuplicate = true;
                        return;
                    }
                    mUntrackedDelay = true;
                } else if (mBeginFrame && info.type == SensorAdditionalInfo.TYPE_VEC3_CALIBRATION) {
                    if (mVec3Calibration) {
                        mVec3CalibrationDuplicate = true;
                        return;
                    }
                    mVec3Calibration = true;
                } else if (info.type == SensorAdditionalInfo.TYPE_FRAME_END && mBeginFrame) {
                    mEndFrame = true;
                    mDone.countDown();
                }
            }
        }

        public void reset(boolean flushPending) {
            mFlushPending = flushPending;
            mBeginFrame = false;
            mEndFrame = false;
            mSensorPlacement = false;
            mDone = new CountDownLatch(1);
        }

        public boolean verify() {
            boolean ret;
            try {
                ret = mDone.await(ALLOWED_ADDITIONAL_INFO_DELIVER_SEC, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                ret = false;
            }
            return ret;
        }

        public String getState() {
            return ""fp="" + mFlushPending +"", b="" + mBeginFrame + "", e="" + mEndFrame;
        }

        // Checks sensor placement data length and determinant of rotation matrix is 1.
        private void verifySensorPlacementData(float[] m) {
            if(m.length < 12) {
                mIsSensorPlacementSizeValid = false;
                return;
            }
            mIsSensorPlacementSizeValid = true;
            double determinant = m[0] * (m[5] * m[10] - m[6] * m[9] ) -
                                 m[1] * (m[4] * m[10] - m[6] * m[8] ) +
                                 m[2] * (m[4] * m[9]  - m[5] * m[8] );
            mIsSensorPlacementRotationValid = (Math.abs(determinant - 1) < EPSILON);
        }

        public boolean beginFrameDuplicate() {
            return mBeginFrameDuplicate;
        }

        public boolean internalTemperature() {
            return mInternalTemperature;
        }
        public boolean internalTemperatureDuplicate() {
            return mInternalTemperatureDuplicate;
        }

        public boolean sampling() {
            return mSampling;
        }
        public boolean samplingDuplicate() {
            return mSamplingDuplicate;
        }

        public boolean sensorPlacement() {
            return mSensorPlacement;
        }
        public boolean sensorPlacementDuplicate() {
            return mSensorPlacementDuplicate;
        }
        public boolean sensorPlacementSizeValid() {
            return mIsSensorPlacementSizeValid;
        }
        public boolean sensorPlacementRotationValid() {
            return mIsSensorPlacementRotationValid;
        }

        public boolean untrackedDelay() {
            return mUntrackedDelay;
        }
        public boolean untrackedDelayDuplicate() {
            return mUntrackedDelayDuplicate;
        }

        public boolean vec3Calibration() {
            return mVec3Calibration;
        }
        public boolean vec3CalibrationDuplicate() {
            return mVec3CalibrationDuplicate;
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Utils.Path.RobustnessPath"	"currentTimeMillis"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Utils/Path/RobustnessPath.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Utils.Path;

import com.android.cts.verifier.sensors.sixdof.Activities.TestActivity;
import com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointAreaCoveredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointDistanceException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointStartPointException;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.RotationData;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Waypoint;

import android.opengl.Matrix;
import java.util.ArrayList;
import java.util.Timer;
import java.util.TimerTask;

/**
 * Handles all the path properties of the robustness path.
 */
public class RobustnessPath extends Path {
    public static final long TIME_TO_ADD_MARKER = 20000;
    private static final int MAXIMUM_ROTATION_ANGLE = 40;
    private static final int MINIMUM_ROTATION_ANGLE = MAXIMUM_ROTATION_ANGLE * -1;
    private static final long TARGET_ROTATION_TIMER_INTERVALS = 100;
    private static final float CHANGE_IN_ANGLE = 0.5f;
    private static final int MAXIMUM_ROTATION_INACCURACY = 10;
    private static final double DISTANCE_FROM_MARKER = 0.5F;


    private static final float[] X_AXIS = new float[]{1, 0, 0, 0};

    private float mTargetRotation = 0;
    private boolean mRotationPhase = true;
    private ArrayList<RotationData> mPathRotations = new ArrayList<>();
    private ArrayList<Long> mMarkerTimeStamp = new ArrayList<>();
    private float mDistanceOfPathFailedRotation = 0;

    private int mOpenGlRotation = 0;

    /**
     * Constructor which starts the timer which changes the targetRotation.
     */
    public RobustnessPath(int openGlRotation) {
        mOpenGlRotation = openGlRotation;
        startChangingTargetRotation();
    }

    /**
     * Performs robustness path related checks on a marker.
     *
     * @param coordinates the coordinates to use for the waypoint
     * @throws WaypointDistanceException    if the location is too close to another.
     * @throws WaypointAreaCoveredException if the area covered by the user is too little.
     * @throws WaypointStartPointException  if the location is not close enough to the start.
     */
    @Override
    public void additionalChecks(float[] coordinates)
            throws WaypointStartPointException, WaypointDistanceException,
            WaypointAreaCoveredException {
        mMarkerTimeStamp.add(System.currentTimeMillis());
        if (mPathMarkers.size() == 0) {
            mTargetRotation = 0;
        }
    }

    /**
     * Starts a timer which changes the target rotation at specified intervals.
     */
    private void startChangingTargetRotation() {
        Timer timer = new Timer();
        timer.scheduleAtFixedRate(new TimerTask() {

            @Override
            public void run() {
                synchronized (TestActivity.POSE_LOCK) {
                    setRotationToMake();
                }
            }
        }, 0, TARGET_ROTATION_TIMER_INTERVALS);
    }

    /**
     * Performs the change to the target rotation.
     */
    private void setRotationToMake() {
        if (mRotationPhase) {
            mTargetRotation = mTargetRotation - CHANGE_IN_ANGLE;
            if (mTargetRotation <= MINIMUM_ROTATION_ANGLE) {
                mRotationPhase = false;
            }
        } else {
            mTargetRotation = mTargetRotation + CHANGE_IN_ANGLE;
            if (mTargetRotation >= MAXIMUM_ROTATION_ANGLE) {
                mRotationPhase = true;
            }
        }
    }

    /**
     * Calculates the time left for the user to place the waypoint.
     *
     * @return the time left based on the current timestamp and the timestamp of the last marker.
     */
    public long calculateTimeRemaining() {
        long timeRemaining;
        if (!mMarkerTimeStamp.isEmpty()) {
            int lastTimestamp = mMarkerTimeStamp.size() - 1;
            timeRemaining = System.currentTimeMillis() - mMarkerTimeStamp.get(lastTimestamp);
            return TIME_TO_ADD_MARKER - timeRemaining;
        }
        return TIME_TO_ADD_MARKER;
    }

    /**
     * Converts the rotation from quaternion to euler.
     *
     * @param rotationQuaternion The quaternions of the current rotation.
     * @return The euler rotation.
     */
    private float calculateRotation(float[] rotationQuaternion) {
        float qx = rotationQuaternion[0];
        float qy = rotationQuaternion[1];
        float qz = rotationQuaternion[2];
        float qw = rotationQuaternion[3];

        // Set initial Vector to be -(X Axis).
        double x = -X_AXIS[0];
        double y = X_AXIS[1];
        double z = X_AXIS[2];

        // Create quaternion based rotation matrix and extract the values that we need.
        final double X = x * (qy * qy + qx * qx - qz * qz - qw * qw)
                + y * (2 * qy * qz - 2 * qx * qw)
                + z * (2 * qy * qw + 2 * qx * qz);
        final double Y = x * (2 * qx * qw + 2 * qy * qz)
                + y * (qx * qx - qy * qy + qz * qz - qw * qw)
                + z * (-2 * qx * qy + 2 * qz * qw);
        final double Z = x * (-2 * qx * qz + 2 * qy * qw)
                + y * (2 * qx * qy + 2 * qz * qw)
                + z * (qx * qx - qy * qy - qz * qz + qw * qw);

        // Invert X and Z axis.
        float[] values = {(float) Z, (float) Y, (float) X, 0.0f};
        MathsUtils.normalizeVector(values);

        // Rotate the X axis based on the orientation of the device.
        float[] adjustedXAxis = new float[4];
        Matrix.multiplyMV(adjustedXAxis, 0, MathsUtils.getDeviceOrientationMatrix(mOpenGlRotation),
                0, X_AXIS, 0);

        // Calculate angle between current pose and adjusted X axis.
        double angle = Math.acos(MathsUtils.dotProduct(values, adjustedXAxis, MathsUtils.VECTOR_3D));

        // Set our angle to be 0 based when upright.
        angle = Math.toDegrees(angle) - MathsUtils.ORIENTATION_90_ANTI_CLOCKWISE;
        angle *= -1;

        return (float) angle;
    }

    /**
     * Test the rotation and create a rotation object.
     *
     * @param rotationQuaternion    The quaternions of the current rotation.
     * @param rotationLocation      The location of the point with the rotation.
     * @param referencePathMarkers  The list of markers in the reference path.
     * @param maximumDistanceToFail The distance that auto fails the test.
     * @return The rotation data if the rotation doesn't cause the test to be invalid, null if the
     * rotation causes the rest to be invalid.
     */
    public RotationData handleRotation(float[] rotationQuaternion, float[] rotationLocation,
                                       ArrayList<Waypoint> referencePathMarkers,
                                       float maximumDistanceToFail) {
        float eulerRotation = calculateRotation(rotationQuaternion);
        boolean rotationTest = testRotation(eulerRotation, rotationLocation);
        boolean rotationTestable = checkIfRotationTestable(rotationLocation, referencePathMarkers);
        if (mDistanceOfPathFailedRotation > maximumDistanceToFail) {
            return null;
        } else {
            return createRotation(eulerRotation, rotationTest, rotationLocation, rotationTestable);
        }
    }

    /**
     * Tests the current rotation against the target rotation.
     *
     * @param eulerRotation    The rotation as a euler angle.
     * @param rotationLocation The location of the current rotation.
     * @return True if the rotation passes, and false if the rotation fails.
     */
    private boolean testRotation(double eulerRotation, float[] rotationLocation) {
        boolean rotationTestState = true;
        double rotationDifference = Math.abs(eulerRotation - mTargetRotation);
        if (rotationDifference > MAXIMUM_ROTATION_INACCURACY) {
            mDistanceOfPathFailedRotation += MathsUtils.distanceCalculationOnXYPlane(
                    rotationLocation, mCurrentPath.get(mCurrentPath.size() - 1).getCoordinates());
            rotationTestState = false;
        }
        return rotationTestState;
    }

    /**
     * Checks to make sure the rotation not close to other markers.
     *
     * @param rotationLocation     The location of the point to validate the distance.
     * @param referencePathMarkers The list of markers in the reference path.
     * @return true if the location is not close to a marker, false if the location is close to a
     * marker.
     */
    private boolean checkIfRotationTestable(
            float[] rotationLocation, ArrayList<Waypoint> referencePathMarkers) {
        for (Waypoint marker : referencePathMarkers) {
            if (MathsUtils.distanceCalculationInXYZSpace(marker.getCoordinates(),
                    rotationLocation) < DISTANCE_FROM_MARKER) {
                return false;
            }
        }
        return true;
    }

    /**
     * Creates a rotation data object.
     *
     * @param currentRotation       The rotation of the current point.
     * @param rotationTestState     Indicates whether the rotation fails or passes the test.
     * @param rotationLocation      The location of the current point.
     * @param testableRotationState Indicates whether the rotation is valid for testing.
     * @return Reference to the rotation data object which contains the rotation.
     */
    private RotationData createRotation(
            float currentRotation, boolean rotationTestState, float[] rotationLocation,
            boolean testableRotationState) {
        RotationData rotationData = new RotationData(
                mTargetRotation, currentRotation, rotationTestState, rotationLocation,
                testableRotationState);
        mPathRotations.add(rotationData);
        return rotationData;
    }

    /**
     * Returns the timestamps for the markers in the path.
     */
    public ArrayList<Long> getMarkerTimeStamp() {
        return new ArrayList<>(mMarkerTimeStamp);
    }

    /**
     * Returns the number of timestamps collected.
     */
    public int getMarkerTimeStampSize() {
        return mMarkerTimeStamp.size();
    }

    /**
     * Returns the rotations recorded for this path.
     */
    public int getRobustnessPathRotationsSize() {
        return mPathRotations.size();
    }

    /**
     * Returns the number of failed rotations.
     */
    public int getFailedRotationsSize() {
        ArrayList<RotationData> failedRotations = new ArrayList<>();
        for (RotationData rotationObject : mPathRotations) {
            if (!rotationObject.getRotationTestState() && rotationObject.getRotationState()) {
                failedRotations.add(rotationObject);
            }
        }
        return failedRotations.size();
    }

    /**
     * Returns the number of passed rotations.
     */
    public int getPassedRotationsSize() {
        ArrayList<RotationData> passedRotations = new ArrayList<>();
        for (RotationData rotationObject : mPathRotations) {
            if (rotationObject.getRotationTestState() && rotationObject.getRotationState()) {
                passedRotations.add(rotationObject);
            }
        }
        return passedRotations.size();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.deviceinfo.CameraDeviceInfo"	"getAllCharacteristicsKeyNames"	""	"/home/gpoor/cts-12-source/cts/tools/cts-device-info/src/com/android/cts/deviceinfo/CameraDeviceInfo.java"	""	"public void test/*
 *.
 */
package com.android.cts.deviceinfo;

import android.content.Context;
import android.graphics.Rect;
import android.hardware.Camera;
import android.hardware.camera2.CameraAccessException;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.CameraManager;
import android.hardware.camera2.params.BlackLevelPattern;
import android.hardware.camera2.params.ColorSpaceTransform;
import android.hardware.camera2.params.StreamConfigurationMap;
import android.hardware.camera2.params.MultiResolutionStreamConfigurationMap;
import android.hardware.camera2.params.MultiResolutionStreamInfo;
import android.media.CamcorderProfile;
import android.os.Build;
import android.util.Log;
import android.util.Rational;
import android.util.Size;
import android.util.SizeF;
import android.util.Range;

import com.android.compatibility.common.deviceinfo.DeviceInfo;
import com.android.compatibility.common.util.DeviceInfoStore;

import java.lang.reflect.Array;
import java.lang.reflect.Field;
import java.lang.reflect.GenericArrayType;
import java.lang.reflect.Modifier;
import java.lang.reflect.ParameterizedType;
import java.lang.reflect.Type;
import java.util.ArrayList;
import java.util.Collection;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;

/**
 * Camera information collector.
 */
public final class CameraDeviceInfo extends DeviceInfo {
    private static final String TAG = ""CameraDeviceInfo"";

    private final static class CameraCharacteristicsStorer {
        private CameraManager mCameraManager;
        private DeviceInfoStore mStore;

        public CameraCharacteristicsStorer(CameraManager cameraManager, DeviceInfoStore store) {
            if (cameraManager == null || store == null) {
                throw new IllegalArgumentException(""can not create an CameraMetadataGetter object""
                        + "" with null CameraManager or null DeviceInfoStore"");
            }

            mCameraManager = cameraManager;
            mStore = store;
        }

        public void storeCameraInfo(String cameraId) throws Exception {
            try {
                CameraCharacteristics chars = mCameraManager.getCameraCharacteristics(cameraId);
                mStore.startGroup(); // per camera chars
                mStore.addResult(""cameraId"", cameraId);
                storeCameraChars(chars);
                mStore.endGroup(); // per camera chars
            } catch (CameraAccessException e) {
                Log.e(TAG,
                        ""Unable to get camera camera static info, skip this camera, error: ""
                                + e.getMessage());
            }
            return;
        }

        public void storePhysicalCameraInfo(String cameraId, List<String> logicalCameras)
                throws Exception {
            try {
                CameraCharacteristics chars = mCameraManager.getCameraCharacteristics(cameraId);
                mStore.startGroup(); // per camera chars
                mStore.addResult(""cameraId"", cameraId);
                mStore.addListResult(""parentLogicalCameraIds"", logicalCameras);
                storeCameraChars(chars);
                mStore.endGroup(); // per camera chars
            } catch (CameraAccessException e) {
                Log.e(TAG,
                        ""Unable to get camera camera static info, skip this camera, error: ""
                                + e.getMessage());
            }
            return;
        }

        private void storeRational(
                Rational rat, String protoName) throws Exception {
            if (protoName == null) {
                mStore.startGroup();
            } else {
                mStore.startGroup(protoName);
            }
            mStore.addResult(""numerator"", rat.getNumerator());
            mStore.addResult(""denominator"", rat.getDenominator());
            mStore.endGroup();
        }

        private void storeSize(
                Size size, String protoName) throws Exception {
            if (protoName == null) {
                mStore.startGroup();
            } else {
                mStore.startGroup(protoName);
            }
            mStore.addResult(""width"", size.getWidth());
            mStore.addResult(""height"", size.getHeight());
            mStore.endGroup();
        }

        private void storeSizeF(
                SizeF size, String protoName) throws Exception {
            if (protoName == null) {
                mStore.startGroup();
            } else {
                mStore.startGroup(protoName);
            }
            mStore.addResult(""width"", size.getWidth());
            mStore.addResult(""height"", size.getHeight());
            mStore.endGroup();
        }

        private void storeRect(
                Rect rect, String protoName) throws Exception {
            if (protoName == null) {
                mStore.startGroup();
            } else {
                mStore.startGroup(protoName);
            }
            mStore.addResult(""left"", rect.left);
            mStore.addResult(""right"", rect.right);
            mStore.addResult(""top"", rect.top);
            mStore.addResult(""bottom"", rect.bottom);
            mStore.endGroup();
        }

        private void storeStreamConfigurationMap(
                StreamConfigurationMap map, String protoName) throws Exception {
            if (protoName == null) {
                mStore.startGroup();
            } else {
                mStore.startGroup(protoName);
            }

            int fmts[] = map.getOutputFormats();
            if (fmts != null) {
                mStore.startArray(""availableStreamConfigurations"");
                for (int fi = 0; fi < Array.getLength(fmts); fi++) {
                    Size sizes[] = map.getOutputSizes(fmts[fi]);
                    if (sizes != null) {
                        for (int si = 0; si < Array.getLength(sizes); si++) {
                            mStore.startGroup();
                            mStore.addResult(""format"", fmts[fi]);
                            mStore.addResult(""width"", sizes[si].getWidth());
                            mStore.addResult(""height"", sizes[si].getHeight());
                            mStore.addResult(""input"", false);
                            mStore.addResult(""minFrameDuration"",
                                            map.getOutputMinFrameDuration(fmts[fi], sizes[si]));
                            mStore.endGroup();
                        }
                    }
                }
                mStore.endArray();
            }

            Size[] highSpeedVideoSizes = map.getHighSpeedVideoSizes();
            if (highSpeedVideoSizes != null && highSpeedVideoSizes.length > 0) {
                mStore.startArray(""availableHighSpeedVideoConfigurations"");
                for (int i = 0; i < highSpeedVideoSizes.length; i++) {
                    Range<Integer>[] fpsRanges = map.getHighSpeedVideoFpsRangesFor(
                            highSpeedVideoSizes[i]);
                    if (fpsRanges != null && fpsRanges.length > 0) {
                        for (int j = 0; j < fpsRanges.length; j++) {
                            mStore.startGroup();
                            mStore.addResult(""width"", highSpeedVideoSizes[i].getWidth());
                            mStore.addResult(""height"", highSpeedVideoSizes[i].getHeight());
                            mStore.addResult(""minFps"", fpsRanges[j].getLower());
                            mStore.addResult(""maxFps"", fpsRanges[j].getUpper());
                            mStore.endGroup();
                        }
                    }
                }
                mStore.endArray();
            }

            int inputFmts[] = map.getInputFormats();
            if (inputFmts != null && inputFmts.length > 0) {
                mStore.startArray(""availableInputConfigurations"");
                for (int i = 0 ; i < inputFmts.length; i++) {
                    Size[] inputSizes = map.getInputSizes(inputFmts[i]);
                    if (inputSizes != null && inputSizes.length > 0) {
                        for (int j = 0; j < inputSizes.length; j++) {
                            mStore.startGroup();
                            mStore.addResult(""inputFormat"", inputFmts[i]);
                            mStore.addResult(""inputWidth"", inputSizes[j].getWidth());
                            mStore.addResult(""inputHeight"", inputSizes[j].getHeight());
                            mStore.endGroup();
                        }
                    }
                }
                mStore.endArray();

                mStore.startArray(""availableInputOutputFormatsMap"");
                for (int i = 0 ; i < inputFmts.length; i++) {
                    int[] outputFmts = map.getValidOutputFormatsForInput(inputFmts[i]);
                    if (outputFmts != null && outputFmts.length > 0) {
                        for (int j = 0; j < outputFmts.length; j++) {
                            mStore.startGroup();
                            mStore.addResult(""inputFormat"", inputFmts[i]);
                            mStore.addResult(""outputFormat"", outputFmts[j]);
                            mStore.endGroup();
                        }
                    }
                }
                mStore.endArray();
            }

            mStore.endGroup();
        }

        private void storeRangeFloat(
                Range<Float> range, String protoName) throws Exception {
            if (protoName == null) {
                mStore.startGroup();
            } else {
                mStore.startGroup(protoName);
            }
            mStore.addResult(""lower"", range.getLower());
            mStore.addResult(""upper"", range.getUpper());
            mStore.endGroup();
        }

        private void storeRangeInt(
                Range<Integer> range, String protoName) throws Exception {
            if (protoName == null) {
                mStore.startGroup();
            } else {
                mStore.startGroup(protoName);
            }
            mStore.addResult(""lower"", range.getLower());
            mStore.addResult(""upper"", range.getUpper());
            mStore.endGroup();
        }

        private void storeRangeLong(
                Range<Long> range, String protoName) throws Exception {
            if (protoName == null) {
                mStore.startGroup();
            } else {
                mStore.startGroup(protoName);
            }
            mStore.addResult(""lower"", range.getLower());
            mStore.addResult(""upper"", range.getUpper());
            mStore.endGroup();
        }

        private void storeColorSpaceTransform(
                ColorSpaceTransform xform, String protoName) throws Exception {
            if (protoName == null) {
                mStore.startGroup();
            } else {
                mStore.startGroup(protoName);
            }

            mStore.startArray(""elements"");
            for (int row = 0; row < 3; row++) {
                for (int col = 0; col < 3; col++) {
                    storeRational((Rational) xform.getElement(col, row), null);
                }
            }
            mStore.endArray();
            mStore.endGroup();
        }

        private void storeBlackLevelPattern(
                BlackLevelPattern pat, String protoName) throws Exception {
            if (protoName == null) {
                mStore.startGroup();
            } else {
                mStore.startGroup(protoName);
            }
            int patVals[] = new int[4];
            pat.copyTo(patVals, 0);
            mStore.addArrayResult(""black_level_pattern"", patVals);
            mStore.endGroup();
        }

        private void storeMultiResStreamConfigurationMap(
                MultiResolutionStreamConfigurationMap map, String protoName) throws Exception {
            if (protoName == null) {
                mStore.startGroup();
            } else {
                mStore.startGroup(protoName);
            }

            mStore.startArray(""availableMultiResolutionConfigurations"");
            int[] fmts = map.getOutputFormats();
            if (fmts != null) {
                for (int fi = 0; fi < Array.getLength(fmts); fi++) {
                    Collection<MultiResolutionStreamInfo> streamInfo = map.getOutputInfo(fmts[fi]);
                    if (streamInfo != null) {
                        for (MultiResolutionStreamInfo oneStream : streamInfo) {
                            mStore.startGroup();
                            mStore.addResult(""format"", fmts[fi]);
                            mStore.addResult(""width"", oneStream.getWidth());
                            mStore.addResult(""height"", oneStream.getHeight());
                            mStore.addResult(""cameraId"", oneStream.getPhysicalCameraId());
                            mStore.addResult(""input"", false);
                            mStore.endGroup();
                        }
                    }
                }
            }

            int[] inputFmts = map.getInputFormats();
            if (inputFmts != null) {
                for (int fi = 0; fi < Array.getLength(inputFmts); fi++) {
                    Collection<MultiResolutionStreamInfo> streamInfo =
                            map.getInputInfo(inputFmts[fi]);
                    if (streamInfo != null) {
                        for (MultiResolutionStreamInfo oneStream : streamInfo) {
                            mStore.startGroup();
                            mStore.addResult(""format"", inputFmts[fi]);
                            mStore.addResult(""width"", oneStream.getWidth());
                            mStore.addResult(""height"", oneStream.getHeight());
                            mStore.addResult(""cameraId"", oneStream.getPhysicalCameraId());
                            mStore.addResult(""input"", true);
                            mStore.endGroup();
                        }
                    }
                }
            }
            mStore.endArray();
            mStore.endGroup();
        }

        private static String getKeyName(Object keyObj) {
            return ((CameraCharacteristics.Key) keyObj).getName();
        }

        private static Object getKeyValue(CameraCharacteristics chars, Object keyObj) {
            return chars.get((CameraCharacteristics.Key) keyObj);
        }

        private void storeEntry(Type keyType, Object keyObj,
                CameraCharacteristics chars) throws Exception {
            String keyName = getKeyName(keyObj);
            String protoName = keyName.replace('.', '_');
            Object keyValue = getKeyValue(chars, keyObj);
            if (keyValue == null) {
                return;
            }

            if (keyType == int.class || keyType == Integer.class) {
                mStore.addResult(protoName, (int) keyValue);
                return;
            } else if (keyType == float.class || keyType == Float.class) {
                mStore.addResult(protoName, (float) keyValue);
                return;
            } else if (keyType == long.class || keyType == Long.class) {
                mStore.addResult(protoName, (long) keyValue);
                return;
            } else if (keyType == double.class || keyType == Double.class) {
                mStore.addResult(protoName, (double) keyValue);
                return;
            } else if (keyType == boolean.class || keyType == Boolean.class) {
                mStore.addResult(protoName, (boolean) keyValue);
                return;
            } else if (keyType == byte.class || keyType == Byte.class) {
                // Infostore does not support byte, convert to int32 and save
                int intValue = (int) ((byte) keyValue);
                mStore.addResult(protoName, intValue);
                return;
            } else if (keyType == Rational.class) {
                storeRational((Rational) keyValue, protoName);
                return;
            } else if (keyType == Size.class) {
                storeSize((Size) keyValue, protoName);
                return;
            } else if (keyType == SizeF.class) {
                storeSizeF((SizeF) keyValue, protoName);
                return;
            } else if (keyType == Rect.class) {
                storeRect((Rect) keyValue, protoName);
                return;
            } else if (keyType == StreamConfigurationMap.class) {
                storeStreamConfigurationMap(
                        (StreamConfigurationMap) keyValue, protoName);
                return;
            } else if (keyType instanceof ParameterizedType &&
                    ((ParameterizedType) keyType).getRawType() == Range.class &&
                    ((ParameterizedType) keyType).getActualTypeArguments()[0] == Float.class) {
                storeRangeFloat((Range<Float>) keyValue, protoName);
                return;
            } else if (keyType instanceof ParameterizedType &&
                    ((ParameterizedType) keyType).getRawType() == Range.class &&
                    ((ParameterizedType) keyType).getActualTypeArguments()[0] == Integer.class) {
                storeRangeInt((Range<Integer>) keyValue, protoName);
                return;
            } else if (keyType instanceof ParameterizedType &&
                    ((ParameterizedType) keyType).getRawType() == Range.class &&
                    ((ParameterizedType) keyType).getActualTypeArguments()[0] == Long.class) {
                storeRangeLong((Range<Long>) keyValue, protoName);
                return;
            } else if (keyType == ColorSpaceTransform.class) {
                storeColorSpaceTransform((ColorSpaceTransform) keyValue, protoName);
                return;
            } else if (keyType == BlackLevelPattern.class) {
                storeBlackLevelPattern((BlackLevelPattern) keyValue, protoName);
                return;
            } else if (keyType == MultiResolutionStreamConfigurationMap.class) {
                storeMultiResStreamConfigurationMap(
                        (MultiResolutionStreamConfigurationMap) keyValue, protoName);
            } else {
                Log.w(TAG, ""Storing unsupported key type: "" + keyType +
                        "" for keyName: "" + keyName);
                return;
            }
        }

        private void storeArrayEntry(Type keyType, Object keyObj,
                CameraCharacteristics chars) throws Exception {
            String keyName = getKeyName(keyObj);
            String protoName = keyName.replace('.', '_');
            Object keyValue = getKeyValue(chars, keyObj);
            if (keyValue == null) {
                return;
            }

            int arrayLen = Array.getLength(keyValue);
            if (arrayLen == 0) {
                return;
            }
            Type elmtType = ((GenericArrayType) keyType).getGenericComponentType();

            if (elmtType == int.class) {
                mStore.addArrayResult(protoName, (int[]) keyValue);
                return;
            } else if (elmtType == float.class) {
                mStore.addArrayResult(protoName, (float[]) keyValue);
                return;
            } else if (elmtType == long.class) {
                mStore.addArrayResult(protoName, (long[]) keyValue);
                return;
            } else if (elmtType == double.class) {
                mStore.addArrayResult(protoName, (double[]) keyValue);
                return;
            } else if (elmtType == boolean.class) {
                mStore.addArrayResult(protoName, (boolean[]) keyValue);
                return;
            } else if (elmtType == byte.class) {
                // Infostore does not support byte, convert to int32 and save
                int[] intValues = new int[arrayLen];
                for (int i = 0; i < arrayLen; i++) {
                    intValues[i] = (int) ((byte) Array.get(keyValue, i));
                }
                mStore.addArrayResult(protoName, intValues);
                return;
            } else if (elmtType == Rational.class) {
                mStore.startArray(protoName);
                for (int i = 0; i < arrayLen; i++) {
                    storeRational((Rational) Array.get(keyValue, i), null);
                }
                mStore.endArray();
                return;
            } else if (elmtType == Size.class) {
                mStore.startArray(protoName);
                for (int i = 0; i < arrayLen; i++) {
                    storeSize((Size) Array.get(keyValue, i), null);
                }
                mStore.endArray();
                return;
            } else if (elmtType == Rect.class) {
                mStore.startArray(protoName);
                for (int i = 0; i < arrayLen; i++) {
                    storeRect((Rect) Array.get(keyValue, i), null);
                }
                mStore.endArray();
                return;
            } else if (elmtType instanceof ParameterizedType &&
                    ((ParameterizedType) elmtType).getRawType() == Range.class &&
                    ((ParameterizedType) elmtType).getActualTypeArguments()[0] == Integer.class) {
                mStore.startArray(protoName);
                for (int i = 0; i < arrayLen; i++) {
                    storeRangeInt((Range<Integer>) Array.get(keyValue, i), null);
                }
                mStore.endArray();
                return;
            } else if (elmtType == BlackLevelPattern.class) {
                mStore.startArray(protoName);
                for (int i = 0; i < arrayLen; i++) {
                    storeBlackLevelPattern((BlackLevelPattern) Array.get(keyValue, i), null);
                }
                mStore.endArray();
                return;
            } else {
                Log.w(TAG, ""Storing unsupported array type: "" + elmtType +
                        "" for keyName: "" + keyName);
                return;
            }
        }

        private void storeCameraChars(
                CameraCharacteristics chars) throws Exception {
            HashSet<String> charsKeyNames = getAllCharacteristicsKeyNames();
            Field[] allFields = chars.getClass().getDeclaredFields();
            for (Field field : allFields) {
                if (Modifier.isPublic(field.getModifiers()) &&
                        Modifier.isStatic(field.getModifiers()) &&
                        field.getType() == CameraCharacteristics.Key.class &&
                        field.getGenericType() instanceof ParameterizedType) {
                    ParameterizedType paramType = (ParameterizedType) field.getGenericType();
                    Type[] argTypes = paramType.getActualTypeArguments();
                    if (argTypes.length > 0) {
                        try {
                            Type keyType = argTypes[0];
                            Object keyObj = field.get(chars);
                            String keyName = getKeyName(keyObj);
                            if (charsKeyNames.contains(keyName)) {
                                if (keyType instanceof GenericArrayType) {
                                    storeArrayEntry(keyType, keyObj, chars);
                                } else {
                                    storeEntry(keyType, keyObj, chars);
                                }
                            }
                        } catch (IllegalAccessException e) {
                            throw new IllegalStateException(
                                    ""Access error for field: "" + field + "": "", e);
                        }
                    }
                }
            }
        }
    }


    @Override
    protected void collectDeviceInfo(DeviceInfoStore store) throws Exception {
        store.addResult(""profile_480p"", CamcorderProfile.hasProfile(CamcorderProfile.QUALITY_480P));
        store.addResult(""profile_720p"", CamcorderProfile.hasProfile(CamcorderProfile.QUALITY_720P));
        store.addResult(""profile_1080p"", CamcorderProfile.hasProfile(CamcorderProfile.QUALITY_1080P));
        store.addResult(""profile_cif"", CamcorderProfile.hasProfile(CamcorderProfile.QUALITY_CIF));
        store.addResult(""profile_qcif"", CamcorderProfile.hasProfile(CamcorderProfile.QUALITY_QCIF));
        store.addResult(""profile_qvga"", CamcorderProfile.hasProfile(CamcorderProfile.QUALITY_QVGA));

        CameraManager cameraManager = (CameraManager)
                getContext().getSystemService(Context.CAMERA_SERVICE);
        try {
            String[] cameraIdList = cameraManager.getCameraIdList();
            HashMap<String, ArrayList<String>> physicalLogicalIdMap =
                    new HashMap<String, ArrayList<String>>();
            store.addResult(""num_of_camera"", cameraIdList.length);
            if (cameraIdList.length > 0) {
                CameraCharacteristicsStorer charsStorer =
                        new CameraCharacteristicsStorer(cameraManager, store);
                store.startArray(""per_camera_info"");
                for (int i = 0; i < cameraIdList.length; i++) {
                    charsStorer.storeCameraInfo(cameraIdList[i]);

                    // Get the physical camera ids
                    CameraCharacteristics ch = cameraManager.getCameraCharacteristics(
                            cameraIdList[i]);
                    for (String physicalId : ch.getPhysicalCameraIds()) {
                        if (physicalLogicalIdMap.get(physicalId) == null) {
                            physicalLogicalIdMap.put(physicalId, new ArrayList<String>());
                        }
                        physicalLogicalIdMap.get(physicalId).add(cameraIdList[i]);
                    }
                }
                store.endArray(); // per_camera_info

                // Store characteristics for hidden physical camera ids
                for (int i = 0; i < cameraIdList.length; ++i) {
                    physicalLogicalIdMap.remove(cameraIdList[i]);
                }
                if (physicalLogicalIdMap.size() > 0) {
                    store.addResult(""num_of_hidden_physical_camera"", physicalLogicalIdMap.size());
                    store.startArray(""per_hidden_physical_camera_info"");
                    for (String physicalId : physicalLogicalIdMap.keySet()) {
                        charsStorer.storePhysicalCameraInfo(physicalId,
                                physicalLogicalIdMap.get(physicalId));
                    }
                    store.endArray(); // per_hidden_physical_camera_info
                }
            }
        } catch (CameraAccessException e) {
            Log.e(TAG,
                    ""Unable to get camera camera ID list, error: ""
                            + e.getMessage());
        }
    }

    /*@O~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~
     * The key entries below this point are generated from metadata
     * definitions in /system/media/camera/docs. Do not modify by hand or
     * modify the comment blocks at the start or end.
     *~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~*/

    private static HashSet<String> getAllCharacteristicsKeyNames() {
        HashSet<String> charsKeyNames = new HashSet<String>();
        charsKeyNames.add(CameraCharacteristics.COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AE_AVAILABLE_ANTIBANDING_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AE_AVAILABLE_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AE_COMPENSATION_RANGE.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AE_COMPENSATION_STEP.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AF_AVAILABLE_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AVAILABLE_EFFECTS.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AVAILABLE_SCENE_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AVAILABLE_VIDEO_STABILIZATION_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AWB_AVAILABLE_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_MAX_REGIONS_AE.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_MAX_REGIONS_AWB.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_MAX_REGIONS_AF.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AE_LOCK_AVAILABLE.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AWB_LOCK_AVAILABLE.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AVAILABLE_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_POST_RAW_SENSITIVITY_BOOST_RANGE.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_AVAILABLE_EXTENDED_SCENE_MODE_CAPABILITIES.getName());
        charsKeyNames.add(CameraCharacteristics.CONTROL_ZOOM_RATIO_RANGE.getName());
        charsKeyNames.add(CameraCharacteristics.EDGE_AVAILABLE_EDGE_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.FLASH_INFO_AVAILABLE.getName());
        charsKeyNames.add(CameraCharacteristics.HOT_PIXEL_AVAILABLE_HOT_PIXEL_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.JPEG_AVAILABLE_THUMBNAIL_SIZES.getName());
        charsKeyNames.add(CameraCharacteristics.LENS_FACING.getName());
        charsKeyNames.add(CameraCharacteristics.LENS_POSE_REFERENCE.getName());
        charsKeyNames.add(CameraCharacteristics.LENS_DISTORTION_MAXIMUM_RESOLUTION.getName());
        charsKeyNames.add(CameraCharacteristics.LENS_INTRINSIC_CALIBRATION_MAXIMUM_RESOLUTION.getName());
        charsKeyNames.add(CameraCharacteristics.LENS_INFO_AVAILABLE_APERTURES.getName());
        charsKeyNames.add(CameraCharacteristics.LENS_INFO_AVAILABLE_FILTER_DENSITIES.getName());
        charsKeyNames.add(CameraCharacteristics.LENS_INFO_AVAILABLE_FOCAL_LENGTHS.getName());
        charsKeyNames.add(CameraCharacteristics.LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION.getName());
        charsKeyNames.add(CameraCharacteristics.LENS_INFO_HYPERFOCAL_DISTANCE.getName());
        charsKeyNames.add(CameraCharacteristics.LENS_INFO_MINIMUM_FOCUS_DISTANCE.getName());
        charsKeyNames.add(CameraCharacteristics.LENS_INFO_FOCUS_DISTANCE_CALIBRATION.getName());
        charsKeyNames.add(CameraCharacteristics.NOISE_REDUCTION_AVAILABLE_NOISE_REDUCTION_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.REQUEST_MAX_NUM_OUTPUT_RAW.getName());
        charsKeyNames.add(CameraCharacteristics.REQUEST_MAX_NUM_OUTPUT_PROC.getName());
        charsKeyNames.add(CameraCharacteristics.REQUEST_MAX_NUM_OUTPUT_PROC_STALLING.getName());
        charsKeyNames.add(CameraCharacteristics.REQUEST_MAX_NUM_INPUT_STREAMS.getName());
        charsKeyNames.add(CameraCharacteristics.REQUEST_PIPELINE_MAX_DEPTH.getName());
        charsKeyNames.add(CameraCharacteristics.REQUEST_PARTIAL_RESULT_COUNT.getName());
        charsKeyNames.add(CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES.getName());
        charsKeyNames.add(CameraCharacteristics.SCALER_AVAILABLE_MAX_DIGITAL_ZOOM.getName());
        charsKeyNames.add(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP.getName());
        charsKeyNames.add(CameraCharacteristics.SCALER_CROPPING_TYPE.getName());
        charsKeyNames.add(CameraCharacteristics.SCALER_MANDATORY_STREAM_COMBINATIONS.getName());
        charsKeyNames.add(CameraCharacteristics.SCALER_MANDATORY_CONCURRENT_STREAM_COMBINATIONS.getName());
        charsKeyNames.add(CameraCharacteristics.SCALER_AVAILABLE_ROTATE_AND_CROP_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.SCALER_DEFAULT_SECURE_IMAGE_SIZE.getName());
        charsKeyNames.add(CameraCharacteristics.SCALER_MULTI_RESOLUTION_STREAM_CONFIGURATION_MAP.getName());
        charsKeyNames.add(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP_MAXIMUM_RESOLUTION.getName());
        charsKeyNames.add(CameraCharacteristics.SCALER_MANDATORY_MAXIMUM_RESOLUTION_STREAM_COMBINATIONS.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT1.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_REFERENCE_ILLUMINANT2.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_CALIBRATION_TRANSFORM1.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_CALIBRATION_TRANSFORM2.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_COLOR_TRANSFORM1.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_COLOR_TRANSFORM2.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_FORWARD_MATRIX1.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_FORWARD_MATRIX2.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_BLACK_LEVEL_PATTERN.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_MAX_ANALOG_SENSITIVITY.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_ORIENTATION.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_AVAILABLE_TEST_PATTERN_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_OPTICAL_BLACK_REGIONS.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_SENSITIVITY_RANGE.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_EXPOSURE_TIME_RANGE.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_MAX_FRAME_DURATION.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_PHYSICAL_SIZE.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_WHITE_LEVEL.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_TIMESTAMP_SOURCE.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_LENS_SHADING_APPLIED.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE_MAXIMUM_RESOLUTION.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE_MAXIMUM_RESOLUTION.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE_MAXIMUM_RESOLUTION.getName());
        charsKeyNames.add(CameraCharacteristics.SENSOR_INFO_BINNING_FACTOR.getName());
        charsKeyNames.add(CameraCharacteristics.SHADING_AVAILABLE_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.STATISTICS_INFO_AVAILABLE_FACE_DETECT_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.STATISTICS_INFO_MAX_FACE_COUNT.getName());
        charsKeyNames.add(CameraCharacteristics.STATISTICS_INFO_AVAILABLE_HOT_PIXEL_MAP_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.STATISTICS_INFO_AVAILABLE_LENS_SHADING_MAP_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.STATISTICS_INFO_AVAILABLE_OIS_DATA_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.TONEMAP_MAX_CURVE_POINTS.getName());
        charsKeyNames.add(CameraCharacteristics.TONEMAP_AVAILABLE_TONE_MAP_MODES.getName());
        charsKeyNames.add(CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL.getName());
        charsKeyNames.add(CameraCharacteristics.INFO_VERSION.getName());
        charsKeyNames.add(CameraCharacteristics.SYNC_MAX_LATENCY.getName());
        charsKeyNames.add(CameraCharacteristics.REPROCESS_MAX_CAPTURE_STALL.getName());
        charsKeyNames.add(CameraCharacteristics.DEPTH_DEPTH_IS_EXCLUSIVE.getName());
        charsKeyNames.add(CameraCharacteristics.LOGICAL_MULTI_CAMERA_SENSOR_SYNC_TYPE.getName());
        charsKeyNames.add(CameraCharacteristics.DISTORTION_CORRECTION_AVAILABLE_MODES.getName());

        return charsKeyNames;
    }

    /*~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~
     * End generated code
     *~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~@~O@*/
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.StaticMetadataTest"	"testHwSupportedLevel"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/StaticMetadataTest.java"	""	"public void testHwSupportedLevel() throws Exception {
        Key<StreamConfigurationMap> key =
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP;
        final float SIZE_ERROR_MARGIN = 0.03f;
        for (String id : mAllCameraIds) {
            initStaticMetadata(id);
            StreamConfigurationMap configs = mStaticInfo.getValueFromKeyNonNull(key);
            Rect activeRect = mStaticInfo.getActiveArraySizeChecked();
            Size sensorSize = new Size(activeRect.width(), activeRect.height());
            List<Integer> availableCaps = mStaticInfo.getAvailableCapabilitiesChecked();

            mCollector.expectTrue(""All devices must contains BACKWARD_COMPATIBLE capability or "" +
                    ""DEPTH_OUTPUT capabillity"" ,
                    availableCaps.contains(REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE) ||
                    availableCaps.contains(REQUEST_AVAILABLE_CAPABILITIES_DEPTH_OUTPUT) );

            if (mStaticInfo.isHardwareLevelAtLeast(
                    CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_3)) {
                mCollector.expectTrue(""Level 3 device must contain YUV_REPROCESSING capability"",
                        availableCaps.contains(REQUEST_AVAILABLE_CAPABILITIES_YUV_REPROCESSING));
                mCollector.expectTrue(""Level 3 device must contain RAW capability"",
                        availableCaps.contains(REQUEST_AVAILABLE_CAPABILITIES_RAW));
            }

            if (mStaticInfo.isHardwareLevelAtLeastFull()) {
                // Capability advertisement must be right.
                mCollector.expectTrue(""Full device must contain MANUAL_SENSOR capability"",
                        availableCaps.contains(REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR));
                mCollector.expectTrue(""Full device must contain MANUAL_POST_PROCESSING capability"",
                        availableCaps.contains(
                                REQUEST_AVAILABLE_CAPABILITIES_MANUAL_POST_PROCESSING));
                mCollector.expectTrue(""Full device must contain BURST_CAPTURE capability"",
                        availableCaps.contains(REQUEST_AVAILABLE_CAPABILITIES_BURST_CAPTURE));

                // Need support per frame control
                mCollector.expectTrue(""Full device must support per frame control"",
                        mStaticInfo.isPerFrameControlSupported());
            }

            if (mStaticInfo.isHardwareLevelLegacy()) {
                mCollector.expectTrue(""Legacy devices must contain BACKWARD_COMPATIBLE capability"",
                        availableCaps.contains(REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE));
            }

            if (availableCaps.contains(REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                mCollector.expectTrue(""MANUAL_SENSOR capability always requires "" +
                        ""READ_SENSOR_SETTINGS capability as well"",
                        availableCaps.contains(REQUEST_AVAILABLE_CAPABILITIES_READ_SENSOR_SETTINGS));
            }

            if (mStaticInfo.isColorOutputSupported()) {
                // Max jpeg resolution must be very close to  sensor resolution
                Size[] jpegSizes = mStaticInfo.getJpegOutputSizesChecked();
                Size maxJpegSize = CameraTestUtils.getMaxSize(jpegSizes);
                float croppedWidth = (float)sensorSize.getWidth();
                float croppedHeight = (float)sensorSize.getHeight();
                float sensorAspectRatio = (float)sensorSize.getWidth() / (float)sensorSize.getHeight();
                float maxJpegAspectRatio = (float)maxJpegSize.getWidth() / (float)maxJpegSize.getHeight();
                if (sensorAspectRatio < maxJpegAspectRatio) {
                    croppedHeight = (float)sensorSize.getWidth() / maxJpegAspectRatio;
                } else if (sensorAspectRatio > maxJpegAspectRatio) {
                    croppedWidth = (float)sensorSize.getHeight() * maxJpegAspectRatio;
                }
                Size croppedSensorSize = new Size((int)croppedWidth, (int)croppedHeight);
                mCollector.expectSizesAreSimilar(
                    ""Active array size or cropped active array size and max JPEG size should be similar"",
                    croppedSensorSize, maxJpegSize, SIZE_ERROR_MARGIN);
            }

            // TODO: test all the keys mandatory for all capability devices.
        }
    }

    /**
     * Test max number of output stream reported by device
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.StaticMetadataTest"	"testCapabilities"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/StaticMetadataTest.java"	""	"public void testCapabilities() throws Exception {
        for (String id : mAllCameraIds) {
            initStaticMetadata(id);
            List<Integer> availableCaps = mStaticInfo.getAvailableCapabilitiesChecked();

            for (Integer capability = REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE;
                    capability <= StaticMetadata.LAST_CAPABILITY_ENUM; capability++) {
                boolean isCapabilityAvailable = availableCaps.contains(capability);
                validateCapability(capability, isCapabilityAvailable);
            }
            // Note: Static metadata for capabilities is tested in ExtendedCameraCharacteristicsTest
        }
    }

    /**
     * Check if request keys' presence match expectation.
     *
     * @param capabilityName The name string of capability being tested. Used for output messages.
     * @param requestKeys The capture request keys to be checked
     * @param expectedPresence Expected presence of {@code requestKeys}. {@code true} for expecting
     *        all keys are available. Otherwise {@code false}
     * @return {@code true} if request keys' presence match expectation. Otherwise {@code false}
     */
    private boolean validateRequestKeysPresence(String capabilityName,
            Collection<CaptureRequest.Key<?>> requestKeys, boolean expectedPresence) {
        boolean actualPresence = mStaticInfo.areRequestKeysAvailable(requestKeys);
        if (expectedPresence != actualPresence) {
            if (expectedPresence) {
                for (CaptureRequest.Key<?> key : requestKeys) {
                    if (!mStaticInfo.areKeysAvailable(key)) {
                        mCollector.addMessage(String.format(
                                ""Camera %s list capability %s but doesn't contain request key %s"",
                                mCameraId, capabilityName, key.getName()));
                    }
                }
            } else {
                Log.w(TAG, String.format(
                        ""Camera %s doesn't list capability %s but contain all required keys"",
                        mCameraId, capabilityName));
            }
            return false;
        }
        return true;
    }

    /**
     * Check if result keys' presence match expectation.
     *
     * @param capabilityName The name string of capability being tested. Used for output messages.
     * @param resultKeys The capture result keys to be checked
     * @param expectedPresence Expected presence of {@code resultKeys}. {@code true} for expecting
     *        all keys are available. Otherwise {@code false}
     * @return {@code true} if result keys' presence match expectation. Otherwise {@code false}
     */
    private boolean validateResultKeysPresence(String capabilityName,
            Collection<CaptureResult.Key<?>> resultKeys, boolean expectedPresence) {
        boolean actualPresence = mStaticInfo.areResultKeysAvailable(resultKeys);
        if (expectedPresence != actualPresence) {
            if (expectedPresence) {
                for (CaptureResult.Key<?> key : resultKeys) {
                    if (!mStaticInfo.areKeysAvailable(key)) {
                        mCollector.addMessage(String.format(
                                ""Camera %s list capability %s but doesn't contain result key %s"",
                                mCameraId, capabilityName, key.getName()));
                    }
                }
            } else {
                Log.w(TAG, String.format(
                        ""Camera %s doesn't list capability %s but contain all required keys"",
                        mCameraId, capabilityName));
            }
            return false;
        }
        return true;
    }

    /**
     * Check if characteristics keys' presence match expectation.
     *
     * @param capabilityName The name string of capability being tested. Used for output messages.
     * @param characteristicsKeys The characteristics keys to be checked
     * @param expectedPresence Expected presence of {@code characteristicsKeys}. {@code true} for
     *        expecting all keys are available. Otherwise {@code false}
     * @return {@code true} if characteristics keys' presence match expectation.
     *         Otherwise {@code false}
     */
    private boolean validateCharacteristicsKeysPresence(String capabilityName,
            Collection<CameraCharacteristics.Key<?>> characteristicsKeys,
            boolean expectedPresence) {
        boolean actualPresence = mStaticInfo.areCharacteristicsKeysAvailable(characteristicsKeys);
        if (expectedPresence != actualPresence) {
            if (expectedPresence) {
                for (CameraCharacteristics.Key<?> key : characteristicsKeys) {
                    if (!mStaticInfo.areKeysAvailable(key)) {
                        mCollector.addMessage(String.format(
                                ""Camera %s list capability %s but doesn't contain"" +
                                ""characteristics key %s"",
                                mCameraId, capabilityName, key.getName()));
                    }
                }
            } else {
                Log.w(TAG, String.format(
                        ""Camera %s doesn't list capability %s but contain all required keys"",
                        mCameraId, capabilityName));
            }
            return false;
        }
        return true;
    }

    private void validateCapability(Integer capability, boolean isCapabilityAvailable) {
        List<CaptureRequest.Key<?>> requestKeys = new ArrayList<>();
        Set<CaptureResult.Key<?>> resultKeys = new HashSet<>();
        // Capability requirements other than key presences
        List<Pair<String, Boolean>> additionalRequirements = new ArrayList<>();

        /* For available capabilities, only check request keys in this test
           Characteristics keys are tested in ExtendedCameraCharacteristicsTest
           Result keys are tested in CaptureResultTest */
        String capabilityName;
        switch (capability) {
            case REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE:
                capabilityName = ""REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE"";
                requestKeys.add(CaptureRequest.CONTROL_AE_ANTIBANDING_MODE);
                requestKeys.add(CaptureRequest.CONTROL_AE_EXPOSURE_COMPENSATION);
                requestKeys.add(CaptureRequest.CONTROL_AE_MODE);
                requestKeys.add(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE);
                requestKeys.add(CaptureRequest.CONTROL_AF_MODE);
                requestKeys.add(CaptureRequest.CONTROL_AF_TRIGGER);
                requestKeys.add(CaptureRequest.CONTROL_AWB_MODE);
                requestKeys.add(CaptureRequest.CONTROL_CAPTURE_INTENT);
                requestKeys.add(CaptureRequest.CONTROL_EFFECT_MODE);
                requestKeys.add(CaptureRequest.CONTROL_MODE);
                requestKeys.add(CaptureRequest.CONTROL_SCENE_MODE);
                requestKeys.add(CaptureRequest.CONTROL_VIDEO_STABILIZATION_MODE);
                requestKeys.add(CaptureRequest.CONTROL_ZOOM_RATIO);
                requestKeys.add(CaptureRequest.FLASH_MODE);
                requestKeys.add(CaptureRequest.JPEG_GPS_LOCATION);
                requestKeys.add(CaptureRequest.JPEG_ORIENTATION);
                requestKeys.add(CaptureRequest.JPEG_QUALITY);
                requestKeys.add(CaptureRequest.JPEG_THUMBNAIL_QUALITY);
                requestKeys.add(CaptureRequest.JPEG_THUMBNAIL_SIZE);
                requestKeys.add(CaptureRequest.SCALER_CROP_REGION);
                requestKeys.add(CaptureRequest.STATISTICS_FACE_DETECT_MODE);
                if (mStaticInfo.getAeMaxRegionsChecked() > 0) {
                    requestKeys.add(CaptureRequest.CONTROL_AE_REGIONS);
                } else {
                    mCollector.expectTrue(
                            ""CONTROL_AE_REGIONS is available but aeMaxRegion is 0"",
                            !mStaticInfo.areKeysAvailable(CaptureRequest.CONTROL_AE_REGIONS));
                }
                if (mStaticInfo.getAwbMaxRegionsChecked() > 0) {
                    requestKeys.add(CaptureRequest.CONTROL_AWB_REGIONS);
                } else {
                    mCollector.expectTrue(
                            ""CONTROL_AWB_REGIONS is available but awbMaxRegion is 0"",
                            !mStaticInfo.areKeysAvailable(CaptureRequest.CONTROL_AWB_REGIONS));
                }
                if (mStaticInfo.getAfMaxRegionsChecked() > 0) {
                    requestKeys.add(CaptureRequest.CONTROL_AF_REGIONS);
                } else {
                    mCollector.expectTrue(
                            ""CONTROL_AF_REGIONS is available but afMaxRegion is 0"",
                            !mStaticInfo.areKeysAvailable(CaptureRequest.CONTROL_AF_REGIONS));
                }
                break;
            case REQUEST_AVAILABLE_CAPABILITIES_MANUAL_POST_PROCESSING:
                capabilityName = ""REQUEST_AVAILABLE_CAPABILITIES_MANUAL_POST_PROCESSING"";
                requestKeys.add(CaptureRequest.TONEMAP_MODE);
                requestKeys.add(CaptureRequest.COLOR_CORRECTION_GAINS);
                requestKeys.add(CaptureRequest.COLOR_CORRECTION_TRANSFORM);
                requestKeys.add(CaptureRequest.SHADING_MODE);
                requestKeys.add(CaptureRequest.STATISTICS_LENS_SHADING_MAP_MODE);
                requestKeys.add(CaptureRequest.TONEMAP_CURVE);
                requestKeys.add(CaptureRequest.COLOR_CORRECTION_ABERRATION_MODE);
                requestKeys.add(CaptureRequest.CONTROL_AWB_LOCK);

                // Legacy mode always doesn't support these requirements
                Boolean contrastCurveModeSupported = false;
                Boolean gammaAndPresetModeSupported = false;
                Boolean offColorAberrationModeSupported = false;
                if (mStaticInfo.isHardwareLevelAtLeastLimited() && mStaticInfo.isColorOutputSupported()) {
                    int[] tonemapModes = mStaticInfo.getAvailableToneMapModesChecked();
                    List<Integer> modeList = (tonemapModes.length == 0) ?
                            new ArrayList<Integer>() :
                            Arrays.asList(CameraTestUtils.toObject(tonemapModes));
                    contrastCurveModeSupported =
                            modeList.contains(CameraMetadata.TONEMAP_MODE_CONTRAST_CURVE);
                    gammaAndPresetModeSupported =
                            modeList.contains(CameraMetadata.TONEMAP_MODE_GAMMA_VALUE) &&
                            modeList.contains(CameraMetadata.TONEMAP_MODE_PRESET_CURVE);

                    int[] colorAberrationModes =
                            mStaticInfo.getAvailableColorAberrationModesChecked();
                    modeList = (colorAberrationModes.length == 0) ?
                            new ArrayList<Integer>() :
                            Arrays.asList(CameraTestUtils.toObject(colorAberrationModes));
                    offColorAberrationModeSupported =
                            modeList.contains(CameraMetadata.COLOR_CORRECTION_ABERRATION_MODE_OFF);
                }
                Boolean tonemapModeQualified =
                        contrastCurveModeSupported || gammaAndPresetModeSupported;
                additionalRequirements.add(new Pair<String, Boolean>(
                        ""Tonemap mode must include {CONTRAST_CURVE} and/or "" +
                        ""{GAMMA_VALUE, PRESET_CURVE}"",
                        tonemapModeQualified));
                additionalRequirements.add(new Pair<String, Boolean>(
                        ""Color aberration mode must include OFF"", offColorAberrationModeSupported));
                additionalRequirements.add(new Pair<String, Boolean>(
                        ""Must support AWB lock"", mStaticInfo.isAwbLockSupported()));
                break;
            case REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR:
                capabilityName = ""REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR"";
                requestKeys.add(CaptureRequest.CONTROL_AE_LOCK);
                requestKeys.add(CaptureRequest.SENSOR_FRAME_DURATION);
                requestKeys.add(CaptureRequest.SENSOR_EXPOSURE_TIME);
                requestKeys.add(CaptureRequest.SENSOR_SENSITIVITY);
                if (mStaticInfo.hasFocuser()) {
                    requestKeys.add(CaptureRequest.LENS_APERTURE);
                    requestKeys.add(CaptureRequest.LENS_FOCUS_DISTANCE);
                    requestKeys.add(CaptureRequest.LENS_FILTER_DENSITY);
                    requestKeys.add(CaptureRequest.LENS_OPTICAL_STABILIZATION_MODE);
                }
                requestKeys.add(CaptureRequest.BLACK_LEVEL_LOCK);
                additionalRequirements.add(new Pair<String, Boolean>(
                        ""Must support AE lock"", mStaticInfo.isAeLockSupported()));
                break;
            case REQUEST_AVAILABLE_CAPABILITIES_RAW:
                // RAW_CAPABILITY needs to check for not just capture request keys
                validateRawCapability(isCapabilityAvailable);
                return;
            case REQUEST_AVAILABLE_CAPABILITIES_BURST_CAPTURE:
                // Tested in ExtendedCameraCharacteristicsTest
                return;
            case REQUEST_AVAILABLE_CAPABILITIES_READ_SENSOR_SETTINGS:
                capabilityName = ""REQUEST_AVAILABLE_CAPABILITIES_READ_SENSOR_SETTINGS"";
                resultKeys.add(CaptureResult.SENSOR_FRAME_DURATION);
                resultKeys.add(CaptureResult.SENSOR_EXPOSURE_TIME);
                resultKeys.add(CaptureResult.SENSOR_SENSITIVITY);
                if (mStaticInfo.hasFocuser()) {
                    resultKeys.add(CaptureResult.LENS_APERTURE);
                    resultKeys.add(CaptureResult.LENS_FOCUS_DISTANCE);
                    resultKeys.add(CaptureResult.LENS_FILTER_DENSITY);
                }
                break;

            case REQUEST_AVAILABLE_CAPABILITIES_YUV_REPROCESSING:
            case REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING:
            case REQUEST_AVAILABLE_CAPABILITIES_REMOSAIC_REPROCESSING:
                // Tested in ExtendedCameraCharacteristicsTest
                return;
            case REQUEST_AVAILABLE_CAPABILITIES_DEPTH_OUTPUT:
                // Tested in ExtendedCameracharacteristicsTest
                return;
            case REQUEST_AVAILABLE_CAPABILITIES_CONSTRAINED_HIGH_SPEED_VIDEO:
            case REQUEST_AVAILABLE_CAPABILITIES_MOTION_TRACKING:
            case REQUEST_AVAILABLE_CAPABILITIES_LOGICAL_MULTI_CAMERA:
            case REQUEST_AVAILABLE_CAPABILITIES_MONOCHROME:
                // Tested in ExtendedCameraCharacteristicsTest
                return;
            case REQUEST_AVAILABLE_CAPABILITIES_SECURE_IMAGE_DATA:
                if (!isCapabilityAvailable) {
                    mCollector.expectTrue(
                        ""SCALER_DEFAULT_SECURE_IMAGE_SIZE must not present if the device"" +
                                ""does not support SECURE_IMAGE_DATA capability"",
                        !mStaticInfo.areKeysAvailable(
                                CameraCharacteristics.SCALER_DEFAULT_SECURE_IMAGE_SIZE));
                }
                return;
            case REQUEST_AVAILABLE_CAPABILITIES_ULTRA_HIGH_RESOLUTION_SENSOR:
                resultKeys.add(CaptureResult.SENSOR_RAW_BINNING_FACTOR_USED);
                resultKeys.add(CaptureResult.SENSOR_PIXEL_MODE);
                requestKeys.add(CaptureRequest.SENSOR_PIXEL_MODE);
                additionalRequirements.add(new Pair<String, Boolean>(
                        ""Must support maximum resolution keys"",
                        mStaticInfo.areMaximumResolutionKeysSupported()));
                return;
            default:
                capabilityName = ""Unknown"";
                assertTrue(String.format(""Unknown capability set: %d"", capability),
                           !isCapabilityAvailable);
                return;
        }

        // Check additional requirements and exit early if possible
        if (!isCapabilityAvailable) {
            for (Pair<String, Boolean> p : additionalRequirements) {
                String requirement = p.first;
                Boolean meetRequirement = p.second;
                // No further check is needed if we've found why capability cannot be advertised
                if (!meetRequirement) {
                    Log.v(TAG, String.format(
                            ""Camera %s doesn't list capability %s because of requirement: %s"",
                            mCameraId, capabilityName, requirement));
                    return;
                }
            }
        }

        boolean matchExpectation = true;
        if (!requestKeys.isEmpty()) {
            matchExpectation &= validateRequestKeysPresence(
                    capabilityName, requestKeys, isCapabilityAvailable);
        }
        if(!resultKeys.isEmpty()) {
            matchExpectation &= validateResultKeysPresence(
                    capabilityName, resultKeys, isCapabilityAvailable);
        }

        // Check additional requirements
        for (Pair<String, Boolean> p : additionalRequirements) {
            String requirement = p.first;
            Boolean meetRequirement = p.second;
            if (isCapabilityAvailable && !meetRequirement) {
                mCollector.addMessage(String.format(
                        ""Camera %s list capability %s but does not meet the requirement: %s"",
                        mCameraId, capabilityName, requirement));
            }
        }

        // In case of isCapabilityAvailable == true, error has been filed in
        // validateRequest/ResultKeysPresence
        if (!matchExpectation && !isCapabilityAvailable) {
            mCollector.addMessage(String.format(
                    ""Camera %s doesn't list capability %s but meets all requirements"",
                    mCameraId, capabilityName));
        }
    }

    private void validateRawCapability(boolean isCapabilityAvailable) {
        String capabilityName = ""REQUEST_AVAILABLE_CAPABILITIES_RAW"";

        Set<CaptureRequest.Key<?>> requestKeys = new HashSet<>();
        requestKeys.add(CaptureRequest.HOT_PIXEL_MODE);
        requestKeys.add(CaptureRequest.STATISTICS_HOT_PIXEL_MAP_MODE);

        Set<CameraCharacteristics.Key<?>> characteristicsKeys = new HashSet<>();
        characteristicsKeys.add(HOT_PIXEL_AVAILABLE_HOT_PIXEL_MODES);
        characteristicsKeys.add(SENSOR_BLACK_LEVEL_PATTERN);
        characteristicsKeys.add(SENSOR_INFO_ACTIVE_ARRAY_SIZE);
        characteristicsKeys.add(SENSOR_INFO_COLOR_FILTER_ARRANGEMENT);
        characteristicsKeys.add(SENSOR_INFO_WHITE_LEVEL);
        characteristicsKeys.add(STATISTICS_INFO_AVAILABLE_HOT_PIXEL_MAP_MODES);
        if (!mStaticInfo.isMonochromeCamera()) {
            characteristicsKeys.add(SENSOR_CALIBRATION_TRANSFORM1);
            characteristicsKeys.add(SENSOR_COLOR_TRANSFORM1);
            characteristicsKeys.add(SENSOR_FORWARD_MATRIX1);
            characteristicsKeys.add(SENSOR_REFERENCE_ILLUMINANT1);
        }

        Set<CaptureResult.Key<?>> resultKeys = new HashSet<>();
        resultKeys.add(CaptureResult.SENSOR_NOISE_PROFILE);
        if (!mStaticInfo.isMonochromeCamera()) {
            resultKeys.add(CaptureResult.SENSOR_GREEN_SPLIT);
            resultKeys.add(CaptureResult.SENSOR_NEUTRAL_COLOR_POINT);
        }

        boolean rawOutputSupported = mStaticInfo.getRawOutputSizesChecked().length > 0;
        boolean requestKeysPresent = mStaticInfo.areRequestKeysAvailable(requestKeys);
        boolean characteristicsKeysPresent =
                mStaticInfo.areCharacteristicsKeysAvailable(characteristicsKeys);
        boolean resultKeysPresent = mStaticInfo.areResultKeysAvailable(resultKeys);
        boolean expectCapabilityPresent = rawOutputSupported && requestKeysPresent &&
                characteristicsKeysPresent && resultKeysPresent;

        if (isCapabilityAvailable != expectCapabilityPresent) {
            if (isCapabilityAvailable) {
                mCollector.expectTrue(
                        ""REQUEST_AVAILABLE_CAPABILITIES_RAW should support RAW_SENSOR output"",
                        rawOutputSupported);
                validateRequestKeysPresence(capabilityName, requestKeys, isCapabilityAvailable);
                validateResultKeysPresence(capabilityName, resultKeys, isCapabilityAvailable);
                validateCharacteristicsKeysPresence(capabilityName, characteristicsKeys,
                        isCapabilityAvailable);
            } else {
                mCollector.addMessage(String.format(
                        ""Camera %s doesn't list capability %s but contain all required keys"" +
                        "" and RAW format output"",
                        mCameraId, capabilityName));
            }
        }
    }

    /**
     * Test lens facing.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.CameraTestUtils"	"ImageDropperListener"	""	"/home/gpoor/cts-12-source/cts/tests/camera/utils/src/android/hardware/camera2/cts/CameraTestUtils.java"	""	"public void test/*
 *.
 */

package android.hardware.camera2.cts;

import android.graphics.Bitmap;
import android.graphics.BitmapFactory;
import android.graphics.ImageFormat;
import android.graphics.PointF;
import android.graphics.Rect;
import android.graphics.SurfaceTexture;
import android.hardware.camera2.CameraAccessException;
import android.hardware.camera2.CameraCaptureSession;
import android.hardware.camera2.CameraConstrainedHighSpeedCaptureSession;
import android.hardware.camera2.CameraDevice;
import android.hardware.camera2.CameraManager;
import android.hardware.camera2.CameraMetadata;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.CaptureFailure;
import android.hardware.camera2.CaptureRequest;
import android.hardware.camera2.CaptureResult;
import android.hardware.camera2.MultiResolutionImageReader;
import android.hardware.camera2.cts.helpers.CameraErrorCollector;
import android.hardware.camera2.cts.helpers.StaticMetadata;
import android.hardware.camera2.params.InputConfiguration;
import android.hardware.camera2.TotalCaptureResult;
import android.hardware.cts.helpers.CameraUtils;
import android.hardware.camera2.params.MeteringRectangle;
import android.hardware.camera2.params.MandatoryStreamCombination;
import android.hardware.camera2.params.MandatoryStreamCombination.MandatoryStreamInformation;
import android.hardware.camera2.params.MultiResolutionStreamConfigurationMap;
import android.hardware.camera2.params.MultiResolutionStreamInfo;
import android.hardware.camera2.params.OutputConfiguration;
import android.hardware.camera2.params.SessionConfiguration;
import android.hardware.camera2.params.StreamConfigurationMap;
import android.location.Location;
import android.location.LocationManager;
import android.media.ExifInterface;
import android.media.Image;
import android.media.ImageReader;
import android.media.ImageWriter;
import android.media.Image.Plane;
import android.os.Build;
import android.os.ConditionVariable;
import android.os.Handler;
import android.util.Log;
import android.util.Pair;
import android.util.Size;
import android.util.Range;
import android.view.Display;
import android.view.Surface;
import android.view.WindowManager;

import com.android.ex.camera2.blocking.BlockingCameraManager;
import com.android.ex.camera2.blocking.BlockingCameraManager.BlockingOpenException;
import com.android.ex.camera2.blocking.BlockingSessionCallback;
import com.android.ex.camera2.blocking.BlockingStateCallback;
import com.android.ex.camera2.exceptions.TimeoutRuntimeException;

import junit.framework.Assert;

import org.mockito.Mockito;

import java.io.FileOutputStream;
import java.io.IOException;
import java.lang.reflect.Array;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.Comparator;
import java.util.Date;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Set;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.Executor;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.text.ParseException;
import java.text.SimpleDateFormat;

/**
 * A package private utility class for wrapping up the camera2 cts test common utility functions
 */
public class CameraTestUtils extends Assert {
    private static final String TAG = ""CameraTestUtils"";
    private static final boolean VERBOSE = Log.isLoggable(TAG, Log.VERBOSE);
    private static final boolean DEBUG = Log.isLoggable(TAG, Log.DEBUG);
    public static final Size SIZE_BOUND_720P = new Size(1280, 720);
    public static final Size SIZE_BOUND_1080P = new Size(1920, 1088);
    public static final Size SIZE_BOUND_2K = new Size(2048, 1088);
    public static final Size SIZE_BOUND_QHD = new Size(2560, 1440);
    public static final Size SIZE_BOUND_2160P = new Size(3840, 2160);
    // Only test the preview size that is no larger than 1080p.
    public static final Size PREVIEW_SIZE_BOUND = SIZE_BOUND_1080P;
    // Default timeouts for reaching various states
    public static final int CAMERA_OPEN_TIMEOUT_MS = 3000;
    public static final int CAMERA_CLOSE_TIMEOUT_MS = 3000;
    public static final int CAMERA_IDLE_TIMEOUT_MS = 3000;
    public static final int CAMERA_ACTIVE_TIMEOUT_MS = 1000;
    public static final int CAMERA_BUSY_TIMEOUT_MS = 1000;
    public static final int CAMERA_UNCONFIGURED_TIMEOUT_MS = 1000;
    public static final int CAMERA_CONFIGURE_TIMEOUT_MS = 3000;
    public static final int CAPTURE_RESULT_TIMEOUT_MS = 3000;
    public static final int CAPTURE_IMAGE_TIMEOUT_MS = 3000;

    public static final int SESSION_CONFIGURE_TIMEOUT_MS = 3000;
    public static final int SESSION_CLOSE_TIMEOUT_MS = 3000;
    public static final int SESSION_READY_TIMEOUT_MS = 5000;
    public static final int SESSION_ACTIVE_TIMEOUT_MS = 1000;

    public static final int MAX_READER_IMAGES = 5;

    // Compensate for the loss of ""sensitivity"" and ""sensitivityBoost""
    public static final int MAX_ISO_MISMATCH = 3;

    public static final String OFFLINE_CAMERA_ID = ""offline_camera_id"";
    public static final String REPORT_LOG_NAME = ""CtsCameraTestCases"";

    private static final int EXIF_DATETIME_LENGTH = 19;
    private static final int EXIF_DATETIME_ERROR_MARGIN_SEC = 60;
    private static final float EXIF_FOCAL_LENGTH_ERROR_MARGIN = 0.001f;
    private static final float EXIF_EXPOSURE_TIME_ERROR_MARGIN_RATIO = 0.05f;
    private static final float EXIF_EXPOSURE_TIME_MIN_ERROR_MARGIN_SEC = 0.002f;
    private static final float EXIF_APERTURE_ERROR_MARGIN = 0.001f;

    private static final float ZOOM_RATIO_THRESHOLD = 0.01f;

    private static final Location sTestLocation0 = new Location(LocationManager.GPS_PROVIDER);
    private static final Location sTestLocation1 = new Location(LocationManager.GPS_PROVIDER);
    private static final Location sTestLocation2 = new Location(LocationManager.NETWORK_PROVIDER);

    static {
        sTestLocation0.setTime(1199145600000L);
        sTestLocation0.setLatitude(37.736071);
        sTestLocation0.setLongitude(-122.441983);
        sTestLocation0.setAltitude(21.0);

        sTestLocation1.setTime(1199145601000L);
        sTestLocation1.setLatitude(0.736071);
        sTestLocation1.setLongitude(0.441983);
        sTestLocation1.setAltitude(1.0);

        sTestLocation2.setTime(1199145602000L);
        sTestLocation2.setLatitude(-89.736071);
        sTestLocation2.setLongitude(-179.441983);
        sTestLocation2.setAltitude(100000.0);
    }

    // Exif test data vectors.
    public static final ExifTestData[] EXIF_TEST_DATA = {
            new ExifTestData(
                    /*gpsLocation*/ sTestLocation0,
                    /* orientation */90,
                    /* jpgQuality */(byte) 80,
                    /* thumbQuality */(byte) 75),
            new ExifTestData(
                    /*gpsLocation*/ sTestLocation1,
                    /* orientation */180,
                    /* jpgQuality */(byte) 90,
                    /* thumbQuality */(byte) 85),
            new ExifTestData(
                    /*gpsLocation*/ sTestLocation2,
                    /* orientation */270,
                    /* jpgQuality */(byte) 100,
                    /* thumbQuality */(byte) 100)
    };

    /**
     * Create an {@link android.media.ImageReader} object and get the surface.
     *
     * @param size The size of this ImageReader to be created.
     * @param format The format of this ImageReader to be created
     * @param maxNumImages The max number of images that can be acquired simultaneously.
     * @param listener The listener used by this ImageReader to notify callbacks.
     * @param handler The handler to use for any listener callbacks.
     */
    public static ImageReader makeImageReader(Size size, int format, int maxNumImages,
            ImageReader.OnImageAvailableListener listener, Handler handler) {
        ImageReader reader;
        reader = ImageReader.newInstance(size.getWidth(), size.getHeight(), format,
                maxNumImages);
        reader.setOnImageAvailableListener(listener, handler);
        if (VERBOSE) Log.v(TAG, ""Created ImageReader size "" + size);
        return reader;
    }

    /**
     * Create an ImageWriter and hook up the ImageListener.
     *
     * @param inputSurface The input surface of the ImageWriter.
     * @param maxImages The max number of Images that can be dequeued simultaneously.
     * @param listener The listener used by this ImageWriter to notify callbacks
     * @param handler The handler to post listener callbacks.
     * @return ImageWriter object created.
     */
    public static ImageWriter makeImageWriter(
            Surface inputSurface, int maxImages,
            ImageWriter.OnImageReleasedListener listener, Handler handler) {
        ImageWriter writer = ImageWriter.newInstance(inputSurface, maxImages);
        writer.setOnImageReleasedListener(listener, handler);
        return writer;
    }

    /**
     * Utility class to store the targets for mandatory stream combination test.
     */
    public static class StreamCombinationTargets {
        public List<SurfaceTexture> mPrivTargets = new ArrayList<>();
        public List<ImageReader> mJpegTargets = new ArrayList<>();
        public List<ImageReader> mYuvTargets = new ArrayList<>();
        public List<ImageReader> mY8Targets = new ArrayList<>();
        public List<ImageReader> mRawTargets = new ArrayList<>();
        public List<ImageReader> mHeicTargets = new ArrayList<>();
        public List<ImageReader> mDepth16Targets = new ArrayList<>();

        public List<MultiResolutionImageReader> mPrivMultiResTargets = new ArrayList<>();
        public List<MultiResolutionImageReader> mJpegMultiResTargets = new ArrayList<>();
        public List<MultiResolutionImageReader> mYuvMultiResTargets = new ArrayList<>();
        public List<MultiResolutionImageReader> mRawMultiResTargets = new ArrayList<>();

        public void close() {
            for (SurfaceTexture target : mPrivTargets) {
                target.release();
            }
            for (ImageReader target : mJpegTargets) {
                target.close();
            }
            for (ImageReader target : mYuvTargets) {
                target.close();
            }
            for (ImageReader target : mY8Targets) {
                target.close();
            }
            for (ImageReader target : mRawTargets) {
                target.close();
            }
            for (ImageReader target : mHeicTargets) {
                target.close();
            }
            for (ImageReader target : mDepth16Targets) {
                target.close();
            }

            for (MultiResolutionImageReader target : mPrivMultiResTargets) {
                target.close();
            }
            for (MultiResolutionImageReader target : mJpegMultiResTargets) {
                target.close();
            }
            for (MultiResolutionImageReader target : mYuvMultiResTargets) {
                target.close();
            }
            for (MultiResolutionImageReader target : mRawMultiResTargets) {
                target.close();
            }
        }
    }

    private static void configureTarget(StreamCombinationTargets targets,
            List<OutputConfiguration> outputConfigs, List<Surface> outputSurfaces,
            int format, Size targetSize, int numBuffers, String overridePhysicalCameraId,
            MultiResolutionStreamConfigurationMap multiResStreamConfig,
            boolean createMultiResiStreamConfig, ImageDropperListener listener, Handler handler) {
        if (createMultiResiStreamConfig) {
            Collection<MultiResolutionStreamInfo> multiResolutionStreams =
                    multiResStreamConfig.getOutputInfo(format);
            MultiResolutionImageReader multiResReader = new MultiResolutionImageReader(
                    multiResolutionStreams, format, numBuffers);
            multiResReader.setOnImageAvailableListener(listener, new HandlerExecutor(handler));
            Collection<OutputConfiguration> configs =
                    OutputConfiguration.createInstancesForMultiResolutionOutput(multiResReader);
            outputConfigs.addAll(configs);
            outputSurfaces.add(multiResReader.getSurface());
            switch (format) {
                case ImageFormat.PRIVATE:
                    targets.mPrivMultiResTargets.add(multiResReader);
                    break;
                case ImageFormat.JPEG:
                    targets.mJpegMultiResTargets.add(multiResReader);
                    break;
                case ImageFormat.YUV_420_888:
                    targets.mYuvMultiResTargets.add(multiResReader);
                    break;
                case ImageFormat.RAW_SENSOR:
                    targets.mRawMultiResTargets.add(multiResReader);
                    break;
                default:
                    fail(""Unknown/Unsupported output format "" + format);
            }
        } else {
            if (format == ImageFormat.PRIVATE) {
                SurfaceTexture target = new SurfaceTexture(/*random int*/1);
                target.setDefaultBufferSize(targetSize.getWidth(), targetSize.getHeight());
                OutputConfiguration config = new OutputConfiguration(new Surface(target));
                if (overridePhysicalCameraId != null) {
                    config.setPhysicalCameraId(overridePhysicalCameraId);
                }
                outputConfigs.add(config);
                outputSurfaces.add(config.getSurface());
                targets.mPrivTargets.add(target);
            } else {
                ImageReader target = ImageReader.newInstance(targetSize.getWidth(),
                        targetSize.getHeight(), format, numBuffers);
                target.setOnImageAvailableListener(listener, handler);
                OutputConfiguration config = new OutputConfiguration(target.getSurface());
                if (overridePhysicalCameraId != null) {
                    config.setPhysicalCameraId(overridePhysicalCameraId);
                }
                outputConfigs.add(config);
                outputSurfaces.add(config.getSurface());

                switch (format) {
                    case ImageFormat.JPEG:
                      targets.mJpegTargets.add(target);
                      break;
                    case ImageFormat.YUV_420_888:
                      targets.mYuvTargets.add(target);
                      break;
                    case ImageFormat.Y8:
                      targets.mY8Targets.add(target);
                      break;
                    case ImageFormat.RAW_SENSOR:
                      targets.mRawTargets.add(target);
                      break;
                    case ImageFormat.HEIC:
                      targets.mHeicTargets.add(target);
                      break;
                    case ImageFormat.DEPTH16:
                      targets.mDepth16Targets.add(target);
                      break;
                    default:
                      fail(""Unknown/Unsupported output format "" + format);
                }
            }
        }
    }

    public static void setupConfigurationTargets(List<MandatoryStreamInformation> streamsInfo,
            StreamCombinationTargets targets,
            List<OutputConfiguration> outputConfigs,
            List<Surface> outputSurfaces, int numBuffers,
            boolean substituteY8, boolean substituteHeic, String overridenPhysicalCameraId,
            MultiResolutionStreamConfigurationMap multiResStreamConfig, Handler handler) {
            List<Surface> uhSurfaces = new ArrayList<Surface>();
        setupConfigurationTargets(streamsInfo, targets, outputConfigs, outputSurfaces, uhSurfaces,
            numBuffers, substituteY8, substituteHeic, overridenPhysicalCameraId,
            multiResStreamConfig, handler);
    }

    public static void setupConfigurationTargets(List<MandatoryStreamInformation> streamsInfo,
            StreamCombinationTargets targets,
            List<OutputConfiguration> outputConfigs,
            List<Surface> outputSurfaces, List<Surface> uhSurfaces, int numBuffers,
            boolean substituteY8, boolean substituteHeic, String overridePhysicalCameraId,
            MultiResolutionStreamConfigurationMap multiResStreamConfig, Handler handler) {

        ImageDropperListener imageDropperListener = new ImageDropperListener();
        List<Surface> chosenSurfaces;
        for (MandatoryStreamInformation streamInfo : streamsInfo) {
            if (streamInfo.isInput()) {
                continue;
            }
            chosenSurfaces = outputSurfaces;
            if (streamInfo.isUltraHighResolution()) {
                chosenSurfaces = uhSurfaces;
            }
            int format = streamInfo.getFormat();
            if (substituteY8 && (format == ImageFormat.YUV_420_888)) {
                format = ImageFormat.Y8;
            } else if (substituteHeic && (format == ImageFormat.JPEG)) {
                format = ImageFormat.HEIC;
            }
            Size[] availableSizes = new Size[streamInfo.getAvailableSizes().size()];
            availableSizes = streamInfo.getAvailableSizes().toArray(availableSizes);
            Size targetSize = CameraTestUtils.getMaxSize(availableSizes);
            boolean createMultiResReader =
                    (multiResStreamConfig != null &&
                     !multiResStreamConfig.getOutputInfo(format).isEmpty() &&
                     streamInfo.isMaximumSize());
            switch (format) {
                case ImageFormat.PRIVATE:
                case ImageFormat.JPEG:
                case ImageFormat.YUV_420_888:
                case ImageFormat.Y8:
                case ImageFormat.HEIC:
                case ImageFormat.DEPTH16:
                {
                    configureTarget(targets, outputConfigs, chosenSurfaces, format,
                            targetSize, numBuffers, overridePhysicalCameraId, multiResStreamConfig,
                            createMultiResReader, imageDropperListener, handler);
                    break;
                }
                case ImageFormat.RAW_SENSOR: {
                    // targetSize could be null in the logical camera case where only
                    // physical camera supports RAW stream.
                    if (targetSize != null) {
                        configureTarget(targets, outputConfigs, chosenSurfaces, format,
                                targetSize, numBuffers, overridePhysicalCameraId,
                                multiResStreamConfig, createMultiResReader, imageDropperListener,
                                handler);
                    }
                    break;
                }
                default:
                    fail(""Unknown output format "" + format);
            }
        }
    }

    /**
     * Close pending images and clean up an {@link android.media.ImageReader} object.
     * @param reader an {@link android.media.ImageReader} to close.
     */
    public static void closeImageReader(ImageReader reader) {
        if (reader != null) {
            reader.close();
        }
    }

    /**
     * Close the pending images then close current active {@link ImageReader} objects.
     */
    public static void closeImageReaders(ImageReader[] readers) {
        if ((readers != null) && (readers.length > 0)) {
            for (ImageReader reader : readers) {
                CameraTestUtils.closeImageReader(reader);
            }
        }
    }

    /**
     * Close pending images and clean up an {@link android.media.ImageWriter} object.
     * @param writer an {@link android.media.ImageWriter} to close.
     */
    public static void closeImageWriter(ImageWriter writer) {
        if (writer != null) {
            writer.close();
        }
    }

    /**
     * Dummy listener that release the image immediately once it is available.
     *
     * <p>
     * It can be used for the case where we don't care the image data at all.
     * </p>
     */
    public static class ImageDropperListener implements ImageReader.OnImageAvailableListener {
        @Override
        public synchronized void onImageAvailable(ImageReader reader) {
            Image image = null;
            try {
                image = reader.acquireNextImage();
            } finally {
                if (image != null) {
                    image.close();
                    mImagesDropped++;
                }
            }
        }

        public synchronized int getImageCount() {
            return mImagesDropped;
        }

        public synchronized void resetImageCount() {
            mImagesDropped = 0;
        }

        private int mImagesDropped = 0;
    }

    /**
     * Image listener that release the image immediately after validating the image
     */
    public static class ImageVerifierListener implements ImageReader.OnImageAvailableListener {
        private Size mSize;
        private int mFormat;
        // Whether the parent ImageReader is valid or not. If the parent ImageReader
        // is destroyed, the acquired Image may become invalid.
        private boolean mReaderIsValid;

        public ImageVerifierListener(Size sz, int format) {
            mSize = sz;
            mFormat = format;
            mReaderIsValid = true;
        }

        public synchronized void onReaderDestroyed() {
            mReaderIsValid = false;
        }

        @Override
        public synchronized void onImageAvailable(ImageReader reader) {
            Image image = null;
            try {
                image = reader.acquireNextImage();
            } finally {
                if (image != null) {
                    // Should only do some quick validity checks in callback, as the ImageReader
                    // could be closed asynchronously, which will close all images acquired from
                    // this ImageReader.
                    checkImage(image, mSize.getWidth(), mSize.getHeight(), mFormat);
                    // checkAndroidImageFormat calls into underlying Image object, which could
                    // become invalid if the ImageReader is destroyed.
                    if (mReaderIsValid) {
                        checkAndroidImageFormat(image);
                    }
                    image.close();
                }
            }
        }
    }

    public static class SimpleImageReaderListener
            implements ImageReader.OnImageAvailableListener {
        private final LinkedBlockingQueue<Image> mQueue =
                new LinkedBlockingQueue<Image>();
        // Indicate whether this listener will drop images or not,
        // when the queued images reaches the reader maxImages
        private final boolean mAsyncMode;
        // maxImages held by the queue in async mode.
        private final int mMaxImages;

        /**
         * Create a synchronous SimpleImageReaderListener that queues the images
         * automatically when they are available, no image will be dropped. If
         * the caller doesn't call getImage(), the producer will eventually run
         * into buffer starvation.
         */
        public SimpleImageReaderListener() {
            mAsyncMode = false;
            mMaxImages = 0;
        }

        /**
         * Create a synchronous/asynchronous SimpleImageReaderListener that
         * queues the images automatically when they are available. For
         * asynchronous listener, image will be dropped if the queued images
         * reach to maxImages queued. If the caller doesn't call getImage(), the
         * producer will not be blocked. For synchronous listener, no image will
         * be dropped. If the caller doesn't call getImage(), the producer will
         * eventually run into buffer starvation.
         *
         * @param asyncMode If the listener is operating at asynchronous mode.
         * @param maxImages The max number of images held by this listener.
         */
        /**
         *
         * @param asyncMode
         */
        public SimpleImageReaderListener(boolean asyncMode, int maxImages) {
            mAsyncMode = asyncMode;
            mMaxImages = maxImages;
        }

        @Override
        public void onImageAvailable(ImageReader reader) {
            try {
                Image imge = reader.acquireNextImage();
                if (imge == null) {
                    return;
                }
                mQueue.put(imge);
                if (mAsyncMode && mQueue.size() >= mMaxImages) {
                    Image img = mQueue.poll();
                    img.close();
                }
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(
                        ""Can't handle InterruptedException in onImageAvailable"");
            }
        }

        /**
         * Get an image from the image reader.
         *
         * @param timeout Timeout value for the wait.
         * @return The image from the image reader.
         */
        public Image getImage(long timeout) throws InterruptedException {
            Image image = mQueue.poll(timeout, TimeUnit.MILLISECONDS);
            assertNotNull(""Wait for an image timed out in "" + timeout + ""ms"", image);
            return image;
        }

        /**
         * Drain the pending images held by this listener currently.
         *
         */
        public void drain() {
            while (!mQueue.isEmpty()) {
                Image image = mQueue.poll();
                assertNotNull(""Unable to get an image"", image);
                image.close();
            }
        }
    }

    public static class SimpleImageWriterListener implements ImageWriter.OnImageReleasedListener {
        private final Semaphore mImageReleasedSema = new Semaphore(0);
        private final ImageWriter mWriter;
        @Override
        public void onImageReleased(ImageWriter writer) {
            if (writer != mWriter) {
                return;
            }

            if (VERBOSE) {
                Log.v(TAG, ""Input image is released"");
            }
            mImageReleasedSema.release();
        }

        public SimpleImageWriterListener(ImageWriter writer) {
            if (writer == null) {
                throw new IllegalArgumentException(""writer cannot be null"");
            }
            mWriter = writer;
        }

        public void waitForImageReleased(long timeoutMs) throws InterruptedException {
            if (!mImageReleasedSema.tryAcquire(timeoutMs, TimeUnit.MILLISECONDS)) {
                fail(""wait for image available timed out after "" + timeoutMs + ""ms"");
            }
        }
    }

    public static class ImageAndMultiResStreamInfo {
        public final Image image;
        public final MultiResolutionStreamInfo streamInfo;

        public ImageAndMultiResStreamInfo(Image image, MultiResolutionStreamInfo streamInfo) {
            this.image = image;
            this.streamInfo = streamInfo;
        }
    }

    public static class SimpleMultiResolutionImageReaderListener
            implements ImageReader.OnImageAvailableListener {
        public SimpleMultiResolutionImageReaderListener(MultiResolutionImageReader owner,
                int maxBuffers, boolean acquireLatest) {
            mOwner = owner;
            mMaxBuffers = maxBuffers;
            mAcquireLatest = acquireLatest;
        }

        @Override
        public void onImageAvailable(ImageReader reader) {
            if (VERBOSE) Log.v(TAG, ""new image available"");

            if (mAcquireLatest) {
                mLastReader = reader;
                mImageAvailable.open();
            } else {
                if (mQueue.size() < mMaxBuffers) {
                    Image image = reader.acquireNextImage();
                    MultiResolutionStreamInfo multiResStreamInfo =
                            mOwner.getStreamInfoForImageReader(reader);
                    mQueue.offer(new ImageAndMultiResStreamInfo(image, multiResStreamInfo));
                }
            }
        }

        public ImageAndMultiResStreamInfo getAnyImageAndInfoAvailable(long timeoutMs)
                throws Exception {
            if (mAcquireLatest) {
                Image image = null;
                if (mImageAvailable.block(timeoutMs)) {
                    if (mLastReader != null) {
                        image = mLastReader.acquireLatestImage();
                        if (VERBOSE) Log.v(TAG, ""acquireLatestImage"");
                    } else {
                        fail(""invalid image reader"");
                    }
                    mImageAvailable.close();
                } else {
                    fail(""wait for image available time out after "" + timeoutMs + ""ms"");
                }
                return new ImageAndMultiResStreamInfo(image,
                        mOwner.getStreamInfoForImageReader(mLastReader));
            } else {
                ImageAndMultiResStreamInfo imageAndInfo = mQueue.poll(timeoutMs,
                        java.util.concurrent.TimeUnit.MILLISECONDS);
                if (imageAndInfo == null) {
                    fail(""wait for image available timed out after "" + timeoutMs + ""ms"");
                }
                return imageAndInfo;
            }
        }

        public void reset() {
            while (!mQueue.isEmpty()) {
                ImageAndMultiResStreamInfo imageAndInfo = mQueue.poll();
                assertNotNull(""Acquired image is not valid"", imageAndInfo.image);
                imageAndInfo.image.close();
            }
            mImageAvailable.close();
            mLastReader = null;
        }

        private LinkedBlockingQueue<ImageAndMultiResStreamInfo> mQueue =
                new LinkedBlockingQueue<ImageAndMultiResStreamInfo>();
        private final MultiResolutionImageReader mOwner;
        private final int mMaxBuffers;
        private final boolean mAcquireLatest;
        private ConditionVariable mImageAvailable = new ConditionVariable();
        private ImageReader mLastReader = null;
    }

    public static class SimpleCaptureCallback extends CameraCaptureSession.CaptureCallback {
        private final LinkedBlockingQueue<TotalCaptureResult> mQueue =
                new LinkedBlockingQueue<TotalCaptureResult>();
        private final LinkedBlockingQueue<CaptureFailure> mFailureQueue =
                new LinkedBlockingQueue<>();
        // (Surface, framenumber) pair for lost buffers
        private final LinkedBlockingQueue<Pair<Surface, Long>> mBufferLostQueue =
                new LinkedBlockingQueue<>();
        private final LinkedBlockingQueue<Integer> mAbortQueue =
                new LinkedBlockingQueue<>();
        // Pair<CaptureRequest, Long> is a pair of capture request and timestamp.
        private final LinkedBlockingQueue<Pair<CaptureRequest, Long>> mCaptureStartQueue =
                new LinkedBlockingQueue<>();
        // Pair<Int, Long> is a pair of sequence id and frame number
        private final LinkedBlockingQueue<Pair<Integer, Long>> mCaptureSequenceCompletedQueue =
                new LinkedBlockingQueue<>();

        private AtomicLong mNumFramesArrived = new AtomicLong(0);

        @Override
        public void onCaptureStarted(CameraCaptureSession session, CaptureRequest request,
                long timestamp, long frameNumber) {
            try {
                mCaptureStartQueue.put(new Pair(request, timestamp));
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(
                        ""Can't handle InterruptedException in onCaptureStarted"");
            }
        }

        @Override
        public void onCaptureCompleted(CameraCaptureSession session, CaptureRequest request,
                TotalCaptureResult result) {
            try {
                mNumFramesArrived.incrementAndGet();
                mQueue.put(result);
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(
                        ""Can't handle InterruptedException in onCaptureCompleted"");
            }
        }

        @Override
        public void onCaptureFailed(CameraCaptureSession session, CaptureRequest request,
                CaptureFailure failure) {
            try {
                mFailureQueue.put(failure);
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(
                        ""Can't handle InterruptedException in onCaptureFailed"");
            }
        }

        @Override
        public void onCaptureSequenceAborted(CameraCaptureSession session, int sequenceId) {
            try {
                mAbortQueue.put(sequenceId);
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(
                        ""Can't handle InterruptedException in onCaptureAborted"");
            }
        }

        @Override
        public void onCaptureSequenceCompleted(CameraCaptureSession session, int sequenceId,
                long frameNumber) {
            try {
                mCaptureSequenceCompletedQueue.put(new Pair(sequenceId, frameNumber));
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(
                        ""Can't handle InterruptedException in onCaptureSequenceCompleted"");
            }
        }

        @Override
        public void onCaptureBufferLost(CameraCaptureSession session,
                CaptureRequest request, Surface target, long frameNumber) {
            try {
                mBufferLostQueue.put(new Pair<>(target, frameNumber));
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(
                        ""Can't handle InterruptedException in onCaptureBufferLost"");
            }
        }

        public long getTotalNumFrames() {
            return mNumFramesArrived.get();
        }

        public CaptureResult getCaptureResult(long timeout) {
            return getTotalCaptureResult(timeout);
        }

        public TotalCaptureResult getCaptureResult(long timeout, long timestamp) {
            try {
                long currentTs = -1L;
                TotalCaptureResult result;
                while (true) {
                    result = mQueue.poll(timeout, TimeUnit.MILLISECONDS);
                    if (result == null) {
                        throw new RuntimeException(
                                ""Wait for a capture result timed out in "" + timeout + ""ms"");
                    }
                    currentTs = result.get(CaptureResult.SENSOR_TIMESTAMP);
                    if (currentTs == timestamp) {
                        return result;
                    }
                }

            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(""Unhandled interrupted exception"", e);
            }
        }

        public TotalCaptureResult getTotalCaptureResult(long timeout) {
            try {
                TotalCaptureResult result = mQueue.poll(timeout, TimeUnit.MILLISECONDS);
                assertNotNull(""Wait for a capture result timed out in "" + timeout + ""ms"", result);
                return result;
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(""Unhandled interrupted exception"", e);
            }
        }

        /**
         * Get the {@link #CaptureResult capture result} for a given
         * {@link #CaptureRequest capture request}.
         *
         * @param myRequest The {@link #CaptureRequest capture request} whose
         *            corresponding {@link #CaptureResult capture result} was
         *            being waited for
         * @param numResultsWait Number of frames to wait for the capture result
         *            before timeout.
         * @throws TimeoutRuntimeException If more than numResultsWait results are
         *            seen before the result matching myRequest arrives, or each
         *            individual wait for result times out after
         *            {@value #CAPTURE_RESULT_TIMEOUT_MS}ms.
         */
        public CaptureResult getCaptureResultForRequest(CaptureRequest myRequest,
                int numResultsWait) {
            return getTotalCaptureResultForRequest(myRequest, numResultsWait);
        }

        /**
         * Get the {@link #TotalCaptureResult total capture result} for a given
         * {@link #CaptureRequest capture request}.
         *
         * @param myRequest The {@link #CaptureRequest capture request} whose
         *            corresponding {@link #TotalCaptureResult capture result} was
         *            being waited for
         * @param numResultsWait Number of frames to wait for the capture result
         *            before timeout.
         * @throws TimeoutRuntimeException If more than numResultsWait results are
         *            seen before the result matching myRequest arrives, or each
         *            individual wait for result times out after
         *            {@value #CAPTURE_RESULT_TIMEOUT_MS}ms.
         */
        public TotalCaptureResult getTotalCaptureResultForRequest(CaptureRequest myRequest,
                int numResultsWait) {
            ArrayList<CaptureRequest> captureRequests = new ArrayList<>(1);
            captureRequests.add(myRequest);
            return getTotalCaptureResultsForRequests(captureRequests, numResultsWait)[0];
        }

        /**
         * Get an array of {@link #TotalCaptureResult total capture results} for a given list of
         * {@link #CaptureRequest capture requests}. This can be used when the order of results
         * may not the same as the order of requests.
         *
         * @param captureRequests The list of {@link #CaptureRequest capture requests} whose
         *            corresponding {@link #TotalCaptureResult capture results} are
         *            being waited for.
         * @param numResultsWait Number of frames to wait for the capture results
         *            before timeout.
         * @throws TimeoutRuntimeException If more than numResultsWait results are
         *            seen before all the results matching captureRequests arrives.
         */
        public TotalCaptureResult[] getTotalCaptureResultsForRequests(
                List<CaptureRequest> captureRequests, int numResultsWait) {
            if (numResultsWait < 0) {
                throw new IllegalArgumentException(""numResultsWait must be no less than 0"");
            }
            if (captureRequests == null || captureRequests.size() == 0) {
                throw new IllegalArgumentException(""captureRequests must have at least 1 request."");
            }

            // Create a request -> a list of result indices map that it will wait for.
            HashMap<CaptureRequest, ArrayList<Integer>> remainingResultIndicesMap = new HashMap<>();
            for (int i = 0; i < captureRequests.size(); i++) {
                CaptureRequest request = captureRequests.get(i);
                ArrayList<Integer> indices = remainingResultIndicesMap.get(request);
                if (indices == null) {
                    indices = new ArrayList<>();
                    remainingResultIndicesMap.put(request, indices);
                }
                indices.add(i);
            }

            TotalCaptureResult[] results = new TotalCaptureResult[captureRequests.size()];
            int i = 0;
            do {
                TotalCaptureResult result = getTotalCaptureResult(CAPTURE_RESULT_TIMEOUT_MS);
                CaptureRequest request = result.getRequest();
                ArrayList<Integer> indices = remainingResultIndicesMap.get(request);
                if (indices != null) {
                    results[indices.get(0)] = result;
                    indices.remove(0);

                    // Remove the entry if all results for this request has been fulfilled.
                    if (indices.isEmpty()) {
                        remainingResultIndicesMap.remove(request);
                    }
                }

                if (remainingResultIndicesMap.isEmpty()) {
                    return results;
                }
            } while (i++ < numResultsWait);

            throw new TimeoutRuntimeException(""Unable to get the expected capture result after ""
                    + ""waiting for "" + numResultsWait + "" results"");
        }

        /**
         * Get an array list of {@link #CaptureFailure capture failure} with maxNumFailures entries
         * at most. If it times out before maxNumFailures failures are received, return the failures
         * received so far.
         *
         * @param maxNumFailures The maximal number of failures to return. If it times out before
         *                       the maximal number of failures are received, return the received
         *                       failures so far.
         * @throws UnsupportedOperationException If an error happens while waiting on the failure.
         */
        public ArrayList<CaptureFailure> getCaptureFailures(long maxNumFailures) {
            ArrayList<CaptureFailure> failures = new ArrayList<>();
            try {
                for (int i = 0; i < maxNumFailures; i++) {
                    CaptureFailure failure = mFailureQueue.poll(CAPTURE_RESULT_TIMEOUT_MS,
                            TimeUnit.MILLISECONDS);
                    if (failure == null) {
                        // If waiting on a failure times out, return the failures so far.
                        break;
                    }
                    failures.add(failure);
                }
            }  catch (InterruptedException e) {
                throw new UnsupportedOperationException(""Unhandled interrupted exception"", e);
            }

            return failures;
        }

        /**
         * Get an array list of lost buffers with maxNumLost entries at most.
         * If it times out before maxNumLost buffer lost callbacks are received, return the
         * lost callbacks received so far.
         *
         * @param maxNumLost The maximal number of buffer lost failures to return. If it times out
         *                   before the maximal number of failures are received, return the received
         *                   buffer lost failures so far.
         * @throws UnsupportedOperationException If an error happens while waiting on the failure.
         */
        public ArrayList<Pair<Surface, Long>> getLostBuffers(long maxNumLost) {
            ArrayList<Pair<Surface, Long>> failures = new ArrayList<>();
            try {
                for (int i = 0; i < maxNumLost; i++) {
                    Pair<Surface, Long> failure = mBufferLostQueue.poll(CAPTURE_RESULT_TIMEOUT_MS,
                            TimeUnit.MILLISECONDS);
                    if (failure == null) {
                        // If waiting on a failure times out, return the failures so far.
                        break;
                    }
                    failures.add(failure);
                }
            }  catch (InterruptedException e) {
                throw new UnsupportedOperationException(""Unhandled interrupted exception"", e);
            }

            return failures;
        }

        /**
         * Get an array list of aborted capture sequence ids with maxNumAborts entries
         * at most. If it times out before maxNumAborts are received, return the aborted sequences
         * received so far.
         *
         * @param maxNumAborts The maximal number of aborted sequences to return. If it times out
         *                     before the maximal number of aborts are received, return the received
         *                     failed sequences so far.
         * @throws UnsupportedOperationException If an error happens while waiting on the failed
         *                                       sequences.
         */
        public ArrayList<Integer> geAbortedSequences(long maxNumAborts) {
            ArrayList<Integer> abortList = new ArrayList<>();
            try {
                for (int i = 0; i < maxNumAborts; i++) {
                    Integer abortSequence = mAbortQueue.poll(CAPTURE_RESULT_TIMEOUT_MS,
                            TimeUnit.MILLISECONDS);
                    if (abortSequence == null) {
                        break;
                    }
                    abortList.add(abortSequence);
                }
            }  catch (InterruptedException e) {
                throw new UnsupportedOperationException(""Unhandled interrupted exception"", e);
            }

            return abortList;
        }

        /**
         * Wait until the capture start of a request and expected timestamp arrives or it times
         * out after a number of capture starts.
         *
         * @param request The request for the capture start to wait for.
         * @param timestamp The timestamp for the capture start to wait for.
         * @param numCaptureStartsWait The number of capture start events to wait for before timing
         *                             out.
         */
        public void waitForCaptureStart(CaptureRequest request, Long timestamp,
                int numCaptureStartsWait) throws Exception {
            Pair<CaptureRequest, Long> expectedShutter = new Pair<>(request, timestamp);

            int i = 0;
            do {
                Pair<CaptureRequest, Long> shutter = mCaptureStartQueue.poll(
                        CAPTURE_RESULT_TIMEOUT_MS, TimeUnit.MILLISECONDS);

                if (shutter == null) {
                    throw new TimeoutRuntimeException(""Unable to get any more capture start "" +
                            ""event after waiting for "" + CAPTURE_RESULT_TIMEOUT_MS + "" ms."");
                } else if (expectedShutter.equals(shutter)) {
                    return;
                }

            } while (i++ < numCaptureStartsWait);

            throw new TimeoutRuntimeException(""Unable to get the expected capture start "" +
                    ""event after waiting for "" + numCaptureStartsWait + "" capture starts"");
        }

        /**
         * Wait until it receives capture sequence completed callback for a given squence ID.
         *
         * @param sequenceId The sequence ID of the capture sequence completed callback to wait for.
         * @param timeoutMs Time to wait for each capture sequence complete callback before
         *                  timing out.
         */
        public long getCaptureSequenceLastFrameNumber(int sequenceId, long timeoutMs) {
            try {
                while (true) {
                    Pair<Integer, Long> completedSequence =
                            mCaptureSequenceCompletedQueue.poll(timeoutMs, TimeUnit.MILLISECONDS);
                    assertNotNull(""Wait for a capture sequence completed timed out in "" +
                            timeoutMs + ""ms"", completedSequence);

                    if (completedSequence.first.equals(sequenceId)) {
                        return completedSequence.second.longValue();
                    }
                }
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(""Unhandled interrupted exception"", e);
            }
        }

        public boolean hasMoreResults()
        {
            return !mQueue.isEmpty();
        }

        public boolean hasMoreFailures()
        {
            return !mFailureQueue.isEmpty();
        }

        public int getNumLostBuffers()
        {
            return mBufferLostQueue.size();
        }

        public boolean hasMoreAbortedSequences()
        {
            return !mAbortQueue.isEmpty();
        }

        public void drain() {
            mQueue.clear();
            mNumFramesArrived.getAndSet(0);
            mFailureQueue.clear();
            mBufferLostQueue.clear();
            mCaptureStartQueue.clear();
            mAbortQueue.clear();
        }
    }

    public static boolean hasCapability(CameraCharacteristics characteristics, int capability) {
        int [] capabilities =
                characteristics.get(CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
        for (int c : capabilities) {
            if (c == capability) {
                return true;
            }
        }
        return false;
    }

    public static boolean isSystemCamera(CameraManager manager, String cameraId)
            throws CameraAccessException {
        CameraCharacteristics characteristics = manager.getCameraCharacteristics(cameraId);
        return hasCapability(characteristics,
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_SYSTEM_CAMERA);
    }

    public static String[] getCameraIdListForTesting(CameraManager manager,
            boolean getSystemCameras)
            throws CameraAccessException {
        String [] ids = manager.getCameraIdListNoLazy();
        List<String> idsForTesting = new ArrayList<String>();
        for (String id : ids) {
            boolean isSystemCamera = isSystemCamera(manager, id);
            if (getSystemCameras == isSystemCamera) {
                idsForTesting.add(id);
            }
        }
        return idsForTesting.toArray(new String[idsForTesting.size()]);
    }

    public static Set<Set<String>> getConcurrentCameraIds(CameraManager manager,
            boolean getSystemCameras)
            throws CameraAccessException {
        Set<String> cameraIds = new HashSet<String>(Arrays.asList(getCameraIdListForTesting(manager, getSystemCameras)));
        Set<Set<String>> combinations =  manager.getConcurrentCameraIds();
        Set<Set<String>> correctComb = new HashSet<Set<String>>();
        for (Set<String> comb : combinations) {
            Set<String> filteredIds = new HashSet<String>();
            for (String id : comb) {
                if (cameraIds.contains(id)) {
                    filteredIds.add(id);
                }
            }
            if (filteredIds.isEmpty()) {
                continue;
            }
            correctComb.add(filteredIds);
        }
        return correctComb;
    }

    /**
     * Block until the camera is opened.
     *
     * <p>Don't use this to test #onDisconnected/#onError since this will throw
     * an AssertionError if it fails to open the camera device.</p>
     *
     * @return CameraDevice opened camera device
     *
     * @throws IllegalArgumentException
     *            If the handler is null, or if the handler's looper is current.
     * @throws CameraAccessException
     *            If open fails immediately.
     * @throws BlockingOpenException
     *            If open fails after blocking for some amount of time.
     * @throws TimeoutRuntimeException
     *            If opening times out. Typically unrecoverable.
     */
    public static CameraDevice openCamera(CameraManager manager, String cameraId,
            CameraDevice.StateCallback listener, Handler handler) throws CameraAccessException,
            BlockingOpenException {

        /**
         * Although camera2 API allows 'null' Handler (it will just use the current
         * thread's Looper), this is not what we want for CTS.
         *
         * In CTS the default looper is used only to process events in between test runs,
         * so anything sent there would not be executed inside a test and the test would fail.
         *
         * In this case, BlockingCameraManager#openCamera performs the check for us.
         */
        return (new BlockingCameraManager(manager)).openCamera(cameraId, listener, handler);
    }


    /**
     * Block until the camera is opened.
     *
     * <p>Don't use this to test #onDisconnected/#onError since this will throw
     * an AssertionError if it fails to open the camera device.</p>
     *
     * @throws IllegalArgumentException
     *            If the handler is null, or if the handler's looper is current.
     * @throws CameraAccessException
     *            If open fails immediately.
     * @throws BlockingOpenException
     *            If open fails after blocking for some amount of time.
     * @throws TimeoutRuntimeException
     *            If opening times out. Typically unrecoverable.
     */
    public static CameraDevice openCamera(CameraManager manager, String cameraId, Handler handler)
            throws CameraAccessException,
            BlockingOpenException {
        return openCamera(manager, cameraId, /*listener*/null, handler);
    }

    /**
     * Configure a new camera session with output surfaces and type.
     *
     * @param camera The CameraDevice to be configured.
     * @param outputSurfaces The surface list that used for camera output.
     * @param listener The callback CameraDevice will notify when capture results are available.
     */
    public static CameraCaptureSession configureCameraSession(CameraDevice camera,
            List<Surface> outputSurfaces, boolean isHighSpeed,
            CameraCaptureSession.StateCallback listener, Handler handler)
            throws CameraAccessException {
        BlockingSessionCallback sessionListener = new BlockingSessionCallback(listener);
        if (isHighSpeed) {
            camera.createConstrainedHighSpeedCaptureSession(outputSurfaces,
                    sessionListener, handler);
        } else {
            camera.createCaptureSession(outputSurfaces, sessionListener, handler);
        }
        CameraCaptureSession session =
                sessionListener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);
        assertFalse(""Camera session should not be a reprocessable session"",
                session.isReprocessable());
        String sessionType = isHighSpeed ? ""High Speed"" : ""Normal"";
        assertTrue(""Capture session type must be "" + sessionType,
                isHighSpeed ==
                CameraConstrainedHighSpeedCaptureSession.class.isAssignableFrom(session.getClass()));

        return session;
    }

    /**
     * Build a new constrained camera session with output surfaces, type and recording session
     * parameters.
     *
     * @param camera The CameraDevice to be configured.
     * @param outputSurfaces The surface list that used for camera output.
     * @param listener The callback CameraDevice will notify when capture results are available.
     * @param initialRequest Initial request settings to use as session parameters.
     */
    public static CameraCaptureSession buildConstrainedCameraSession(CameraDevice camera,
            List<Surface> outputSurfaces, CameraCaptureSession.StateCallback listener,
            Handler handler, CaptureRequest initialRequest) throws CameraAccessException {
        BlockingSessionCallback sessionListener = new BlockingSessionCallback(listener);

        List<OutputConfiguration> outConfigurations = new ArrayList<>(outputSurfaces.size());
        for (Surface surface : outputSurfaces) {
            outConfigurations.add(new OutputConfiguration(surface));
        }
        SessionConfiguration sessionConfig = new SessionConfiguration(
                SessionConfiguration.SESSION_HIGH_SPEED, outConfigurations,
                new HandlerExecutor(handler), sessionListener);
        sessionConfig.setSessionParameters(initialRequest);
        camera.createCaptureSession(sessionConfig);

        CameraCaptureSession session =
                sessionListener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);
        assertFalse(""Camera session should not be a reprocessable session"",
                session.isReprocessable());
        assertTrue(""Capture session type must be High Speed"",
                CameraConstrainedHighSpeedCaptureSession.class.isAssignableFrom(
                        session.getClass()));

        return session;
    }

    /**
     * Configure a new camera session with output configurations.
     *
     * @param camera The CameraDevice to be configured.
     * @param outputs The OutputConfiguration list that is used for camera output.
     * @param listener The callback CameraDevice will notify when capture results are available.
     */
    public static CameraCaptureSession configureCameraSessionWithConfig(CameraDevice camera,
            List<OutputConfiguration> outputs,
            CameraCaptureSession.StateCallback listener, Handler handler)
            throws CameraAccessException {
        BlockingSessionCallback sessionListener = new BlockingSessionCallback(listener);
        camera.createCaptureSessionByOutputConfigurations(outputs, sessionListener, handler);
        CameraCaptureSession session =
                sessionListener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);
        assertFalse(""Camera session should not be a reprocessable session"",
                session.isReprocessable());
        return session;
    }

    /**
     * Try configure a new camera session with output configurations.
     *
     * @param camera The CameraDevice to be configured.
     * @param outputs The OutputConfiguration list that is used for camera output.
     * @param initialRequest The session parameters passed in during stream configuration
     * @param listener The callback CameraDevice will notify when capture results are available.
     */
    public static CameraCaptureSession tryConfigureCameraSessionWithConfig(CameraDevice camera,
            List<OutputConfiguration> outputs, CaptureRequest initialRequest,
            CameraCaptureSession.StateCallback listener, Handler handler)
            throws CameraAccessException {
        BlockingSessionCallback sessionListener = new BlockingSessionCallback(listener);
        SessionConfiguration sessionConfig = new SessionConfiguration(
                SessionConfiguration.SESSION_REGULAR, outputs, new HandlerExecutor(handler),
                sessionListener);
        sessionConfig.setSessionParameters(initialRequest);
        camera.createCaptureSession(sessionConfig);

        Integer[] sessionStates = {BlockingSessionCallback.SESSION_READY,
                                   BlockingSessionCallback.SESSION_CONFIGURE_FAILED};
        int state = sessionListener.getStateWaiter().waitForAnyOfStates(
                Arrays.asList(sessionStates), SESSION_CONFIGURE_TIMEOUT_MS);

        CameraCaptureSession session = null;
        if (state == BlockingSessionCallback.SESSION_READY) {
            session = sessionListener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);
            assertFalse(""Camera session should not be a reprocessable session"",
                    session.isReprocessable());
        }
        return session;
    }

    /**
     * Configure a new camera session with output surfaces and initial session parameters.
     *
     * @param camera The CameraDevice to be configured.
     * @param outputSurfaces The surface list that used for camera output.
     * @param listener The callback CameraDevice will notify when session is available.
     * @param handler The handler used to notify callbacks.
     * @param initialRequest Initial request settings to use as session parameters.
     */
    public static CameraCaptureSession configureCameraSessionWithParameters(CameraDevice camera,
            List<Surface> outputSurfaces, BlockingSessionCallback listener,
            Handler handler, CaptureRequest initialRequest) throws CameraAccessException {
        List<OutputConfiguration> outConfigurations = new ArrayList<>(outputSurfaces.size());
        for (Surface surface : outputSurfaces) {
            outConfigurations.add(new OutputConfiguration(surface));
        }
        SessionConfiguration sessionConfig = new SessionConfiguration(
                SessionConfiguration.SESSION_REGULAR, outConfigurations,
                new HandlerExecutor(handler), listener);
        sessionConfig.setSessionParameters(initialRequest);
        camera.createCaptureSession(sessionConfig);

        CameraCaptureSession session = listener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);
        assertFalse(""Camera session should not be a reprocessable session"",
                session.isReprocessable());
        assertFalse(""Capture session type must be regular"",
                CameraConstrainedHighSpeedCaptureSession.class.isAssignableFrom(
                        session.getClass()));

        return session;
    }

    /**
     * Configure a new camera session with output surfaces.
     *
     * @param camera The CameraDevice to be configured.
     * @param outputSurfaces The surface list that used for camera output.
     * @param listener The callback CameraDevice will notify when capture results are available.
     */
    public static CameraCaptureSession configureCameraSession(CameraDevice camera,
            List<Surface> outputSurfaces,
            CameraCaptureSession.StateCallback listener, Handler handler)
            throws CameraAccessException {

        return configureCameraSession(camera, outputSurfaces, /*isHighSpeed*/false,
                listener, handler);
    }

    public static CameraCaptureSession configureReprocessableCameraSession(CameraDevice camera,
            InputConfiguration inputConfiguration, List<Surface> outputSurfaces,
            CameraCaptureSession.StateCallback listener, Handler handler)
            throws CameraAccessException {
        List<OutputConfiguration> outputConfigs = new ArrayList<OutputConfiguration>();
        for (Surface surface : outputSurfaces) {
            outputConfigs.add(new OutputConfiguration(surface));
        }
        CameraCaptureSession session = configureReprocessableCameraSessionWithConfigurations(
                camera, inputConfiguration, outputConfigs, listener, handler);

        return session;
    }

    public static CameraCaptureSession configureReprocessableCameraSessionWithConfigurations(
            CameraDevice camera, InputConfiguration inputConfiguration,
            List<OutputConfiguration> outputConfigs, CameraCaptureSession.StateCallback listener,
            Handler handler) throws CameraAccessException {
        BlockingSessionCallback sessionListener = new BlockingSessionCallback(listener);
        SessionConfiguration sessionConfig = new SessionConfiguration(
                SessionConfiguration.SESSION_REGULAR, outputConfigs, new HandlerExecutor(handler),
                sessionListener);
        sessionConfig.setInputConfiguration(inputConfiguration);
        camera.createCaptureSession(sessionConfig);

        Integer[] sessionStates = {BlockingSessionCallback.SESSION_READY,
                                   BlockingSessionCallback.SESSION_CONFIGURE_FAILED};
        int state = sessionListener.getStateWaiter().waitForAnyOfStates(
                Arrays.asList(sessionStates), SESSION_CONFIGURE_TIMEOUT_MS);

        assertTrue(""Creating a reprocessable session failed."",
                state == BlockingSessionCallback.SESSION_READY);
        CameraCaptureSession session =
                sessionListener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);
        assertTrue(""Camera session should be a reprocessable session"", session.isReprocessable());

        return session;
    }

    /**
     * Create a reprocessable camera session with input and output configurations.
     *
     * @param camera The CameraDevice to be configured.
     * @param inputConfiguration The input configuration used to create this session.
     * @param outputs The output configurations used to create this session.
     * @param listener The callback CameraDevice will notify when capture results are available.
     * @param handler The handler used to notify callbacks.
     * @return The session ready to use.
     * @throws CameraAccessException
     */
    public static CameraCaptureSession configureReprocCameraSessionWithConfig(CameraDevice camera,
            InputConfiguration inputConfiguration, List<OutputConfiguration> outputs,
            CameraCaptureSession.StateCallback listener, Handler handler)
            throws CameraAccessException {
        BlockingSessionCallback sessionListener = new BlockingSessionCallback(listener);
        camera.createReprocessableCaptureSessionByConfigurations(inputConfiguration, outputs,
                sessionListener, handler);

        Integer[] sessionStates = {BlockingSessionCallback.SESSION_READY,
                                   BlockingSessionCallback.SESSION_CONFIGURE_FAILED};
        int state = sessionListener.getStateWaiter().waitForAnyOfStates(
                Arrays.asList(sessionStates), SESSION_CONFIGURE_TIMEOUT_MS);

        assertTrue(""Creating a reprocessable session failed."",
                state == BlockingSessionCallback.SESSION_READY);

        CameraCaptureSession session =
                sessionListener.waitAndGetSession(SESSION_CONFIGURE_TIMEOUT_MS);
        assertTrue(""Camera session should be a reprocessable session"", session.isReprocessable());

        return session;
    }

    public static <T> void assertArrayNotEmpty(T arr, String message) {
        assertTrue(message, arr != null && Array.getLength(arr) > 0);
    }

    /**
     * Check if the format is a legal YUV format camera supported.
     */
    public static void checkYuvFormat(int format) {
        if ((format != ImageFormat.YUV_420_888) &&
                (format != ImageFormat.NV21) &&
                (format != ImageFormat.YV12)) {
            fail(""Wrong formats: "" + format);
        }
    }

    /**
     * Check if image size and format match given size and format.
     */
    public static void checkImage(Image image, int width, int height, int format) {
        // Image reader will wrap YV12/NV21 image by YUV_420_888
        if (format == ImageFormat.NV21 || format == ImageFormat.YV12) {
            format = ImageFormat.YUV_420_888;
        }
        assertNotNull(""Input image is invalid"", image);
        assertEquals(""Format doesn't match"", format, image.getFormat());
        assertEquals(""Width doesn't match"", width, image.getWidth());
        assertEquals(""Height doesn't match"", height, image.getHeight());
    }

    /**
     * <p>Read data from all planes of an Image into a contiguous unpadded, unpacked
     * 1-D linear byte array, such that it can be write into disk, or accessed by
     * software conveniently. It supports YUV_420_888/NV21/YV12 and JPEG input
     * Image format.</p>
     *
     * <p>For YUV_420_888/NV21/YV12/Y8/Y16, it returns a byte array that contains
     * the Y plane data first, followed by U(Cb), V(Cr) planes if there is any
     * (xstride = width, ystride = height for chroma and luma components).</p>
     *
     * <p>For JPEG, it returns a 1-D byte array contains a complete JPEG image.</p>
     *
     * <p>For YUV P010, it returns a byte array that contains Y plane first, followed
     * by the interleaved U(Cb)/V(Cr) plane.</p>
     */
    public static byte[] getDataFromImage(Image image) {
        assertNotNull(""Invalid image:"", image);
        int format = image.getFormat();
        int width = image.getWidth();
        int height = image.getHeight();
        int rowStride, pixelStride;
        byte[] data = null;

        // Read image data
        Plane[] planes = image.getPlanes();
        assertTrue(""Fail to get image planes"", planes != null && planes.length > 0);

        // Check image validity
        checkAndroidImageFormat(image);

        ByteBuffer buffer = null;
        // JPEG doesn't have pixelstride and rowstride, treat it as 1D buffer.
        // Same goes for DEPTH_POINT_CLOUD, RAW_PRIVATE, DEPTH_JPEG, and HEIC
        if (format == ImageFormat.JPEG || format == ImageFormat.DEPTH_POINT_CLOUD ||
                format == ImageFormat.RAW_PRIVATE || format == ImageFormat.DEPTH_JPEG ||
                format == ImageFormat.HEIC) {
            buffer = planes[0].getBuffer();
            assertNotNull(""Fail to get jpeg/depth/heic ByteBuffer"", buffer);
            data = new byte[buffer.remaining()];
            buffer.get(data);
            buffer.rewind();
            return data;
        } else if (format == ImageFormat.YCBCR_P010) {
            // P010 samples are stored within 16 bit values
            int offset = 0;
            int bytesPerPixelRounded = (ImageFormat.getBitsPerPixel(format) + 7) / 8;
            data = new byte[width * height * bytesPerPixelRounded];
            assertTrue(""Unexpected number of planes, expected "" + 3 + "" actual "" + planes.length,
                    planes.length == 3);
            for (int i = 0; i < 2; i++) {
                buffer = planes[i].getBuffer();
                assertNotNull(""Fail to get bytebuffer from plane"", buffer);
                buffer.rewind();
                rowStride = planes[i].getRowStride();
                if (VERBOSE) {
                    Log.v(TAG, ""rowStride "" + rowStride);
                    Log.v(TAG, ""width "" + width);
                    Log.v(TAG, ""height "" + height);
                }
                int h = (i == 0) ? height : height / 2;
                for (int row = 0; row < h; row++) {
                    int length = rowStride;
                    buffer.get(data, offset, length);
                    offset += length;
                }
                if (VERBOSE) Log.v(TAG, ""Finished reading data from plane "" + i);
                buffer.rewind();
            }
            return data;
        }

        int offset = 0;
        data = new byte[width * height * ImageFormat.getBitsPerPixel(format) / 8];
        int maxRowSize = planes[0].getRowStride();
        for (int i = 0; i < planes.length; i++) {
            if (maxRowSize < planes[i].getRowStride()) {
                maxRowSize = planes[i].getRowStride();
            }
        }
        byte[] rowData = new byte[maxRowSize];
        if(VERBOSE) Log.v(TAG, ""get data from "" + planes.length + "" planes"");
        for (int i = 0; i < planes.length; i++) {
            buffer = planes[i].getBuffer();
            assertNotNull(""Fail to get bytebuffer from plane"", buffer);
            buffer.rewind();
            rowStride = planes[i].getRowStride();
            pixelStride = planes[i].getPixelStride();
            assertTrue(""pixel stride "" + pixelStride + "" is invalid"", pixelStride > 0);
            if (VERBOSE) {
                Log.v(TAG, ""pixelStride "" + pixelStride);
                Log.v(TAG, ""rowStride "" + rowStride);
                Log.v(TAG, ""width "" + width);
                Log.v(TAG, ""height "" + height);
            }
            // For multi-planar yuv images, assuming yuv420 with 2x2 chroma subsampling.
            int w = (i == 0) ? width : width / 2;
            int h = (i == 0) ? height : height / 2;
            assertTrue(""rowStride "" + rowStride + "" should be >= width "" + w , rowStride >= w);
            for (int row = 0; row < h; row++) {
                int bytesPerPixel = ImageFormat.getBitsPerPixel(format) / 8;
                int length;
                if (pixelStride == bytesPerPixel) {
                    // Special case: optimized read of the entire row
                    length = w * bytesPerPixel;
                    buffer.get(data, offset, length);
                    offset += length;
                } else {
                    // Generic case: should work for any pixelStride but slower.
                    // Use intermediate buffer to avoid read byte-by-byte from
                    // DirectByteBuffer, which is very bad for performance
                    length = (w - 1) * pixelStride + bytesPerPixel;
                    buffer.get(rowData, 0, length);
                    for (int col = 0; col < w; col++) {
                        data[offset++] = rowData[col * pixelStride];
                    }
                }
                // Advance buffer the remainder of the row stride
                if (row < h - 1) {
                    buffer.position(buffer.position() + rowStride - length);
                }
            }
            if (VERBOSE) Log.v(TAG, ""Finished reading data from plane "" + i);
            buffer.rewind();
        }
        return data;
    }

    /**
     * <p>Check android image format validity for an image, only support below formats:</p>
     *
     * <p>YUV_420_888/NV21/YV12, can add more for future</p>
     */
    public static void checkAndroidImageFormat(Image image) {
        int format = image.getFormat();
        Plane[] planes = image.getPlanes();
        switch (format) {
            case ImageFormat.YUV_420_888:
            case ImageFormat.NV21:
            case ImageFormat.YV12:
            case ImageFormat.YCBCR_P010:
                assertEquals(""YUV420 format Images should have 3 planes"", 3, planes.length);
                break;
            case ImageFormat.JPEG:
            case ImageFormat.RAW_SENSOR:
            case ImageFormat.RAW_PRIVATE:
            case ImageFormat.DEPTH16:
            case ImageFormat.DEPTH_POINT_CLOUD:
            case ImageFormat.DEPTH_JPEG:
            case ImageFormat.Y8:
            case ImageFormat.HEIC:
                assertEquals(""JPEG/RAW/depth/Y8 Images should have one plane"", 1, planes.length);
                break;
            default:
                fail(""Unsupported Image Format: "" + format);
        }
    }

    public static void dumpFile(String fileName, Bitmap data) {
        FileOutputStream outStream;
        try {
            Log.v(TAG, ""output will be saved as "" + fileName);
            outStream = new FileOutputStream(fileName);
        } catch (IOException ioe) {
            throw new RuntimeException(""Unable to create debug output file "" + fileName, ioe);
        }

        try {
            data.compress(Bitmap.CompressFormat.JPEG, /*quality*/90, outStream);
            outStream.close();
        } catch (IOException ioe) {
            throw new RuntimeException(""failed writing data to file "" + fileName, ioe);
        }
    }

    public static void dumpFile(String fileName, byte[] data) {
        FileOutputStream outStream;
        try {
            Log.v(TAG, ""output will be saved as "" + fileName);
            outStream = new FileOutputStream(fileName);
        } catch (IOException ioe) {
            throw new RuntimeException(""Unable to create debug output file "" + fileName, ioe);
        }

        try {
            outStream.write(data);
            outStream.close();
        } catch (IOException ioe) {
            throw new RuntimeException(""failed writing data to file "" + fileName, ioe);
        }
    }

    /**
     * Get the available output sizes for the user-defined {@code format}.
     *
     * <p>Note that implementation-defined/hidden formats are not supported.</p>
     */
    public static Size[] getSupportedSizeForFormat(int format, String cameraId,
            CameraManager cameraManager) throws CameraAccessException {
        CameraCharacteristics properties = cameraManager.getCameraCharacteristics(cameraId);
        assertNotNull(""Can't get camera characteristics!"", properties);
        if (VERBOSE) {
            Log.v(TAG, ""get camera characteristics for camera: "" + cameraId);
        }
        StreamConfigurationMap configMap =
                properties.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
        Size[] availableSizes = configMap.getOutputSizes(format);
        assertArrayNotEmpty(availableSizes, ""availableSizes should not be empty for format: ""
                + format);
        Size[] highResAvailableSizes = configMap.getHighResolutionOutputSizes(format);
        if (highResAvailableSizes != null && highResAvailableSizes.length > 0) {
            Size[] allSizes = new Size[availableSizes.length + highResAvailableSizes.length];
            System.arraycopy(availableSizes, 0, allSizes, 0,
                    availableSizes.length);
            System.arraycopy(highResAvailableSizes, 0, allSizes, availableSizes.length,
                    highResAvailableSizes.length);
            availableSizes = allSizes;
        }
        if (VERBOSE) Log.v(TAG, ""Supported sizes are: "" + Arrays.deepToString(availableSizes));
        return availableSizes;
    }

    /**
     * Get the available output sizes for the given class.
     *
     */
    public static Size[] getSupportedSizeForClass(Class klass, String cameraId,
            CameraManager cameraManager) throws CameraAccessException {
        CameraCharacteristics properties = cameraManager.getCameraCharacteristics(cameraId);
        assertNotNull(""Can't get camera characteristics!"", properties);
        if (VERBOSE) {
            Log.v(TAG, ""get camera characteristics for camera: "" + cameraId);
        }
        StreamConfigurationMap configMap =
                properties.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
        Size[] availableSizes = configMap.getOutputSizes(klass);
        assertArrayNotEmpty(availableSizes, ""availableSizes should not be empty for class: ""
                + klass);
        Size[] highResAvailableSizes = configMap.getHighResolutionOutputSizes(ImageFormat.PRIVATE);
        if (highResAvailableSizes != null && highResAvailableSizes.length > 0) {
            Size[] allSizes = new Size[availableSizes.length + highResAvailableSizes.length];
            System.arraycopy(availableSizes, 0, allSizes, 0,
                    availableSizes.length);
            System.arraycopy(highResAvailableSizes, 0, allSizes, availableSizes.length,
                    highResAvailableSizes.length);
            availableSizes = allSizes;
        }
        if (VERBOSE) Log.v(TAG, ""Supported sizes are: "" + Arrays.deepToString(availableSizes));
        return availableSizes;
    }

    /**
     * Size comparator that compares the number of pixels it covers.
     *
     * <p>If two the areas of two sizes are same, compare the widths.</p>
     */
    public static class SizeComparator implements Comparator<Size> {
        @Override
        public int compare(Size lhs, Size rhs) {
            return CameraUtils
                    .compareSizes(lhs.getWidth(), lhs.getHeight(), rhs.getWidth(), rhs.getHeight());
        }
    }

    /**
     * Get sorted size list in descending order. Remove the sizes larger than
     * the bound. If the bound is null, don't do the size bound filtering.
     */
    static public List<Size> getSupportedPreviewSizes(String cameraId,
            CameraManager cameraManager, Size bound) throws CameraAccessException {

        Size[] rawSizes = getSupportedSizeForClass(android.view.SurfaceHolder.class, cameraId,
                cameraManager);
        assertArrayNotEmpty(rawSizes,
                ""Available sizes for SurfaceHolder class should not be empty"");
        if (VERBOSE) {
            Log.v(TAG, ""Supported sizes are: "" + Arrays.deepToString(rawSizes));
        }

        if (bound == null) {
            return getAscendingOrderSizes(Arrays.asList(rawSizes), /*ascending*/false);
        }

        List<Size> sizes = new ArrayList<Size>();
        for (Size sz: rawSizes) {
            if (sz.getWidth() <= bound.getWidth() && sz.getHeight() <= bound.getHeight()) {
                sizes.add(sz);
            }
        }
        return getAscendingOrderSizes(sizes, /*ascending*/false);
    }

    /**
     * Get a sorted list of sizes from a given size list.
     *
     * <p>
     * The size is compare by area it covers, if the areas are same, then
     * compare the widths.
     * </p>
     *
     * @param sizeList The input size list to be sorted
     * @param ascending True if the order is ascending, otherwise descending order
     * @return The ordered list of sizes
     */
    static public List<Size> getAscendingOrderSizes(final List<Size> sizeList, boolean ascending) {
        if (sizeList == null) {
            throw new IllegalArgumentException(""sizeList shouldn't be null"");
        }

        Comparator<Size> comparator = new SizeComparator();
        List<Size> sortedSizes = new ArrayList<Size>();
        sortedSizes.addAll(sizeList);
        Collections.sort(sortedSizes, comparator);
        if (!ascending) {
            Collections.reverse(sortedSizes);
        }

        return sortedSizes;
    }

    /**
     * Get sorted (descending order) size list for given format. Remove the sizes larger than
     * the bound. If the bound is null, don't do the size bound filtering.
     */
    static public List<Size> getSortedSizesForFormat(String cameraId,
            CameraManager cameraManager, int format, Size bound) throws CameraAccessException {
        Comparator<Size> comparator = new SizeComparator();
        Size[] sizes = getSupportedSizeForFormat(format, cameraId, cameraManager);
        List<Size> sortedSizes = null;
        if (bound != null) {
            sortedSizes = new ArrayList<Size>(/*capacity*/1);
            for (Size sz : sizes) {
                if (comparator.compare(sz, bound) <= 0) {
                    sortedSizes.add(sz);
                }
            }
        } else {
            sortedSizes = Arrays.asList(sizes);
        }
        assertTrue(""Supported size list should have at least one element"",
                sortedSizes.size() > 0);

        Collections.sort(sortedSizes, comparator);
        // Make it in descending order.
        Collections.reverse(sortedSizes);
        return sortedSizes;
    }

    /**
     * Get supported video size list for a given camera device.
     *
     * <p>
     * Filter out the sizes that are larger than the bound. If the bound is
     * null, don't do the size bound filtering.
     * </p>
     */
    static public List<Size> getSupportedVideoSizes(String cameraId,
            CameraManager cameraManager, Size bound) throws CameraAccessException {

        Size[] rawSizes = getSupportedSizeForClass(android.media.MediaRecorder.class,
                cameraId, cameraManager);
        assertArrayNotEmpty(rawSizes,
                ""Available sizes for MediaRecorder class should not be empty"");
        if (VERBOSE) {
            Log.v(TAG, ""Supported sizes are: "" + Arrays.deepToString(rawSizes));
        }

        if (bound == null) {
            return getAscendingOrderSizes(Arrays.asList(rawSizes), /*ascending*/false);
        }

        List<Size> sizes = new ArrayList<Size>();
        for (Size sz: rawSizes) {
            if (sz.getWidth() <= bound.getWidth() && sz.getHeight() <= bound.getHeight()) {
                sizes.add(sz);
            }
        }
        return getAscendingOrderSizes(sizes, /*ascending*/false);
    }

    /**
     * Get supported video size list (descending order) for a given camera device.
     *
     * <p>
     * Filter out the sizes that are larger than the bound. If the bound is
     * null, don't do the size bound filtering.
     * </p>
     */
    static public List<Size> getSupportedStillSizes(String cameraId,
            CameraManager cameraManager, Size bound) throws CameraAccessException {
        return getSortedSizesForFormat(cameraId, cameraManager, ImageFormat.JPEG, bound);
    }

    static public List<Size> getSupportedHeicSizes(String cameraId,
            CameraManager cameraManager, Size bound) throws CameraAccessException {
        return getSortedSizesForFormat(cameraId, cameraManager, ImageFormat.HEIC, bound);
    }

    static public Size getMinPreviewSize(String cameraId, CameraManager cameraManager)
            throws CameraAccessException {
        List<Size> sizes = getSupportedPreviewSizes(cameraId, cameraManager, null);
        return sizes.get(sizes.size() - 1);
    }

    /**
     * Get max supported preview size for a camera device.
     */
    static public Size getMaxPreviewSize(String cameraId, CameraManager cameraManager)
            throws CameraAccessException {
        return getMaxPreviewSize(cameraId, cameraManager, /*bound*/null);
    }

    /**
     * Get max preview size for a camera device in the supported sizes that are no larger
     * than the bound.
     */
    static public Size getMaxPreviewSize(String cameraId, CameraManager cameraManager, Size bound)
            throws CameraAccessException {
        List<Size> sizes = getSupportedPreviewSizes(cameraId, cameraManager, bound);
        return sizes.get(0);
    }

    /**
     * Get max depth size for a camera device.
     */
    static public Size getMaxDepthSize(String cameraId, CameraManager cameraManager)
            throws CameraAccessException {
        List<Size> sizes = getSortedSizesForFormat(cameraId, cameraManager, ImageFormat.DEPTH16,
                /*bound*/ null);
        return sizes.get(0);
    }

    /**
     * Get the largest size by area.
     *
     * @param sizes an array of sizes, must have at least 1 element
     *
     * @return Largest Size
     *
     * @throws IllegalArgumentException if sizes was null or had 0 elements
     */
    public static Size getMaxSize(Size... sizes) {
        if (sizes == null || sizes.length == 0) {
            throw new IllegalArgumentException(""sizes was empty"");
        }

        Size sz = sizes[0];
        for (Size size : sizes) {
            if (size.getWidth() * size.getHeight() > sz.getWidth() * sz.getHeight()) {
                sz = size;
            }
        }

        return sz;
    }

    /**
     * Get the largest size by area within (less than) bound
     *
     * @param sizes an array of sizes, must have at least 1 element
     *
     * @return Largest Size. Null if no such size exists within bound.
     *
     * @throws IllegalArgumentException if sizes was null or had 0 elements, or bound is invalid.
     */
    public static Size getMaxSizeWithBound(Size[] sizes, int bound) {
        if (sizes == null || sizes.length == 0) {
            throw new IllegalArgumentException(""sizes was empty"");
        }
        if (bound <= 0) {
            throw new IllegalArgumentException(""bound is invalid"");
        }

        Size sz = null;
        for (Size size : sizes) {
            if (size.getWidth() * size.getHeight() >= bound) {
                continue;
            }

            if (sz == null ||
                    size.getWidth() * size.getHeight() > sz.getWidth() * sz.getHeight()) {
                sz = size;
            }
        }

        return sz;
    }

    /**
     * Returns true if the given {@code array} contains the given element.
     *
     * @param array {@code array} to check for {@code elem}
     * @param elem {@code elem} to test for
     * @return {@code true} if the given element is contained
     */
    public static boolean contains(int[] array, int elem) {
        if (array == null) return false;
        for (int i = 0; i < array.length; i++) {
            if (elem == array[i]) return true;
        }
        return false;
    }

    /**
     * Get object array from byte array.
     *
     * @param array Input byte array to be converted
     * @return Byte object array converted from input byte array
     */
    public static Byte[] toObject(byte[] array) {
        return convertPrimitiveArrayToObjectArray(array, Byte.class);
    }

    /**
     * Get object array from int array.
     *
     * @param array Input int array to be converted
     * @return Integer object array converted from input int array
     */
    public static Integer[] toObject(int[] array) {
        return convertPrimitiveArrayToObjectArray(array, Integer.class);
    }

    /**
     * Get object array from float array.
     *
     * @param array Input float array to be converted
     * @return Float object array converted from input float array
     */
    public static Float[] toObject(float[] array) {
        return convertPrimitiveArrayToObjectArray(array, Float.class);
    }

    /**
     * Get object array from double array.
     *
     * @param array Input double array to be converted
     * @return Double object array converted from input double array
     */
    public static Double[] toObject(double[] array) {
        return convertPrimitiveArrayToObjectArray(array, Double.class);
    }

    /**
     * Convert a primitive input array into its object array version (e.g. from int[] to Integer[]).
     *
     * @param array Input array object
     * @param wrapperClass The boxed class it converts to
     * @return Boxed version of primitive array
     */
    private static <T> T[] convertPrimitiveArrayToObjectArray(final Object array,
            final Class<T> wrapperClass) {
        // getLength does the null check and isArray check already.
        int arrayLength = Array.getLength(array);
        if (arrayLength == 0) {
            throw new IllegalArgumentException(""Input array shouldn't be empty"");
        }

        @SuppressWarnings(""unchecked"")
        final T[] result = (T[]) Array.newInstance(wrapperClass, arrayLength);
        for (int i = 0; i < arrayLength; i++) {
            Array.set(result, i, Array.get(array, i));
        }
        return result;
    }

    /**
     * Validate image based on format and size.
     *
     * @param image The image to be validated.
     * @param width The image width.
     * @param height The image height.
     * @param format The image format.
     * @param filePath The debug dump file path, null if don't want to dump to
     *            file.
     * @throws UnsupportedOperationException if calling with an unknown format
     */
    public static void validateImage(Image image, int width, int height, int format,
            String filePath) {
        checkImage(image, width, height, format);

        /**
         * TODO: validate timestamp:
         * 1. capture result timestamp against the image timestamp (need
         * consider frame drops)
         * 2. timestamps should be monotonically increasing for different requests
         */
        if(VERBOSE) Log.v(TAG, ""validating Image"");
        byte[] data = getDataFromImage(image);
        assertTrue(""Invalid image data"", data != null && data.length > 0);

        switch (format) {
            // Clients must be able to process and handle depth jpeg images like any other
            // regular jpeg.
            case ImageFormat.DEPTH_JPEG:
            case ImageFormat.JPEG:
                validateJpegData(data, width, height, filePath);
                break;
            case ImageFormat.YCBCR_P010:
                validateP010Data(data, width, height, format, image.getTimestamp(), filePath);
                break;
            case ImageFormat.YUV_420_888:
            case ImageFormat.YV12:
                validateYuvData(data, width, height, format, image.getTimestamp(), filePath);
                break;
            case ImageFormat.RAW_SENSOR:
                validateRaw16Data(data, width, height, format, image.getTimestamp(), filePath);
                break;
            case ImageFormat.DEPTH16:
                validateDepth16Data(data, width, height, format, image.getTimestamp(), filePath);
                break;
            case ImageFormat.DEPTH_POINT_CLOUD:
                validateDepthPointCloudData(data, width, height, format, image.getTimestamp(), filePath);
                break;
            case ImageFormat.RAW_PRIVATE:
                validateRawPrivateData(data, width, height, image.getTimestamp(), filePath);
                break;
            case ImageFormat.Y8:
                validateY8Data(data, width, height, format, image.getTimestamp(), filePath);
                break;
            case ImageFormat.HEIC:
                validateHeicData(data, width, height, filePath);
                break;
            default:
                throw new UnsupportedOperationException(""Unsupported format for validation: ""
                        + format);
        }
    }

    public static class HandlerExecutor implements Executor {
        private final Handler mHandler;

        public HandlerExecutor(Handler handler) {
            assertNotNull(""handler must be valid"", handler);
            mHandler = handler;
        }

        @Override
        public void execute(Runnable runCmd) {
            mHandler.post(runCmd);
        }
    }

    /**
     * Provide a mock for {@link CameraDevice.StateCallback}.
     *
     * <p>Only useful because mockito can't mock {@link CameraDevice.StateCallback} which is an
     * abstract class.</p>
     *
     * <p>
     * Use this instead of other classes when needing to verify interactions, since
     * trying to spy on {@link BlockingStateCallback} (or others) will cause unnecessary extra
     * interactions which will cause false test failures.
     * </p>
     *
     */
    public static class MockStateCallback extends CameraDevice.StateCallback {

        @Override
        public void onOpened(CameraDevice camera) {
        }

        @Override
        public void onDisconnected(CameraDevice camera) {
        }

        @Override
        public void onError(CameraDevice camera, int error) {
        }

        private MockStateCallback() {}

        /**
         * Create a Mockito-ready mocked StateCallback.
         */
        public static MockStateCallback mock() {
            return Mockito.spy(new MockStateCallback());
        }
    }

    public static void validateJpegData(byte[] jpegData, int width, int height, String filePath) {
        BitmapFactory.Options bmpOptions = new BitmapFactory.Options();
        // DecodeBound mode: only parse the frame header to get width/height.
        // it doesn't decode the pixel.
        bmpOptions.inJustDecodeBounds = true;
        BitmapFactory.decodeByteArray(jpegData, 0, jpegData.length, bmpOptions);
        assertEquals(width, bmpOptions.outWidth);
        assertEquals(height, bmpOptions.outHeight);

        // Pixel decoding mode: decode whole image. check if the image data
        // is decodable here.
        assertNotNull(""Decoding jpeg failed"",
                BitmapFactory.decodeByteArray(jpegData, 0, jpegData.length));
        if (DEBUG && filePath != null) {
            String fileName =
                    filePath + ""/"" + width + ""x"" + height + "".jpeg"";
            dumpFile(fileName, jpegData);
        }
    }

    private static void validateYuvData(byte[] yuvData, int width, int height, int format,
            long ts, String filePath) {
        checkYuvFormat(format);
        if (VERBOSE) Log.v(TAG, ""Validating YUV data"");
        int expectedSize = width * height * ImageFormat.getBitsPerPixel(format) / 8;
        assertEquals(""Yuv data doesn't match"", expectedSize, yuvData.length);

        // TODO: Can add data validation for test pattern.

        if (DEBUG && filePath != null) {
            String fileName =
                    filePath + ""/"" + width + ""x"" + height + ""_"" + ts / 1e6 + "".yuv"";
            dumpFile(fileName, yuvData);
        }
    }

    private static void validateP010Data(byte[] p010Data, int width, int height, int format,
            long ts, String filePath) {
        if (VERBOSE) Log.v(TAG, ""Validating P010 data"");
        // The P010 10 bit samples are stored in two bytes so the size needs to be adjusted
        // accordingly.
        int bytesPerPixelRounded = (ImageFormat.getBitsPerPixel(format) + 7) / 8;
        int expectedSize = width * height * bytesPerPixelRounded;
        assertEquals(""P010 data doesn't match"", expectedSize, p010Data.length);

        if (DEBUG && filePath != null) {
            String fileName =
                    filePath + ""/"" + width + ""x"" + height + ""_"" + ts / 1e6 + "".p010"";
            dumpFile(fileName, p010Data);
        }
    }
    private static void validateRaw16Data(byte[] rawData, int width, int height, int format,
            long ts, String filePath) {
        if (VERBOSE) Log.v(TAG, ""Validating raw data"");
        int expectedSize = width * height * ImageFormat.getBitsPerPixel(format) / 8;
        assertEquals(""Raw data doesn't match"", expectedSize, rawData.length);

        // TODO: Can add data validation for test pattern.

        if (DEBUG && filePath != null) {
            String fileName =
                    filePath + ""/"" + width + ""x"" + height + ""_"" + ts / 1e6 + "".raw16"";
            dumpFile(fileName, rawData);
        }

        return;
    }

    private static void validateY8Data(byte[] rawData, int width, int height, int format,
            long ts, String filePath) {
        if (VERBOSE) Log.v(TAG, ""Validating Y8 data"");
        int expectedSize = width * height * ImageFormat.getBitsPerPixel(format) / 8;
        assertEquals(""Y8 data doesn't match"", expectedSize, rawData.length);

        // TODO: Can add data validation for test pattern.

        if (DEBUG && filePath != null) {
            String fileName =
                    filePath + ""/"" + width + ""x"" + height + ""_"" + ts / 1e6 + "".y8"";
            dumpFile(fileName, rawData);
        }

        return;
    }

    private static void validateRawPrivateData(byte[] rawData, int width, int height,
            long ts, String filePath) {
        if (VERBOSE) Log.v(TAG, ""Validating private raw data"");
        // Expect each RAW pixel should occupy at least one byte and no more than 30 bytes
        int expectedSizeMin = width * height;
        int expectedSizeMax = width * height * 30;

        assertTrue(""Opaque RAW size "" + rawData.length + ""out of normal bound ["" +
                expectedSizeMin + "","" + expectedSizeMax + ""]"",
                expectedSizeMin <= rawData.length && rawData.length <= expectedSizeMax);

        if (DEBUG && filePath != null) {
            String fileName =
                    filePath + ""/"" + width + ""x"" + height + ""_"" + ts / 1e6 + "".rawPriv"";
            dumpFile(fileName, rawData);
        }

        return;
    }

    private static void validateDepth16Data(byte[] depthData, int width, int height, int format,
            long ts, String filePath) {

        if (VERBOSE) Log.v(TAG, ""Validating depth16 data"");
        int expectedSize = width * height * ImageFormat.getBitsPerPixel(format) / 8;
        assertEquals(""Depth data doesn't match"", expectedSize, depthData.length);


        if (DEBUG && filePath != null) {
            String fileName =
                    filePath + ""/"" + width + ""x"" + height + ""_"" + ts / 1e6 + "".depth16"";
            dumpFile(fileName, depthData);
        }

        return;

    }

    private static void validateDepthPointCloudData(byte[] depthData, int width, int height, int format,
            long ts, String filePath) {

        if (VERBOSE) Log.v(TAG, ""Validating depth point cloud data"");

        // Can't validate size since it is variable

        if (DEBUG && filePath != null) {
            String fileName =
                    filePath + ""/"" + width + ""x"" + height + ""_"" + ts / 1e6 + "".depth_point_cloud"";
            dumpFile(fileName, depthData);
        }

        return;

    }

    private static void validateHeicData(byte[] heicData, int width, int height, String filePath) {
        BitmapFactory.Options bmpOptions = new BitmapFactory.Options();
        // DecodeBound mode: only parse the frame header to get width/height.
        // it doesn't decode the pixel.
        bmpOptions.inJustDecodeBounds = true;
        BitmapFactory.decodeByteArray(heicData, 0, heicData.length, bmpOptions);
        assertEquals(width, bmpOptions.outWidth);
        assertEquals(height, bmpOptions.outHeight);

        // Pixel decoding mode: decode whole image. check if the image data
        // is decodable here.
        assertNotNull(""Decoding heic failed"",
                BitmapFactory.decodeByteArray(heicData, 0, heicData.length));
        if (DEBUG && filePath != null) {
            String fileName =
                    filePath + ""/"" + width + ""x"" + height + "".heic"";
            dumpFile(fileName, heicData);
        }
    }

    public static <T> T getValueNotNull(CaptureResult result, CaptureResult.Key<T> key) {
        if (result == null) {
            throw new IllegalArgumentException(""Result must not be null"");
        }

        T value = result.get(key);
        assertNotNull(""Value of Key "" + key.getName() + ""shouldn't be null"", value);
        return value;
    }

    public static <T> T getValueNotNull(CameraCharacteristics characteristics,
            CameraCharacteristics.Key<T> key) {
        if (characteristics == null) {
            throw new IllegalArgumentException(""Camera characteristics must not be null"");
        }

        T value = characteristics.get(key);
        assertNotNull(""Value of Key "" + key.getName() + ""shouldn't be null"", value);
        return value;
    }

    /**
     * Get a crop region for a given zoom factor and center position.
     * <p>
     * The center position is normalized position in range of [0, 1.0], where
     * (0, 0) represents top left corner, (1.0. 1.0) represents bottom right
     * corner. The center position could limit the effective minimal zoom
     * factor, for example, if the center position is (0.75, 0.75), the
     * effective minimal zoom position becomes 2.0. If the requested zoom factor
     * is smaller than 2.0, a crop region with 2.0 zoom factor will be returned.
     * </p>
     * <p>
     * The aspect ratio of the crop region is maintained the same as the aspect
     * ratio of active array.
     * </p>
     *
     * @param zoomFactor The zoom factor to generate the crop region, it must be
     *            >= 1.0
     * @param center The normalized zoom center point that is in the range of [0, 1].
     * @param maxZoom The max zoom factor supported by this device.
     * @param activeArray The active array size of this device.
     * @return crop region for the given normalized center and zoom factor.
     */
    public static Rect getCropRegionForZoom(float zoomFactor, final PointF center,
            final float maxZoom, final Rect activeArray) {
        if (zoomFactor < 1.0) {
            throw new IllegalArgumentException(""zoom factor "" + zoomFactor + "" should be >= 1.0"");
        }
        if (center.x > 1.0 || center.x < 0) {
            throw new IllegalArgumentException(""center.x "" + center.x
                    + "" should be in range of [0, 1.0]"");
        }
        if (center.y > 1.0 || center.y < 0) {
            throw new IllegalArgumentException(""center.y "" + center.y
                    + "" should be in range of [0, 1.0]"");
        }
        if (maxZoom < 1.0) {
            throw new IllegalArgumentException(""max zoom factor "" + maxZoom + "" should be >= 1.0"");
        }
        if (activeArray == null) {
            throw new IllegalArgumentException(""activeArray must not be null"");
        }

        float minCenterLength = Math.min(Math.min(center.x, 1.0f - center.x),
                Math.min(center.y, 1.0f - center.y));
        float minEffectiveZoom =  0.5f / minCenterLength;
        if (minEffectiveZoom > maxZoom) {
            throw new IllegalArgumentException(""Requested center "" + center.toString() +
                    "" has minimal zoomable factor "" + minEffectiveZoom + "", which exceeds max""
                            + "" zoom factor "" + maxZoom);
        }

        if (zoomFactor < minEffectiveZoom) {
            Log.w(TAG, ""Requested zoomFactor "" + zoomFactor + "" < minimal zoomable factor ""
                    + minEffectiveZoom + "". It will be overwritten by "" + minEffectiveZoom);
            zoomFactor = minEffectiveZoom;
        }

        int cropCenterX = (int)(activeArray.width() * center.x);
        int cropCenterY = (int)(activeArray.height() * center.y);
        int cropWidth = (int) (activeArray.width() / zoomFactor);
        int cropHeight = (int) (activeArray.height() / zoomFactor);

        return new Rect(
                /*left*/cropCenterX - cropWidth / 2,
                /*top*/cropCenterY - cropHeight / 2,
                /*right*/ cropCenterX + cropWidth / 2,
                /*bottom*/cropCenterY + cropHeight / 2);
    }

    /**
     * Get AeAvailableTargetFpsRanges and sort them in descending order by max fps
     *
     * @param staticInfo camera static metadata
     * @return AeAvailableTargetFpsRanges in descending order by max fps
     */
    public static Range<Integer>[] getDescendingTargetFpsRanges(StaticMetadata staticInfo) {
        Range<Integer>[] fpsRanges = staticInfo.getAeAvailableTargetFpsRangesChecked();
        Arrays.sort(fpsRanges, new Comparator<Range<Integer>>() {
            public int compare(Range<Integer> r1, Range<Integer> r2) {
                return r2.getUpper() - r1.getUpper();
            }
        });
        return fpsRanges;
    }

    /**
     * Get AeAvailableTargetFpsRanges with max fps not exceeding 30
     *
     * @param staticInfo camera static metadata
     * @return AeAvailableTargetFpsRanges with max fps not exceeding 30
     */
    public static List<Range<Integer>> getTargetFpsRangesUpTo30(StaticMetadata staticInfo) {
        Range<Integer>[] fpsRanges = staticInfo.getAeAvailableTargetFpsRangesChecked();
        ArrayList<Range<Integer>> fpsRangesUpTo30 = new ArrayList<Range<Integer>>();
        for (Range<Integer> fpsRange : fpsRanges) {
            if (fpsRange.getUpper() <= 30) {
                fpsRangesUpTo30.add(fpsRange);
            }
        }
        return fpsRangesUpTo30;
    }

    /**
     * Get AeAvailableTargetFpsRanges with max fps greater than 30
     *
     * @param staticInfo camera static metadata
     * @return AeAvailableTargetFpsRanges with max fps greater than 30
     */
    public static List<Range<Integer>> getTargetFpsRangesGreaterThan30(StaticMetadata staticInfo) {
        Range<Integer>[] fpsRanges = staticInfo.getAeAvailableTargetFpsRangesChecked();
        ArrayList<Range<Integer>> fpsRangesGreaterThan30 = new ArrayList<Range<Integer>>();
        for (Range<Integer> fpsRange : fpsRanges) {
            if (fpsRange.getUpper() > 30) {
                fpsRangesGreaterThan30.add(fpsRange);
            }
        }
        return fpsRangesGreaterThan30;
    }

    /**
     * Calculate output 3A region from the intersection of input 3A region and cropped region.
     *
     * @param requestRegions The input 3A regions
     * @param cropRect The cropped region
     * @return expected 3A regions output in capture result
     */
    public static MeteringRectangle[] getExpectedOutputRegion(
            MeteringRectangle[] requestRegions, Rect cropRect){
        MeteringRectangle[] resultRegions = new MeteringRectangle[requestRegions.length];
        for (int i = 0; i < requestRegions.length; i++) {
            Rect requestRect = requestRegions[i].getRect();
            Rect resultRect = new Rect();
            boolean intersect = resultRect.setIntersect(requestRect, cropRect);
            resultRegions[i] = new MeteringRectangle(
                    resultRect,
                    intersect ? requestRegions[i].getMeteringWeight() : 0);
        }
        return resultRegions;
    }

    /**
     * Copy source image data to destination image.
     *
     * @param src The source image to be copied from.
     * @param dst The destination image to be copied to.
     * @throws IllegalArgumentException If the source and destination images have
     *             different format, size, or one of the images is not copyable.
     */
    public static void imageCopy(Image src, Image dst) {
        if (src == null || dst == null) {
            throw new IllegalArgumentException(""Images should be non-null"");
        }
        if (src.getFormat() != dst.getFormat()) {
            throw new IllegalArgumentException(""Src and dst images should have the same format"");
        }
        if (src.getFormat() == ImageFormat.PRIVATE ||
                dst.getFormat() == ImageFormat.PRIVATE) {
            throw new IllegalArgumentException(""PRIVATE format images are not copyable"");
        }

        Size srcSize = new Size(src.getWidth(), src.getHeight());
        Size dstSize = new Size(dst.getWidth(), dst.getHeight());
        if (!srcSize.equals(dstSize)) {
            throw new IllegalArgumentException(""source image size "" + srcSize + "" is different""
                    + "" with "" + ""destination image size "" + dstSize);
        }

        // TODO: check the owner of the dst image, it must be from ImageWriter, other source may
        // not be writable. Maybe we should add an isWritable() method in image class.

        Plane[] srcPlanes = src.getPlanes();
        Plane[] dstPlanes = dst.getPlanes();
        ByteBuffer srcBuffer = null;
        ByteBuffer dstBuffer = null;
        for (int i = 0; i < srcPlanes.length; i++) {
            srcBuffer = srcPlanes[i].getBuffer();
            dstBuffer = dstPlanes[i].getBuffer();
            int srcPos = srcBuffer.position();
            srcBuffer.rewind();
            dstBuffer.rewind();
            int srcRowStride = srcPlanes[i].getRowStride();
            int dstRowStride = dstPlanes[i].getRowStride();
            int srcPixStride = srcPlanes[i].getPixelStride();
            int dstPixStride = dstPlanes[i].getPixelStride();

            if (srcPixStride > 2 || dstPixStride > 2) {
                throw new IllegalArgumentException(""source pixel stride "" + srcPixStride +
                        "" with destination pixel stride "" + dstPixStride +
                        "" is not supported"");
            }

            if (srcRowStride == dstRowStride && srcPixStride == dstPixStride &&
                    srcPixStride == 1) {
                // Fast path, just copy the content in the byteBuffer all together.
                dstBuffer.put(srcBuffer);
            } else {
                Size effectivePlaneSize = getEffectivePlaneSizeForImage(src, i);
                int srcRowByteCount = srcRowStride;
                int dstRowByteCount = dstRowStride;
                byte[] srcDataRow = new byte[Math.max(srcRowStride, dstRowStride)];

                if (srcPixStride == dstPixStride && srcPixStride == 1) {
                    // Row by row copy case
                    for (int row = 0; row < effectivePlaneSize.getHeight(); row++) {
                        if (row == effectivePlaneSize.getHeight() - 1) {
                            // Special case for interleaved planes: need handle the last row
                            // carefully to avoid memory corruption. Check if we have enough bytes
                            // to copy.
                            srcRowByteCount = Math.min(srcRowByteCount, srcBuffer.remaining());
                            dstRowByteCount = Math.min(dstRowByteCount, dstBuffer.remaining());
                        }
                        srcBuffer.get(srcDataRow, /*offset*/0, srcRowByteCount);
                        dstBuffer.put(srcDataRow, /*offset*/0, dstRowByteCount);
                    }
                } else {
                    // Row by row per pixel copy case
                    byte[] dstDataRow = new byte[dstRowByteCount];
                    for (int row = 0; row < effectivePlaneSize.getHeight(); row++) {
                        if (row == effectivePlaneSize.getHeight() - 1) {
                            // Special case for interleaved planes: need handle the last row
                            // carefully to avoid memory corruption. Check if we have enough bytes
                            // to copy.
                            int remainingBytes = srcBuffer.remaining();
                            if (srcRowByteCount > remainingBytes) {
                                srcRowByteCount = remainingBytes;
                            }
                            remainingBytes = dstBuffer.remaining();
                            if (dstRowByteCount > remainingBytes) {
                                dstRowByteCount = remainingBytes;
                            }
                        }
                        srcBuffer.get(srcDataRow, /*offset*/0, srcRowByteCount);
                        int pos = dstBuffer.position();
                        dstBuffer.get(dstDataRow, /*offset*/0, dstRowByteCount);
                        dstBuffer.position(pos);
                        for (int x = 0; x < effectivePlaneSize.getWidth(); x++) {
                            dstDataRow[x * dstPixStride] = srcDataRow[x * srcPixStride];
                        }
                        dstBuffer.put(dstDataRow, /*offset*/0, dstRowByteCount);
                    }
                }
            }
            srcBuffer.position(srcPos);
            dstBuffer.rewind();
        }
    }

    private static Size getEffectivePlaneSizeForImage(Image image, int planeIdx) {
        switch (image.getFormat()) {
            case ImageFormat.YUV_420_888:
                if (planeIdx == 0) {
                    return new Size(image.getWidth(), image.getHeight());
                } else {
                    return new Size(image.getWidth() / 2, image.getHeight() / 2);
                }
            case ImageFormat.JPEG:
            case ImageFormat.RAW_SENSOR:
            case ImageFormat.RAW10:
            case ImageFormat.RAW12:
            case ImageFormat.DEPTH16:
                return new Size(image.getWidth(), image.getHeight());
            case ImageFormat.PRIVATE:
                return new Size(0, 0);
            default:
                throw new UnsupportedOperationException(
                        String.format(""Invalid image format %d"", image.getFormat()));
        }
    }

    /**
     * <p>
     * Checks whether the two images are strongly equal.
     * </p>
     * <p>
     * Two images are strongly equal if and only if the data, formats, sizes,
     * and timestamps are same. For {@link ImageFormat#PRIVATE PRIVATE} format
     * images, the image data is not not accessible thus the data comparison is
     * effectively skipped as the number of planes is zero.
     * </p>
     * <p>
     * Note that this method compares the pixel data even outside of the crop
     * region, which may not be necessary for general use case.
     * </p>
     *
     * @param lhsImg First image to be compared with.
     * @param rhsImg Second image to be compared with.
     * @return true if the two images are equal, false otherwise.
     * @throws IllegalArgumentException If either of image is null.
     */
    public static boolean isImageStronglyEqual(Image lhsImg, Image rhsImg) {
        if (lhsImg == null || rhsImg == null) {
            throw new IllegalArgumentException(""Images should be non-null"");
        }

        if (lhsImg.getFormat() != rhsImg.getFormat()) {
            Log.i(TAG, ""lhsImg format "" + lhsImg.getFormat() + "" is different with rhsImg format ""
                    + rhsImg.getFormat());
            return false;
        }

        if (lhsImg.getWidth() != rhsImg.getWidth()) {
            Log.i(TAG, ""lhsImg width "" + lhsImg.getWidth() + "" is different with rhsImg width ""
                    + rhsImg.getWidth());
            return false;
        }

        if (lhsImg.getHeight() != rhsImg.getHeight()) {
            Log.i(TAG, ""lhsImg height "" + lhsImg.getHeight() + "" is different with rhsImg height ""
                    + rhsImg.getHeight());
            return false;
        }

        if (lhsImg.getTimestamp() != rhsImg.getTimestamp()) {
            Log.i(TAG, ""lhsImg timestamp "" + lhsImg.getTimestamp()
                    + "" is different with rhsImg timestamp "" + rhsImg.getTimestamp());
            return false;
        }

        if (!lhsImg.getCropRect().equals(rhsImg.getCropRect())) {
            Log.i(TAG, ""lhsImg crop rect "" + lhsImg.getCropRect()
                    + "" is different with rhsImg crop rect "" + rhsImg.getCropRect());
            return false;
        }

        // Compare data inside of the image.
        Plane[] lhsPlanes = lhsImg.getPlanes();
        Plane[] rhsPlanes = rhsImg.getPlanes();
        ByteBuffer lhsBuffer = null;
        ByteBuffer rhsBuffer = null;
        for (int i = 0; i < lhsPlanes.length; i++) {
            lhsBuffer = lhsPlanes[i].getBuffer();
            rhsBuffer = rhsPlanes[i].getBuffer();
            lhsBuffer.rewind();
            rhsBuffer.rewind();
            // Special case for YUV420_888 buffer with different layout or
            // potentially differently interleaved U/V planes.
            if (lhsImg.getFormat() == ImageFormat.YUV_420_888 &&
                    (lhsPlanes[i].getPixelStride() != rhsPlanes[i].getPixelStride() ||
                     lhsPlanes[i].getRowStride() != rhsPlanes[i].getRowStride() ||
                     (lhsPlanes[i].getPixelStride() != 1))) {
                int width = getEffectivePlaneSizeForImage(lhsImg, i).getWidth();
                int height = getEffectivePlaneSizeForImage(lhsImg, i).getHeight();
                int rowSizeL = lhsPlanes[i].getRowStride();
                int rowSizeR = rhsPlanes[i].getRowStride();
                byte[] lhsRow = new byte[rowSizeL];
                byte[] rhsRow = new byte[rowSizeR];
                int pixStrideL = lhsPlanes[i].getPixelStride();
                int pixStrideR = rhsPlanes[i].getPixelStride();
                for (int r = 0; r < height; r++) {
                    if (r == height -1) {
                        rowSizeL = lhsBuffer.remaining();
                        rowSizeR = rhsBuffer.remaining();
                    }
                    lhsBuffer.get(lhsRow, /*offset*/0, rowSizeL);
                    rhsBuffer.get(rhsRow, /*offset*/0, rowSizeR);
                    for (int c = 0; c < width; c++) {
                        if (lhsRow[c * pixStrideL] != rhsRow[c * pixStrideR]) {
                            Log.i(TAG, String.format(
                                    ""byte buffers for plane %d row %d col %d don't match."",
                                    i, r, c));
                            return false;
                        }
                    }
                }
            } else {
                // Compare entire buffer directly
                if (!lhsBuffer.equals(rhsBuffer)) {
                    Log.i(TAG, ""byte buffers for plane "" +  i + "" don't match."");
                    return false;
                }
            }
        }

        return true;
    }

    /**
     * Set jpeg related keys in a capture request builder.
     *
     * @param builder The capture request builder to set the keys inl
     * @param exifData The exif data to set.
     * @param thumbnailSize The thumbnail size to set.
     * @param collector The camera error collector to collect errors.
     */
    public static void setJpegKeys(CaptureRequest.Builder builder, ExifTestData exifData,
            Size thumbnailSize, CameraErrorCollector collector) {
        builder.set(CaptureRequest.JPEG_THUMBNAIL_SIZE, thumbnailSize);
        builder.set(CaptureRequest.JPEG_GPS_LOCATION, exifData.gpsLocation);
        builder.set(CaptureRequest.JPEG_ORIENTATION, exifData.jpegOrientation);
        builder.set(CaptureRequest.JPEG_QUALITY, exifData.jpegQuality);
        builder.set(CaptureRequest.JPEG_THUMBNAIL_QUALITY,
                exifData.thumbnailQuality);

        // Validate request set and get.
        collector.expectEquals(""JPEG thumbnail size request set and get should match"",
                thumbnailSize, builder.get(CaptureRequest.JPEG_THUMBNAIL_SIZE));
        collector.expectTrue(""GPS locations request set and get should match."",
                areGpsFieldsEqual(exifData.gpsLocation,
                builder.get(CaptureRequest.JPEG_GPS_LOCATION)));
        collector.expectEquals(""JPEG orientation request set and get should match"",
                exifData.jpegOrientation,
                builder.get(CaptureRequest.JPEG_ORIENTATION));
        collector.expectEquals(""JPEG quality request set and get should match"",
                exifData.jpegQuality, builder.get(CaptureRequest.JPEG_QUALITY));
        collector.expectEquals(""JPEG thumbnail quality request set and get should match"",
                exifData.thumbnailQuality,
                builder.get(CaptureRequest.JPEG_THUMBNAIL_QUALITY));
    }

    /**
     * Simple validation of JPEG"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.OrientationEventListenerTest"	"testConstructor"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/OrientationEventListenerTest.java"	""	"public void testConstructor() {
        new MyOrientationEventListener(mContext);

        new MyOrientationEventListener(mContext, SensorManager.SENSOR_DELAY_UI);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.view.cts.OrientationEventListenerTest"	"testCanDetectOrientation"	"CtsViewTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/view/src/android/view/cts/OrientationEventListenerTest.java"	""	"public void testCanDetectOrientation() {
        SensorManager sm = (SensorManager)mContext.getSystemService(Context.SENSOR_SERVICE);
        // Orientation can only be detected if there is an accelerometer
        boolean hasSensor = (sm.getDefaultSensor(Sensor.TYPE_ACCELEROMETER) != null);

        MyOrientationEventListener listener = new MyOrientationEventListener(mContext);
        assertEquals(hasSensor, listener.canDetectOrientation());
    }

    private static class MyOrientationEventListener extends OrientationEventListener {
        public MyOrientationEventListener(Context context) {
            super(context);
        }

        public MyOrientationEventListener(Context context, int rate) {
            super(context, rate);
        }

        @Override
        public void onOrientationChanged(int orientation) {
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testSensorProperties"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testSensorProperties() {
        // sensor type: [getMinDelay()]
        Map<Integer, Object[]> expectedProperties = new HashMap<>(3);
        if(getContext().getPackageManager().hasSystemFeature(PackageManager.FEATURE_WATCH)) {
                expectedProperties.put(Sensor.TYPE_ACCELEROMETER, new Object[]{20000});
                expectedProperties.put(Sensor.TYPE_GYROSCOPE, new Object[]{20000});
        }else {
                expectedProperties.put(Sensor.TYPE_ACCELEROMETER, new Object[]{10000});
                expectedProperties.put(Sensor.TYPE_GYROSCOPE, new Object[]{10000});
        }
        expectedProperties.put(Sensor.TYPE_MAGNETIC_FIELD, new Object[]{100000});

        SensorManager sensorManager =
                (SensorManager) getContext().getSystemService(Context.SENSOR_SERVICE);
        assertNotNull(""SensorManager not present in the system."", sensorManager);
        for (Entry<Integer, Object[]> entry : expectedProperties.entrySet()) {
            Sensor sensor = sensorManager.getDefaultSensor(entry.getKey());
            if (sensor != null) {
                if (entry.getValue()[0] != null) {
                    int expected = (Integer) entry.getValue()[0];
                    String msg = String.format(
                            ""%s: min delay %dus expected to be less than or equal to %dus"",
                            sensor.getName(),
                            sensor.getMinDelay(),
                            expected);
                    assertTrue(msg, sensor.getMinDelay() <= expected);
                }
            }
        }
    }

    // TODO: Figure out if a better way to enumerate test cases programmatically exists that works
    // with CTS framework."	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelerometer_fastest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelerometer_fastest() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER, SensorManager.SENSOR_DELAY_FASTEST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelerometer_200hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelerometer_200hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER, RATE_200HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelerometer_100hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelerometer_100hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER, RATE_100HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelerometer_50hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelerometer_50hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER, RATE_50HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelerometer_25hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelerometer_25hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER, RATE_25HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelerometer_15hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelerometer_15hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER, RATE_15HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelerometer_10hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelerometer_10hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER, RATE_10HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelerometer_5hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelerometer_5hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER, RATE_5HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelerometer_1hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelerometer_1hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER, RATE_1HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelerometer_automotive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelerometer_automotive() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER, RATE_25HZ, true);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelUncalibrated_fastest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelUncalibrated_fastest() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED, SensorManager.SENSOR_DELAY_FASTEST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelUncalibrated_200hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelUncalibrated_200hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED, RATE_200HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelUncalibrated_100hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelUncalibrated_100hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED, RATE_100HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelUncalibrated_50hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelUncalibrated_50hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED, RATE_50HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelUncalibrated_25hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelUncalibrated_25hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED, RATE_25HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelUncalibrated_15hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelUncalibrated_15hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED, RATE_15HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelUncalibrated_10hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelUncalibrated_10hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED, RATE_10HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelUncalibrated_5hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelUncalibrated_5hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED, RATE_5HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testAccelUncalibrated_1hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testAccelUncalibrated_1hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED, RATE_1HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticField_fastest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticField_fastest() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD, SensorManager.SENSOR_DELAY_FASTEST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticField_200hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticField_200hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD, RATE_200HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticField_100hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticField_100hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD, RATE_100HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticField_50hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticField_50hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD, RATE_50HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticField_25hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticField_25hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD, RATE_25HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticField_15hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticField_15hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD, RATE_15HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticField_10hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticField_10hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD, RATE_10HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticField_5hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticField_5hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD, RATE_5HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticField_1hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticField_1hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD, RATE_1HZ);
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testOrientation_fastest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testOrientation_fastest() throws Throwable {
        runSensorTest(Sensor.TYPE_ORIENTATION, SensorManager.SENSOR_DELAY_FASTEST);
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testOrientation_200hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testOrientation_200hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ORIENTATION, RATE_200HZ);
    }
    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testOrientation_100hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testOrientation_100hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ORIENTATION, RATE_100HZ);
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testOrientation_50hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testOrientation_50hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ORIENTATION, RATE_50HZ);
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testOrientation_25hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testOrientation_25hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ORIENTATION, RATE_25HZ);
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testOrientation_15hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testOrientation_15hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ORIENTATION, RATE_15HZ);
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testOrientation_10hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testOrientation_10hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ORIENTATION, RATE_10HZ);
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testOrientation_5hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testOrientation_5hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ORIENTATION, RATE_5HZ);
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testOrientation_1hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testOrientation_1hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ORIENTATION, RATE_1HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscope_fastest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscope_fastest() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE, SensorManager.SENSOR_DELAY_FASTEST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscope_200hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscope_200hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE, RATE_200HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscope_100hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscope_100hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE, RATE_100HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscope_50hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscope_50hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE, RATE_50HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscope_25hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscope_25hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE, RATE_25HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscope_15hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscope_15hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE, RATE_15HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscope_10hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscope_10hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE, RATE_10HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscope_5hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscope_5hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE, RATE_5HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscope_1hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscope_1hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE, RATE_1HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testPressure_fastest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testPressure_fastest() throws Throwable {
        runSensorTest(Sensor.TYPE_PRESSURE, SensorManager.SENSOR_DELAY_FASTEST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testPressure_200hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testPressure_200hz() throws Throwable {
        runSensorTest(Sensor.TYPE_PRESSURE, RATE_200HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testPressure_100hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testPressure_100hz() throws Throwable {
        runSensorTest(Sensor.TYPE_PRESSURE, RATE_100HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testPressure_50hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testPressure_50hz() throws Throwable {
        runSensorTest(Sensor.TYPE_PRESSURE, RATE_50HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testPressure_25hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testPressure_25hz() throws Throwable {
        runSensorTest(Sensor.TYPE_PRESSURE, RATE_25HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testPressure_15hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testPressure_15hz() throws Throwable {
        runSensorTest(Sensor.TYPE_PRESSURE, RATE_15HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testPressure_10hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testPressure_10hz() throws Throwable {
        runSensorTest(Sensor.TYPE_PRESSURE, RATE_10HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testPressure_5hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testPressure_5hz() throws Throwable {
        runSensorTest(Sensor.TYPE_PRESSURE, RATE_5HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testPressure_1hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testPressure_1hz() throws Throwable {
        runSensorTest(Sensor.TYPE_PRESSURE, RATE_1HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGravity_fastest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGravity_fastest() throws Throwable {
        runSensorTest(Sensor.TYPE_GRAVITY, SensorManager.SENSOR_DELAY_FASTEST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGravity_200hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGravity_200hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GRAVITY, RATE_200HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGravity_100hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGravity_100hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GRAVITY, RATE_100HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGravity_50hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGravity_50hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GRAVITY, RATE_50HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGravity_25hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGravity_25hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GRAVITY, RATE_25HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGravity_15hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGravity_15hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GRAVITY, RATE_15HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGravity_10hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGravity_10hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GRAVITY, RATE_10HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGravity_5hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGravity_5hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GRAVITY, RATE_5HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGravity_1hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGravity_1hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GRAVITY, RATE_1HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testRotationVector_fastest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testRotationVector_fastest() throws Throwable {
        runSensorTest(Sensor.TYPE_ROTATION_VECTOR, SensorManager.SENSOR_DELAY_FASTEST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testRotationVector_200hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testRotationVector_200hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ROTATION_VECTOR, RATE_200HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testRotationVector_100hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testRotationVector_100hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ROTATION_VECTOR, RATE_100HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testRotationVector_50hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testRotationVector_50hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ROTATION_VECTOR, RATE_50HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testRotationVector_25hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testRotationVector_25hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ROTATION_VECTOR, RATE_25HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testRotationVector_15hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testRotationVector_15hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ROTATION_VECTOR, RATE_15HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testRotationVector_10hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testRotationVector_10hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ROTATION_VECTOR, RATE_10HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testRotationVector_5hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testRotationVector_5hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ROTATION_VECTOR, RATE_5HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testRotationVector_1hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testRotationVector_1hz() throws Throwable {
        runSensorTest(Sensor.TYPE_ROTATION_VECTOR, RATE_1HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticFieldUncalibrated_fastest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticFieldUncalibrated_fastest() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, SensorManager.SENSOR_DELAY_FASTEST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticFieldUncalibrated_200hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticFieldUncalibrated_200hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, RATE_200HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticFieldUncalibrated_100hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticFieldUncalibrated_100hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, RATE_100HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticFieldUncalibrated_50hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticFieldUncalibrated_50hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, RATE_50HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticFieldUncalibrated_25hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticFieldUncalibrated_25hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, RATE_25HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticFieldUncalibrated_15hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticFieldUncalibrated_15hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, RATE_15HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticFieldUncalibrated_10hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticFieldUncalibrated_10hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, RATE_10HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticFieldUncalibrated_5hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticFieldUncalibrated_5hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, RATE_5HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testMagneticFieldUncalibrated_1hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testMagneticFieldUncalibrated_1hz() throws Throwable {
        runSensorTest(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, RATE_1HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGameRotationVector_fastest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGameRotationVector_fastest() throws Throwable {
        runSensorTest(Sensor.TYPE_GAME_ROTATION_VECTOR, SensorManager.SENSOR_DELAY_FASTEST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGameRotationVector_200hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGameRotationVector_200hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GAME_ROTATION_VECTOR, RATE_200HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGameRotationVector_100hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGameRotationVector_100hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GAME_ROTATION_VECTOR, RATE_100HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGameRotationVector_50hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGameRotationVector_50hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GAME_ROTATION_VECTOR, RATE_50HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGameRotationVector_25hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGameRotationVector_25hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GAME_ROTATION_VECTOR, RATE_25HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGameRotationVector_15hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGameRotationVector_15hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GAME_ROTATION_VECTOR, RATE_15HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGameRotationVector_10hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGameRotationVector_10hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GAME_ROTATION_VECTOR, RATE_10HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGameRotationVector_5hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGameRotationVector_5hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GAME_ROTATION_VECTOR, RATE_5HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGameRotationVector_1hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGameRotationVector_1hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GAME_ROTATION_VECTOR, RATE_1HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscopeUncalibrated_fastest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscopeUncalibrated_fastest() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, SensorManager.SENSOR_DELAY_FASTEST);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscopeUncalibrated_200hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscopeUncalibrated_200hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, RATE_200HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscopeUncalibrated_100hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscopeUncalibrated_100hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, RATE_100HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscopeUncalibrated_50hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscopeUncalibrated_50hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, RATE_50HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscopeUncalibrated_25hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscopeUncalibrated_25hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, RATE_25HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscopeUncalibrated_15hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscopeUncalibrated_15hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, RATE_15HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscopeUncalibrated_10hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscopeUncalibrated_10hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, RATE_10HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscopeUncalibrated_5hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscopeUncalibrated_5hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, RATE_5HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testGyroscopeUncalibrated_1hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testGyroscopeUncalibrated_1hz() throws Throwable {
        runSensorTest(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, RATE_1HZ);
    }

    public void  testGeomagneticRotationVector_fastest() throws Throwable {
        runSensorTest(Sensor.TYPE_GEOMAGNETIC_ROTATION_VECTOR, SensorManager.SENSOR_DELAY_FASTEST);
    }

    public void  testLinearAcceleration_200hz() throws Throwable {
        runSensorTest(Sensor.TYPE_LINEAR_ACCELERATION, RATE_200HZ);
    }

    public void  testLinearAcceleration_100hz() throws Throwable {
        runSensorTest(Sensor.TYPE_LINEAR_ACCELERATION, RATE_100HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testLinearAcceleration_50hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testLinearAcceleration_50hz() throws Throwable {
        runSensorTest(Sensor.TYPE_LINEAR_ACCELERATION, RATE_50HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testLinearAcceleration_25hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testLinearAcceleration_25hz() throws Throwable {
        runSensorTest(Sensor.TYPE_LINEAR_ACCELERATION, RATE_25HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testLinearAcceleration_15hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testLinearAcceleration_15hz() throws Throwable {
        runSensorTest(Sensor.TYPE_LINEAR_ACCELERATION, RATE_15HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testLinearAcceleration_10hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testLinearAcceleration_10hz() throws Throwable {
        runSensorTest(Sensor.TYPE_LINEAR_ACCELERATION, RATE_10HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testLinearAcceleration_5hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testLinearAcceleration_5hz() throws Throwable {
        runSensorTest(Sensor.TYPE_LINEAR_ACCELERATION, RATE_5HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SingleSensorTests"	"testLinearAcceleration_1hz"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SingleSensorTests.java"	""	"public void testLinearAcceleration_1hz() throws Throwable {
        runSensorTest(Sensor.TYPE_LINEAR_ACCELERATION, RATE_1HZ);
    }

    private void runSensorTest(int sensorType, int rateUs) throws Throwable {
        runSensorTest(sensorType, rateUs, false);
    }

    private void runSensorTest(int sensorType, int rateUs,
            boolean isAutomotiveSpecificTest) throws Throwable {
        SensorCtsHelper.sleep(3, TimeUnit.SECONDS);
        TestSensorEnvironment environment = new TestSensorEnvironment(
                getContext(),
                sensorType,
                shouldEmulateSensorUnderLoad(),
                rateUs,
                isAutomotiveSpecificTest);
        TestSensorOperation op =
                TestSensorOperation.createOperation(environment, 5, TimeUnit.SECONDS);
        op.addDefaultVerifications();

        try {
            op.execute(getCurrentTestNode());
        } finally {
            SensorStats stats = op.getStats();
            stats.log(TAG);

            String fileName = String.format(
                    ""single_%s_%s.txt"",
                    SensorStats.getSanitizedSensorName(environment.getSensor()),
                    environment.getFrequencyString());
            stats.logToFile(environment.getContext(), fileName);
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.helpers.OpenCVLibrary"	"isLoaded"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/helpers/OpenCVLibrary.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.helpers;

import android.content.ComponentName;
import android.content.Context;
import android.content.Intent;
import android.content.ServiceConnection;
import android.os.IBinder;
import android.util.Log;

import org.opencv.android.BaseLoaderCallback;
import org.opencv.android.LoaderCallbackInterface;
import org.opencv.android.OpenCVLoader;

import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

/**
 * OpenCV library loader class
 */
public class OpenCVLibrary {

    private final static String TAG = ""OpenCVLibraryProbe"";
    private final static int ASYNC_LOAD_TIMEOUT_SEC = 30;
    private static boolean sLoaded = false;

    /**
     * Load OpenCV Library in async mode
     *
     * @param context Activity context.
     * @param allowStatic Allow trying load from local package.
     * @param allowInstall Allow installing package from play store.
     *
     * @return if load succeed return true. Return false otherwise.
     */
    public static boolean load(Context context,
            boolean allowLocal, boolean allowPackage, boolean allowInstall) {
        // only need to load once
        if (!sLoaded) {
            // Try static load first
            if (allowLocal && OpenCVLoader.initDebug()) {
                sLoaded = true;
            } else if (allowPackage) {
                if (allowInstall || probePackage(context)) {
                    final CountDownLatch done = new CountDownLatch(1);
                    // Load the library through async loader
                    OpenCVLoader.initAsync(OpenCVLoader.OPENCV_VERSION_3_0_0, context,
                            new BaseLoaderCallback(context) {
                                @Override
                                public void onManagerConnected(int status) {
                                    Log.v(TAG, ""New Loading status: "" + status);
                                    switch (status) {
                                        case LoaderCallbackInterface.SUCCESS: {
                                            sLoaded = true;
                                        }
                                        break;
                                        default: {
                                            Log.e(TAG, ""Connecting OpenCV Manager failed"");
                                        }
                                        break;
                                    }
                                    done.countDown();
                                }
                            });
                    try {
                        if (!done.await(ASYNC_LOAD_TIMEOUT_SEC, TimeUnit.SECONDS)) {
                            Log.e(TAG, ""Time out when attempt async load"");
                        }
                    } catch (InterruptedException e) {
                        Thread.currentThread().interrupt();
                    }
                }
            }
        }
        return sLoaded;
    }

    /**
     * Test if the library is loaded
     * @return a boolean indicates whether the OpenCV library is loaded.
     */
    public static boolean isLoaded() {
        return sLoaded;
    }

    /**
     * Probe if the OpenCV Manager package is installed
     *
     * @return a boolean indicate wheather OpenCV Manager is installed
     */
    private static boolean probePackage(Context context) {
        Intent intent = new Intent(""org.opencv.engine.BIND"");
        intent.setPackage(""org.opencv.engine"");

        ServiceConnection conn = new ServiceConnection() {
            @Override
            public void onServiceConnected(ComponentName className, IBinder service) {
                // Do nothing
            }
            @Override
            public void onServiceDisconnected(ComponentName className) {
                // Do nothing
            }
        };

        boolean ret = false;
        try {
            if (context.bindService(intent, conn, Context.BIND_AUTO_CREATE)) {
                ret = true;
            }
        } finally {
            context.unbindService(conn);
        }

        return ret;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.StandardDeviationVerificationTest"	"testVerify"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/StandardDeviationVerificationTest.java"	""	"public void testVerify() {
        // Stddev should be {sqrt(2.5), sqrt(2.5), sqrt(2.5)}
        float[][] values = {
                {0, 1, 0},
                {1, 2, 2},
                {2, 3, 4},
                {3, 4, 6},
                {4, 5, 8},
        };
        float[] standardDeviations = {
                (float) Math.sqrt(2.5), (float) Math.sqrt(2.5), (float) Math.sqrt(10.0)
        };

        float[] threshold = {2, 2, 4};
        runVerification(threshold, values, true, standardDeviations);

        threshold = new float[]{1, 2, 4};
        runVerification(threshold, values, false, standardDeviations);

        threshold = new float[]{2, 1, 4};
        runVerification(threshold, values, false, standardDeviations);

        threshold = new float[]{2, 2, 3};
        runVerification(threshold, values, false, standardDeviations);
    }

    private void runVerification(float[] threshold, float[][] values, boolean pass,
            float[] standardDeviations) {
        SensorStats stats = new SensorStats();
        StandardDeviationVerification verification = getVerification(threshold, values);
        if (pass) {
            verification.verify(stats);
        } else {
            boolean failed = false;
            try {
                verification.verify(stats);
            } catch (AssertionError e) {
                // Expected;
                failed = true;
            }
            assertTrue(""Expected an AssertionError"", failed);
        }
        assertEquals(pass, stats.getValue(StandardDeviationVerification.PASSED_KEY));
        float[] actual = (float[]) stats.getValue(SensorStats.STANDARD_DEVIATION_KEY);
        for (int i = 0; i < standardDeviations.length; i++) {
            assertEquals(standardDeviations[i], actual[i], 0.1);
        }
    }

    private static StandardDeviationVerification getVerification(
            float[] threshold,
            float[] ... values) {
        Collection<TestSensorEvent> events = new ArrayList<>(values.length);
        for (float[] value : values) {
            events.add(new TestSensorEvent(null, 0, 0, value));
        }
        StandardDeviationVerification verification = new StandardDeviationVerification(threshold);
        verification.addSensorEvents(events);
        return verification;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.helpers.StaticMetadat"	"getCharacteristics"	""	"/home/gpoor/cts-12-source/cts/tests/camera/utils/src/android/hardware/camera2/cts/helpers/StaticMetadata.java"	""	"public void test/*
 *.
 */

package android.hardware.camera2.cts.helpers;

import android.graphics.Rect;
import android.graphics.ImageFormat;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.CameraCharacteristics.Key;
import android.hardware.camera2.CameraMetadata;
import android.hardware.camera2.CaptureRequest;
import android.hardware.camera2.CaptureResult;
import android.hardware.camera2.cts.CameraTestUtils;
import android.hardware.camera2.params.StreamConfigurationMap;
import android.hardware.camera2.params.Capability;
import android.util.Range;
import android.util.Size;
import android.util.Log;
import android.util.Rational;

import junit.framework.Assert;

import java.lang.reflect.Array;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Set;

import static android.hardware.camera2.cts.helpers.AssertHelpers.*;
import static android.hardware.camera2.CameraCharacteristics.*;

/**
 * Helpers to get common static info out of the camera.
 *
 * <p>Avoid boiler plate by putting repetitive get/set patterns in this class.</p>
 *
 * <p>Attempt to be durable against the camera device having bad or missing metadata
 * by providing reasonable defaults and logging warnings when that happens.</p>
 */
public class StaticMetadata {

    private static final String TAG = ""StaticMetadata"";
    private static final int IGNORE_SIZE_CHECK = -1;

    private static final long SENSOR_INFO_EXPOSURE_TIME_RANGE_MIN_AT_MOST = 100000L; // 100us
    private static final long SENSOR_INFO_EXPOSURE_TIME_RANGE_MAX_AT_LEAST = 100000000; // 100ms
    private static final int SENSOR_INFO_SENSITIVITY_RANGE_MIN_AT_MOST = 100;
    private static final int SENSOR_INFO_SENSITIVITY_RANGE_MAX_AT_LEAST = 800;
    private static final int STATISTICS_INFO_MAX_FACE_COUNT_MIN_AT_LEAST = 4;
    private static final int TONEMAP_MAX_CURVE_POINTS_AT_LEAST = 64;
    private static final int CONTROL_AE_COMPENSATION_RANGE_DEFAULT_MIN = -2;
    private static final int CONTROL_AE_COMPENSATION_RANGE_DEFAULT_MAX = 2;
    private static final Rational CONTROL_AE_COMPENSATION_STEP_DEFAULT = new Rational(1, 2);
    private static final byte REQUEST_PIPELINE_MAX_DEPTH_MAX = 8;
    private static final int MAX_REPROCESS_MAX_CAPTURE_STALL = 4;

    // TODO: Consider making this work across any metadata object, not just camera characteristics
    private final CameraCharacteristics mCharacteristics;
    private final CheckLevel mLevel;
    private final CameraErrorCollector mCollector;

    // Last defined capability enum, for iterating over all of them
    public static final int LAST_CAPABILITY_ENUM =
            CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_REMOSAIC_REPROCESSING;

    // Access via getAeModeName() to account for vendor extensions
    public static final String[] AE_MODE_NAMES = new String[] {
        ""AE_MODE_OFF"",
        ""AE_MODE_ON"",
        ""AE_MODE_ON_AUTO_FLASH"",
        ""AE_MODE_ON_ALWAYS_FLASH"",
        ""AE_MODE_ON_AUTO_FLASH_REDEYE""
    };

    // Access via getAfModeName() to account for vendor extensions
    public static final String[] AF_MODE_NAMES = new String[] {
        ""AF_MODE_OFF"",
        ""AF_MODE_AUTO"",
        ""AF_MODE_MACRO"",
        ""AF_MODE_CONTINUOUS_VIDEO"",
        ""AF_MODE_CONTINUOUS_PICTURE"",
        ""AF_MODE_EDOF""
    };

    // Index with android.control.aeState
    public static final String[] AE_STATE_NAMES = new String[] {
        ""AE_STATE_INACTIVE"",
        ""AE_STATE_SEARCHING"",
        ""AE_STATE_CONVERGED"",
        ""AE_STATE_LOCKED"",
        ""AE_STATE_FLASH_REQUIRED"",
        ""AE_STATE_PRECAPTURE""
    };

    // Index with android.control.afState
    public static final String[] AF_STATE_NAMES = new String[] {
        ""AF_STATE_INACTIVE"",
        ""AF_STATE_PASSIVE_SCAN"",
        ""AF_STATE_PASSIVE_FOCUSED"",
        ""AF_STATE_ACTIVE_SCAN"",
        ""AF_STATE_FOCUSED_LOCKED"",
        ""AF_STATE_NOT_FOCUSED_LOCKED"",
        ""AF_STATE_PASSIVE_UNFOCUSED""
    };

    // Index with android.control.aePrecaptureTrigger
    public static final String[] AE_TRIGGER_NAMES = new String[] {
        ""AE_TRIGGER_IDLE"",
        ""AE_TRIGGER_START"",
        ""AE_TRIGGER_CANCEL""
    };

    // Index with android.control.afTrigger
    public static final String[] AF_TRIGGER_NAMES = new String[] {
        ""AF_TRIGGER_IDLE"",
        ""AF_TRIGGER_START"",
        ""AF_TRIGGER_CANCEL""
    };

    public enum CheckLevel {
        /** Only log warnings for metadata check failures. Execution continues. */
        WARN,
        /**
         * Use ErrorCollector to collect the metadata check failures, Execution
         * continues.
         */
        COLLECT,
        /** Assert the metadata check failures. Execution aborts. */
        ASSERT
    }

    /**
     * Construct a new StaticMetadata object.
     *
     *<p> Default constructor, only log warnings for the static metadata check failures</p>
     *
     * @param characteristics static info for a camera
     * @throws IllegalArgumentException if characteristics was null
     */
    public StaticMetadata(CameraCharacteristics characteristics) {
        this(characteristics, CheckLevel.WARN, /*collector*/null);
    }

    /**
     * Construct a new StaticMetadata object with {@link CameraErrorCollector}.
     * <p>
     * When level is not {@link CheckLevel.COLLECT}, the {@link CameraErrorCollector} will be
     * ignored, otherwise, it will be used to log the check failures.
     * </p>
     *
     * @param characteristics static info for a camera
     * @param collector The {@link CameraErrorCollector} used by this StaticMetadata
     * @throws IllegalArgumentException if characteristics or collector was null.
     */
    public StaticMetadata(CameraCharacteristics characteristics, CameraErrorCollector collector) {
        this(characteristics, CheckLevel.COLLECT, collector);
    }

    /**
     * Construct a new StaticMetadata object with {@link CheckLevel} and
     * {@link CameraErrorCollector}.
     * <p>
     * When level is not {@link CheckLevel.COLLECT}, the {@link CameraErrorCollector} will be
     * ignored, otherwise, it will be used to log the check failures.
     * </p>
     *
     * @param characteristics static info for a camera
     * @param level The {@link CheckLevel} of this StaticMetadata
     * @param collector The {@link CameraErrorCollector} used by this StaticMetadata
     * @throws IllegalArgumentException if characteristics was null or level was
     *         {@link CheckLevel.COLLECT} but collector was null.
     */
    public StaticMetadata(CameraCharacteristics characteristics, CheckLevel level,
            CameraErrorCollector collector) {
        if (characteristics == null) {
            throw new IllegalArgumentException(""characteristics was null"");
        }
        if (level == CheckLevel.COLLECT && collector == null) {
            throw new IllegalArgumentException(""collector must valid when COLLECT level is set"");
        }

        mCharacteristics = characteristics;
        mLevel = level;
        mCollector = collector;
    }

    /**
     * Get the CameraCharacteristics associated with this StaticMetadata.
     *
     * @return A non-null CameraCharacteristics object
     */
    public CameraCharacteristics getCharacteristics() {
        return mCharacteristics;
    }

    /**
     * Whether or not the hardware level reported by android.info.supportedHardwareLevel
     * is at least {@value CameraMetadata#INFO_SUPPORTED_HARDWARE_LEVEL_FULL}.
     *
     * <p>If the camera device is not reporting the hardwareLevel, this
     * will cause the test to fail.</p>
     *
     * @return {@code true} if the device is {@code FULL}, {@code false} otherwise.
     */
    public boolean isHardwareLevelAtLeastFull() {
        return isHardwareLevelAtLeast(CameraMetadata.INFO_SUPPORTED_HARDWARE_LEVEL_FULL);
    }

    /**
     * Whether or not the hardware level reported by android.info.supportedHardwareLevel is
     * at least the desired one (but could be higher)
     */
    public boolean isHardwareLevelAtLeast(int level) {
        final int[] sortedHwLevels = {
            CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_LEGACY,
            CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_EXTERNAL,
            CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED,
            CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_FULL,
            CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_3
        };
        int deviceLevel = getHardwareLevelChecked();
        if (level == deviceLevel) {
            return true;
        }

        for (int sortedlevel : sortedHwLevels) {
            if (sortedlevel == level) {
                return true;
            } else if (sortedlevel == deviceLevel) {
                return false;
            }
        }
        Assert.fail(""Unknown hardwareLevel "" + level + "" and device hardware level "" + deviceLevel);
        return false;
    }

    /**
     * Whether or not the camera is an external camera. If so the hardware level
     * reported by android.info.supportedHardwareLevel is
     * {@value CameraMetadata#INFO_SUPPORTED_HARDWARE_LEVEL_EXTERNAL}.
     *
     * <p>If the camera device is not reporting the hardwareLevel, this
     * will cause the test to fail.</p>
     *
     * @return {@code true} if the device is external, {@code false} otherwise.
     */
    public boolean isExternalCamera() {
        int deviceLevel = getHardwareLevelChecked();
        return deviceLevel == CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_EXTERNAL;
    }

    /**
     * Whether or not the hardware level reported by android.info.supportedHardwareLevel
     * Return the supported hardware level of the device, or fail if no value is reported.
     *
     * @return the supported hardware level as a constant defined for
     *      {@link CameraCharacteristics#INFO_SUPPORTED_HARDWARE_LEVEL}.
     */
    public int getHardwareLevelChecked() {
        Integer hwLevel = getValueFromKeyNonNull(
                CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL);
        if (hwLevel == null) {
            Assert.fail(""No supported hardware level reported."");
        }
        return hwLevel;
    }

    /**
     * Whether or not the hardware level reported by android.info.supportedHardwareLevel
     * is {@value CameraMetadata#INFO_SUPPORTED_HARDWARE_LEVEL_LEGACY}.
     *
     * <p>If the camera device is not reporting the hardwareLevel, this
     * will cause the test to fail.</p>
     *
     * @return {@code true} if the device is {@code LEGACY}, {@code false} otherwise.
     */
    public boolean isHardwareLevelLegacy() {
        return getHardwareLevelChecked() == CameraMetadata.INFO_SUPPORTED_HARDWARE_LEVEL_LEGACY;
    }

    /**
     * Whether or not the per frame control is supported by the camera device.
     *
     * @return {@code true} if per frame control is supported, {@code false} otherwise.
     */
    public boolean isPerFrameControlSupported() {
        return getSyncMaxLatency() == CameraMetadata.SYNC_MAX_LATENCY_PER_FRAME_CONTROL;
    }

    /**
     * Get the maximum number of frames to wait for a request settings being applied
     *
     * @return CameraMetadata.SYNC_MAX_LATENCY_UNKNOWN for unknown latency
     *         CameraMetadata.SYNC_MAX_LATENCY_PER_FRAME_CONTROL for per frame control
     *         a positive int otherwise
     */
    public int getSyncMaxLatency() {
        Integer value = getValueFromKeyNonNull(CameraCharacteristics.SYNC_MAX_LATENCY);
        if (value == null) {
            return CameraMetadata.SYNC_MAX_LATENCY_UNKNOWN;
        }
        return value;
    }

    /**
     * Get the color filter arrangement for this camera device.
     *
     * @return Color Filter arrangement of this camera device
     */
    public int getCFAChecked() {
        Integer cfa = getValueFromKeyNonNull(
                CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT);
        if (cfa == null) {
            Assert.fail(""No color filter array (CFA) reported."");
        }
        return cfa;
    }

    public boolean isNIRColorFilter() {
        Integer cfa = mCharacteristics.get(
                CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT);
        if (cfa == null) {
            return false;
        }
        return cfa == CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_NIR;
    }

    /**
     * Whether or not the hardware level reported by android.info.supportedHardwareLevel
     * is {@value CameraMetadata#INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED}.
     *
     * <p>If the camera device is incorrectly reporting the hardwareLevel, this
     * will always return {@code true}.</p>
     *
     * @return {@code true} if the device is {@code LIMITED}, {@code false} otherwise.
     */
    public boolean isHardwareLevelLimited() {
        return getHardwareLevelChecked() == CameraMetadata.INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED;
    }

    /**
     * Whether or not the hardware level reported by {@code android.info.supportedHardwareLevel}
     * is at least {@link CameraMetadata#INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED}.
     *
     * <p>If the camera device is incorrectly reporting the hardwareLevel, this
     * will always return {@code false}.</p>
     *
     * @return
     *          {@code true} if the device is {@code LIMITED} or {@code FULL},
     *          {@code false} otherwise (i.e. LEGACY).
     */
    public boolean isHardwareLevelAtLeastLimited() {
        return isHardwareLevelAtLeast(CameraMetadata.INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED);
    }

    /**
     * Get the maximum number of partial result a request can expect
     *
     * @return 1 if partial result is not supported.
     *         a integer value larger than 1 if partial result is supported.
     */
    public int getPartialResultCount() {
        Integer value = mCharacteristics.get(CameraCharacteristics.REQUEST_PARTIAL_RESULT_COUNT);
        if (value == null) {
            // Optional key. Default value is 1 if key is missing.
            return 1;
        }
        return value;
    }

    /**
     * Get the exposure time value and clamp to the range if needed.
     *
     * @param exposure Input exposure time value to check.
     * @return Exposure value in the legal range.
     */
    public long getExposureClampToRange(long exposure) {
        long minExposure = getExposureMinimumOrDefault(Long.MAX_VALUE);
        long maxExposure = getExposureMaximumOrDefault(Long.MIN_VALUE);
        if (minExposure > SENSOR_INFO_EXPOSURE_TIME_RANGE_MIN_AT_MOST) {
            failKeyCheck(CameraCharacteristics.SENSOR_INFO_EXPOSURE_TIME_RANGE,
                    String.format(
                    ""Min value %d is too large, set to maximal legal value %d"",
                    minExposure, SENSOR_INFO_EXPOSURE_TIME_RANGE_MIN_AT_MOST));
            minExposure = SENSOR_INFO_EXPOSURE_TIME_RANGE_MIN_AT_MOST;
        }
        if (isHardwareLevelAtLeastFull() &&
                maxExposure < SENSOR_INFO_EXPOSURE_TIME_RANGE_MAX_AT_LEAST) {
            failKeyCheck(CameraCharacteristics.SENSOR_INFO_EXPOSURE_TIME_RANGE,
                    String.format(
                    ""Max value %d is too small, set to minimal legal value %d"",
                    maxExposure, SENSOR_INFO_EXPOSURE_TIME_RANGE_MAX_AT_LEAST));
            maxExposure = SENSOR_INFO_EXPOSURE_TIME_RANGE_MAX_AT_LEAST;
        }

        return Math.max(minExposure, Math.min(maxExposure, exposure));
    }

    /**
     * Check if the camera device support focuser.
     *
     * @return true if camera device support focuser, false otherwise.
     */
    public boolean hasFocuser() {
        if (areKeysAvailable(CameraCharacteristics.LENS_INFO_MINIMUM_FOCUS_DISTANCE)) {
            // LEGACY devices don't have lens.info.minimumFocusDistance, so guard this query
            return (getMinimumFocusDistanceChecked() > 0);
        } else {
            // Check available AF modes
            int[] availableAfModes = mCharacteristics.get(
                    CameraCharacteristics.CONTROL_AF_AVAILABLE_MODES);

            if (availableAfModes == null) {
                return false;
            }

            // Assume that if we have an AF mode which doesn't ignore AF trigger, we have a focuser
            boolean hasFocuser = false;
            loop: for (int mode : availableAfModes) {
                switch (mode) {
                    case CameraMetadata.CONTROL_AF_MODE_AUTO:
                    case CameraMetadata.CONTROL_AF_MODE_CONTINUOUS_PICTURE:
                    case CameraMetadata.CONTROL_AF_MODE_CONTINUOUS_VIDEO:
                    case CameraMetadata.CONTROL_AF_MODE_MACRO:
                        hasFocuser = true;
                        break loop;
                }
            }

            return hasFocuser;
        }
    }

    /**
     * Check if the camera device has flash unit.
     * @return true if flash unit is available, false otherwise.
     */
    public boolean hasFlash() {
        return getFlashInfoChecked();
    }

    /**
     * Get minimum focus distance.
     *
     * @return minimum focus distance, 0 if minimum focus distance is invalid.
     */
    public float getMinimumFocusDistanceChecked() {
        Key<Float> key = CameraCharacteristics.LENS_INFO_MINIMUM_FOCUS_DISTANCE;
        Float minFocusDistance;

        /**
         * android.lens.info.minimumFocusDistance - required for FULL and MANUAL_SENSOR-capable
         *   devices; optional for all other devices.
         */
        if (isHardwareLevelAtLeastFull() || isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
            minFocusDistance = getValueFromKeyNonNull(key);
        } else {
            minFocusDistance = mCharacteristics.get(key);
        }

        if (minFocusDistance == null) {
            return 0.0f;
        }

        checkTrueForKey(key, "" minFocusDistance value shouldn't be negative"",
                minFocusDistance >= 0);
        if (minFocusDistance < 0) {
            minFocusDistance = 0.0f;
        }

        return minFocusDistance;
    }

    /**
     * Get focusDistanceCalibration.
     *
     * @return focusDistanceCalibration, UNCALIBRATED if value is invalid.
     */
    public int getFocusDistanceCalibrationChecked() {
        Key<Integer> key = CameraCharacteristics.LENS_INFO_FOCUS_DISTANCE_CALIBRATION;
        Integer calibration = getValueFromKeyNonNull(key);

        if (calibration == null) {
            return CameraMetadata.LENS_INFO_FOCUS_DISTANCE_CALIBRATION_UNCALIBRATED;
        }

        checkTrueForKey(key, "" value is out of range"" ,
                calibration >= CameraMetadata.LENS_INFO_FOCUS_DISTANCE_CALIBRATION_UNCALIBRATED &&
                calibration <= CameraMetadata.LENS_INFO_FOCUS_DISTANCE_CALIBRATION_CALIBRATED);

        return calibration;
    }

    public static String getAeModeName(int aeMode) {
        return (aeMode >= AE_MODE_NAMES.length) ? String.format(""VENDOR_AE_MODE_%d"", aeMode) :
                AE_MODE_NAMES[aeMode];
    }

    public static String getAfModeName(int afMode) {
        return (afMode >= AF_MODE_NAMES.length) ? String.format(""VENDOR_AF_MODE_%d"", afMode) :
                AF_MODE_NAMES[afMode];
    }

    /**
     * Get max AE regions and do validity check.
     *
     * @return AE max regions supported by the camera device
     */
    public int getAeMaxRegionsChecked() {
        Integer regionCount = mCharacteristics.get(CameraCharacteristics.CONTROL_MAX_REGIONS_AE);
        if (regionCount == null) {
            return 0;
        }
        return regionCount;
    }

    /**
     * Get max AWB regions and do validity check.
     *
     * @return AWB max regions supported by the camera device
     */
    public int getAwbMaxRegionsChecked() {
        Integer regionCount = mCharacteristics.get(CameraCharacteristics.CONTROL_MAX_REGIONS_AWB);
        if (regionCount == null) {
            return 0;
        }
        return regionCount;
    }

    /**
     * Get max AF regions and do validity check.
     *
     * @return AF max regions supported by the camera device
     */
    public int getAfMaxRegionsChecked() {
        Integer regionCount = mCharacteristics.get(CameraCharacteristics.CONTROL_MAX_REGIONS_AF);
        if (regionCount == null) {
            return 0;
        }
        return regionCount;
    }
    /**
     * Get the available anti-banding modes.
     *
     * @return The array contains available anti-banding modes.
     */
    public int[] getAeAvailableAntiBandingModesChecked() {
        Key<int[]> key = CameraCharacteristics.CONTROL_AE_AVAILABLE_ANTIBANDING_MODES;
        int[] modes = getValueFromKeyNonNull(key);

        boolean foundAuto = false;
        boolean found50Hz = false;
        boolean found60Hz = false;
        for (int mode : modes) {
            checkTrueForKey(key, ""mode value "" + mode + "" is out if range"",
                    mode >= CameraMetadata.CONTROL_AE_ANTIBANDING_MODE_OFF ||
                    mode <= CameraMetadata.CONTROL_AE_ANTIBANDING_MODE_AUTO);
            if (mode == CameraMetadata.CONTROL_AE_ANTIBANDING_MODE_AUTO) {
                foundAuto = true;
            } else if (mode == CameraMetadata.CONTROL_AE_ANTIBANDING_MODE_50HZ) {
                found50Hz = true;
            } else if (mode == CameraMetadata.CONTROL_AE_ANTIBANDING_MODE_60HZ) {
                found60Hz = true;
            }
        }
        // Must contain AUTO mode or one of 50/60Hz mode.
        checkTrueForKey(key, ""Either AUTO mode or both 50HZ/60HZ mode should present"",
                foundAuto || (found50Hz && found60Hz));

        return modes;
    }

    /**
     * Check if the antibanding OFF mode is supported.
     *
     * @return true if antibanding OFF mode is supported, false otherwise.
     */
    public boolean isAntiBandingOffModeSupported() {
        List<Integer> antiBandingModes =
                Arrays.asList(CameraTestUtils.toObject(getAeAvailableAntiBandingModesChecked()));

        return antiBandingModes.contains(CameraMetadata.CONTROL_AE_ANTIBANDING_MODE_OFF);
    }

    public Boolean getFlashInfoChecked() {
        Key<Boolean> key = CameraCharacteristics.FLASH_INFO_AVAILABLE;
        Boolean hasFlash = getValueFromKeyNonNull(key);

        // In case the failOnKey only gives warning.
        if (hasFlash == null) {
            return false;
        }

        return hasFlash;
    }

    public int[] getAvailableTestPatternModesChecked() {
        Key<int[]> key =
                CameraCharacteristics.SENSOR_AVAILABLE_TEST_PATTERN_MODES;
        int[] modes = getValueFromKeyNonNull(key);

        if (modes == null) {
            return new int[0];
        }

        int expectValue = CameraCharacteristics.SENSOR_TEST_PATTERN_MODE_OFF;
        Integer[] boxedModes = CameraTestUtils.toObject(modes);
        checkTrueForKey(key, "" value must contain OFF mode"",
                Arrays.asList(boxedModes).contains(expectValue));

        return modes;
    }

    /**
     * Get available thumbnail sizes and do the validity check.
     *
     * @return The array of available thumbnail sizes
     */
    public Size[] getAvailableThumbnailSizesChecked() {
        Key<Size[]> key = CameraCharacteristics.JPEG_AVAILABLE_THUMBNAIL_SIZES;
        Size[] sizes = getValueFromKeyNonNull(key);
        final List<Size> sizeList = Arrays.asList(sizes);

        // Size must contain (0, 0).
        checkTrueForKey(key, ""size should contain (0, 0)"", sizeList.contains(new Size(0, 0)));

        // Each size must be distinct.
        checkElementDistinct(key, sizeList);

        // Must be sorted in ascending order by area, by width if areas are same.
        List<Size> orderedSizes =
                CameraTestUtils.getAscendingOrderSizes(sizeList, /*ascending*/true);
        checkTrueForKey(key, ""Sizes should be in ascending order: Original "" + sizeList.toString()
                + "", Expected "" + orderedSizes.toString(), orderedSizes.equals(sizeList));

        // TODO: Aspect ratio match, need wait for android.scaler.availableStreamConfigurations
        // implementation see b/12958122.

        return sizes;
    }

    /**
     * Get available focal lengths and do the validity check.
     *
     * @return The array of available focal lengths
     */
    public float[] getAvailableFocalLengthsChecked() {
        Key<float[]> key = CameraCharacteristics.LENS_INFO_AVAILABLE_FOCAL_LENGTHS;
        float[] focalLengths = getValueFromKeyNonNull(key);

        checkTrueForKey(key, ""Array should contain at least one element"", focalLengths.length >= 1);

        for (int i = 0; i < focalLengths.length; i++) {
            checkTrueForKey(key,
                    String.format(""focalLength[%d] %f should be positive."", i, focalLengths[i]),
                    focalLengths[i] > 0);
        }
        checkElementDistinct(key, Arrays.asList(CameraTestUtils.toObject(focalLengths)));

        return focalLengths;
    }

    /**
     * Get available apertures and do the validity check.
     *
     * @return The non-null array of available apertures
     */
    public float[] getAvailableAperturesChecked() {
        Key<float[]> key = CameraCharacteristics.LENS_INFO_AVAILABLE_APERTURES;
        float[] apertures = getValueFromKeyNonNull(key);

        checkTrueForKey(key, ""Array should contain at least one element"", apertures.length >= 1);

        for (int i = 0; i < apertures.length; i++) {
            checkTrueForKey(key,
                    String.format(""apertures[%d] %f should be positive."", i, apertures[i]),
                    apertures[i] > 0);
        }
        checkElementDistinct(key, Arrays.asList(CameraTestUtils.toObject(apertures)));

        return apertures;
    }

    /**
     * Get and check the available hot pixel map modes.
     *
     * @return the available hot pixel map modes
     */
    public int[] getAvailableHotPixelModesChecked() {
        Key<int[]> key = CameraCharacteristics.HOT_PIXEL_AVAILABLE_HOT_PIXEL_MODES;
        int[] modes = getValueFromKeyNonNull(key);

        if (modes == null) {
            return new int[0];
        }

        List<Integer> modeList = Arrays.asList(CameraTestUtils.toObject(modes));
        if (isHardwareLevelAtLeastFull()) {
            checkTrueForKey(key, ""Full-capability camera devices must support FAST mode"",
                    modeList.contains(CameraMetadata.HOT_PIXEL_MODE_FAST));
        }

        if (isHardwareLevelAtLeastLimited()) {
            // FAST and HIGH_QUALITY mode must be both present or both not present
            List<Integer> coupledModes = Arrays.asList(new Integer[] {
                    CameraMetadata.HOT_PIXEL_MODE_FAST,
                    CameraMetadata.HOT_PIXEL_MODE_HIGH_QUALITY
            });
            checkTrueForKey(
                    key, "" FAST and HIGH_QUALITY mode must both present or both not present"",
                    containsAllOrNone(modeList, coupledModes));
        }
        checkElementDistinct(key, modeList);
        checkArrayValuesInRange(key, modes, CameraMetadata.HOT_PIXEL_MODE_OFF,
                CameraMetadata.HOT_PIXEL_MODE_HIGH_QUALITY);

        return modes;
    }

    /**
     * Get and check available face detection modes.
     *
     * @return The non-null array of available face detection modes
     */
    public int[] getAvailableFaceDetectModesChecked() {
        Key<int[]> key = CameraCharacteristics.STATISTICS_INFO_AVAILABLE_FACE_DETECT_MODES;
        int[] modes = getValueFromKeyNonNull(key);

        if (modes == null) {
            return new int[0];
        }

        List<Integer> modeList = Arrays.asList(CameraTestUtils.toObject(modes));
        checkTrueForKey(key, ""Array should contain OFF mode"",
                modeList.contains(CameraMetadata.STATISTICS_FACE_DETECT_MODE_OFF));
        checkElementDistinct(key, modeList);
        checkArrayValuesInRange(key, modes, CameraMetadata.STATISTICS_FACE_DETECT_MODE_OFF,
                CameraMetadata.STATISTICS_FACE_DETECT_MODE_FULL);

        return modes;
    }

    /**
     * Get and check max face detected count.
     *
     * @return max number of faces that can be detected
     */
    public int getMaxFaceCountChecked() {
        Key<Integer> key = CameraCharacteristics.STATISTICS_INFO_MAX_FACE_COUNT;
        Integer count = getValueFromKeyNonNull(key);

        if (count == null) {
            return 0;
        }

        List<Integer> faceDetectModes =
                Arrays.asList(CameraTestUtils.toObject(getAvailableFaceDetectModesChecked()));
        if (faceDetectModes.contains(CameraMetadata.STATISTICS_FACE_DETECT_MODE_OFF) &&
                faceDetectModes.size() == 1) {
            checkTrueForKey(key, "" value must be 0 if only OFF mode is supported in ""
                    + ""availableFaceDetectionModes"", count == 0);
        } else {
            int maxFaceCountAtLeast = STATISTICS_INFO_MAX_FACE_COUNT_MIN_AT_LEAST;

            // Legacy mode may support fewer than STATISTICS_INFO_MAX_FACE_COUNT_MIN_AT_LEAST faces.
            if (isHardwareLevelLegacy()) {
                maxFaceCountAtLeast = 1;
            }
            checkTrueForKey(key, "" value must be no less than "" + maxFaceCountAtLeast + "" if SIMPLE""
                    + ""or FULL is also supported in availableFaceDetectionModes"",
                    count >= maxFaceCountAtLeast);
        }

        return count;
    }

    /**
     * Get and check the available tone map modes.
     *
     * @return the available tone map modes
     */
    public int[] getAvailableToneMapModesChecked() {
        Key<int[]> key = CameraCharacteristics.TONEMAP_AVAILABLE_TONE_MAP_MODES;
        int[] modes = mCharacteristics.get(key);

        if (modes == null) {
            return new int[0];
        }

        List<Integer> modeList = Arrays.asList(CameraTestUtils.toObject(modes));
        checkTrueForKey(key, "" Camera devices must always support FAST mode"",
                modeList.contains(CameraMetadata.TONEMAP_MODE_FAST));
        // Qualification check for MANUAL_POSTPROCESSING capability is in
        // StaticMetadataTest#testCapabilities

        if (isHardwareLevelAtLeastLimited()) {
            // FAST and HIGH_QUALITY mode must be both present or both not present
            List<Integer> coupledModes = Arrays.asList(new Integer[] {
                    CameraMetadata.TONEMAP_MODE_FAST,
                    CameraMetadata.TONEMAP_MODE_HIGH_QUALITY
            });
            checkTrueForKey(
                    key, "" FAST and HIGH_QUALITY mode must both present or both not present"",
                    containsAllOrNone(modeList, coupledModes));
        }
        checkElementDistinct(key, modeList);
        checkArrayValuesInRange(key, modes, CameraMetadata.TONEMAP_MODE_CONTRAST_CURVE,
                CameraMetadata.TONEMAP_MODE_PRESET_CURVE);

        return modes;
    }

    /**
     * Get and check max tonemap curve point.
     *
     * @return Max tonemap curve points.
     */
    public int getMaxTonemapCurvePointChecked() {
        Key<Integer> key = CameraCharacteristics.TONEMAP_MAX_CURVE_POINTS;
        Integer count = getValueFromKeyNonNull(key);
        List<Integer> modeList =
                Arrays.asList(CameraTestUtils.toObject(getAvailableToneMapModesChecked()));
        boolean tonemapCurveOutputSupported =
                modeList.contains(CameraMetadata.TONEMAP_MODE_CONTRAST_CURVE) ||
                modeList.contains(CameraMetadata.TONEMAP_MODE_GAMMA_VALUE) ||
                modeList.contains(CameraMetadata.TONEMAP_MODE_PRESET_CURVE);

        if (count == null) {
            if (tonemapCurveOutputSupported) {
                Assert.fail(""Tonemap curve output is supported but MAX_CURVE_POINTS is null"");
            }
            return 0;
        }

        if (tonemapCurveOutputSupported) {
            checkTrueForKey(key, ""Tonemap curve output supported camera device must support ""
                    + ""maxCurvePoints >= "" + TONEMAP_MAX_CURVE_POINTS_AT_LEAST,
                    count >= TONEMAP_MAX_CURVE_POINTS_AT_LEAST);
        }

        return count;
    }

    /**
     * Get and check pixel array size.
     */
    public Size getPixelArraySizeChecked() {
        return getPixelArraySizeChecked(/*maxResolution*/ false);
    }

    /**
     * Get and check pixel array size.
     */
    public Size getPixelArraySizeChecked(boolean maxResolution) {
        Key<Size> key = maxResolution ?
                CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE_MAXIMUM_RESOLUTION :
                CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE;
        Size pixelArray = getValueFromKeyNonNull(key);
        if (pixelArray == null) {
            return new Size(0, 0);
        }

        return pixelArray;
    }

    /**
     * Get and check pre-correction active array size.
     */
    public Rect getPreCorrectedActiveArraySizeChecked() {
        return getPreCorrectedActiveArraySizeChecked(/*maxResolution*/ false);
    }

    /**
     * Get and check pre-correction active array size.
     */
    public Rect getPreCorrectedActiveArraySizeChecked(boolean maxResolution) {
        Key<Rect> key = maxResolution ?
                CameraCharacteristics.SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE_MAXIMUM_RESOLUTION :
                        CameraCharacteristics.SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE;
        Rect activeArray = getValueFromKeyNonNull(key);

        if (activeArray == null) {
            return new Rect(0, 0, 0, 0);
        }

        Size pixelArraySize = getPixelArraySizeChecked(maxResolution);
        checkTrueForKey(key, ""values left/top are invalid"", activeArray.left >= 0 && activeArray.top >= 0);
        checkTrueForKey(key, ""values width/height are invalid"",
                activeArray.width() <= pixelArraySize.getWidth() &&
                activeArray.height() <= pixelArraySize.getHeight());

        return activeArray;
    }

    /**
     * Get and check active array size.
     */
    public Rect getActiveArraySizeChecked() {
        return getActiveArraySizeChecked(/*maxResolution*/ false);
    }

    /**
     * Get and check active array size.
     */
    public Rect getActiveArraySizeChecked(boolean maxResolution) {
        Key<Rect> key = maxResolution ?
                CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE_MAXIMUM_RESOLUTION :
                        CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE;
        Rect activeArray = getValueFromKeyNonNull(key);

        if (activeArray == null) {
            return new Rect(0, 0, 0, 0);
        }

        Size pixelArraySize = getPixelArraySizeChecked(maxResolution);
        checkTrueForKey(key, ""values left/top are invalid"", activeArray.left >= 0 && activeArray.top >= 0);
        checkTrueForKey(key, ""values width/height are invalid"",
                activeArray.width() <= pixelArraySize.getWidth() &&
                activeArray.height() <= pixelArraySize.getHeight());

        return activeArray;
    }

    /**
     * Get the dimensions to use for RAW16 buffers.
     */
    public Size getRawDimensChecked() throws Exception {
        return getRawDimensChecked(/*maxResolution*/ false);
    }

    /**
     * Get the dimensions to use for RAW16 buffers.
     */
    public Size getRawDimensChecked(boolean maxResolution) throws Exception {
        Size[] targetCaptureSizes = getAvailableSizesForFormatChecked(ImageFormat.RAW_SENSOR,
                        StaticMetadata.StreamDirection.Output, /*fastSizes*/true, /*slowSizes*/true,
                        maxResolution);
        Assert.assertTrue(""No capture sizes available for RAW format!"",
                targetCaptureSizes.length != 0);
        Rect activeArray = getPreCorrectedActiveArraySizeChecked(maxResolution);
        Size preCorrectionActiveArraySize =
                new Size(activeArray.width(), activeArray.height());
        Size pixelArraySize = getPixelArraySizeChecked(maxResolution);
        Assert.assertTrue(""Missing pre-correction active array size"", activeArray.width() > 0 &&
                activeArray.height() > 0);
        Assert.assertTrue(""Missing pixel array size"", pixelArraySize.getWidth() > 0 &&
                pixelArraySize.getHeight() > 0);
        Size[] allowedArraySizes = new Size[] { preCorrectionActiveArraySize,
                pixelArraySize };
        return assertArrayContainsAnyOf(""Available sizes for RAW format"" +
                "" must include either the pre-corrected active array size, or the full "" +
                ""pixel array size"", targetCaptureSizes, allowedArraySizes);
    }

    /**
     * Get the sensitivity value and clamp to the range if needed.
     *
     * @param sensitivity Input sensitivity value to check.
     * @return Sensitivity value in legal range.
     */
    public int getSensitivityClampToRange(int sensitivity) {
        int minSensitivity = getSensitivityMinimumOrDefault();
        int maxSensitivity = getSensitivityMaximumOrDefault();
        if (minSensitivity > SENSOR_INFO_SENSITIVITY_RANGE_MIN_AT_MOST) {
            failKeyCheck(CameraCharacteristics.SENSOR_INFO_SENSITIVITY_RANGE,
                    String.format(
                    ""Min value %d is too large, set to maximal legal value %d"",
                    minSensitivity, SENSOR_INFO_SENSITIVITY_RANGE_MIN_AT_MOST));
            minSensitivity = SENSOR_INFO_SENSITIVITY_RANGE_MIN_AT_MOST;
        }
        if (maxSensitivity < SENSOR_INFO_SENSITIVITY_RANGE_MAX_AT_LEAST) {
            failKeyCheck(CameraCharacteristics.SENSOR_INFO_SENSITIVITY_RANGE,
                    String.format(
                    ""Max value %d is too small, set to minimal legal value %d"",
                    maxSensitivity, SENSOR_INFO_SENSITIVITY_RANGE_MAX_AT_LEAST));
            maxSensitivity = SENSOR_INFO_SENSITIVITY_RANGE_MAX_AT_LEAST;
        }

        return Math.max(minSensitivity, Math.min(maxSensitivity, sensitivity));
    }

    /**
     * Get maxAnalogSensitivity for a camera device.
     * <p>
     * This is only available for FULL capability device, return 0 if it is unavailable.
     * </p>
     *
     * @return maxAnalogSensitivity, 0 if it is not available.
     */
    public int getMaxAnalogSensitivityChecked() {

        Key<Integer> key = CameraCharacteristics.SENSOR_MAX_ANALOG_SENSITIVITY;
        Integer maxAnalogsensitivity = mCharacteristics.get(key);
        if (maxAnalogsensitivity == null) {
            if (isHardwareLevelAtLeastFull()) {
                Assert.fail(""Full device should report max analog sensitivity"");
            }
            return 0;
        }

        int minSensitivity = getSensitivityMinimumOrDefault();
        int maxSensitivity = getSensitivityMaximumOrDefault();
        checkTrueForKey(key, "" Max analog sensitivity "" + maxAnalogsensitivity
                + "" should be no larger than max sensitivity "" + maxSensitivity,
                maxAnalogsensitivity <= maxSensitivity);
        checkTrueForKey(key, "" Max analog sensitivity "" + maxAnalogsensitivity
                + "" should be larger than min sensitivity "" + maxSensitivity,
                maxAnalogsensitivity > minSensitivity);

        return maxAnalogsensitivity;
    }

    /**
     * Get hyperfocalDistance and do the validity check.
     * <p>
     * Note that, this tag is optional, will return -1 if this tag is not
     * available.
     * </p>
     *
     * @return hyperfocalDistance of this device, -1 if this tag is not available.
     */
    public float getHyperfocalDistanceChecked() {
        Key<Float> key = CameraCharacteristics.LENS_INFO_HYPERFOCAL_DISTANCE;
        Float hyperfocalDistance = getValueFromKeyNonNull(key);
        if (hyperfocalDistance == null) {
            return -1;
        }

        if (hasFocuser()) {
            float minFocusDistance = getMinimumFocusDistanceChecked();
            checkTrueForKey(key, String.format("" hyperfocal distance %f should be in the range of""
                    + "" should be in the range of (%f, %f]"", hyperfocalDistance, 0.0f,
                    minFocusDistance),
                    hyperfocalDistance > 0 && hyperfocalDistance <= minFocusDistance);
        }

        return hyperfocalDistance;
    }

    /**
     * Get the minimum value for a sensitivity range from android.sensor.info.sensitivityRange.
     *
     * <p>If the camera is incorrectly reporting values, log a warning and return
     * the default value instead, which is the largest minimum value required to be supported
     * by all camera devices.</p>
     *
     * @return The value reported by the camera device or the defaultValue otherwise.
     */
    public int getSensitivityMinimumOrDefault() {
        return getSensitivityMinimumOrDefault(SENSOR_INFO_SENSITIVITY_RANGE_MIN_AT_MOST);
    }

    /**
     * Get the minimum value for a sensitivity range from android.sensor.info.sensitivityRange.
     *
     * <p>If the camera is incorrectly reporting values, log a warning and return
     * the default value instead.</p>
     *
     * @param defaultValue Value to return if no legal value is available
     * @return The value reported by the camera device or the defaultValue otherwise.
     */
    public int getSensitivityMinimumOrDefault(int defaultValue) {
        Range<Integer> range = mCharacteristics.get(
                CameraCharacteristics.SENSOR_INFO_SENSITIVITY_RANGE);
        if (range == null) {
            if (isHardwareLevelAtLeastFull()) {
                failKeyCheck(CameraCharacteristics.SENSOR_INFO_SENSITIVITY_RANGE,
                        ""had no valid minimum value; using default of "" + defaultValue);
            }
            return defaultValue;
        }
        return range.getLower();
    }

    /**
     * Get the maximum value for a sensitivity range from android.sensor.info.sensitivityRange.
     *
     * <p>If the camera is incorrectly reporting values, log a warning and return
     * the default value instead, which is the smallest maximum value required to be supported
     * by all camera devices.</p>
     *
     * @return The value reported by the camera device or the defaultValue otherwise.
     */
    public int getSensitivityMaximumOrDefault() {
        return getSensitivityMaximumOrDefault(SENSOR_INFO_SENSITIVITY_RANGE_MAX_AT_LEAST);
    }

    /**
     * Get the maximum value for a sensitivity range from android.sensor.info.sensitivityRange.
     *
     * <p>If the camera is incorrectly reporting values, log a warning and return
     * the default value instead.</p>
     *
     * @param defaultValue Value to return if no legal value is available
     * @return The value reported by the camera device or the defaultValue otherwise.
     */
    public int getSensitivityMaximumOrDefault(int defaultValue) {
        Range<Integer> range = mCharacteristics.get(
                CameraCharacteristics.SENSOR_INFO_SENSITIVITY_RANGE);
        if (range == null) {
            if (isHardwareLevelAtLeastFull()) {
                failKeyCheck(CameraCharacteristics.SENSOR_INFO_SENSITIVITY_RANGE,
                        ""had no valid maximum value; using default of "" + defaultValue);
            }
            return defaultValue;
        }
        return range.getUpper();
    }

    /**
     * Get the minimum value for an exposure range from android.sensor.info.exposureTimeRange.
     *
     * <p>If the camera is incorrectly reporting values, log a warning and return
     * the default value instead.</p>
     *
     * @param defaultValue Value to return if no legal value is available
     * @return The value reported by the camera device or the defaultValue otherwise.
     */
    public long getExposureMinimumOrDefault(long defaultValue) {
        Range<Long> range = getValueFromKeyNonNull(
                CameraCharacteristics.SENSOR_INFO_EXPOSURE_TIME_RANGE);
        if (range == null) {
            failKeyCheck(CameraCharacteristics.SENSOR_INFO_EXPOSURE_TIME_RANGE,
                    ""had no valid minimum value; using default of "" + defaultValue);
            return defaultValue;
        }
        return range.getLower();
    }

    /**
     * Get the minimum value for an exposure range from android.sensor.info.exposureTimeRange.
     *
     * <p>If the camera is incorrectly reporting values, log a warning and return
     * the default value instead, which is the largest minimum value required to be supported
     * by all camera devices.</p>
     *
     * @return The value reported by the camera device or the defaultValue otherwise.
     */
    public long getExposureMinimumOrDefault() {
        return getExposureMinimumOrDefault(SENSOR_INFO_EXPOSURE_TIME_RANGE_MIN_AT_MOST);
    }

    /**
     * Get the maximum value for an exposure range from android.sensor.info.exposureTimeRange.
     *
     * <p>If the camera is incorrectly reporting values, log a warning and return
     * the default value instead.</p>
     *
     * @param defaultValue Value to return if no legal value is available
     * @return The value reported by the camera device or the defaultValue otherwise.
     */
    public long getExposureMaximumOrDefault(long defaultValue) {
        Range<Long> range = getValueFromKeyNonNull(
                CameraCharacteristics.SENSOR_INFO_EXPOSURE_TIME_RANGE);
        if (range == null) {
            failKeyCheck(CameraCharacteristics.SENSOR_INFO_EXPOSURE_TIME_RANGE,
                    ""had no valid maximum value; using default of "" + defaultValue);
            return defaultValue;
        }
        return range.getUpper();
    }

    /**
     * Get the maximum value for an exposure range from android.sensor.info.exposureTimeRange.
     *
     * <p>If the camera is incorrectly reporting values, log a warning and return
     * the default value instead, which is the smallest maximum value required to be supported
     * by all camera devices.</p>
     *
     * @return The value reported by the camera device or the defaultValue otherwise.
     */
    public long getExposureMaximumOrDefault() {
        return getExposureMaximumOrDefault(SENSOR_INFO_EXPOSURE_TIME_RANGE_MAX_AT_LEAST);
    }

    /**
     * get android.control.availableModes and do the validity check.
     *
     * @return available control modes.
     */
    public int[] getAvailableControlModesChecked() {
        Key<int[]> modesKey = CameraCharacteristics.CONTROL_AVAILABLE_MODES;
        int[] modes = getValueFromKeyNonNull(modesKey);
        if (modes == null) {
            modes = new int[0];
        }

        List<Integer> modeList = Arrays.asList(CameraTestUtils.toObject(modes));
        checkTrueForKey(modesKey, ""value is empty"", !modeList.isEmpty());

        // All camera device must support AUTO
        checkTrueForKey(modesKey, ""values "" + modeList.toString() + "" must contain AUTO mode"",
                modeList.contains(CameraMetadata.CONTROL_MODE_AUTO));

        boolean isAeOffSupported =  Arrays.asList(
                CameraTestUtils.toObject(getAeAvailableModesChecked())).contains(
                        CameraMetadata.CONTROL_AE_MODE_OFF);
        boolean isAfOffSupported =  Arrays.asList(
                CameraTestUtils.toObject(getAfAvailableModesChecked())).contains(
                        CameraMetadata.CONTROL_AF_MODE_OFF);
        boolean isAwbOffSupported =  Arrays.asList(
                CameraTestUtils.toObject(getAwbAvailableModesChecked())).contains(
                        CameraMetadata.CONTROL_AWB_MODE_OFF);
        if (isAeOffSupported && isAfOffSupported && isAwbOffSupported) {
            // 3A OFF controls are supported, OFF mode must be supported here.
            checkTrueForKey(modesKey, ""values "" + modeList.toString() + "" must contain OFF mode"",
                    modeList.contains(CameraMetadata.CONTROL_MODE_OFF));
        }

        if (isSceneModeSupported()) {
            checkTrueForKey(modesKey, ""values "" + modeList.toString() + "" must contain""
                    + "" USE_SCENE_MODE"",
                    modeList.contains(CameraMetadata.CONTROL_MODE_USE_SCENE_MODE));
        }

        return modes;
    }

    public boolean isSceneModeSupported() {
        List<Integer> availableSceneModes = Arrays.asList(
                CameraTestUtils.toObject(getAvailableSceneModesChecked()));

        if (availableSceneModes.isEmpty()) {
            return false;
        }

        // If sceneMode is not supported, camera device will contain single entry: DISABLED.
        return availableSceneModes.size() > 1 ||
                !availableSceneModes.contains(CameraMetadata.CONTROL_SCENE_MODE_DISABLED);
    }

    /**
     * Get aeAvailableModes and do the validity check.
     *
     * <p>Depending on the check level this class has, for WAR or COLLECT levels,
     * If the aeMode list is invalid, return an empty mode array. The the caller doesn't
     * have to abort the execution even the aeMode list is invalid.</p>
     * @return AE available modes
     */
    public int[] getAeAvailableModesChecked() {
        Key<int[]> modesKey = CameraCharacteristics.CONTROL_AE_AVAILABLE_MODES;
        int[] modes = getValueFromKeyNonNull(modesKey);
        if (modes == null) {
            modes = new int[0];
        }
        List<Integer> modeList = new ArrayList<Integer>();
        for (int mode : modes) {
            // Skip vendor-added modes
            if (mode <= CameraMetadata.CONTROL_AE_MODE_ON_AUTO_FLASH_REDEYE) {
                modeList.add(mode);
            }
        }
        checkTrueForKey(modesKey, ""value is empty"", !modeList.isEmpty());
        modes = new int[modeList.size()];
        for (int i = 0; i < modeList.size(); i++) {
            modes[i] = modeList.get(i);
        }

        // All camera device must support ON
        checkTrueForKey(modesKey, ""values "" + modeList.toString() + "" must contain ON mode"",
                modeList.contains(CameraMetadata.CONTROL_AE_MODE_ON));

        // All camera devices with flash units support ON_AUTO_FLASH and ON_ALWAYS_FLASH
        Key<Boolean> flashKey= CameraCharacteristics.FLASH_INFO_AVAILABLE;
        Boolean hasFlash = getValueFromKeyNonNull(flashKey);
        if (hasFlash == null) {
            hasFlash = false;
        }
        if (hasFlash) {
            boolean flashModeConsistentWithFlash =
                    modeList.contains(CameraMetadata.CONTROL_AE_MODE_ON_AUTO_FLASH) &&
                    modeList.contains(CameraMetadata.CONTROL_AE_MODE_ON_ALWAYS_FLASH);
            checkTrueForKey(modesKey,
                    ""value must contain ON_AUTO_FLASH and ON_ALWAYS_FLASH and  when flash is"" +
                    ""available"", flashModeConsistentWithFlash);
        } else {
            boolean flashModeConsistentWithoutFlash =
                    !(modeList.contains(CameraMetadata.CONTROL_AE_MODE_ON_AUTO_FLASH) ||
                    modeList.contains(CameraMetadata.CONTROL_AE_MODE_ON_ALWAYS_FLASH) ||
                    modeList.contains(CameraMetadata.CONTROL_AE_MODE_ON_AUTO_FLASH_REDEYE));
            checkTrueForKey(modesKey,
                    ""value must not contain ON_AUTO_FLASH, ON_ALWAYS_FLASH and"" +
                    ""ON_AUTO_FLASH_REDEYE when flash is unavailable"",
                    flashModeConsistentWithoutFlash);
        }

        // FULL mode camera devices always support OFF mode.
        boolean condition =
                !isHardwareLevelAtLeastFull() || modeList.contains(CameraMetadata.CONTROL_AE_MODE_OFF);
        checkTrueForKey(modesKey, ""Full capability device must have OFF mode"", condition);

        // Boundary check.
        for (int mode : modes) {
            checkTrueForKey(modesKey, ""Value "" + mode + "" is out of bound"",
                    mode >= CameraMetadata.CONTROL_AE_MODE_OFF
                    && mode <= CameraMetadata.CONTROL_AE_MODE_ON_AUTO_FLASH_REDEYE);
        }

        return modes;
    }

    /**
     * Get available AWB modes and do the validity check.
     *
     * @return array that contains available AWB modes, empty array if awbAvailableModes is
     * unavailable.
     */
    public int[] getAwbAvailableModesChecked() {
        Key<int[]> key =
                CameraCharacteristics.CONTROL_AWB_AVAILABLE_MODES;
        int[] awbModes = getValueFromKeyNonNull(key);

        if (awbModes == null) {
            return new int[0];
        }

        List<Integer> modesList = Arrays.asList(CameraTestUtils.toObject(awbModes));
        checkTrueForKey(key, "" All camera devices must support AUTO mode"",
                modesList.contains(CameraMetadata.CONTROL_AWB_MODE_AUTO));
        if (isHardwareLevelAtLeastFull()) {
            checkTrueForKey(key, "" Full capability camera devices must support OFF mode"",
                    modesList.contains(CameraMetadata.CONTROL_AWB_MODE_OFF));
        }

        return awbModes;
    }

    /**
     * Get available AF modes and do the validity check.
     *
     * @return array that contains available AF modes, empty array if afAvailableModes is
     * unavailable.
     */
    public int[] getAfAvailableModesChecked() {
        Key<int[]> key =
                CameraCharacteristics.CONTROL_AF_AVAILABLE_MODES;
        int[] afModes = getValueFromKeyNonNull(key);

        if (afModes == null) {
            return new int[0];
        }

        List<Integer> modesList = new ArrayList<Integer>();
        for (int afMode : afModes) {
            // Skip vendor-added AF modes
            if (afMode > CameraCharacteristics.CONTROL_AF_MODE_EDOF) continue;
            modesList.add(afMode);
        }
        afModes = new int[modesList.size()];
        for (int i = 0; i < modesList.size(); i++) {
            afModes[i] = modesList.get(i);
        }

        if (isHardwareLevelAtLeastLimited()) {
            // Some LEGACY mode devices do not support AF OFF
            checkTrueForKey(key, "" All camera devices must support OFF mode"",
                    modesList.contains(CameraMetadata.CONTROL_AF_MODE_OFF));
        }
        if (hasFocuser()) {
            checkTrueForKey(key, "" Camera devices that have focuser units must support AUTO mode"",
                    modesList.contains(CameraMetadata.CONTROL_AF_MODE_AUTO));
        }

        return afModes;
    }

    /**
     * Get supported raw output sizes and do the check.
     *
     * @return Empty size array if raw output is not supported
     */
    public Size[] getRawOutputSizesChecked() {
        return getAvailableSizesForFormatChecked(ImageFormat.RAW_SENSOR,
                StreamDirection.Output);
    }

    /**
     * Get supported jpeg output sizes and do the check.
     *
     * @return Empty size array if jpeg output is not supported
     */
    public Size[] getJpegOutputSizesChecked() {
        return getAvailableSizesForFormatChecked(ImageFormat.JPEG,
                StreamDirection.Output);
    }

    /**
     * Get supported heic output sizes and do the check.
     *
     * @return Empty size array if heic output is not supported
     */
    public Size[] getHeicOutputSizesChecked() {
        return getAvailableSizesForFormatChecked(ImageFormat.HEIC,
                StreamDirection.Output);
    }

    /**
     * Used to determine the stream direction for various helpers that look up
     * format or size information.
     */
    public enum StreamDirection {
        /** Stream is used with {@link android.hardware.camera2.CameraDevice#configureOutputs} */
        Output,
        /** Stream is used with {@code CameraDevice#configureInputs} -- NOT YET PUBLIC */
        Input
    }

    /**
     * Get available formats for a given direction.
     *
     * @param direction The stream direction, input or output.
     * @return The formats of the given direction, empty array if no available format is found.
     */
    public int[] getAvailableFormats(StreamDirection direction) {
        Key<StreamConfigurationMap> key =
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP;
        StreamConfigurationMap config = getValueFromKeyNonNull(key);

        if (config == null) {
            return new int[0];
        }

        switch (direction) {
            case Output:
                return config.getOutputFormats();
            case Input:
                return config.getInputFormats();
            default:
                throw new IllegalArgumentException(""direction must be output or input"");
        }
    }

    /**
     * Get valid output formats for a given input format.
     *
     * @param inputFormat The input format used to produce the output images.
     * @return The output formats for the given input format, empty array if
     *         no available format is found.
     */
    public int[] getValidOutputFormatsForInput(int inputFormat) {
        Key<StreamConfigurationMap> key =
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP;
        StreamConfigurationMap config = getValueFromKeyNonNull(key);

        if (config == null) {
            return new int[0];
        }

        return config.getValidOutputFormatsForInput(inputFormat);
    }

    /**
     * Get available sizes for given format and direction.
     *
     * @param format The format for the requested size array.
     * @param direction The stream direction, input or output.
     * @return The sizes of the given format, empty array if no available size is found.
     */
    public Size[] getAvailableSizesForFormatChecked(int format, StreamDirection direction) {
        return getAvailableSizesForFormatChecked(format, direction,
                /*fastSizes*/true, /*slowSizes*/true, /*maxResolution*/false);
    }

    /**
     * Get available sizes for given format and direction, and whether to limit to slow or fast
     * resolutions.
     *
     * @param format The format for the requested size array.
     * @param direction The stream direction, input or output.
     * @param fastSizes whether to include getOutputSizes() sizes (generally faster)
     * @param slowSizes whether to include getHighResolutionOutputSizes() sizes (generally slower)
     * @return The sizes of the given format, empty array if no available size is found.
     */
    public Size[] getAvailableSizesForFormatChecked(int format, StreamDirection direction,
            boolean fastSizes, boolean slowSizes) {
        return  getAvailableSizesForFormatChecked(format, direction, fastSizes, slowSizes,
                /*maxResolution*/ false);
    }

    /**
     * Get available sizes for given format and direction, and whether to limit to slow or fast
     * resolutions.
     *
     * @param format The format for the requested size array.
     * @param direction The stream direction, input or output.
     * @param fastSizes whether to include getOutputSizes() sizes (generally faster)
     * @param slowSizes whether to include getHighResolutionOutputSizes() sizes (generally slower)
     * @return The sizes of the given format, empty array if no available size is found.
     */
    public Size[] getAvailableSizesForFormatChecked(int format, StreamDirection direction,
            boolean fastSizes, boolean slowSizes, boolean maxResolution) {
        Key<StreamConfigurationMap> key = maxResolution ?
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP_MAXIMUM_RESOLUTION :
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP;
        StreamConfigurationMap config = getValueFromKeyNonNull(key);

        if (config == null) {
            return new Size[0];
        }

        Size[] sizes = null;

        switch (direction) {
            case Output:
                Size[] fastSizeList = null;
                Size[] slowSizeList = null;
                if (fastSizes) {
                    fastSizeList = config.getOutputSizes(format);
                }
                if (slowSizes) {
                    slowSizeList = config.getHighResolutionOutputSizes(format);
                }
                if (fastSizeList != null && slowSizeList != null) {
                    sizes = new Size[slowSizeList.length + fastSizeList.length];
                    System.arraycopy(fastSizeList, 0, sizes, 0, fastSizeList.length);
                    System.arraycopy(slowSizeList, 0, sizes, fastSizeList.length, slowSizeList.length);
                } else if (fastSizeList != null) {
                    sizes = fastSizeList;
                } else if (slowSizeList != null) {
                    sizes = slowSizeList;
                }
                break;
            case Input:
                sizes = config.getInputSizes(format);
                break;
            default:
                throw new IllegalArgumentException(""direction must be output or input"");
        }

        if (sizes == null) {
            sizes = new Size[0];
        }

        return sizes;
    }

    /**
     * Get available AE target fps ranges.
     *
     * @return Empty int array if aeAvailableTargetFpsRanges is invalid.
     */
    @SuppressWarnings(""raw"")
    public Range<Integer>[] getAeAvailableTargetFpsRangesChecked() {
        Key<Range<Integer>[]> key =
                CameraCharacteristics.CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES;
        Range<Integer>[] fpsRanges = getValueFromKeyNonNull(key);

        if (fpsRanges == null) {
            return new Range[0];
        }

        // Round down to 2 boundary if it is not integer times of 2, to avoid array out of bound
        // in case the above check fails.
        int fpsRangeLength = fpsRanges.length;
        int minFps, maxFps;
        long maxFrameDuration = getMaxFrameDurationChecked();
        for (int i = 0; i < fpsRangeLength; i += 1) {
            minFps = fpsRanges[i].getLower();
            maxFps = fpsRanges[i].getUpper();
            checkTrueForKey(key, "" min fps must be no larger than max fps!"",
                    minFps > 0 && maxFps >= minFps);
            long maxDuration = (long) (1e9 / minFps);
            checkTrueForKey(key, String.format(
                    "" the frame duration %d for min fps %d must smaller than maxFrameDuration %d"",
                    maxDuration, minFps, maxFrameDuration), maxDuration <= maxFrameDuration);
        }
        return fpsRanges;
    }

    /**
     * Get the highest supported target FPS range.
     * Prioritizes maximizing the min FPS, then the max FPS without lowering min FPS.
     */
    public Range<Integer> getAeMaxTargetFpsRange() {
        Range<Integer>[] fpsRanges = getAeAvailableTargetFpsRangesChecked();

        Range<Integer> targetRange = fpsRanges[0];
        // Assume unsorted list of target FPS ranges, so use two passes, first maximize min FPS
        for (Range<Integer> candidateRange : fpsRanges) {
            if (candidateRange.getLower() > targetRange.getLower()) {
                targetRange = candidateRange;
            }
        }
        // Then maximize max FPS while not lowering min FPS
        for (Range<Integer> candidateRange : fpsRanges) {
            if (candidateRange.getLower() >= targetRange.getLower() &&
                    candidateRange.getUpper() > targetRange.getUpper()) {
                targetRange = candidateRange;
            }
        }
        return targetRange;
    }

    /**
     * Get max frame duration.
     *
     * @return 0 if maxFrameDuration is null
     */
    public long getMaxFrameDurationChecked() {
        Key<Long> key =
                CameraCharacteristics.SENSOR_INFO_MAX_FRAME_DURATION;
        Long maxDuration = getValueFromKeyNonNull(key);

        if (maxDuration == null) {
            return 0;
        }

        return maxDuration;
    }

    /**
     * Get available minimal frame durations for a given format.
     *
     * @param format One of the format from {@link ImageFormat}.
     * @return HashMap of minimal frame durations for different sizes, empty HashMap
     *         if availableMinFrameDurations is null.
     */
    public HashMap<Size, Long> getAvailableMinFrameDurationsForFormatChecked(int format) {

        HashMap<Size, Long> minDurationMap = new HashMap<Size, Long>();

        Key<StreamConfigurationMap> key =
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP;
        StreamConfigurationMap config = getValueFromKeyNonNull(key);

        if (config == null) {
            return minDurationMap;
        }

        for (android.util.Size size : getAvailableSizesForFormatChecked(format,
                StreamDirection.Output)) {
            long minFrameDuration = config.getOutputMinFrameDuration(format, size);

            if (minFrameDuration != 0) {
                minDurationMap.put(new Size(size.getWidth(), size.getHeight()), minFrameDuration);
            }
        }

        return minDurationMap;
    }

    public int[] getAvailableEdgeModesChecked() {
        Key<int[]> key = CameraCharacteristics.EDGE_AVAILABLE_EDGE_MODES;
        int[] edgeModes = getValueFromKeyNonNull(key);

        if (edgeModes == null) {
            return new int[0];
        }

        List<Integer> modeList = Arrays.asList(CameraTestUtils.toObject(edgeModes));
        // Full device should always include OFF and FAST
        if (isHardwareLevelAtLeastFull()) {
            checkTrueForKey(key, ""Full device must contain OFF and FAST edge modes"",
                    modeList.contains(CameraMetadata.EDGE_MODE_OFF) &&
                    modeList.contains(CameraMetadata.EDGE_MODE_FAST));
        }

        if (isHardwareLevelAtLeastLimited()) {
            // FAST and HIGH_QUALITY mode must be both present or both not present
            List<Integer> coupledModes = Arrays.asList(new Integer[] {
                    CameraMetadata.EDGE_MODE_FAST,
                    CameraMetadata.EDGE_MODE_HIGH_QUALITY
            });
            checkTrueForKey(
                    key, "" FAST and HIGH_QUALITY mode must both present or both not present"",
                    containsAllOrNone(modeList, coupledModes));
        }

        return edgeModes;
    }

      public int[] getAvailableShadingModesChecked() {
        Key<int[]> key = CameraCharacteristics.SHADING_AVAILABLE_MODES;
        int[] shadingModes = getValueFromKeyNonNull(key);

        if (shadingModes == null) {
            return new int[0];
        }

        List<Integer> modeList = Arrays.asList(CameraTestUtils.toObject(shadingModes));
        // Full device should always include OFF and FAST
        if (isHardwareLevelAtLeastFull()) {
            checkTrueForKey(key, ""Full device must contain OFF and FAST shading modes"",
                    modeList.contains(CameraMetadata.SHADING_MODE_OFF) &&
                    modeList.contains(CameraMetadata.SHADING_MODE_FAST));
        }

        if (isHardwareLevelAtLeastLimited()) {
            // FAST and HIGH_QUALITY mode must be both present or both not present
            List<Integer> coupledModes = Arrays.asList(new Integer[] {
                    CameraMetadata.SHADING_MODE_FAST,
                    CameraMetadata.SHADING_MODE_HIGH_QUALITY
            });
            checkTrueForKey(
                    key, "" FAST and HIGH_QUALITY mode must both present or both not present"",
                    containsAllOrNone(modeList, coupledModes));
        }

        return shadingModes;
    }

    public int[] getAvailableNoiseReductionModesChecked() {
        Key<int[]> key =
                CameraCharacteristics.NOISE_REDUCTION_AVAILABLE_NOISE_REDUCTION_MODES;
        int[] noiseReductionModes = getValueFromKeyNonNull(key);

        if (noiseReductionModes == null) {
            return new int[0];
        }

        List<Integer> modeList = Arrays.asList(CameraTestUtils.toObject(noiseReductionModes));
        // Full device should always include OFF and FAST
        if (isHardwareLevelAtLeastFull()) {

            checkTrueForKey(key, ""Full device must contain OFF and FAST noise reduction modes"",
                    modeList.contains(CameraMetadata.NOISE_REDUCTION_MODE_OFF) &&
                    modeList.contains(CameraMetadata.NOISE_REDUCTION_MODE_FAST));
        }

        if (isHardwareLevelAtLeastLimited()) {
            // FAST and HIGH_QUALITY mode must be both present or both not present
            List<Integer> coupledModes = Arrays.asList(new Integer[] {
                    CameraMetadata.NOISE_REDUCTION_MODE_FAST,
                    CameraMetadata.NOISE_REDUCTION_MODE_HIGH_QUALITY
            });
            checkTrueForKey(
                    key, "" FAST and HIGH_QUALITY mode must both present or both not present"",
                    containsAllOrNone(modeList, coupledModes));
        }
        return noiseReductionModes;
    }

    /**
     * Get value of key android.control.aeCompensationStep and do the validity check.
     *
     * @return default value if the value is null.
     */
    public Rational getAeCompensationStepChecked() {
        Key<Rational> key =
                CameraCharacteristics.CONTROL_AE_COMPENSATION_STEP;
        Rational compensationStep = getValueFromKeyNonNull(key);

        if (compensationStep == null) {
            // Return default step.
            return CONTROL_AE_COMPENSATION_STEP_DEFAULT;
        }

        // Legacy devices don't have a minimum step requirement
        if (isHardwareLevelAtLeastLimited()) {
            float compensationStepF =
                    (float) compensationStep.getNumerator() / compensationStep.getDenominator();
            checkTrueForKey(key, "" value must be no more than 1/2"", compensationStepF <= 0.5f);
        }

        return compensationStep;
    }

    /**
     * Get value of key android.control.aeCompensationRange and do the validity check.
     *
     * @return default value if the value is null or malformed.
     */
    public Range<Integer> getAeCompensationRangeChecked() {
        Key<Range<Integer>> key =
                CameraCharacteristics.CONTROL_AE_COMPENSATION_RANGE;
        Range<Integer> compensationRange = getValueFromKeyNonNull(key);
        Rational compensationStep = getAeCompensationStepChecked();
        float compensationStepF = compensationStep.floatValue();
        final Range<Integer> DEFAULT_RANGE = Range.create(
                (int)(CONTROL_AE_COMPENSATION_RANGE_DEFAULT_MIN / compensationStepF),
                (int)(CONTROL_AE_COMPENSATION_RANGE_DEFAULT_MAX / compensationStepF));
        final Range<Integer> ZERO_RANGE = Range.create(0, 0);
        if (compensationRange == null) {
            return ZERO_RANGE;
        }

        // Legacy devices don't have a minimum range requirement
        if (isHardwareLevelAtLeastLimited() && !compensationRange.equals(ZERO_RANGE)) {
            checkTrueForKey(key, "" range value must be at least "" + DEFAULT_RANGE
                    + "", actual "" + compensationRange + "", compensation step "" + compensationStep,
                   compensationRange.getLower() <= DEFAULT_RANGE.getLower() &&
                   compensationRange.getUpper() >= DEFAULT_RANGE.getUpper());
        }

        return compensationRange;
    }

    /**
     * Get availableVideoStabilizationModes and do the validity check.
     *
     * @return available video stabilization modes, empty array if it is unavailable.
     */
    public int[] getAvailableVideoStabilizationModesChecked() {
        Key<int[]> key =
                CameraCharacteristics.CONTROL_AVAILABLE_VIDEO_STABILIZATION_MODES;
        int[] modes = getValueFromKeyNonNull(key);

        if (modes == null) {
            return new int[0];
        }

        List<Integer> modeList = Arrays.asList(CameraTestUtils.toObject(modes));
        checkTrueForKey(key, "" All device should support OFF mode"",
                modeList.contains(CameraMetadata.CONTROL_VIDEO_STABILIZATION_MODE_OFF));
        checkArrayValuesInRange(key, modes,
                CameraMetadata.CONTROL_VIDEO_STABILIZATION_MODE_OFF,
                CameraMetadata.CONTROL_VIDEO_STABILIZATION_MODE_ON);

        return modes;
    }

    public boolean isVideoStabilizationSupported() {
        Integer[] videoStabModes =
                CameraTestUtils.toObject(getAvailableVideoStabilizationModesChecked());
        return Arrays.asList(videoStabModes).contains(
                CameraMetadata.CONTROL_VIDEO_STABILIZATION_MODE_ON);
    }

    /**
     * Get availableOpticalStabilization and do the validity check.
     *
     * @return available optical stabilization modes, empty array if it is unavailable.
     */
    public int[] getAvailableOpticalStabilizationChecked() {
        Key<int[]> key =
                CameraCharacteristics.LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION;
        int[] modes = getValueFromKeyNonNull(key);

        if (modes == null) {
            return new int[0];
        }

        checkArrayValuesInRange(key, modes,
                CameraMetadata.LENS_OPTICAL_STABILIZATION_MODE_OFF,
                CameraMetadata.LENS_OPTICAL_STABILIZATION_MODE_ON);

        return modes;
    }

    /**
     * Get the scaler's max digital zoom ({@code >= 1.0f}) ratio between crop and active array
     * @return the max zoom ratio, or {@code 1.0f} if the value is unavailable
     */
    public float getAvailableMaxDigitalZoomChecked() {
        Key<Float> key =
                CameraCharacteristics.SCALER_AVAILABLE_MAX_DIGITAL_ZOOM;

        Float maxZoom = getValueFromKeyNonNull(key);
        if (maxZoom == null) {
            return 1.0f;
        }

        checkTrueForKey(key, "" max digital zoom should be no less than 1"",
                maxZoom >= 1.0f && !Float.isNaN(maxZoom) && !Float.isInfinite(maxZoom));

        return maxZoom;
    }

    public Range<Float> getZoomRatioRangeChecked() {
        Key<Range<Float>> key =
                CameraCharacteristics.CONTROL_ZOOM_RATIO_RANGE;

        Range<Float> zoomRatioRange = getValueFromKeyNonNull(key);
        if (zoomRatioRange == null) {
            return new Range<Float>(1.0f, 1.0f);
        }

        checkTrueForKey(key, String.format("" min zoom ratio %f should be no more than 1"",
                zoomRatioRange.getLower()), zoomRatioRange.getLower() <= 1.0);
        checkTrueForKey(key, String.format("" max zoom ratio %f should be no less than 1"",
                zoomRatioRange.getUpper()), zoomRatioRange.getUpper() >= 1.0);
        final float ZOOM_MIN_RANGE = 0.01f;
        checkTrueForKey(key, "" zoom ratio range should be reasonably large"",
                zoomRatioRange.getUpper().equals(zoomRatioRange.getLower()) ||
                zoomRatioRange.getUpper() - zoomRatioRange.getLower() > ZOOM_MIN_RANGE);
        return zoomRatioRange;
    }

    public int[] getAvailableSceneModesChecked() {
        Key<int[]> key =
                CameraCharacteristics.CONTROL_AVAILABLE_SCENE_MODES;
        int[] modes = getValueFromKeyNonNull(key);

        if (modes == null) {
            return new int[0];
        }

        List<Integer> modeList = Arrays.asList(CameraTestUtils.toObject(modes));
        // FACE_PRIORITY must be included if face detection is supported.
        if (areKeysAvailable(CameraCharacteristics.STATISTICS_INFO_MAX_FACE_COUNT) &&
                getMaxFaceCountChecked() > 0) {
            checkTrueForKey(key, "" FACE_PRIORITY must be included if face detection is supported"",
                    modeList.contains(CameraMetadata.CONTROL_SCENE_MODE_FACE_PRIORITY));
        }

        return modes;
    }

    public int[] getAvailableEffectModesChecked() {
        Key<int[]> key =
                CameraCharacteristics.CONTROL_AVAILABLE_EFFECTS;
        int[] modes = getValueFromKeyNonNull(key);

        if (modes == null) {
            return new int[0];
        }

        List<Integer> modeList = Arrays.asList(CameraTestUtils.toObject(modes));
        // OFF must be included.
        checkTrueForKey(key, "" OFF must be included"",
                modeList.contains(CameraMetadata.CONTROL_EFFECT_MODE_OFF));

        return modes;
    }

    public Capability[] getAvailableExtendedSceneModeCapsChecked() {
        final Size FULL_HD = new Size(1920, 1080);
        Rect activeRect = getValueFromKeyNonNull(
                CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE);
        Key<Capability[]> key =
                CameraCharacteristics.CONTROL_AVAILABLE_EXTENDED_SCENE_MODE_CAPABILITIES;
        Capability[] caps = mCharacteristics.get(key);
        if (caps == null) {
            return new Capability[0];
        }

        Size[] yuvSizes = getAvailableSizesForFormatChecked(ImageFormat.YUV_420_888,
                StaticMetadata.StreamDirection.Output);
        List<Size> yuvSizesList = Arrays.asList(yuvSizes);
        for (Capability cap : caps) {
            int extendedSceneMode = cap.getMode();
            Size maxStreamingSize = cap.getMaxStreamingSize();
            boolean maxStreamingSizeIsZero =
                    maxStreamingSize.getWidth() == 0 && maxStreamingSize.getHeight() == 0;
            switch (extendedSceneMode) {
                case CameraMetadata.CONTROL_EXTENDED_SCENE_MODE_BOKEH_STILL_CAPTURE:
                    // STILL_CAPTURE: Must either be (0, 0), or one of supported yuv/private sizes.
                    // Because spec requires yuv and private sizes match, only check YUV sizes here.
                    checkTrueForKey(key,
                            String.format("" maxStreamingSize [%d, %d] for extended scene mode "" +
                            ""%d must be a supported YCBCR_420_888 size, or (0, 0)"",
                            maxStreamingSize.getWidth(), maxStreamingSize.getHeight(),
                            extendedSceneMode),
                            yuvSizesList.contains(maxStreamingSize) || maxStreamingSizeIsZero);
                    break;
                case CameraMetadata.CONTROL_EXTENDED_SCENE_MODE_BOKEH_CONTINUOUS:
                    // CONTINUOUS: Must be one of supported yuv/private stream sizes.
                    checkTrueForKey(key,
                            String.format("" maxStreamingSize [%d, %d] for extended scene mode "" +
                            ""%d must be a supported YCBCR_420_888 size."",
                            maxStreamingSize.getWidth(), maxStreamingSize.getHeight(),
                            extendedSceneMode), yuvSizesList.contains(maxStreamingSize));
                    // Must be at least 1080p if sensor is at least 1080p.
                    if (activeRect.width() >= FULL_HD.getWidth() &&
                            activeRect.height() >= FULL_HD.getHeight()) {
                        checkTrueForKey(key,
                                String.format("" maxStreamingSize [%d, %d] for extended scene "" +
                                ""mode %d must be at least 1080p"", maxStreamingSize.getWidth(),
                                maxStreamingSize.getHeight(), extendedSceneMode),
                                maxStreamingSize.getWidth() >= FULL_HD.getWidth() &&
                                maxStreamingSize.getHeight() >= FULL_HD.getHeight());
                    }
                    break;
                default:
                    break;
            }
        }

        return caps;
    }

    /**
     * Get and check the available color aberration modes
     *
     * @return the available color aberration modes
     */
    public int[] getAvailableColorAberrationModesChecked() {
        Key<int[]> key =
                CameraCharacteristics.COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES;
        int[] modes = getValueFromKeyNonNull(key);

        if (modes == null) {
            return new int[0];
        }

        List<Integer> modeList = Arrays.asList(CameraTestUtils.toObject(modes));
        checkTrueForKey(key, "" Camera devices must always support either OFF or FAST mode"",
                modeList.contains(CameraMetadata.COLOR_CORRECTION_ABERRATION_MODE_OFF) ||
                modeList.contains(CameraMetadata.COLOR_CORRECTION_ABERRATION_MODE_FAST));

        if (isHardwareLevelAtLeastLimited()) {
            // FAST and HIGH_QUALITY mode must be both present or both not present
            List<Integer> coupledModes = Arrays.asList(new Integer[] {
                    CameraMetadata.COLOR_CORRECTION_ABERRATION_MODE_FAST,
                    CameraMetadata.COLOR_CORRECTION_ABERRATION_MODE_HIGH_QUALITY
            });
            checkTrueForKey(
                    key, "" FAST and HIGH_QUALITY mode must both present or both not present"",
                    containsAllOrNone(modeList, coupledModes));
        }
        checkElementDistinct(key, modeList);
        checkArrayValuesInRange(key, modes,
                CameraMetadata.COLOR_CORRECTION_ABERRATION_MODE_OFF,
                CameraMetadata.COLOR_CORRECTION_ABERRATION_MODE_HIGH_QUALITY);

        return modes;
    }

    /**
     * Get max pipeline depth and do the validity check.
     *
     * @return max pipeline depth, default value if it is not available.
     */
    public byte getPipelineMaxDepthChecked() {
        Key<Byte> key =
                CameraCharacteristics.REQUEST_PIPELINE_MAX_DEPTH;
        Byte maxDepth = getValueFromKeyNonNull(key);

        if (maxDepth == null) {
            return REQUEST_PIPELINE_MAX_DEPTH_MAX;
        }

        checkTrueForKey(key, "" max pipeline depth should be no larger than ""
                + REQUEST_PIPELINE_MAX_DEPTH_MAX, maxDepth <= REQUEST_PIPELINE_MAX_DEPTH_MAX);

        return maxDepth;
    }

    /**
     * Get available lens shading modes.
     */
     public int[] getAvailableLensShadingModesChecked() {
         Key<int[]> key =
                 CameraCharacteristics.SHADING_AVAILABLE_MODES;
         int[] modes = getValueFromKeyNonNull(key);
         if (modes == null) {
             return new int[0];
         }

         List<Integer> modeList = Arrays.asList(CameraTestUtils.toObject(modes));
         // FAST must be included.
         checkTrueForKey(key, "" FAST must be included"",
                 modeList.contains(CameraMetadata.SHADING_MODE_FAST));

         if (isCapabilitySupported(
                 CameraMetadata.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_POST_PROCESSING)) {
             checkTrueForKey(key, "" OFF must be included for MANUAL_POST_PROCESSING devices"",
                     modeList.contains(CameraMetadata.SHADING_MODE_OFF));
         }
         return modes;
     }

     /**
      * Get available lens shading map modes.
      */
      public int[] getAvailableLensShadingMapModesChecked() {
          Key<int[]> key =
                  CameraCharacteristics.STATISTICS_INFO_AVAILABLE_LENS_SHADING_MAP_MODES;
          int[] modes = getValueFromKeyNonNull(key);
          if (modes == null) {
              return new int[0];
          }

          List<Integer> modeList = Arrays.asList(CameraTestUtils.toObject(modes));

          if (isCapabilitySupported(
                  CameraMetadata.REQUEST_AVAILABLE_CAPABILITIES_RAW)) {
              checkTrueForKey(key, "" ON must be included for RAW capability devices"",
                      modeList.contains(CameraMetadata.STATISTICS_LENS_SHADING_MAP_MODE_ON));
          }
          return modes;
      }


    /**
     * Get available capabilities and do the validity check.
     *
     * @return reported available capabilities list, empty list if the value is unavailable.
     */
    public List<Integer> getAvailableCapabilitiesChecked() {
        Key<int[]> key =
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES;
        int[] availableCaps = getValueFromKeyNonNull(key);
        List<Integer> capList;

        if (availableCaps == null) {
            return new ArrayList<Integer>();
        }

        checkArrayValuesInRange(key, availableCaps,
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE,
                LAST_CAPABILITY_ENUM);
        capList = Arrays.asList(CameraTestUtils.toObject(availableCaps));
        return capList;
    }

    /**
     * Determine whether the current device supports a capability or not.
     *
     * @param capability (non-negative)
     *
     * @return {@code true} if the capability is supported, {@code false} otherwise.
     *
     * @throws IllegalArgumentException if {@code capability} was negative
     *
     * @see CameraCharacteristics#REQUEST_AVAILABLE_CAPABILITIES
     */
    public boolean isCapabilitySupported(int capability) {
        if (capability < 0) {
            throw new IllegalArgumentException(""capability must be non-negative"");
        }

        List<Integer> availableCapabilities = getAvailableCapabilitiesChecked();

        return availableCapabilities.contains(capability);
    }

    /**
     * Determine whether the current device supports a private reprocessing capability or not.
     *
     * @return {@code true} if the capability is supported, {@code false} otherwise.
     *
     * @throws IllegalArgumentException if {@code capability} was negative
     */
    public boolean isPrivateReprocessingSupported() {
        return isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING);
    }

    /**
     * Get sorted (descending order) size list for given input format. Remove the sizes larger than
     * the bound. If the bound is null, don't do the size bound filtering.
     *
     * @param format input format
     * @param bound maximum allowed size bound
     *
     * @return Sorted input size list (descending order)
     */
    public List<Size> getSortedSizesForInputFormat(int format, Size bound) {
        Size[] availableSizes = getAvailableSizesForFormatChecked(format, StreamDirection.Input);
        if (bound == null) {
            return CameraTestUtils.getAscendingOrderSizes(Arrays.asList(availableSizes),
                    /*ascending*/false);
        }

        List<Size> sizes = new ArrayList<Size>();
        for (Size sz: availableSizes) {
            if (sz.getWidth() <= bound.getWidth() && sz.getHeight() <= bound.getHeight()) {
                sizes.add(sz);
            }
        }

        return CameraTestUtils.getAscendingOrderSizes(sizes, /*ascending*/false);
    }


    /**
     * Determine whether or not all the {@code keys} are available characteristics keys
     * (as in {@link CameraCharacteristics#getKeys}.
     *
     * <p>If this returns {@code true}, then querying for this key from a characteristics
     * object will always return a non-{@code null} value.</p>
     *
     * @param keys collection of camera characteristics keys
     * @return whether or not all characteristics keys are available
     */
    public final boolean areCharacteristicsKeysAvailable(
            Collection<CameraCharacteristics.Key<?>> keys) {
        return mCharacteristics.getKeys().containsAll(keys);
    }

    /**
     * Determine whether or not all the {@code keys} are available result keys
     * (as in {@link CameraCharacteristics#getAvailableCaptureResultKeys}.
     *
     * <p>If this returns {@code true}, then querying for this key from a result
     * object will almost always return a non-{@code null} value.</p>
     *
     * <p>In some cases (e.g. lens shading map), the request must have additional settings
     * configured in order for the key to correspond to a value.</p>
     *
     * @param keys collection of capture result keys
     * @return whether or not all result keys are available
     */
    public final boolean areResultKeysAvailable(Collection<CaptureResult.Key<?>> keys) {
        return mCharacteristics.getAvailableCaptureResultKeys().containsAll(keys);
    }

    /**
     * Determine whether or not all the {@code keys} are available request keys
     * (as in {@link CameraCharacteristics#getAvailableCaptureRequestKeys}.
     *
     * <p>If this returns {@code true}, then setting this key in the request builder
     * may have some effect (and if it's {@code false}, then the camera device will
     * definitely ignore it).</p>
     *
     * <p>In some cases (e.g. manual control of exposure), other keys must be also be set
     * in order for a key to take effect (e.g. control.mode set to OFF).</p>
     *
     * @param keys collection of capture request keys
     * @return whether or not all result keys are available
     */
    public final boolean areRequestKeysAvailable(Collection<CaptureRequest.Key<?>> keys) {
        return mCharacteristics.getAvailableCaptureRequestKeys().containsAll(keys);
    }

    /**
     * Determine whether or not all the {@code keys} are available characteristics keys
     * (as in {@link CameraCharacteristics#getKeys}.
     *
     * <p>If this returns {@code true}, then querying for this key from a characteristics
     * object will always return a non-{@code null} value.</p>
     *
     * @param keys one or more camera characteristic keys
     * @return whether or not all characteristics keys are available
     */
    @SafeVarargs
    public final boolean areKeysAvailable(CameraCharacteristics.Key<?>... keys) {
        return areCharacteristicsKeysAvailable(Arrays.asList(keys));
    }

    /**
     * Determine whether or not all the {@code keys} are available result keys
     * (as in {@link CameraCharacteristics#getAvailableCaptureResultKeys}.
     *
     * <p>If this returns {@code true}, then querying for this key from a result
     * object will almost always return a non-{@code null} value.</p>
     *
     * <p>In some cases (e.g. lens shading map), the request must have additional settings
     * configured in order for the key to correspond to a value.</p>
     *
     * @param keys one or more capture result keys
     * @return whether or not all result keys are available
     */
    @SafeVarargs
    public final boolean areKeysAvailable(CaptureResult.Key<?>... keys) {
        return areResultKeysAvailable(Arrays.asList(keys));
    }

    /**
     * Determine whether or not all the {@code keys} are available request keys
     * (as in {@link CameraCharacteristics#getAvailableCaptureRequestKeys}.
     *
     * <p>If this returns {@code true}, then setting this key in the request builder
     * may have some effect (and if it's {@code false}, then the camera device will
     * definitely ignore it).</p>
     *
     * <p>In some cases (e.g. manual control of exposure), other keys must be also be set
     * in order for a key to take effect (e.g. control.mode set to OFF).</p>
     *
     * @param keys one or more capture request keys
     * @return whether or not all result keys are available
     */
    @SafeVarargs
    public final boolean areKeysAvailable(CaptureRequest.Key<?>... keys) {
        return areRequestKeysAvailable(Arrays.asList(keys));
    }

    /*
     * Determine if camera device support AE lock control
     *
     * @return {@code true} if AE lock control is supported
     */
    public boolean isAeLockSupported() {
        return getValueFromKeyNonNull(CameraCharacteristics.CONTROL_AE_LOCK_AVAILABLE);
    }

    /*
     * Determine if camera device supports keys that must be supported by
     * ULTRA_HIGH_RESOLUTION_SENSORs
     *
     * @return {@code true} if minimum set of keys are supported
     */
    public boolean areMaximumResolutionKeysSupported() {
        return mCharacteristics.get(
                CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE_MAXIMUM_RESOLUTION) != null &&
                mCharacteristics.get(
                        SENSOR_INFO_PRE_CORRECTION_ACTIVE_ARRAY_SIZE_MAXIMUM_RESOLUTION) != null &&
                mCharacteristics.get(
                        SENSOR_INFO_PIXEL_ARRAY_SIZE_MAXIMUM_RESOLUTION) != null &&
                mCharacteristics.get(
                        SCALER_STREAM_CONFIGURATION_MAP_MAXIMUM_RESOLUTION) != null;
    }

    /*
     * Determine if camera device support AWB lock control
     *
     * @return {@code true} if AWB lock control is supported
     */
    public boolean isAwbLockSupported() {
        return getValueFromKeyNonNull(CameraCharacteristics.CONTROL_AWB_LOCK_AVAILABLE);
    }


    /*
     * Determine if camera device support manual lens shading map control
     *
     * @return {@code true} if manual lens shading map control is supported
     */
    public boolean isManualLensShadingMapSupported() {
        return areKeysAvailable(CaptureRequest.SHADING_MODE);
    }

    /**
     * Determine if camera device support manual color correction control
     *
     * @return {@code true} if manual color correction control is supported
     */
    public boolean isColorCorrectionSupported() {
        return areKeysAvailable(CaptureRequest.COLOR_CORRECTION_MODE);
    }

    /**
     * Determine if camera device support manual tone mapping control
     *
     * @return {@code true} if manual tone mapping control is supported
     */
    public boolean isManualToneMapSupported() {
        return areKeysAvailable(CaptureRequest.TONEMAP_MODE);
    }

    /**
     * Determine if camera device support manual color aberration control
     *
     * @return {@code true} if manual color aberration control is supported
     */
    public boolean isManualColorAberrationControlSupported() {
        return areKeysAvailable(CaptureRequest.COLOR_CORRECTION_ABERRATION_MODE);
    }

    /**
     * Determine if camera device support edge mode control
     *
     * @return {@code true} if edge mode control is supported
     */
    public boolean isEdgeModeControlSupported() {
        return areKeysAvailable(CaptureRequest.EDGE_MODE);
    }

    /**
     * Determine if camera device support hot pixel mode control
     *
     * @return {@code true} if hot pixel mode control is supported
     */
    public boolean isHotPixelMapModeControlSupported() {
        return areKeysAvailable(CaptureRequest.HOT_PIXEL_MODE);
    }

    /**
     * Determine if camera device support noise reduction mode control
     *
     * @return {@code true} if noise reduction mode control is supported
     */
    public boolean isNoiseReductionModeControlSupported() {
        return areKeysAvailable(CaptureRequest.NOISE_REDUCTION_MODE);
    }

    /**
     * Get max number of output raw streams and do the basic validity check.
     *
     * @return reported max number of raw output stream
     */
    public int getMaxNumOutputStreamsRawChecked() {
        Integer maxNumStreams =
                getValueFromKeyNonNull(CameraCharacteristics.REQUEST_MAX_NUM_OUTPUT_RAW);
        if (maxNumStreams == null)
            return 0;
        return maxNumStreams;
    }

    /**
     * Get max number of output processed streams and do the basic validity check.
     *
     * @return reported max number of processed output stream
     */
    public int getMaxNumOutputStreamsProcessedChecked() {
        Integer maxNumStreams =
                getValueFromKeyNonNull(CameraCharacteristics.REQUEST_MAX_NUM_OUTPUT_PROC);
        if (maxNumStreams == null)
            return 0;
        return maxNumStreams;
    }

    /**
     * Get max number of output stalling processed streams and do the basic validity check.
     *
     * @return reported max number of stalling processed output stream
     */
    public int getMaxNumOutputStreamsProcessedStallChecked() {
        Integer maxNumStreams =
                getValueFromKeyNonNull(CameraCharacteristics.REQUEST_MAX_NUM_OUTPUT_PROC_STALLING);
        if (maxNumStreams == null)
            return 0;
        return maxNumStreams;
    }

    /**
     * Get lens facing and do the validity check
     * @return lens facing, return default value (BACK) if value is unavailable.
     */
    public int getLensFacingChecked() {
        Key<Integer> key =
                CameraCharacteristics.LENS_FACING;
        Integer facing = getValueFromKeyNonNull(key);

        if (facing == null) {
            return CameraCharacteristics.LENS_FACING_BACK;
        }

        checkTrueForKey(key, "" value is out of range "",
                facing >= CameraCharacteristics.LENS_FACING_FRONT &&
                facing <= CameraCharacteristics.LENS_FACING_EXTERNAL);
        return facing;
    }

    /**
     * Get maxCaptureStall frames or default value (if value doesn't exist)
     * @return maxCaptureStall frames or default value.
     */
    public int getMaxCaptureStallOrDefault() {
        Key<Integer> key =
                CameraCharacteristics.REPROCESS_MAX_CAPTURE_STALL;
        Integer value = getValueFromKeyNonNull(key);

        if (value == null) {
            return MAX_REPROCESS_MAX_CAPTURE_STALL;
        }

        checkTrueForKey(key, "" value is out of range "",
                value >= 0 &&
                value <= MAX_REPROCESS_MAX_CAPTURE_STALL);

        return value;
    }

    /**
     * Get the scaler's cropping type (center only or freeform)
     * @return cropping type, return default value (CENTER_ONLY) if value is unavailable
     */
    public int getScalerCroppingTypeChecked() {
        Key<Integer> key =
                CameraCharacteristics.SCALER_CROPPING_TYPE;
        Integer value = getValueFromKeyNonNull(key);

        if (value == null) {
            return CameraCharacteristics.SCALER_CROPPING_TYPE_CENTER_ONLY;
        }

        checkTrueForKey(key, "" value is out of range "",
                value >= CameraCharacteristics.SCALER_CROPPING_TYPE_CENTER_ONLY &&
                value <= CameraCharacteristics.SCALER_CROPPING_TYPE_FREEFORM);

        return value;
    }

    /**
     * Check if the constrained high speed video is supported by the camera device.
     * The high speed FPS ranges and sizes are sanitized in
     * ExtendedCameraCharacteristicsTest#testConstrainedHighSpeedCapability.
     *
     * @return true if the constrained high speed video is supported, false otherwise.
     */
    public boolean isConstrainedHighSpeedVideoSupported() {
        List<Integer> availableCapabilities = getAvailableCapabilitiesChecked();
        return (availableCapabilities.contains(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_CONSTRAINED_HIGH_SPEED_VIDEO));
    }

    /**
     * Check if this camera device is a logical multi-camera backed by multiple
     * physical cameras.
     *
     * @return true if this is a logical multi-camera.
     */
    public boolean isLogicalMultiCamera() {
        List<Integer> availableCapabilities = getAvailableCapabilitiesChecked();
        return (availableCapabilities.contains(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_LOGICAL_MULTI_CAMERA));
    }

    /**
     * Check if this camera device is an ULTRA_HIGH_RESOLUTION_SENSOR
     *
     * @return true if this is an ultra high resolution sensor
     */
    public boolean isUltraHighResolutionSensor() {
        List<Integer> availableCapabilities = getAvailableCapabilitiesChecked();
        return (availableCapabilities.contains(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_ULTRA_HIGH_RESOLUTION_SENSOR));
    }
    /**
     * Check if this camera device is a monochrome camera with Y8 support.
     *
     * @return true if this is a monochrome camera with Y8 support.
     */
    public boolean isMonochromeWithY8() {
        int[] supportedFormats = getAvailableFormats(
                StaticMetadata.StreamDirection.Output);
        return (isColorOutputSupported()
                && isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MONOCHROME)
                && CameraTestUtils.contains(supportedFormats, ImageFormat.Y8));
    }

    /**
     * Check if high speed video is supported (HIGH_SPEED_VIDEO scene mode is
     * supported, supported high speed fps ranges and sizes are valid).
     *
     * @return true if high speed video is supported.
     */
    public boolean isHighSpeedVideoSupported() {
        List<Integer> sceneModes =
                Arrays.asList(CameraTestUtils.toObject(getAvailableSceneModesChecked()));
        if (sceneModes.contains(CameraCharacteristics.CONTROL_SCENE_MODE_HIGH_SPEED_VIDEO)) {
            StreamConfigurationMap config =
                    getValueFromKeyNonNull(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
            if (config == null) {
                return false;
            }
            Size[] availableSizes = config.getHighSpeedVideoSizes();
            if (availableSizes.length == 0) {
                return false;
            }

            for (Size size : availableSizes) {
                Range<Integer>[] availableFpsRanges = config.getHighSpeedVideoFpsRangesFor(size);
                if (availableFpsRanges.length == 0) {
                    return false;
                }
            }

            return true;
        } else {
            return false;
        }
    }

    /**
     * Check if depth output is supported, based on the depth capability
     */
    public boolean isDepthOutputSupported() {
        return isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_DEPTH_OUTPUT);
    }

    /**
     * Check if offline processing is supported, based on the respective capability
     */
    public boolean isOfflineProcessingSupported() {
        return isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_OFFLINE_PROCESSING);
    }

    /**
     * Check if standard outputs (PRIVATE, YUV, JPEG) outputs are supported, based on the
     * backwards-compatible capability
     */
    public boolean isColorOutputSupported() {
        return isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE);
    }

    /**
     * Check if this camera is a MONOCHROME camera.
     */
    public boolean isMonochromeCamera() {
        return isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MONOCHROME);
    }

    /**
     * Check if optical black regions key is supported.
     */
    public boolean isOpticalBlackRegionSupported() {
        return areKeysAvailable(CameraCharacteristics.SENSOR_OPTICAL_BLACK_REGIONS);
    }

    /**
     * Check if HEIC format is supported
     */
    public boolean isHeicSupported() {
        int[] formats = getAvailableFormats(StaticMetadata.StreamDirection.Output);
        return CameraTestUtils.contains(formats, ImageFormat.HEIC);
    }

    /**
     * Check if Depth Jpeg format is supported
     */
    public boolean isDepthJpegSupported() {
        int[] formats = getAvailableFormats(StaticMetadata.StreamDirection.Output);
        return CameraTestUtils.contains(formats, ImageFormat.DEPTH_JPEG);
    }

    /**
     * Check if the dynamic black level is supported.
     *
     * <p>
     * Note that: This also indicates if the white level is supported, as dynamic black and white
     * level must be all supported or none of them is supported.
     * </p>
     */
    public boolean isDynamicBlackLevelSupported() {
        return areKeysAvailable(CaptureResult.SENSOR_DYNAMIC_BLACK_LEVEL);
    }

    /**
     * Check if the enable ZSL key is supported.
     */
    public boolean isEnableZslSupported() {
        return areKeysAvailable(CaptureRequest.CONTROL_ENABLE_ZSL);
    }

    /**
     * Check if AF scene change key is supported.
     */
    public boolean isAfSceneChangeSupported() {
        return areKeysAvailable(CaptureResult.CONTROL_AF_SCENE_CHANGE);
    }

    /**
     * Check if OIS data mode is supported.
     */
    public boolean isOisDataModeSupported() {
        int[] availableOisDataModes = mCharacteristics.get(
                CameraCharacteristics.STATISTICS_INFO_AVAILABLE_OIS_DATA_MODES);

        if (availableOisDataModes == null) {
            return false;
        }

        for (int mode : availableOisDataModes) {
            if (mode == CameraMetadata.STATISTICS_OIS_DATA_MODE_ON) {
                return true;
            }
        }

        return false;
    }

    /**
     * Check if rotate and crop is supported
     */
    public boolean isRotateAndCropSupported() {
        int[] availableRotateAndCropModes = mCharacteristics.get(
                CameraCharacteristics.SCALER_AVAILABLE_ROTATE_AND_CROP_MODES);

        if (availableRotateAndCropModes == null) {
            return false;
        }

        for (int mode : availableRotateAndCropModes) {
            if (mode != CameraMetadata.SCALER_ROTATE_AND_CROP_NONE) {
                return true;
            }
        }

        return false;
    }

    /**
     * Check if distortion correction is supported.
     */
    public boolean isDistortionCorrectionSupported() {
        boolean distortionCorrectionSupported = false;
        int[] distortionModes = mCharacteristics.get(
                CameraCharacteristics.DISTORTION_CORRECTION_AVAILABLE_MODES);
        if (distortionModes == null) {
            return false;
        }

        for (int mode : distortionModes) {
            if (mode != CaptureRequest.DISTORTION_CORRECTION_MODE_OFF) {
                return true;
            }
        }

        return false;
    }

    /**
     * Check if active physical camera Id metadata is supported.
     */
    public boolean isActivePhysicalCameraIdSupported() {
        return areKeysAvailable(CaptureResult.LOGICAL_MULTI_CAMERA_ACTIVE_PHYSICAL_ID);
    }

    /**
     * Get the value in index for a fixed-size array from a given key.
     *
     * <p>If the camera device is incorrectly reporting values, log a warning and return
     * the default value instead.</p>
     *
     * @param key Key to fetch
     * @param defaultValue Default value to return if camera device uses invalid values
     * @param name Human-readable name for the array index (logging only)
     * @param index Array index of the subelement
     * @param size Expected fixed size of the array
     *
     * @return The value reported by the camera device, or the defaultValue otherwise.
     */
    private <T> T getArrayElementOrDefault(Key<?> key, T defaultValue, String name, int index,
            int size) {
        T elementValue = getArrayElementCheckRangeNonNull(
                key,
                index,
                size);

        if (elementValue == null) {
            failKeyCheck(key,
                    ""had no valid "" + name + "" value; using default of "" + defaultValue);
            elementValue = defaultValue;
        }

        return elementValue;
    }

    /**
     * Fetch an array sub-element from an array value given by a key.
     *
     * <p>
     * Prints a warning if the sub-element was null.
     * </p>
     *
     * <p>Use for variable-size arrays since this does not check the array size.</p>
     *
     * @param key Metadata key to look up
     * @param element A non-negative index value.
     * @return The array sub-element, or null if the checking failed.
     */
    private <T> T getArrayElementNonNull(Key<?> key, int element) {
        return getArrayElementCheckRangeNonNull(key, element, IGNORE_SIZE_CHECK);
    }

    /**
     * Fetch an array sub-element from an array value given by a key.
     *
     * <p>
     * Prints a warning if the array size does not match the size, or if the sub-element was null.
     * </p>
     *
     * @param key Metadata key to look up
     * @param element The index in [0,size)
     * @param size A positive size value or otherwise {@value #IGNORE_SIZE_CHECK}
     * @return The array sub-element, or null if the checking failed.
     */
    private <T> T getArrayElementCheckRangeNonNull(Key<?> key, int element, int size) {
        Object array = getValueFromKeyNonNull(key);

        if (array == null) {
            // Warning already printed
            return null;
        }

        if (size != IGNORE_SIZE_CHECK) {
            int actualLength = Array.getLength(array);
            if (actualLength != size) {
                failKeyCheck(key,
                        String.format(""had the wrong number of elements (%d), expected (%d)"",
                                actualLength, size));
                return null;
            }
        }

        @SuppressWarnings(""unchecked"")
        T val = (T) Array.get(array, element);

        if (val == null) {
            failKeyCheck(key, ""had a null element at index"" + element);
            return null;
        }

        return val;
    }

    /**
     * Gets the key, logging warnings for null values.
     */
    public <T> T getValueFromKeyNonNull(Key<T> key) {
        if (key == null) {
            throw new IllegalArgumentException(""key was null"");
        }

        T value = mCharacteristics.get(key);

        if (value == null) {
            failKeyCheck(key, ""was null"");
        }

        return value;
    }

    private void checkArrayValuesInRange(Key<int[]> key, int[] array, int min, int max) {
        for (int value : array) {
            checkTrueForKey(key, String.format("" value is out of range [%d, %d]"", min, max),
                    value <= max && value >= min);
        }
    }

    private void checkArrayValuesInRange(Key<byte[]> key, byte[] array, byte min, byte max) {
        for (byte value : array) {
            checkTrueForKey(key, String.format("" value is out of range [%d, %d]"", min, max),
                    value <= max && value >= min);
        }
    }

    /**
     * Check the uniqueness of the values in a list.
     *
     * @param key The key to be checked
     * @param list The list contains the value of the key
     */
    private <U, T> void checkElementDistinct(Key<U> key, List<T> list) {
        // Each size must be distinct.
        Set<T> sizeSet = new HashSet<T>(list);
        checkTrueForKey(key, ""Each size must be distinct"", sizeSet.size() == list.size());
    }

    private <T> void checkTrueForKey(Key<T> key, String message, boolean condition) {
        if (!condition) {
            failKeyCheck(key, message);
        }
    }

    /* Helper function to check if the coupled modes are either all present or all non-present */
    private <T> boolean containsAllOrNone(Collection<T> observedModes, Collection<T> coupledModes) {
        if (observedModes.containsAll(coupledModes)) {
            return true;
        }
        for (T mode : coupledModes) {
            if (observedModes.contains(mode)) {
                return false;
            }
        }
        return true;
    }

    private <T> void failKeyCheck(Key<T> key, String message) {
        // TODO: Consider only warning once per key/message combination if it's too spammy.
        // TODO: Consider offering other options such as throwing an assertion exception
        String failureCause = String.format(""The static info key '%s' %s"", key.getName(), message);
        switch (mLevel) {
            case WARN:
                Log.w(TAG, failureCause);
                break;
            case COLLECT:
                mCollector.addMessage(failureCause);
                break;
            case ASSERT:
                Assert.fail(failureCause);
            default:
                throw new UnsupportedOperationException(""Unhandled level "" + mLevel);
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.devicepolicy.DeviceOwnerTest"	"testSensorToggleRestriction"	"CtsDevicePolicyManagerTestCases"	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/src/com/android/cts/devicepolicy/DeviceOwnerTest.java"	""	"public void testSensorToggleRestriction() throws Exception {
        executeDeviceOwnerTest(""SensorToggleRestrictionTest"");
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.RVCVXCheckAnalyzer"	"exists"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/RVCVXCheckAnalyzer.java"	""	"public void testpackage com.android.cts.verifier.sensors;

/*
 *.
 */
import android.media.MediaCodec;
import android.media.MediaExtractor;
import android.media.MediaFormat;
import android.os.Debug;
import android.os.Environment;
import android.os.PowerManager;
import android.util.JsonWriter;
import android.util.Log;

import org.opencv.core.Mat;
import org.opencv.core.CvType;
import org.opencv.core.MatOfDouble;
import org.opencv.core.MatOfFloat;
import org.opencv.core.MatOfPoint2f;
import org.opencv.core.MatOfPoint3f;
import org.opencv.core.Point;
import org.opencv.core.Size;
import org.opencv.imgcodecs.Imgcodecs;
import org.opencv.imgproc.Imgproc;
import org.opencv.calib3d.Calib3d;
import org.opencv.core.Core;

import org.json.JSONObject;
import org.json.JSONException;

import java.io.BufferedReader;
import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.FileReader;
import java.io.IOException;
import java.io.OutputStream;
import java.io.OutputStreamWriter;
import java.nio.ByteBuffer;
import java.util.ArrayList;

import android.opengl.GLES20;
import javax.microedition.khronos.opengles.GL10;

/**
 *  This class does analysis on the recorded RVCVCXCheck data sets.
 */
public class RVCVXCheckAnalyzer {
    private static final String TAG = ""RVCVXAnalysis"";
    private static final boolean LOCAL_LOGV = false;
    private static final boolean LOCAL_LOGD = true;
    private final String mPath;

    private static final boolean OUTPUT_DEBUG_IMAGE = false;
    private static final double VALID_FRAME_THRESHOLD = 0.8;
    private static final double REPROJECTION_THRESHOLD_RATIO = 0.01;
    private static final boolean FORCE_CV_ANALYSIS  = false;
    private static final boolean TRACE_VIDEO_ANALYSIS = false;
    private static final double DECIMATION_FPS_TARGET = 15.0;
    private static final double MIN_VIDEO_LENGTH_SEC = 10;

    private final boolean mHaveInvertedImu;

    RVCVXCheckAnalyzer(String path, boolean haveInvertedImu)
    {
        mPath = path;
        mHaveInvertedImu = haveInvertedImu;
    }

    /**
     * A class that contains  the analysis results
     *
     */
    class AnalyzeReport {
        public boolean error=true;
        public String reason = ""incomplete"";

        // roll pitch yaw RMS error ( \sqrt{\frac{1}{n} \sum e_i^2 })
        // unit in rad
        public double roll_rms_error;
        public double pitch_rms_error;
        public double yaw_rms_error;

        // roll pitch yaw max error
        // unit in rad
        public double roll_max_error;
        public double pitch_max_error;
        public double yaw_max_error;

        // optimal t delta between sensor and camera data set to make best match
        public double optimal_delta_t;
        // the associate yaw offset based on initial values
        public double yaw_offset;

        public int n_of_frame;
        public int n_of_valid_frame;

        // both data below are in [sec]
        public double sensor_period_avg;
        public double sensor_period_stdev;

        /**
         * write Json format serialization to a file in case future processing need the data
         */
        public void writeToFile(File file) {
            try {
                writeJSONToStream(new FileOutputStream(file));
            } catch (FileNotFoundException e) {
                e.printStackTrace();
                Log.e(TAG, ""Cannot create analyze report file."");
            }
        }

        /**
         * Get the JSON format serialization
         *@return Json format serialization as String
         */
        @Override
        public String toString() {
            ByteArrayOutputStream s = new ByteArrayOutputStream();
            writeJSONToStream(s);
            return new String(s.toByteArray(),  java.nio.charset.StandardCharsets.UTF_8);
        }

        private void writeJSONToStream(OutputStream s) {
            try{
                JsonWriter writer =
                        new JsonWriter(
                                new OutputStreamWriter( s )
                        );
                writer.beginObject();
                writer.setLenient(true);

                writer.name(""roll_rms_error"").value(roll_rms_error);
                writer.name(""pitch_rms_error"").value(pitch_rms_error);
                writer.name(""yaw_rms_error"").value(yaw_rms_error);
                writer.name(""roll_max_error"").value(roll_max_error);
                writer.name(""pitch_max_error"").value(pitch_max_error);
                writer.name(""yaw_max_error"").value(yaw_max_error);
                writer.name(""optimal_delta_t"").value(optimal_delta_t);
                writer.name(""yaw_offset"").value(yaw_offset);
                writer.name(""n_of_frame"").value(n_of_frame);
                writer.name(""n_of_valid_frame"").value(n_of_valid_frame);
                writer.name(""sensor_period_avg"").value(sensor_period_avg);
                writer.name(""sensor_period_stdev"").value(sensor_period_stdev);

                writer.endObject();

                writer.close();
            } catch (IOException e) {
                // do nothing
                Log.e(TAG, ""Error in serialize analyze report to JSON"");
            } catch (IllegalArgumentException e) {
                e.printStackTrace();
                Log.e(TAG, ""Invalid parameter to write into JSON format"");
            }
        }
    }

    /**
     *  Process data set stored in the path specified in constructor
     *  and return an analyze report to caller
     *
     *  @return An AnalyzeReport that contains detailed information about analysis
     */
    public AnalyzeReport processDataSet() {
        int nframe;// number of frames in video
        int nslog; // number of sensor log
        int nvlog; // number of video generated log


        AnalyzeReport report = new AnalyzeReport();

        ArrayList<AttitudeRec> srecs = new ArrayList<>();
        ArrayList<AttitudeRec> vrecs = new ArrayList<>();
        ArrayList<AttitudeRec> srecs2 = new ArrayList<>();


        final boolean use_solved = new File(mPath, ""vision_rpy.log"").exists() && !FORCE_CV_ANALYSIS;

        if (use_solved) {
            nframe = nvlog = loadAttitudeRecs(new File(mPath, ""vision_rpy.log""), vrecs);
            nslog = loadAttitudeRecs(new File(mPath, ""sensor_rpy.log""),srecs);
        }else {
            nframe = analyzeVideo(vrecs);
            nvlog = vrecs.size();

            if (LOCAL_LOGV) {
                Log.v(TAG, ""Post video analysis nvlog = "" + nvlog + "" nframe="" + nframe);
            }
            if (nvlog <= 0 || nframe <= 0) {
                // invalid results
                report.reason = ""Unable to load recorded video."";
                return report;
            }
            if (nframe < MIN_VIDEO_LENGTH_SEC*VALID_FRAME_THRESHOLD) {
                // video is too short
                Log.w(TAG, ""Video record is to short, n frame = "" + nframe);
                report.reason = ""Video too short."";
                return report;
            }
            if ((double) nvlog / nframe < VALID_FRAME_THRESHOLD) {
                // too many invalid frames
                Log.w(TAG, ""Too many invalid frames, n valid frame = "" + nvlog +
                        "", n total frame = "" + nframe);
                report.reason = ""Too many invalid frames."";
                return report;
            }

            fixFlippedAxis(vrecs);

            nslog = loadSensorLog(srecs);
        }

        // Gradient descent will have faster performance than this simple search,
        // but the performance is dominated by the vision part, so it is not very necessary.
        double delta_t;
        double min_rms = Double.MAX_VALUE;
        double min_delta_t =0.;
        double min_yaw_offset =0.;

        // pre-allocation
        for (AttitudeRec i: vrecs) {
            srecs2.add(new AttitudeRec(0,0,0,0));
        }

        // find optimal offset
        for (delta_t = -2.0; delta_t<2.0; delta_t +=0.01) {
            double rms;
            resampleSensorLog(srecs, vrecs, delta_t, 0.0, srecs2);
            rms = Math.sqrt(calcSqrErr(vrecs, srecs2, 0)+ calcSqrErr(vrecs, srecs2, 1));
            if (rms < min_rms) {
                min_rms = rms;
                min_delta_t = delta_t;
                min_yaw_offset = vrecs.get(0).yaw - srecs2.get(0).yaw;
            }
        }
        // sample at optimal offset
        resampleSensorLog(srecs, vrecs, min_delta_t, min_yaw_offset, srecs2);

        if (!use_solved) {
            dumpAttitudeRecs(new File(mPath, ""vision_rpy.log""), vrecs);
            dumpAttitudeRecs(new File(mPath, ""sensor_rpy.log""), srecs);
        }
        dumpAttitudeRecs(new File(mPath, ""sensor_rpy_resampled.log""), srecs2);
        dumpAttitudeError(new File(mPath, ""attitude_error.log""), vrecs, srecs2);

        // fill report fields
        report.roll_rms_error = Math.sqrt(calcSqrErr(vrecs, srecs2, 0));
        report.pitch_rms_error = Math.sqrt(calcSqrErr(vrecs, srecs2, 1));
        report.yaw_rms_error = Math.sqrt(calcSqrErr(vrecs, srecs2, 2));

        report.roll_max_error = calcMaxErr(vrecs, srecs2, 0);
        report.pitch_max_error = calcMaxErr(vrecs, srecs2, 1);
        report.yaw_max_error = calcMaxErr(vrecs, srecs2, 2);

        report.optimal_delta_t = min_delta_t;
        report.yaw_offset = (min_yaw_offset);

        report.n_of_frame = nframe;
        report.n_of_valid_frame = nvlog;

        double [] sensor_period_stat = calcSensorPeriodStat(srecs);
        report.sensor_period_avg = sensor_period_stat[0];
        report.sensor_period_stdev = sensor_period_stat[1];

        // output report to file and log in JSON format as well
        report.writeToFile(new File(mPath, ""report.json""));
        if (LOCAL_LOGV)    Log.v(TAG, ""Report in JSON:"" + report.toString());

        report.reason = ""Completed"";
        report.error = false;
        return report;
    }

    /**
     * Generate pattern geometry like this one
     * http://docs.opencv.org/trunk/_downloads/acircles_pattern.png
     *
     * @return Array of 3D points
     */
    private MatOfPoint3f asymmetricalCircleGrid(Size size) {
        final int cn = 3;

        int n = (int)(size.width * size.height);
        float positions[] = new float[n * cn];
        float unit=0.02f;
        MatOfPoint3f grid = new MatOfPoint3f();

        for (int i = 0; i < size.height; i++) {
            for (int j = 0; j < size.width * cn; j += cn) {
                positions[(int) (i * size.width * cn + j + 0)] =
                        (2 * (j / cn) + i % 2) * (float) unit;
                positions[(int) (i * size.width * cn + j + 1)] =
                        i * unit;
                positions[(int) (i * size.width * cn + j + 2)] = 0;
            }
        }
        grid.create(n, 1, CvType.CV_32FC3);
        grid.put(0, 0, positions);
        return grid;
    }

    /**
     *  Create a camera intrinsic matrix using input parameters
     *
     *  The camera intrinsic matrix will be like:
     *
     *       +-                       -+
     *       |  f   0    center.width  |
     *   A = |  0   f    center.height |
     *       |  0   0         1        |
     *       +-                       -+
     *
     *  @return An approximated (not actually calibrated) camera matrix
     */
    private static Mat cameraMatrix(float f, Size center) {
        final double [] data = {f, 0, center.width, 0, f, center.height, 0, 0, 1f};
        Mat m = new Mat(3,3, CvType.CV_64F);
        m.put(0, 0, data);
        return m;
    }

    /**
     *  Attitude record in time roll pitch yaw format.
     *
     */
    private class AttitudeRec {
        public double time;
        public double roll;
        public double pitch;
        public double yaw;

        // ctor
        AttitudeRec(double atime, double aroll, double apitch, double ayaw) {
            time = atime;
            roll = aroll;
            pitch = apitch;
            yaw = ayaw;
        }

        // ctor
        AttitudeRec(double atime, double [] rpy) {
            time = atime;
            roll = rpy[0];
            pitch = rpy[1];
            yaw = rpy[2];
        }

        // copy value of another to this
        void assign(AttitudeRec rec) {
            time = rec.time;
            roll = rec.time;
            pitch = rec.pitch;
            yaw = rec.yaw;
        }

        // copy roll-pitch-yaw value but leave the time specified by atime
        void assign(AttitudeRec rec, double atime) {
            time = atime;
            roll = rec.time;
            pitch = rec.pitch;
            yaw = rec.yaw;
        }

        // set each field separately
        void set(double atime, double aroll, double apitch, double ayaw) {
            time = atime;
            roll = aroll;
            pitch = apitch;
            yaw = ayaw;
        }
    }


    /**
     *  Load the sensor log in (time Roll-pitch-yaw) format to a ArrayList<AttitudeRec>
     *
     *  @return the number of sensor log items
     */
    private int loadSensorLog(ArrayList<AttitudeRec> recs) {
        //ArrayList<AttitudeRec> recs = new ArrayList<AttitudeRec>();
        File csvFile = new File(mPath, ""sensor.log"");
        BufferedReader br=null;
        String line;

        // preallocate and reuse
        double [] quat = new double[4];
        double [] rpy = new double[3];

        double t0 = -1;

        Log.i(TAG, ""Converting sensor log; inverted IMU adjustment: "" + mHaveInvertedImu);
        try {
            br = new BufferedReader(new FileReader(csvFile));
            while ((line = br.readLine()) != null) {
                //space separator
                String[] items = line.split("" "");

                if (items.length != 5) {
                    recs.clear();
                    return -1;
                }

                quat[0] = Double.parseDouble(items[1]);
                quat[1] = Double.parseDouble(items[2]);
                quat[2] = Double.parseDouble(items[3]);
                quat[3] = Double.parseDouble(items[4]);

                //
                quat2rpy(quat, rpy);

                if (mHaveInvertedImu) {
                    // Compensate for front-facing camera rotated around hinge along
                    // Y-axis with IMU on same panel (so IMU X & Z axes are inverted
                    // compared to what we expect): offset roll by 180 degrees and
                    // invert pitch and roll directions
                    rpy[0] -= Math.PI;
                    if (rpy[0] <= -Math.PI) {
                      rpy[0] += 2 * Math.PI;
                    }
                    rpy[0] *= -1;
                    rpy[1] *= -1;
                }

                if (t0 < 0) {
                    t0 = Long.parseLong(items[0])/1e9;
                }
                recs.add(new AttitudeRec(Long.parseLong(items[0])/1e9-t0, rpy));
            }

        } catch (FileNotFoundException e) {
            e.printStackTrace();
            Log.e(TAG, ""Cannot find sensor logging data"");
        } catch (IOException e) {
            e.printStackTrace();
            Log.e(TAG, ""Cannot read sensor logging data"");
        } finally {
            if (br != null) {
                try {
                    br.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }

        return recs.size();
    }

    /**
     * Read video meta info
     */
    private class VideoMetaInfo {
        public double fps;
        public int frameWidth;
        public int frameHeight;
        public double fovWidth;
        public double fovHeight;
        public boolean valid = false;

        VideoMetaInfo(File file) {

            BufferedReader br=null;
            String line;
            String content="""";
            try {
                br = new BufferedReader(new FileReader(file));
                while ((line = br.readLine()) != null) {
                    content = content +line;
                }

            } catch (FileNotFoundException e) {
                e.printStackTrace();
                Log.e(TAG, ""Cannot find video meta info file"");
            } catch (IOException e) {
                e.printStackTrace();
                Log.e(TAG, ""Cannot read video meta info file"");
            } finally {
                if (br != null) {
                    try {
                        br.close();
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                }
            }

            if (content.isEmpty()) {
                return;
            }

            try {
                JSONObject json = new JSONObject(content);
                frameWidth = json.getInt(""width"");
                frameHeight = json.getInt(""height"");
                fps = json.getDouble(""frameRate"");
                fovWidth = json.getDouble(""fovW"")*Math.PI/180.0;
                fovHeight = json.getDouble(""fovH"")*Math.PI/180.0;
            } catch (JSONException e) {
                return;
            }

            valid = true;

        }
    }



    /**
     * Debugging helper function, load ArrayList<AttitudeRec> from a file dumped out by
     * dumpAttitudeRecs
     */
    private int loadAttitudeRecs(File file, ArrayList<AttitudeRec> recs) {
        BufferedReader br=null;
        String line;
        double time;
        double [] rpy = new double[3];

        try {
            br = new BufferedReader(new FileReader(file));
            while ((line = br.readLine()) != null) {
                //space separator
                String[] items = line.split("" "");

                if (items.length != 4) {
                    recs.clear();
                    return -1;
                }

                time = Double.parseDouble(items[0]);
                rpy[0] = Double.parseDouble(items[1]);
                rpy[1] = Double.parseDouble(items[2]);
                rpy[2] = Double.parseDouble(items[3]);

                recs.add(new AttitudeRec(time, rpy));
            }

        } catch (FileNotFoundException e) {
            e.printStackTrace();
            Log.e(TAG, ""Cannot find AttitudeRecs file specified."");
        } catch (IOException e) {
            e.printStackTrace();
            Log.e(TAG, ""Read AttitudeRecs file failure"");
        } finally {
            if (br != null) {
                try {
                    br.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }

        return recs.size();
    }
    /**
     * Debugging helper function, Dump an ArrayList<AttitudeRec> to a file
     */
    private void dumpAttitudeRecs(File file, ArrayList<AttitudeRec> recs) {
        OutputStreamWriter w=null;
        try {
            w = new OutputStreamWriter(new FileOutputStream(file));

            for (AttitudeRec r : recs) {
                w.write(String.format(""%f %f %f %f\r\n"", r.time, r.roll, r.pitch, r.yaw));
            }
            w.close();
        } catch(FileNotFoundException e) {
            e.printStackTrace();
            Log.e(TAG, ""Cannot create AttitudeRecs file."");
        } catch (IOException e) {
            Log.e(TAG, ""Write AttitudeRecs file failure"");
        } finally {
            if (w!=null) {
                try {
                    w.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
    }

    /**
     *  Read the sensor log in ArrayList<AttitudeRec> format and find out the sensor sample time
     *  statistics: mean and standard deviation.
     *
     *  @return The returned value will be a double array with exact 2 items, first [0] will be
     *  mean and the second [1]  will be the standard deviation.
     *
     */
    private double [] calcSensorPeriodStat(ArrayList<AttitudeRec> srec)   {
        double tp = srec.get(0).time;
        int i;
        double sum = 0.0;
        double sumsq = 0.0;
        for(i=1; i<srec.size(); ++i) {
            double dt;
            dt = srec.get(i).time - tp;
            sum += dt;
            sumsq += dt*dt;
            tp += dt;
        }
        double [] ret = new double[2];
        ret[0] = sum/srec.size();
        ret[1] = Math.sqrt(sumsq/srec.size() - ret[0]*ret[0]);
        return ret;
    }

    /**
     * Flipping the axis as the image are flipped upside down in OpenGL frames
     */
    private void fixFlippedAxis(ArrayList<AttitudeRec> vrecs)   {
        for (AttitudeRec i: vrecs) {
            i.yaw = -i.yaw;
        }
    }

    /**
     *  Calculate the maximum error on the specified axis between two time aligned (resampled)
     *  ArrayList<AttitudeRec>. Yaw axis needs special treatment as 0 and 2pi error are same thing
     *
     * @param ra  one ArrayList of AttitudeRec
     * @param rb  the other ArrayList of AttitudeRec
     * @param axis axis id for the comparison (0 = roll, 1 = pitch, 2 = yaw)
     * @return Maximum error
     */
    private double calcMaxErr(ArrayList<AttitudeRec> ra, ArrayList<AttitudeRec> rb, int axis)  {
        // check if they are valid and comparable data
        if (ra.size() != rb.size()) {
            throw new ArrayIndexOutOfBoundsException(""Two array has to be the same"");
        }
        // check input parameter validity
        if (axis<0 || axis > 2) {
            throw new IllegalArgumentException(""Invalid data axis."");
        }

        int i;
        double max = 0.0;
        double diff = 0.0;
        for(i=0; i<ra.size(); ++i) {
            // make sure they are aligned data
            if (ra.get(i).time != rb.get(i).time) {
                throw new IllegalArgumentException(""Element ""+i+
                        "" of two inputs has different time."");
            }
            switch(axis) {
                case 0:
                    diff = ra.get(i).roll - rb.get(i).roll; // they always opposite of each other..
                    break;
                case 1:
                    diff = ra.get(i).pitch - rb.get(i).pitch;
                    break;
                case 2:
                    diff = Math.abs(((4*Math.PI + ra.get(i).yaw - rb.get(i).yaw)%(2*Math.PI))
                            -Math.PI)-Math.PI;
                    break;
            }
            diff = Math.abs(diff);
            if (diff>max) {
                max = diff;
            }
        }
        return max;
    }

    /**
     *  Calculate the RMS error on the specified axis between two time aligned (resampled)
     *  ArrayList<AttitudeRec>. Yaw axis needs special treatment as 0 and 2pi error are same thing
     *
     * @param ra  one ArrayList of AttitudeRec
     * @param rb  the other ArrayList of AttitudeRec
     * @param axis axis id for the comparison (0 = roll, 1 = pitch, 2 = yaw)
     * @return Mean square error
     */
    private double calcSqrErr(ArrayList<AttitudeRec> ra, ArrayList<AttitudeRec> rb, int axis) {
        // check if they are valid and comparable data
        if (ra.size() != rb.size()) {
            throw new ArrayIndexOutOfBoundsException(""Two array has to be the same"");
        }
        // check input parameter validity
        if (axis<0 || axis > 2) {
            throw new IllegalArgumentException(""Invalid data axis."");
        }

        int i;
        double sum = 0.0;
        double diff = 0.0;
        for(i=0; i<ra.size(); ++i) {
            // check input data validity
            if (ra.get(i).time != rb.get(i).time) {
                throw new IllegalArgumentException(""Element ""+i+
                        "" of two inputs has different time."");
            }

            switch(axis) {
                case 0:
                    diff = ra.get(i).roll - rb.get(i).roll;
                    break;
                case 1:
                    diff = ra.get(i).pitch - rb.get(i).pitch;
                    break;
                case 2:
                    diff = Math.abs(((4*Math.PI + ra.get(i).yaw - rb.get(i).yaw)%(2*Math.PI))-
                            Math.PI)-Math.PI;
                    break;
            }

            sum += diff*diff;
        }
        return sum/ra.size();
    }

    /**
     * Debugging helper function. Dump the error between two time aligned ArrayList<AttitudeRec>'s
     *
     * @param file File to write to
     * @param ra  one ArrayList of AttitudeRec
     * @param rb  the other ArrayList of AttitudeRec
     */
    private void dumpAttitudeError(File file, ArrayList<AttitudeRec> ra, ArrayList<AttitudeRec> rb){
        if (ra.size() != rb.size()) {
            throw new ArrayIndexOutOfBoundsException(""Two array has to be the same"");
        }

        int i;

        ArrayList<AttitudeRec> rerr = new ArrayList<>();
        for(i=0; i<ra.size(); ++i) {
            if (ra.get(i).time != rb.get(i).time) {
                throw new IllegalArgumentException(""Element ""+ i
                        + "" of two inputs has different time."");
            }

            rerr.add(new AttitudeRec(ra.get(i).time, ra.get(i).roll - rb.get(i).roll,
                    ra.get(i).pitch - rb.get(i).pitch,
                    (Math.abs(((4*Math.PI + ra.get(i).yaw - rb.get(i).yaw)%(2*Math.PI))
                            -Math.PI)-Math.PI)));

        }
        dumpAttitudeRecs(file, rerr);
    }

    /**
     * Resample one ArrayList<AttitudeRec> with respect to another ArrayList<AttitudeRec>
     *
     * @param rec           the ArrayList of AttitudeRec to be sampled
     * @param timebase      the other ArrayList of AttitudeRec that serves as time base
     * @param delta_t       offset in time before resample
     * @param yaw_offset    offset in yaw axis
     * @param resampled     output ArrayList of AttitudeRec
     */

    private void resampleSensorLog(ArrayList<AttitudeRec> rec, ArrayList<AttitudeRec> timebase,
            double delta_t, double yaw_offset, ArrayList<AttitudeRec> resampled)    {
        int i;
        int j = -1;
        for(i=0; i<timebase.size(); i++) {
            double time = timebase.get(i).time + delta_t;

            while(j<rec.size()-1 && rec.get(j+1).time < time) j++;

            if (j == -1) {
                //use first
                resampled.get(i).assign(rec.get(0), timebase.get(i).time);
            } else if (j == rec.size()-1) {
                // use last
                resampled.get(i).assign(rec.get(j), timebase.get(i).time);
            } else {
                // do linear resample
                double alpha = (time - rec.get(j).time)/((rec.get(j+1).time - rec.get(j).time));
                double roll = (1-alpha) * rec.get(j).roll + alpha * rec.get(j+1).roll;
                double pitch = (1-alpha) * rec.get(j).pitch + alpha * rec.get(j+1).pitch;
                double yaw = (1-alpha) * rec.get(j).yaw + alpha * rec.get(j+1).yaw + yaw_offset;
                resampled.get(i).set(timebase.get(i).time, roll, pitch, yaw);
            }
        }
    }

    /**
     * Analyze video frames using computer vision approach and generate a ArrayList<AttitudeRec>
     *
     * @param recs  output ArrayList of AttitudeRec
     * @return total number of frame of the video
     */
    private int analyzeVideo(ArrayList<AttitudeRec> recs) {
        VideoMetaInfo meta = new VideoMetaInfo(new File(mPath, ""videometa.json""));

        int decimation = 1;
        boolean use_timestamp = true;

        // roughly determine if decimation is necessary
        if (meta.fps > DECIMATION_FPS_TARGET) {
            decimation = (int)(meta.fps / DECIMATION_FPS_TARGET);
            meta.fps /=decimation;
        }

        VideoDecoderForOpenCV videoDecoder = new VideoDecoderForOpenCV(
                new File(mPath, ""video.mp4""), decimation);


        Mat frame;
        Mat gray = new Mat();
        int i = -1;

        Size frameSize = videoDecoder.getSize();

        if (frameSize.width != meta.frameWidth || frameSize.height != meta.frameHeight) {
            // this is very unlikely
            return -1;
        }

        if (TRACE_VIDEO_ANALYSIS) {
            Debug.startMethodTracing(""cvprocess"");
        }

        final int patternWidth = 4;
        final int patternHeight = 11;
        Size patternSize = new Size(patternWidth, patternHeight);

        float fc = (float)(meta.frameWidth/2.0/Math.tan(meta.fovWidth/2.0));
        Mat camMat = cameraMatrix(fc, new Size(frameSize.width/2, frameSize.height/2));
        MatOfDouble coeff = new MatOfDouble(); // dummy

        MatOfPoint2f centers = new MatOfPoint2f();
        MatOfPoint3f grid = asymmetricalCircleGrid(patternSize);
        Mat rvec = new MatOfFloat();
        Mat tvec = new MatOfFloat();

        MatOfPoint2f reprojCenters = new MatOfPoint2f();

        if (LOCAL_LOGV) {
            Log.v(TAG, ""Camera Mat = \n"" + camMat.dump());
        }

        long startTime = System.nanoTime();
        long [] ts = new long[1];

        while ((frame = videoDecoder.getFrame(ts)) !=null) {
            if (LOCAL_LOGV) {
                Log.v(TAG, ""got a frame "" + i);
            }

            if (use_timestamp && ts[0] == -1) {
                use_timestamp = false;
            }

            // has to be in front, as there are cases where execution
            // will skip the later part of this while
            i++;

            // convert to gray manually as by default findCirclesGridDefault uses COLOR_BGR2GRAY
            Imgproc.cvtColor(frame, gray, Imgproc.COLOR_RGB2GRAY);

            boolean foundPattern = Calib3d.findCirclesGrid(
                    gray,  patternSize, centers, Calib3d.CALIB_CB_ASYMMETRIC_GRID);

            if (!foundPattern) {
                // skip to next frame
                continue;
            }

            if (OUTPUT_DEBUG_IMAGE) {
                Calib3d.drawChessboardCorners(frame, patternSize, centers, true);
            }

            // figure out the extrinsic parameters using real ground truth 3D points and the pixel
            // position of blobs found in findCircleGrid, an estimated camera matrix and
            // no-distortion are assumed.
            boolean foundSolution =
                    Calib3d.solvePnP(grid, centers, camMat, coeff, rvec, tvec,
                            false, Calib3d.CV_ITERATIVE);

            if (!foundSolution) {
                // skip to next frame
                if (LOCAL_LOGV) {
                    Log.v(TAG, ""cannot find pnp solution in frame "" + i + "", skipped."");
                }
                continue;
            }

            // reproject points to for evaluation of result accuracy of solvePnP
            Calib3d.projectPoints(grid, rvec, tvec, camMat, coeff, reprojCenters);

            // Calculate the average distance between opposite corners of the pattern in pixels
            Point[] centerPoints = centers.toArray();
            Point bottomLeftPos = centerPoints[0];
            Point bottomRightPos = centerPoints[patternWidth - 1];
            Point topLeftPos = centerPoints[(patternHeight * patternWidth) - patternWidth];
            Point topRightPos = centerPoints[(patternHeight * patternWidth) - 1];
            double avgPixelDist = (getDistanceBetweenPoints(bottomLeftPos, topRightPos)
                    + getDistanceBetweenPoints(bottomRightPos, topLeftPos)) / 2;

            // Calculate the average pixel error between the circle centers from the video and the
            // reprojected circle centers based on the estimated camera position. The error provides
            // a way to estimate how accurate the assumed test device's position is. If the error
            // is high, then the frame should be discarded to prevent an inaccurate test device's
            // position from being compared against the rotation vector sample at that time.
            Point[] reprojectedPointsArray = reprojCenters.toArray();
            double avgCenterError = 0.0;
            for (int curCenter = 0; curCenter < reprojectedPointsArray.length; curCenter++) {
                avgCenterError += getDistanceBetweenPoints(
                        reprojectedPointsArray[curCenter], centerPoints[curCenter]);
            }
            avgCenterError /= reprojectedPointsArray.length;

            if (LOCAL_LOGV) {
                Log.v(TAG, ""Found attitude, re-projection error = "" + avgCenterError);
            }

            // if error is reasonable, add it into the results. Use a dynamic threshold based on
            // the pixel distance of opposite corners of the pattern to prevent higher resolution
            // video or the distance between the camera and the test pattern from impacting the test
            if (avgCenterError < REPROJECTION_THRESHOLD_RATIO * avgPixelDist) {
                double [] rv = new double[3];
                double timestamp;

                rvec.get(0,0, rv);
                if (use_timestamp) {
                    timestamp = (double)ts[0] / 1e6;
                } else {
                    timestamp = (double) i / meta.fps;
                }
                if (LOCAL_LOGV) Log.v(TAG, String.format(""Added frame %d  ts = %f"", i, timestamp));
                recs.add(new AttitudeRec(timestamp, rodr2rpy(rv)));
            }

            if (OUTPUT_DEBUG_IMAGE) {
                Calib3d.drawChessboardCorners(frame, patternSize, reprojCenters, true);
                Imgcodecs.imwrite(mPath + ""/RVCVRecData/DebugCV/img"" + i + "".png"", frame);
            }
        }

        if (LOCAL_LOGV) {
            Log.v(TAG, ""Finished decoding"");
        }

        if (TRACE_VIDEO_ANALYSIS) {
            Debug.stopMethodTracing();
        }

        if (LOCAL_LOGV) {
            // time analysis
            double totalTime = (System.nanoTime()-startTime)/1e9;
            Log.i(TAG, ""Total time: ""+totalTime +""s, Per frame time: ""+totalTime/i );
        }
        return i;
    }

    /**
     * OpenCV for Android have not support the VideoCapture from file
     * This is a make shift solution before it is supported.
     * One issue right now is that the glReadPixels is quite slow .. around 6.5ms for a 720p frame
     */
    private class VideoDecoderForOpenCV implements Runnable {
        static final String TAG = ""VideoDecoderForOpenCV"";

        private MediaExtractor extractor=null;
        private MediaCodec decoder=null;
        private CtsMediaOutputSurface surface=null;

        private MatBuffer mMatBuffer;

        private final File mVideoFile;

        private boolean valid;
        private Object setupSignal;

        private Thread mThread;
        private int mDecimation;

        /**
         * Constructor
         * @param file video file
         * @param decimation process every ""decimation"" number of frame
         */
        VideoDecoderForOpenCV(File file, int decimation) {
            mVideoFile = file;
            mDecimation = decimation;
            valid = false;

            start();
        }

        /**
         * Constructor
         * @param file video file
         */
        VideoDecoderForOpenCV(File file)   {
            this(file, 1);
        }

        /**
         * Test if video decoder is in valid states ready to output video.
         * @return true of force.
         */
        public boolean isValid() {
            return valid;
        }

        private void start() {
            setupSignal = new Object();
            mThread = new Thread(this);
            mThread.start();

            synchronized (setupSignal) {
                try {
                    setupSignal.wait();
                } catch (InterruptedException e) {
                    Log.e(TAG, ""Interrupted when waiting for video decoder setup ready"");
                }
            }
        }
        private void stop() {
            if (mThread != null) {
                mThread.interrupt();
                try {
                    mThread.join();
                } catch (InterruptedException e) {
                    Log.e(TAG, ""Interrupted when waiting for video decoder thread to stop"");
                }
                try {
                    decoder.stop();
                }catch (IllegalStateException e) {
                    Log.e(TAG, ""Video decoder is not in a state that can be stopped"");
                }
            }
            mThread = null;
        }

        void teardown() {
            if (decoder!=null) {
                decoder.release();
                decoder = null;
            }
            if (surface!=null) {
                surface.release();
                surface = null;
            }
            if (extractor!=null) {
                extractor.release();
                extractor = null;
            }
        }

        void setup() {
            int width=0, height=0;

            extractor = new MediaExtractor();

            try {
                extractor.setDataSource(mVideoFile.getPath());
            } catch (IOException e) {
                return;
            }

            for (int i = 0; i < extractor.getTrackCount(); i++) {
                MediaFormat format = extractor.getTrackFormat(i);
                String mime = format.getString(MediaFormat.KEY_MIME);
                width = format.getInteger(MediaFormat.KEY_WIDTH);
                height = format.getInteger(MediaFormat.KEY_HEIGHT);

                if (mime.startsWith(""video/"")) {
                    extractor.selectTrack(i);
                    try {
                        decoder = MediaCodec.createDecoderByType(mime);
                    }catch (IOException e) {
                        continue;
                    }
                    // Decode to surface
                    //decoder.configure(format, surface, null, 0);

                    // Decode to offscreen surface
                    surface = new CtsMediaOutputSurface(width, height);
                    mMatBuffer = new MatBuffer(width, height);

                    decoder.configure(format, surface.getSurface(), null, 0);
                    break;
                }
            }

            if (decoder == null) {
                Log.e(TAG, ""Can't find video info!"");
                return;
            }
            valid = true;
        }

        @Override
        public void run() {
            setup();

            synchronized (setupSignal) {
                setupSignal.notify();
            }

            if (!valid) {
                return;
            }

            decoder.start();

            ByteBuffer[] inputBuffers = decoder.getInputBuffers();
            ByteBuffer[] outputBuffers = decoder.getOutputBuffers();
            MediaCodec.BufferInfo info = new MediaCodec.BufferInfo();

            boolean isEOS = false;
            long startMs = System.currentTimeMillis();
            long timeoutUs = 10000;

            int iframe = 0;
            long frameTimestamp = 0;

            while (!Thread.interrupted()) {
                if (!isEOS) {
                    int inIndex = decoder.dequeueInputBuffer(10000);
                    if (inIndex >= 0) {
                        ByteBuffer buffer = inputBuffers[inIndex];
                        int sampleSize = extractor.readSampleData(buffer, 0);
                        if (sampleSize < 0) {
                            if (LOCAL_LOGD) {
                                Log.d(""VideoDecoderForOpenCV"",
                                        ""InputBuffer BUFFER_FLAG_END_OF_STREAM"");
                            }
                            decoder.queueInputBuffer(inIndex, 0, 0, 0,
                                    MediaCodec.BUFFER_FLAG_END_OF_STREAM);
                            isEOS = true;
                        } else {
                            frameTimestamp = extractor.getSampleTime();
                            decoder.queueInputBuffer(inIndex, 0, sampleSize, frameTimestamp, 0);
                            if (LOCAL_LOGD) {
                                Log.d(TAG, String.format(""Frame %d sample time %f s"",
                                            iframe, (double)frameTimestamp/1e6));
                            }
                            extractor.advance();
                        }
                    }
                }

                int outIndex = decoder.dequeueOutputBuffer(info, 10000);
                MediaFormat outFormat;
                switch (outIndex) {
                    case MediaCodec.INFO_OUTPUT_BUFFERS_CHANGED:
                        if (LOCAL_LOGD) {
                            Log.d(TAG, ""INFO_OUTPUT_BUFFERS_CHANGED"");
                        }
                        outputBuffers = decoder.getOutputBuffers();
                        break;
                    case MediaCodec.INFO_OUTPUT_FORMAT_CHANGED:
                        outFormat = decoder.getOutputFormat();
                        if (LOCAL_LOGD) {
                            Log.d(TAG, ""New format "" + outFormat);
                        }
                        break;
                    case MediaCodec.INFO_TRY_AGAIN_LATER:
                        if (LOCAL_LOGD) {
                            Log.d(TAG, ""dequeueOutputBuffer timed out!"");
                        }
                        break;
                    default:

                        ByteBuffer buffer = outputBuffers[outIndex];
                        boolean doRender = (info.size != 0);

                        // As soon as we call releaseOutputBuffer, the buffer will be forwarded
                        // to SurfaceTexture to convert to a texture.  The API doesn't
                        // guarantee that the texture will be available before the call
                        // returns, so we need to wait for the onFrameAvailable callback to
                        // fire.  If we don't wait, we risk rendering from the previous frame.
                        decoder.releaseOutputBuffer(outIndex, doRender);

                        if (doRender) {
                            surface.awaitNewImage();
                            surface.drawImage();
                            if (LOCAL_LOGV) {
                                Log.v(TAG, ""Finish drawing a frame!"");
                            }
                            if ((iframe++ % mDecimation) == 0) {
                                //Send the frame for processing
                                mMatBuffer.put(frameTimestamp);
                            }
                        }
                        break;
                }

                if ((info.flags & MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0) {
                    if (LOCAL_LOGD) {
                        Log.d(""VideoDecoderForOpenCV"", ""OutputBuffer BUFFER_FLAG_END_OF_STREAM"");
                    }
                    break;
                }
            }
            mMatBuffer.invalidate();

            decoder.stop();

            teardown();
            mThread = null;
        }


        /**
         * Get next valid frame
         * @return Frame in OpenCV mat
         */
        public Mat getFrame(long ts[]) {
            return mMatBuffer.get(ts);
        }

        /**
         * Get the size of the frame
         * @return size of the frame
         */
        Size getSize() {
            return mMatBuffer.getSize();
        }

        /**
         * A synchronized buffer
         */
        class MatBuffer {
            private Mat mat;
            private byte[] bytes;
            private ByteBuffer buf;
            private long timestamp;
            private boolean full;

            private int mWidth, mHeight;
            private boolean mValid = false;

            MatBuffer(int width, int height) {
                mWidth = width;
                mHeight = height;

                mat = new Mat(height, width, CvType.CV_8UC4); //RGBA
                buf = ByteBuffer.allocateDirect(width*height*4);
                bytes = new byte[width*height*4];
                timestamp = -1;

                mValid = true;
                full = false;
            }

            public synchronized void invalidate() {
                mValid = false;
                notifyAll();
            }

            public synchronized Mat get(long ts[]) {

                if (!mValid) return null;
                while (full == false) {
                    try {
                        wait();
                        if (!mValid) return null;
                    } catch (InterruptedException e) {
                        return null;
                    }
                }
                mat.put(0,0, bytes);
                full = false;
                notifyAll();
                ts[0] = timestamp;
                return mat;
            }

            public synchronized void put(long ts) {
                while (full) {
                    try {
                        wait();
                    } catch (InterruptedException e) {
                        Log.e(TAG, ""Interrupted when waiting for space in buffer"");
                    }
                }
                GLES20.glReadPixels(0, 0, mWidth, mHeight, GL10.GL_RGBA,
                        GL10.GL_UNSIGNED_BYTE, buf);
                buf.get(bytes);
                buf.rewind();

                timestamp = ts;
                full = true;
                notifyAll();
            }

            public Size getSize() {
                if (valid) {
                    return mat.size();
                }
                return new Size();
            }
        }
    }


    /* a small set of math functions */
    private static double [] quat2rpy( double [] q) {
        double [] rpy = {Math.atan2(2*(q[0]*q[1]+q[2]*q[3]), 1-2*(q[1]*q[1]+q[2]*q[2])),
                Math.asin(2*(q[0]*q[2] - q[3]*q[1])),
                Math.atan2(2*(q[0]*q[3]+q[1]*q[2]), 1-2*(q[2]*q[2]+q[3]*q[3]))};
        return rpy;
    }

    private static void quat2rpy( double [] q, double[] rpy) {
        rpy[0] = Math.atan2(2*(q[0]*q[1]+q[2]*q[3]), 1-2*(q[1]*q[1]+q[2]*q[2]));
        rpy[1] = Math.asin(2*(q[0]*q[2] - q[3]*q[1]));
        rpy[2] = Math.atan2(2*(q[0]*q[3]+q[1]*q[2]), 1-2*(q[2]*q[2]+q[3]*q[3]));
    }

    private static Mat quat2rpy(Mat quat) {
        double [] q = new double[4];
        quat.get(0,0,q);

        double [] rpy = {Math.atan2(2*(q[0]*q[1]+q[2]*q[3]), 1-2*(q[1]*q[1]+q[2]*q[2])),
                Math.asin(2*(q[0]*q[2] - q[3]*q[1])),
                Math.atan2(2*(q[0]*q[3]+q[1]*q[2]), 1-2*(q[2]*q[2]+q[3]*q[3]))};

        Mat rpym = new Mat(3,1, CvType.CV_64F);
        rpym.put(0,0, rpy);
        return rpym;
    }

    private static double [] rodr2quat( double [] r) {
        double t = Math.sqrt(r[0]*r[0]+r[1]*r[1]+r[2]*r[2]);
        double [] quat = {Math.cos(t/2), Math.sin(t/2)*r[0]/t,Math.sin(t/2)*r[1]/t,
                Math.sin(t/2)*r[2]/t};
        return quat;
    }

    private static void rodr2quat( double [] r, double [] quat) {
        double t = Math.sqrt(r[0]*r[0]+r[1]*r[1]+r[2]*r[2]);
        quat[0] = Math.cos(t/2);
        quat[1] = Math.sin(t/2)*r[0]/t;
        quat[2] = Math.sin(t/2)*r[1]/t;
        quat[3] = Math.sin(t/2)*r[2]/t;
    }

    private static Mat rodr2quat(Mat rodr) {
        double t = Core.norm(rodr);
        double [] r = new double[3];
        rodr.get(0,0,r);

        double [] quat = {Math.cos(t/2), Math.sin(t/2)*r[0]/t,Math.sin(t/2)*r[1]/t,
                Math.sin(t/2)*r[2]/t};
        Mat quatm = new Mat(4,1, CvType.CV_64F);
        quatm.put(0, 0, quat);
        return quatm;
    }

    private static double [] rodr2rpy( double [] r) {
        return quat2rpy(rodr2quat(r));
    }

    private double getDistanceBetweenPoints(Point a, Point b) {
        return Math.sqrt(Math.pow(a.x - b.x, 2) + Math.pow(a.y - b.y, 2));
    }
    //////////////////

}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.StillCaptureTest"	"testAePrecaptureTriggerCancelJpegCapture"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/StillCaptureTest.java"	""	"public void testAePrecaptureTriggerCancelJpegCapture() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.i(TAG, ""Testing AE precapture cancel for jpeg capture for Camera "" + id);

                StaticMetadata staticInfo = mAllStaticInfo.get(id);
                // Legacy device doesn't support AE precapture trigger
                if (staticInfo.isHardwareLevelLegacy()) {
                    Log.i(TAG, ""Skipping AE precapture trigger cancel test on legacy devices"");
                    continue;
                }
                if (!staticInfo.isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + id + "" does not support color outputs, skipping"");
                    continue;
                }
                openDevice(id);
                takePictureTestByCamera(/*aeRegions*/null, /*awbRegions*/null, /*afRegions*/null,
                        /*addAeTriggerCancel*/true, /*allocateBitmap*/false,
                        /*previewRequest*/null, /*stillRequest*/null);
            } finally {
                closeDevice();
                closeImageReader();
            }
        }
    }

    /**
     * Test allocate some bitmaps while taking picture.
     * <p>
     * Per android CDD (5.0 and newer), android devices should support allocation of at least 3
     * bitmaps equal to the size of the images produced by the largest resolution camera sensor on
     * the devices.
     * </p>
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.StillCaptureTest"	"testFocalLengths"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/StillCaptureTest.java"	""	"public void testFocalLengths() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                StaticMetadata staticInfo = mAllStaticInfo.get(id);
                if (staticInfo.isHardwareLevelLegacy()) {
                    Log.i(TAG, ""Camera "" + id + "" is legacy, skipping"");
                    continue;
                }
                if (!staticInfo.isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + id + "" does not support color outputs, skipping"");
                    continue;
                }
                if (staticInfo.isExternalCamera()) {
                    Log.i(TAG, ""Camera "" + id + "" is external, skipping"");
                    continue;
                }
                openDevice(id);
                focalLengthTestByCamera();
            } finally {
                closeDevice();
                closeImageReader();
            }
        }
    }

    private void focalLengthTestByCamera() throws Exception {
        float[] focalLengths = mStaticInfo.getAvailableFocalLengthsChecked();
        int numStillCaptures = focalLengths.length;

        Size maxStillSz = mOrderedStillSizes.get(0);
        Size maxPreviewSz = mOrderedPreviewSizes.get(0);
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        SimpleImageReaderListener imageListener = new SimpleImageReaderListener();
        CaptureRequest.Builder previewRequest =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        CaptureRequest.Builder stillRequest =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
        Size thumbnailSize = new Size(0, 0);
        Location sTestLocation = new Location(LocationManager.GPS_PROVIDER);
        sTestLocation.setTime(1199145600000L);
        sTestLocation.setLatitude(37.736071);
        sTestLocation.setLongitude(-122.441983);
        sTestLocation.setAltitude(21.0);
        ExifTestData exifTestData = new ExifTestData(
                /* gpsLocation */ sTestLocation,
                /* orientation */ 0,
                /* jpgQuality */ (byte) 80,
                /* thumbnailQuality */ (byte) 75);
        setJpegKeys(stillRequest, exifTestData, thumbnailSize, mCollector);
        CaptureResult result;

        // Set the max number of images to number of focal lengths supported
        prepareStillCaptureAndStartPreview(previewRequest, stillRequest, maxPreviewSz,
                maxStillSz, resultListener, focalLengths.length, imageListener, false /*isHeic*/);

        for(float focalLength : focalLengths) {

            previewRequest.set(CaptureRequest.LENS_FOCAL_LENGTH, focalLength);
            mSession.setRepeatingRequest(previewRequest.build(), resultListener, mHandler);
            waitForSettingsApplied(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
            waitForResultValue(resultListener, CaptureResult.LENS_STATE,
                    CaptureResult.LENS_STATE_STATIONARY, NUM_RESULTS_WAIT_TIMEOUT);
            result = resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
            mCollector.expectEquals(""Focal length in preview result and request should be the same"",
                    previewRequest.get(CaptureRequest.LENS_FOCAL_LENGTH),
                    result.get(CaptureResult.LENS_FOCAL_LENGTH));

            stillRequest.set(CaptureRequest.LENS_FOCAL_LENGTH, focalLength);
            CaptureRequest request = stillRequest.build();
            resultListener = new SimpleCaptureCallback();
            mSession.capture(request, resultListener, mHandler);
            result = resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
            mCollector.expectEquals(
                    ""Focal length in still capture result and request should be the same"",
                    stillRequest.get(CaptureRequest.LENS_FOCAL_LENGTH),
                    result.get(CaptureResult.LENS_FOCAL_LENGTH));

            Image image = imageListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);

            validateJpegCapture(image, maxStillSz);
            verifyJpegKeys(image, result, maxStillSz, thumbnailSize, exifTestData,
                    mStaticInfo, mCollector, mDebugFileNameBase, ImageFormat.JPEG);
        }
    }


    /**
     * Start preview,take a picture and test preview is still running after snapshot
     */
    private void previewPersistenceTestByCamera() throws Exception {
        Size maxStillSz = mOrderedStillSizes.get(0);
        Size maxPreviewSz = mOrderedPreviewSizes.get(0);

        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        SimpleCaptureCallback stillResultListener = new SimpleCaptureCallback();
        SimpleImageReaderListener imageListener = new SimpleImageReaderListener();
        CaptureRequest.Builder previewRequest =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        CaptureRequest.Builder stillRequest =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
        prepareStillCaptureAndStartPreview(previewRequest, stillRequest, maxPreviewSz,
                maxStillSz, resultListener, imageListener, false /*isHeic*/);

        // make sure preview is actually running
        waitForNumResults(resultListener, NUM_FRAMES_WAITED);

        // take a picture
        CaptureRequest request = stillRequest.build();
        mSession.capture(request, stillResultListener, mHandler);
        stillResultListener.getCaptureResultForRequest(request,
                WAIT_FOR_RESULT_TIMEOUT_MS);

        // validate image
        Image image = imageListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
        validateJpegCapture(image, maxStillSz);

        // make sure preview is still running after still capture
        waitForNumResults(resultListener, NUM_FRAMES_WAITED);

        stopPreview();

        // Free image resources
        image.close();
        closeImageReader();
        return;
    }

    /**
     * Take a picture for a given set of 3A regions for a particular camera.
     * <p>
     * Before take a still capture, it triggers an auto focus and lock it first,
     * then wait for AWB to converge and lock it, then trigger a precapture
     * metering sequence and wait for AE converged. After capture is received, the
     * capture result and image are validated.
     * </p>
     *
     * @param aeRegions AE regions for this capture
     * @param awbRegions AWB regions for this capture
     * @param afRegions AF regions for this capture
     */
    private void takePictureTestByCamera(
            MeteringRectangle[] aeRegions, MeteringRectangle[] awbRegions,
            MeteringRectangle[] afRegions) throws Exception {
        takePictureTestByCamera(aeRegions, awbRegions, afRegions,
                /*addAeTriggerCancel*/false, /*allocateBitmap*/false,
                /*previewRequest*/null, /*stillRequest*/null);
    }

    /**
     * Take a picture for a given set of 3A regions for a particular camera.
     * <p>
     * Before take a still capture, it triggers an auto focus and lock it first,
     * then wait for AWB to converge and lock it, then trigger a precapture
     * metering sequence and wait for AE converged. After capture is received, the
     * capture result and image are validated. If {@code addAeTriggerCancel} is true,
     * a precapture trigger cancel will be inserted between two adjacent triggers, which
     * should effective cancel the first trigger.
     * </p>
     *
     * @param aeRegions AE regions for this capture
     * @param awbRegions AWB regions for this capture
     * @param afRegions AF regions for this capture
     * @param addAeTriggerCancel If a AE precapture trigger cancel is sent after the trigger.
     * @param allocateBitmap If a set of bitmaps are allocated during the test for memory test.
     * @param previewRequest The preview request builder to use, or null to use the default
     * @param stillRequest The still capture request to use, or null to use the default
     */
    private void takePictureTestByCamera(
            MeteringRectangle[] aeRegions, MeteringRectangle[] awbRegions,
            MeteringRectangle[] afRegions, boolean addAeTriggerCancel, boolean allocateBitmap,
            CaptureRequest.Builder previewRequest, CaptureRequest.Builder stillRequest)
                    throws Exception {

        boolean hasFocuser = mStaticInfo.hasFocuser();

        Size maxStillSz = mOrderedStillSizes.get(0);
        Size maxPreviewSz = mOrderedPreviewSizes.get(0);
        CaptureResult result;
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        SimpleImageReaderListener imageListener = new SimpleImageReaderListener();
        if (previewRequest == null) {
            previewRequest = mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        }
        if (stillRequest == null) {
            stillRequest = mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
        }
        prepareStillCaptureAndStartPreview(previewRequest, stillRequest, maxPreviewSz,
                maxStillSz, resultListener, imageListener, false /*isHeic*/);

        // Set AE mode to ON_AUTO_FLASH if flash is available.
        if (mStaticInfo.hasFlash()) {
            previewRequest.set(CaptureRequest.CONTROL_AE_MODE,
                    CaptureRequest.CONTROL_AE_MODE_ON_AUTO_FLASH);
            stillRequest.set(CaptureRequest.CONTROL_AE_MODE,
                    CaptureRequest.CONTROL_AE_MODE_ON_AUTO_FLASH);
        }

        Camera2Focuser focuser = null;
        /**
         * Step 1: trigger an auto focus run, and wait for AF locked.
         */
        boolean canSetAfRegion = hasFocuser && (afRegions != null) &&
                isRegionsSupportedFor3A(MAX_REGIONS_AF_INDEX);
        if (hasFocuser) {
            SimpleAutoFocusListener afListener = new SimpleAutoFocusListener();
            focuser = new Camera2Focuser(mCamera, mSession, mPreviewSurface, afListener,
                    mStaticInfo.getCharacteristics(), mHandler);
            if (canSetAfRegion) {
                previewRequest.set(CaptureRequest.CONTROL_AF_REGIONS, afRegions);
                stillRequest.set(CaptureRequest.CONTROL_AF_REGIONS, afRegions);
            }
            focuser.startAutoFocus(afRegions);
            afListener.waitForAutoFocusDone(WAIT_FOR_FOCUS_DONE_TIMEOUT_MS);
        }

        /**
         * Have to get the current AF mode to be used for other 3A repeating
         * request, otherwise, the new AF mode in AE/AWB request could be
         * different with existing repeating requests being sent by focuser,
         * then it could make AF unlocked too early. Beside that, for still
         * capture, AF mode must not be different with the one in current
         * repeating request, otherwise, the still capture itself would trigger
         * an AF mode change, and the AF lock would be lost for this capture.
         */
        int currentAfMode = CaptureRequest.CONTROL_AF_MODE_OFF;
        if (hasFocuser) {
            currentAfMode = focuser.getCurrentAfMode();
        }
        previewRequest.set(CaptureRequest.CONTROL_AF_MODE, currentAfMode);
        stillRequest.set(CaptureRequest.CONTROL_AF_MODE, currentAfMode);

        /**
         * Step 2: AF is already locked, wait for AWB converged, then lock it.
         */
        resultListener = new SimpleCaptureCallback();
        boolean canSetAwbRegion =
                (awbRegions != null) && isRegionsSupportedFor3A(MAX_REGIONS_AWB_INDEX);
        if (canSetAwbRegion) {
            previewRequest.set(CaptureRequest.CONTROL_AWB_REGIONS, awbRegions);
            stillRequest.set(CaptureRequest.CONTROL_AWB_REGIONS, awbRegions);
        }
        mSession.setRepeatingRequest(previewRequest.build(), resultListener, mHandler);
        if (mStaticInfo.isHardwareLevelAtLeastLimited()) {
            waitForResultValue(resultListener, CaptureResult.CONTROL_AWB_STATE,
                    CaptureResult.CONTROL_AWB_STATE_CONVERGED, NUM_RESULTS_WAIT_TIMEOUT);
        } else {
            // LEGACY Devices don't have the AWB_STATE reported in results, so just wait
            waitForSettingsApplied(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
        }
        boolean canSetAwbLock = mStaticInfo.isAwbLockSupported();
        if (canSetAwbLock) {
            previewRequest.set(CaptureRequest.CONTROL_AWB_LOCK, true);
        }
        mSession.setRepeatingRequest(previewRequest.build(), resultListener, mHandler);
        // Validate the next result immediately for region and mode.
        result = resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
        mCollector.expectEquals(""AWB mode in result and request should be same"",
                previewRequest.get(CaptureRequest.CONTROL_AWB_MODE),
                result.get(CaptureResult.CONTROL_AWB_MODE));
        if (canSetAwbRegion) {
            MeteringRectangle[] resultAwbRegions =
                    getValueNotNull(result, CaptureResult.CONTROL_AWB_REGIONS);
            mCollector.expectEquals(""AWB regions in result and request should be same"",
                    awbRegions, resultAwbRegions);
        }

        /**
         * Step 3: trigger an AE precapture metering sequence and wait for AE converged.
         */
        resultListener = new SimpleCaptureCallback();
        boolean canSetAeRegion =
                (aeRegions != null) && isRegionsSupportedFor3A(MAX_REGIONS_AE_INDEX);
        if (canSetAeRegion) {
            previewRequest.set(CaptureRequest.CONTROL_AE_REGIONS, aeRegions);
            stillRequest.set(CaptureRequest.CONTROL_AE_REGIONS, aeRegions);
        }
        mSession.setRepeatingRequest(previewRequest.build(), resultListener, mHandler);
        previewRequest.set(CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER,
                CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_START);
        mSession.capture(previewRequest.build(), resultListener, mHandler);
        if (addAeTriggerCancel) {
            // Cancel the current precapture trigger, then send another trigger.
            // The camera device should behave as if the first trigger is not sent.
            // Wait one request to make the trigger start doing something before cancel.
            waitForNumResults(resultListener, /*numResultsWait*/ 1);
            previewRequest.set(CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER,
                    CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_CANCEL);
            mSession.capture(previewRequest.build(), resultListener, mHandler);
            waitForResultValue(resultListener, CaptureResult.CONTROL_AE_PRECAPTURE_TRIGGER,
                    CaptureResult.CONTROL_AE_PRECAPTURE_TRIGGER_CANCEL,
                    NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
            // Issue another trigger
            previewRequest.set(CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER,
                    CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_START);
            mSession.capture(previewRequest.build(), resultListener, mHandler);
        }
        waitForAeStable(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

        // Validate the next result immediately for region and mode.
        result = resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
        mCollector.expectEquals(""AE mode in result and request should be same"",
                previewRequest.get(CaptureRequest.CONTROL_AE_MODE),
                result.get(CaptureResult.CONTROL_AE_MODE));
        if (canSetAeRegion) {
            MeteringRectangle[] resultAeRegions =
                    getValueNotNull(result, CaptureResult.CONTROL_AE_REGIONS);

            mCollector.expectMeteringRegionsAreSimilar(
                    ""AE regions in result and request should be similar"",
                    aeRegions,
                    resultAeRegions,
                    METERING_REGION_ERROR_PERCENT_DELTA);
        }

        /**
         * Step 4: take a picture when all 3A are in good state.
         */
        resultListener = new SimpleCaptureCallback();
        CaptureRequest request = stillRequest.build();
        mSession.capture(request, resultListener, mHandler);
        // Validate the next result immediately for region and mode.
        result = resultListener.getCaptureResultForRequest(request, WAIT_FOR_RESULT_TIMEOUT_MS);
        mCollector.expectEquals(""AF mode in result and request should be same"",
                stillRequest.get(CaptureRequest.CONTROL_AF_MODE),
                result.get(CaptureResult.CONTROL_AF_MODE));
        if (canSetAfRegion) {
            MeteringRectangle[] resultAfRegions =
                    getValueNotNull(result, CaptureResult.CONTROL_AF_REGIONS);
            mCollector.expectMeteringRegionsAreSimilar(
                    ""AF regions in result and request should be similar"",
                    afRegions,
                    resultAfRegions,
                    METERING_REGION_ERROR_PERCENT_DELTA);
        }

        if (hasFocuser) {
            // Unlock auto focus.
            focuser.cancelAutoFocus();
        }

        // validate image
        Image image = imageListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
        validateJpegCapture(image, maxStillSz);
        // Test if the system can allocate 3 bitmap successfully, per android CDD camera memory
        // requirements added by CDD 5.0
        if (allocateBitmap) {
            Bitmap bm[] = new Bitmap[MAX_ALLOCATED_BITMAPS];
            for (int i = 0; i < MAX_ALLOCATED_BITMAPS; i++) {
                bm[i] = Bitmap.createBitmap(
                        maxStillSz.getWidth(), maxStillSz.getHeight(), Config.ARGB_8888);
                assertNotNull(""Created bitmap #"" + i + "" shouldn't be null"", bm[i]);
            }
        }

        // Free image resources
        image.close();

        stopPreview();
    }

    /**
     * Test touch region for focus by camera.
     */
    private void touchForFocusTestByCamera() throws Exception {
        SimpleCaptureCallback listener = new SimpleCaptureCallback();
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        Size maxPreviewSz = mOrderedPreviewSizes.get(0);
        startPreview(requestBuilder, maxPreviewSz, listener);

        SimpleAutoFocusListener afListener = new SimpleAutoFocusListener();
        Camera2Focuser focuser = new Camera2Focuser(mCamera, mSession, mPreviewSurface, afListener,
                mStaticInfo.getCharacteristics(), mHandler);
        ArrayList<MeteringRectangle[]> testAfRegions = get3ARegionTestCasesForCamera();

        for (MeteringRectangle[] afRegions : testAfRegions) {
            focuser.touchForAutoFocus(afRegions);
            afListener.waitForAutoFocusDone(WAIT_FOR_FOCUS_DONE_TIMEOUT_MS);
            focuser.cancelAutoFocus();
        }
    }

    private void previewStillCombinationTestByCamera() throws Exception {
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        SimpleImageReaderListener imageListener = new SimpleImageReaderListener();

        Size QCIF = new Size(176, 144);
        Size FULL_HD = new Size(1920, 1080);
        for (Size stillSz : mOrderedStillSizes)
            for (Size previewSz : mOrderedPreviewSizes) {
                if (VERBOSE) {
                    Log.v(TAG, ""Testing JPEG capture size "" + stillSz.toString()
                            + "" with preview size "" + previewSz.toString() + "" for camera ""
                            + mCamera.getId());
                }

                // Skip testing QCIF + >FullHD combinations
                if (stillSz.equals(QCIF) &&
                        ((previewSz.getWidth() > FULL_HD.getWidth()) ||
                         (previewSz.getHeight() > FULL_HD.getHeight()))) {
                    continue;
                }

                if (previewSz.equals(QCIF) &&
                        ((stillSz.getWidth() > FULL_HD.getWidth()) ||
                         (stillSz.getHeight() > FULL_HD.getHeight()))) {
                    continue;
                }

                CaptureRequest.Builder previewRequest =
                        mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
                CaptureRequest.Builder stillRequest =
                        mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
                prepareStillCaptureAndStartPreview(previewRequest, stillRequest, previewSz,
                        stillSz, resultListener, imageListener, false /*isHeic*/);
                mSession.capture(stillRequest.build(), resultListener, mHandler);
                Image image = imageListener.getImage((mStaticInfo.isHardwareLevelLegacy()) ?
                        RELAXED_CAPTURE_IMAGE_TIMEOUT_MS : CAPTURE_IMAGE_TIMEOUT_MS);
                validateJpegCapture(image, stillSz);

                // Free image resources
                image.close();

                // stopPreview must be called here to make sure next time a preview stream
                // is created with new size.
                stopPreview();
                // Drain the results after each combination. Depending on the device the results
                // can be relatively big and could accumulate fairly quickly after many iterations.
                resultListener.drain();
            }
    }

    /**
     * Basic raw capture test for each camera.
     */
    private void rawCaptureTestByCamera(CaptureRequest.Builder stillRequest) throws Exception {
        Size maxPreviewSz = mOrderedPreviewSizes.get(0);
        Size size = mStaticInfo.getRawDimensChecked();

        // Prepare raw capture and start preview.
        CaptureRequest.Builder previewBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        CaptureRequest.Builder rawBuilder = (stillRequest != null) ? stillRequest :
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        SimpleImageReaderListener imageListener = new SimpleImageReaderListener();
        prepareRawCaptureAndStartPreview(previewBuilder, rawBuilder, maxPreviewSz, size,
                resultListener, imageListener);

        if (VERBOSE) {
            Log.v(TAG, ""Testing Raw capture with size "" + size.toString()
                    + "", preview size "" + maxPreviewSz);
        }

        CaptureRequest rawRequest = rawBuilder.build();
        mSession.capture(rawRequest, resultListener, mHandler);

        Image image = imageListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
        validateRaw16Image(image, size);
        if (DEBUG) {
            byte[] rawBuffer = getDataFromImage(image);
            String rawFileName = mDebugFileNameBase + ""/test"" + ""_"" + size.toString() + ""_cam"" +
                    mCamera.getId() + "".raw16"";
            Log.d(TAG, ""Dump raw file into "" + rawFileName);
            dumpFile(rawFileName, rawBuffer);
        }

        // Free image resources
        image.close();

        stopPreview();
    }

    private void fullRawCaptureTestByCamera(CaptureRequest.Builder stillRequest) throws Exception {
        Size maxPreviewSz = mOrderedPreviewSizes.get(0);
        Size maxStillSz = mOrderedStillSizes.get(0);

        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        SimpleImageReaderListener jpegListener = new SimpleImageReaderListener();
        SimpleImageReaderListener rawListener = new SimpleImageReaderListener();

        Size size = mStaticInfo.getRawDimensChecked();

        if (VERBOSE) {
            Log.v(TAG, ""Testing multi capture with size "" + size.toString()
                    + "", preview size "" + maxPreviewSz);
        }

        // Prepare raw capture and start preview.
        CaptureRequest.Builder previewBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        CaptureRequest.Builder multiBuilder = (stillRequest != null) ? stillRequest :
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);

        ImageReader rawReader = null;
        ImageReader jpegReader = null;

        try {
            // Create ImageReaders.
            rawReader = makeImageReader(size,
                    ImageFormat.RAW_SENSOR, MAX_READER_IMAGES, rawListener, mHandler);
            jpegReader = makeImageReader(maxStillSz,
                    ImageFormat.JPEG, MAX_READER_IMAGES, jpegListener, mHandler);
            updatePreviewSurface(maxPreviewSz);

            // Configure output streams with preview and jpeg streams.
            List<Surface> outputSurfaces = new ArrayList<Surface>();
            outputSurfaces.add(rawReader.getSurface());
            outputSurfaces.add(jpegReader.getSurface());
            outputSurfaces.add(mPreviewSurface);
            mSessionListener = new BlockingSessionCallback();
            mSession = configureCameraSession(mCamera, outputSurfaces,
                    mSessionListener, mHandler);

            // Configure the requests.
            previewBuilder.addTarget(mPreviewSurface);
            multiBuilder.addTarget(mPreviewSurface);
            multiBuilder.addTarget(rawReader.getSurface());
            multiBuilder.addTarget(jpegReader.getSurface());

            // Start preview.
            mSession.setRepeatingRequest(previewBuilder.build(), null, mHandler);

            // Poor man's 3A, wait 2 seconds for AE/AF (if any) to settle.
            // TODO: Do proper 3A trigger and lock (see testTakePictureTest).
            Thread.sleep(3000);

            multiBuilder.set(CaptureRequest.STATISTICS_LENS_SHADING_MAP_MODE,
                    CaptureRequest.STATISTICS_LENS_SHADING_MAP_MODE_ON);
            CaptureRequest multiRequest = multiBuilder.build();

            mSession.capture(multiRequest, resultListener, mHandler);

            CaptureResult result = resultListener.getCaptureResultForRequest(multiRequest,
                    NUM_RESULTS_WAIT_TIMEOUT);
            Image jpegImage = jpegListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
            basicValidateBlobImage(jpegImage, maxStillSz, ImageFormat.JPEG);
            Image rawImage = rawListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
            validateRaw16Image(rawImage, size);
            verifyRawCaptureResult(multiRequest, result);


            ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
            try (DngCreator dngCreator = new DngCreator(mStaticInfo.getCharacteristics(), result)) {
                dngCreator.writeImage(outputStream, rawImage);
            }

            if (DEBUG) {
                byte[] rawBuffer = outputStream.toByteArray();
                String rawFileName = mDebugFileNameBase + ""/raw16_"" + TAG + size.toString() +
                        ""_cam_"" + mCamera.getId() + "".dng"";
                Log.d(TAG, ""Dump raw file into "" + rawFileName);
                dumpFile(rawFileName, rawBuffer);

                byte[] jpegBuffer = getDataFromImage(jpegImage);
                String jpegFileName = mDebugFileNameBase + ""/jpeg_"" + TAG + size.toString() +
                        ""_cam_"" + mCamera.getId() + "".jpg"";
                Log.d(TAG, ""Dump jpeg file into "" + rawFileName);
                dumpFile(jpegFileName, jpegBuffer);
            }

            stopPreview();
        } finally {
            CameraTestUtils.closeImageReader(rawReader);
            CameraTestUtils.closeImageReader(jpegReader);
            rawReader = null;
            jpegReader = null;
        }
    }

    /**
     * Validate that raw {@link CaptureResult}.
     *
     * @param rawRequest a {@link CaptureRequest} use to capture a RAW16 image.
     * @param rawResult the {@link CaptureResult} corresponding to the given request.
     */
    private void verifyRawCaptureResult(CaptureRequest rawRequest, CaptureResult rawResult) {
        assertNotNull(rawRequest);
        assertNotNull(rawResult);

        if (!mStaticInfo.isMonochromeCamera()) {
            Rational[] empty = new Rational[] { Rational.ZERO, Rational.ZERO, Rational.ZERO};
            Rational[] neutralColorPoint = mCollector.expectKeyValueNotNull(""NeutralColorPoint"",
                    rawResult, CaptureResult.SENSOR_NEUTRAL_COLOR_POINT);
            if (neutralColorPoint != null) {
                mCollector.expectEquals(""NeutralColorPoint length"", empty.length,
                        neutralColorPoint.length);
                mCollector.expectNotEquals(""NeutralColorPoint cannot be all zeroes, "", empty,
                        neutralColorPoint);
                mCollector.expectValuesGreaterOrEqual(""NeutralColorPoint"", neutralColorPoint,
                        Rational.ZERO);
            }

            mCollector.expectKeyValueGreaterOrEqual(rawResult,
                    CaptureResult.SENSOR_GREEN_SPLIT, 0.0f);
        }

        Pair<Double, Double>[] noiseProfile = mCollector.expectKeyValueNotNull(""NoiseProfile"",
                rawResult, CaptureResult.SENSOR_NOISE_PROFILE);
        if (noiseProfile != null) {
            int cfa = mStaticInfo.getCFAChecked();
            int numCfaChannels = 0;
            switch (cfa) {
                case CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_RGGB:
                case CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_GRBG:
                case CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_GBRG:
                case CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_BGGR:
                    numCfaChannels = 4;
                    break;
                case CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_MONO:
                case CameraCharacteristics.SENSOR_INFO_COLOR_FILTER_ARRANGEMENT_NIR:
                    numCfaChannels = 1;
                    break;
                default:
                    Assert.fail(""Invalid color filter arrangement "" + cfa);
                    break;
            }
            mCollector.expectEquals(""NoiseProfile length"", noiseProfile.length, numCfaChannels);
            for (Pair<Double, Double> p : noiseProfile) {
                mCollector.expectTrue(""NoiseProfile coefficients "" + p +
                        "" must have: S > 0, O >= 0"", p.first > 0 && p.second >= 0);
            }
        }

        Integer hotPixelMode = mCollector.expectKeyValueNotNull(""HotPixelMode"", rawResult,
                CaptureResult.HOT_PIXEL_MODE);
        Boolean hotPixelMapMode = mCollector.expectKeyValueNotNull(""HotPixelMapMode"", rawResult,
                CaptureResult.STATISTICS_HOT_PIXEL_MAP_MODE);
        Point[] hotPixelMap = rawResult.get(CaptureResult.STATISTICS_HOT_PIXEL_MAP);

        Size pixelArraySize = mStaticInfo.getPixelArraySizeChecked();
        boolean[] availableHotPixelMapModes = mStaticInfo.getValueFromKeyNonNull(
                        CameraCharacteristics.STATISTICS_INFO_AVAILABLE_HOT_PIXEL_MAP_MODES);

        if (hotPixelMode != null) {
            Integer requestMode = mCollector.expectKeyValueNotNull(rawRequest,
                    CaptureRequest.HOT_PIXEL_MODE);
            if (requestMode != null) {
                mCollector.expectKeyValueEquals(rawResult, CaptureResult.HOT_PIXEL_MODE,
                        requestMode);
            }
        }

        if (hotPixelMapMode != null) {
            Boolean requestMapMode = mCollector.expectKeyValueNotNull(rawRequest,
                    CaptureRequest.STATISTICS_HOT_PIXEL_MAP_MODE);
            if (requestMapMode != null) {
                mCollector.expectKeyValueEquals(rawResult,
                        CaptureResult.STATISTICS_HOT_PIXEL_MAP_MODE, requestMapMode);
            }

            if (!hotPixelMapMode) {
                mCollector.expectTrue(""HotPixelMap must be empty"", hotPixelMap == null ||
                        hotPixelMap.length == 0);
            } else {
                mCollector.expectTrue(""HotPixelMap must not be empty"", hotPixelMap != null);
                mCollector.expectNotNull(""AvailableHotPixelMapModes must not be null"",
                        availableHotPixelMapModes);
                if (availableHotPixelMapModes != null) {
                    mCollector.expectContains(""HotPixelMapMode"", availableHotPixelMapModes, true);
                }

                int height = pixelArraySize.getHeight();
                int width = pixelArraySize.getWidth();
                for (Point p : hotPixelMap) {
                    mCollector.expectTrue(""Hotpixel "" + p + "" must be in pixelArray "" +
                            pixelArraySize, p.x >= 0 && p.x < width && p.y >= 0 && p.y < height);
                }
            }
        }
        // TODO: profileHueSatMap, and profileToneCurve aren't supported yet.

    }

    /**
     * Issue a still capture and validate the exif information.
     * <p>
     * TODO: Differentiate full and limited device, some of the checks rely on
     * per frame control and synchronization, most of them don't.
     * </p>
     */
    private void stillExifTestByCamera(int format, Size stillSize) throws Exception {
        assertTrue(format == ImageFormat.JPEG || format == ImageFormat.HEIC);
        boolean isHeic = (format == ImageFormat.HEIC);

        Size maxPreviewSz = mOrderedPreviewSizes.get(0);
        if (VERBOSE) {
            Log.v(TAG, ""Testing exif with size "" + stillSize.toString()
                    + "", preview size "" + maxPreviewSz);
        }

        // prepare capture and start preview.
        CaptureRequest.Builder previewBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        CaptureRequest.Builder stillBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        SimpleImageReaderListener imageListener = new SimpleImageReaderListener();
        prepareStillCaptureAndStartPreview(previewBuilder, stillBuilder, maxPreviewSz, stillSize,
                resultListener, imageListener, isHeic);

        // Set the jpeg keys, then issue a capture
        Size[] thumbnailSizes = mStaticInfo.getAvailableThumbnailSizesChecked();
        Size maxThumbnailSize = thumbnailSizes[thumbnailSizes.length - 1];
        Size[] testThumbnailSizes = new Size[EXIF_TEST_DATA.length];
        Arrays.fill(testThumbnailSizes, maxThumbnailSize);
        // Make sure thumbnail size (0, 0) is covered.
        testThumbnailSizes[0] = new Size(0, 0);

        for (int i = 0; i < EXIF_TEST_DATA.length; i++) {
            setJpegKeys(stillBuilder, EXIF_TEST_DATA[i], testThumbnailSizes[i], mCollector);

            // Capture a jpeg/heic image.
            CaptureRequest request = stillBuilder.build();
            mSession.capture(request, resultListener, mHandler);
            CaptureResult stillResult =
                    resultListener.getCaptureResultForRequest(request, NUM_RESULTS_WAIT_TIMEOUT);
            Image image = imageListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);

            verifyJpegKeys(image, stillResult, stillSize, testThumbnailSizes[i], EXIF_TEST_DATA[i],
                    mStaticInfo, mCollector, mDebugFileNameBase, format);

            // Free image resources
            image.close();
        }
    }

    /**
     * Issue a still capture and validate the dynamic depth output.
     */
    private void stillDynamicDepthTestByCamera(int format, Size stillSize) throws Exception {
        assertTrue(format == ImageFormat.DEPTH_JPEG);

        Size maxPreviewSz = mOrderedPreviewSizes.get(0);
        if (VERBOSE) {
            Log.v(TAG, ""Testing dynamic depth with size "" + stillSize.toString()
                    + "", preview size "" + maxPreviewSz);
        }

        // prepare capture and start preview.
        CaptureRequest.Builder previewBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        CaptureRequest.Builder stillBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        SimpleImageReaderListener imageListener = new SimpleImageReaderListener();
        prepareCaptureAndStartPreview(previewBuilder, stillBuilder, maxPreviewSz, stillSize,
                ImageFormat.DEPTH_JPEG, resultListener, /*sessionListener*/null,
                MAX_READER_IMAGES, imageListener);

        // Capture a few dynamic depth images and check whether they are valid jpegs.
        for (int i = 0; i < MAX_READER_IMAGES; i++) {
            CaptureRequest request = stillBuilder.build();
            mSession.capture(request, resultListener, mHandler);
            CaptureResult stillResult =
                resultListener.getCaptureResultForRequest(request, NUM_RESULTS_WAIT_TIMEOUT);
            Image image = imageListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
            assertNotNull(""Unable to acquire next image"", image);
            CameraTestUtils.validateImage(image, stillSize.getWidth(), stillSize.getHeight(),
                    format, null /*filePath*/);

            // Free image resources
            image.close();
        }
    }

    private void aeCompensationTestByCamera() throws Exception {
        Range<Integer> compensationRange = mStaticInfo.getAeCompensationRangeChecked();
        // Skip the test if exposure compensation is not supported.
        if (compensationRange.equals(Range.create(0, 0))) {
            return;
        }

        Rational step = mStaticInfo.getAeCompensationStepChecked();
        float stepF = (float) step.getNumerator() / step.getDenominator();
        int stepsPerEv = (int) Math.round(1.0 / stepF);
        int numSteps = (compensationRange.getUpper() - compensationRange.getLower()) / stepsPerEv;

        Size maxStillSz = mOrderedStillSizes.get(0);
        Size maxPreviewSz = mOrderedPreviewSizes.get(0);
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        SimpleImageReaderListener imageListener = new SimpleImageReaderListener();
        CaptureRequest.Builder previewRequest =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        CaptureRequest.Builder stillRequest =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
        boolean canSetAeLock = mStaticInfo.isAeLockSupported();
        boolean canReadSensorSettings = mStaticInfo.isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_READ_SENSOR_SETTINGS);

        if (canSetAeLock) {
            stillRequest.set(CaptureRequest.CONTROL_AE_LOCK, true);
        }

        CaptureResult normalResult;
        CaptureResult compensatedResult;

        boolean canReadExposureValueRange = mStaticInfo.areKeysAvailable(
                CameraCharacteristics.SENSOR_INFO_SENSITIVITY_RANGE,
                CameraCharacteristics.SENSOR_INFO_EXPOSURE_TIME_RANGE);
        boolean canVerifyExposureValue = canReadSensorSettings && canReadExposureValueRange;
        long minExposureValue = -1;
        long maxExposureValuePreview = -1;
        long maxExposureValueStill = -1;
        if (canReadExposureValueRange) {
            // Minimum exposure settings is mostly static while maximum exposure setting depends on
            // frame rate range which in term depends on capture request.
            minExposureValue = mStaticInfo.getSensitivityMinimumOrDefault() *
                    mStaticInfo.getExposureMinimumOrDefault() / 1000;
            long maxSensitivity = mStaticInfo.getSensitivityMaximumOrDefault();
            long maxExposureTimeUs = mStaticInfo.getExposureMaximumOrDefault() / 1000;
            maxExposureValuePreview = getMaxExposureValue(previewRequest, maxExposureTimeUs,
                    maxSensitivity);
            maxExposureValueStill = getMaxExposureValue(stillRequest, maxExposureTimeUs,
                    maxSensitivity);
        }

        // Set the max number of images to be same as the burst count, as the verification
        // could be much slower than producing rate, and we don't want to starve producer.
        prepareStillCaptureAndStartPreview(previewRequest, stillRequest, maxPreviewSz,
                maxStillSz, resultListener, numSteps, imageListener, false /*isHeic*/);

        for (int i = 0; i <= numSteps; i++) {
            int exposureCompensation = i * stepsPerEv + compensationRange.getLower();
            double expectedRatio = Math.pow(2.0, exposureCompensation / stepsPerEv);

            // Wait for AE to be stabilized before capture: CONVERGED or FLASH_REQUIRED.
            waitForAeStable(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
            normalResult = resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);

            long normalExposureValue = -1;
            if (canVerifyExposureValue) {
                // get and check if current exposure value is valid
                normalExposureValue = getExposureValue(normalResult);
                mCollector.expectInRange(""Exposure setting out of bound"", normalExposureValue,
                        minExposureValue, maxExposureValuePreview);

                // Only run the test if expectedExposureValue is within valid range
                long expectedExposureValue = (long) (normalExposureValue * expectedRatio);
                if (expectedExposureValue < minExposureValue ||
                    expectedExposureValue > maxExposureValueStill) {
                    continue;
                }
                Log.v(TAG, ""Expect ratio: "" + expectedRatio +
                        "" normalExposureValue: "" + normalExposureValue +
                        "" expectedExposureValue: "" + expectedExposureValue +
                        "" minExposureValue: "" + minExposureValue +
                        "" maxExposureValuePreview: "" + maxExposureValuePreview +
                        "" maxExposureValueStill: "" + maxExposureValueStill);
            }

            // Now issue exposure compensation and wait for AE locked. AE could take a few
            // frames to go back to locked state
            previewRequest.set(CaptureRequest.CONTROL_AE_EXPOSURE_COMPENSATION,
                    exposureCompensation);
            if (canSetAeLock) {
                previewRequest.set(CaptureRequest.CONTROL_AE_LOCK, true);
            }
            mSession.setRepeatingRequest(previewRequest.build(), resultListener, mHandler);
            if (canSetAeLock) {
                waitForAeLocked(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
            } else {
                waitForSettingsApplied(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
            }

            // Issue still capture
            if (VERBOSE) {
                Log.v(TAG, ""Verifying capture result for ae compensation value ""
                        + exposureCompensation);
            }

            stillRequest.set(CaptureRequest.CONTROL_AE_EXPOSURE_COMPENSATION, exposureCompensation);
            CaptureRequest request = stillRequest.build();
            mSession.capture(request, resultListener, mHandler);

            compensatedResult = resultListener.getCaptureResultForRequest(
                    request, WAIT_FOR_RESULT_TIMEOUT_MS);

            if (canVerifyExposureValue) {
                // Verify the exposure value compensates as requested
                long compensatedExposureValue = getExposureValue(compensatedResult);
                mCollector.expectInRange(""Exposure setting out of bound"", compensatedExposureValue,
                        minExposureValue, maxExposureValueStill);
                double observedRatio = (double) compensatedExposureValue / normalExposureValue;
                double error = observedRatio / expectedRatio;
                String errorString = String.format(
                        ""Exposure compensation ratio exceeds error tolerence:"" +
                        "" expected(%f) observed(%f)."" +
                        "" Normal exposure time %d us, sensitivity %d."" +
                        "" Compensated exposure time %d us, sensitivity %d"",
                        expectedRatio, observedRatio,
                        (int) (getValueNotNull(
                                normalResult, CaptureResult.SENSOR_EXPOSURE_TIME) / 1000),
                        getValueNotNull(normalResult, CaptureResult.SENSOR_SENSITIVITY),
                        (int) (getValueNotNull(
                                compensatedResult, CaptureResult.SENSOR_EXPOSURE_TIME) / 1000),
                        getValueNotNull(compensatedResult, CaptureResult.SENSOR_SENSITIVITY));
                mCollector.expectInRange(errorString, error,
                        1.0 - AE_COMPENSATION_ERROR_TOLERANCE,
                        1.0 + AE_COMPENSATION_ERROR_TOLERANCE);
            }

            mCollector.expectEquals(""Exposure compensation result should match requested value."",
                    exposureCompensation,
                    compensatedResult.get(CaptureResult.CONTROL_AE_EXPOSURE_COMPENSATION));
            if (canSetAeLock) {
                mCollector.expectTrue(""Exposure lock should be set"",
                        compensatedResult.get(CaptureResult.CONTROL_AE_LOCK));
            }

            Image image = imageListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
            validateJpegCapture(image, maxStillSz);
            image.close();

            // Recover AE compensation and lock
            previewRequest.set(CaptureRequest.CONTROL_AE_EXPOSURE_COMPENSATION, 0);
            if (canSetAeLock) {
                previewRequest.set(CaptureRequest.CONTROL_AE_LOCK, false);
            }
            mSession.setRepeatingRequest(previewRequest.build(), resultListener, mHandler);
        }
    }

    private long getExposureValue(CaptureResult result) throws Exception {
        int expTimeUs = (int) (getValueNotNull(result, CaptureResult.SENSOR_EXPOSURE_TIME) / 1000);
        int sensitivity = getValueNotNull(result, CaptureResult.SENSOR_SENSITIVITY);
        Integer postRawSensitivity = result.get(CaptureResult.CONTROL_POST_RAW_SENSITIVITY_BOOST);
        if (postRawSensitivity != null) {
            return (long) sensitivity * postRawSensitivity / 100 * expTimeUs;
        }
        return (long) sensitivity * expTimeUs;
    }

    private long getMaxExposureValue(CaptureRequest.Builder request, long maxExposureTimeUs,
                long maxSensitivity)  throws Exception {
        Range<Integer> fpsRange = request.get(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE);
        long maxFrameDurationUs = Math.round(1000000.0 / fpsRange.getLower());
        long currentMaxExposureTimeUs = Math.min(maxFrameDurationUs, maxExposureTimeUs);
        return currentMaxExposureTimeUs * maxSensitivity;
    }


    //----------------------------------------------------------------
    //---------Below are common functions for all tests.--------------
    //----------------------------------------------------------------
    /**
     * Validate standard raw (RAW16) capture image.
     *
     * @param image The raw16 format image captured
     * @param rawSize The expected raw size
     */
    private static void validateRaw16Image(Image image, Size rawSize) {
        CameraTestUtils.validateImage(image, rawSize.getWidth(), rawSize.getHeight(),
                ImageFormat.RAW_SENSOR, /*filePath*/null);
    }

    /**
     * Validate JPEG capture image object correctness and test.
     * <p>
     * In addition to image object correctness, this function also does the decoding
     * test, which is slower.
     * </p>
     *
     * @param image The JPEG image to be verified.
     * @param jpegSize The JPEG capture size to be verified against.
     */
    private static void validateJpegCapture(Image image, Size jpegSize) {
        CameraTestUtils.validateImage(image, jpegSize.getWidth(), jpegSize.getHeight(),
                ImageFormat.JPEG, /*filePath*/null);
    }

    private static class SimpleAutoFocusListener implements Camera2Focuser.AutoFocusListener {
        final ConditionVariable focusDone = new ConditionVariable();
        @Override
        public void onAutoFocusLocked(boolean success) {
            focusDone.open();
        }

        public void waitForAutoFocusDone(long timeoutMs) {
            if (focusDone.block(timeoutMs)) {
                focusDone.close();
            } else {
                throw new TimeoutRuntimeException(""Wait for auto focus done timed out after ""
                        + timeoutMs + ""ms"");
            }
        }
    }

    /**
     * Get 5 3A region test cases, each with one square region in it.
     * The first one is at center, the other four are at corners of
     * active array rectangle.
     *
     * @return array of test 3A regions
     */
    private ArrayList<MeteringRectangle[]> get3ARegionTestCasesForCamera() {
        final int TEST_3A_REGION_NUM = 5;
        final int DEFAULT_REGION_WEIGHT = 30;
        final int DEFAULT_REGION_SCALE_RATIO = 8;
        ArrayList<MeteringRectangle[]> testCases =
                new ArrayList<MeteringRectangle[]>(TEST_3A_REGION_NUM);
        final Rect activeArraySize = mStaticInfo.getActiveArraySizeChecked();
        int regionWidth = activeArraySize.width() / DEFAULT_REGION_SCALE_RATIO - 1;
        int regionHeight = activeArraySize.height() / DEFAULT_REGION_SCALE_RATIO - 1;
        int centerX = activeArraySize.width() / 2;
        int centerY = activeArraySize.height() / 2;
        int bottomRightX = activeArraySize.width() - 1;
        int bottomRightY = activeArraySize.height() - 1;

        // Center region
        testCases.add(
                new MeteringRectangle[] {
                    new MeteringRectangle(
                            centerX - regionWidth / 2,  // x
                            centerY - regionHeight / 2, // y
                            regionWidth,                // width
                            regionHeight,               // height
                            DEFAULT_REGION_WEIGHT)});

        // Upper left corner
        testCases.add(
                new MeteringRectangle[] {
                    new MeteringRectangle(
                            0,                // x
                            0,                // y
                            regionWidth,      // width
                            regionHeight,     // height
                            DEFAULT_REGION_WEIGHT)});

        // Upper right corner
        testCases.add(
                new MeteringRectangle[] {
                    new MeteringRectangle(
                            bottomRightX - regionWidth, // x
                            0,                          // y
                            regionWidth,                // width
                            regionHeight,               // height
                            DEFAULT_REGION_WEIGHT)});

        // Bottom left corner
        testCases.add(
                new MeteringRectangle[] {
                    new MeteringRectangle(
                            0,                           // x
                            bottomRightY - regionHeight, // y
                            regionWidth,                 // width
                            regionHeight,                // height
                            DEFAULT_REGION_WEIGHT)});

        // Bottom right corner
        testCases.add(
                new MeteringRectangle[] {
                    new MeteringRectangle(
                            bottomRightX - regionWidth,  // x
                            bottomRightY - regionHeight, // y
                            regionWidth,                 // width
                            regionHeight,                // height
                            DEFAULT_REGION_WEIGHT)});

        if (VERBOSE) {
            StringBuilder sb = new StringBuilder();
            for (MeteringRectangle[] mr : testCases) {
                sb.append(""{"");
                sb.append(Arrays.toString(mr));
                sb.append(""}, "");
            }
            if (sb.length() > 1)
                sb.setLength(sb.length() - 2); // Remove the redundant comma and space at the end
            Log.v(TAG, ""Generated test regions are: "" + sb.toString());
        }

        return testCases;
    }

    private boolean isRegionsSupportedFor3A(int index) {
        int maxRegions = 0;
        switch (index) {
            case MAX_REGIONS_AE_INDEX:
                maxRegions = mStaticInfo.getAeMaxRegionsChecked();
                break;
            case MAX_REGIONS_AWB_INDEX:
                maxRegions = mStaticInfo.getAwbMaxRegionsChecked();
                break;
            case  MAX_REGIONS_AF_INDEX:
                maxRegions = mStaticInfo.getAfMaxRegionsChecked();
                break;
            default:
                throw new IllegalArgumentException(""Unknown algorithm index"");
        }
        boolean isRegionsSupported = maxRegions > 0;
        if (index == MAX_REGIONS_AF_INDEX && isRegionsSupported) {
            mCollector.expectTrue(
                    ""Device reports non-zero max AF region count for a camera without focuser!"",
                    mStaticInfo.hasFocuser());
            isRegionsSupported = isRegionsSupported && mStaticInfo.hasFocuser();
        }

        return isRegionsSupported;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.car.ParkingBrakeOnTestActivity"	"setPassFailButtonClickListeners"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/car/ParkingBrakeOnTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.car;

import android.car.Car;
import android.car.hardware.CarPropertyConfig;
import android.car.hardware.CarPropertyValue;
import android.car.hardware.property.CarPropertyManager;
import android.car.VehicleAreaType;
import android.car.VehiclePropertyIds;
import android.os.Bundle;
import android.widget.TextView;
import android.util.ArraySet;
import android.util.Log;

import com.android.cts.verifier.PassFailButtons;
import com.android.cts.verifier.R;

import java.util.Arrays;
import java.util.List;

/** A CTS Verifier test case to verify PARKING_BRAKE_ON is implemented correctly.*/
public class ParkingBrakeOnTestActivity extends PassFailButtons.Activity {
    private static final String TAG = ParkingBrakeOnTestActivity.class.getSimpleName();
    private static final int TOTAL_MATCHES_NEEDED_TO_FINISH = 2;
    private Boolean mCurrentParkingBrakeOnValue;
    private TextView mInstructionTextView;
    private TextView mCurrentParkingBrakeOnValueTextView;
    private int mTotalTimesNewValueMatchInstruction = 0;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);

        // Setup the UI.
        setContentView(R.layout.parking_brake_on_test);
        setPassFailButtonClickListeners();
        setInfoResources(R.string.parking_brake_on_test, R.string.parking_brake_on_test_desc, -1);
        getPassButton().setEnabled(false);

        mInstructionTextView = (TextView) findViewById(R.id.instruction);
        mInstructionTextView.setText(""Waiting to get first PARKING_BRAKE_ON callback"");
        mCurrentParkingBrakeOnValueTextView =
            (TextView) findViewById(R.id.current_parking_brake_on_value);


        CarPropertyManager carPropertyManager =
            (CarPropertyManager) Car.createCar(this).getCarManager(Car.PROPERTY_SERVICE);

        if(!carPropertyManager.registerCallback(mCarPropertyEventCallback,
            VehiclePropertyIds.PARKING_BRAKE_ON, CarPropertyManager.SENSOR_RATE_ONCHANGE)) {
            mInstructionTextView.setText(""ERROR: Unable to register for PARKING_BRAKE_ON callback"");
            Log.e(TAG, ""Failed to register callback for PARKING_BRAKE_ON with CarPropertyManager"");
        }
    }

    private final CarPropertyManager.CarPropertyEventCallback mCarPropertyEventCallback =
      new CarPropertyManager.CarPropertyEventCallback() {
        @Override
        public void onChangeEvent(CarPropertyValue value) {
            if(value.getStatus() != CarPropertyValue.STATUS_AVAILABLE) {
                Log.e(TAG, ""New CarPropertyValue's status is not available - propId: "" +
                    value.getPropertyId() + "" status: "" + value.getStatus());
                return;
            }

            Boolean newValue = (Boolean) value.getValue();
            Log.i(TAG, ""New PARKING_BRAKE_ON value: "" + newValue);

            // On the first callback, mCurrentParkingBrakeOnValue will be null, so just save the
            // current value. All other callbacks, check if the PARKING_BRAKE_ON value has switched.
            // If switched, update the count.
            if (mCurrentParkingBrakeOnValue != null &&
                !mCurrentParkingBrakeOnValue.equals(newValue)) {
                mTotalTimesNewValueMatchInstruction++;
            }

            mCurrentParkingBrakeOnValue = newValue;
            mCurrentParkingBrakeOnValueTextView.setText(mCurrentParkingBrakeOnValue.toString());

            // Check if the test is finished. If not finished, update the instructions.
            if(mTotalTimesNewValueMatchInstruction >= TOTAL_MATCHES_NEEDED_TO_FINISH) {
                mInstructionTextView.setText(""Test Finished!"");
                getPassButton().setEnabled(true);
            } else if(mCurrentParkingBrakeOnValue) {
                mInstructionTextView.setText(""Disengage the Parking Brake"");
            } else {
                mInstructionTextView.setText(""Engage the Parking Brake"");
            }
        }

        @Override
        public void onErrorEvent(int propId, int zone) {
            Log.e(TAG, ""propId: "" + propId + "" zone: "" + zone);
        }
      };
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.SensorCtsHelperTest"	"testGetFrequency"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/SensorCtsHelperTest.java"	""	"public void testGetFrequency() {
        assertEquals(1.0, SensorCtsHelper.getFrequency(1, TimeUnit.SECONDS), 0.001);
        assertEquals(10.0, SensorCtsHelper.getFrequency(0.1, TimeUnit.SECONDS), 0.001);
        assertEquals(10.0, SensorCtsHelper.getFrequency(100, TimeUnit.MILLISECONDS), 0.001);
        assertEquals(1000.0, SensorCtsHelper.getFrequency(1, TimeUnit.MILLISECONDS), 0.001);
        assertEquals(10000.0, SensorCtsHelper.getFrequency(0.1, TimeUnit.MILLISECONDS), 0.001);
        assertEquals(10000.0, SensorCtsHelper.getFrequency(100, TimeUnit.MICROSECONDS), 0.001);
        assertEquals(1000000.0, SensorCtsHelper.getFrequency(1, TimeUnit.MICROSECONDS), 0.001);
        assertEquals(10000000.0, SensorCtsHelper.getFrequency(0.1, TimeUnit.MICROSECONDS), 0.001);
        assertEquals(10000000.0, SensorCtsHelper.getFrequency(100, TimeUnit.NANOSECONDS), 0.001);
        assertEquals(1000000000.0, SensorCtsHelper.getFrequency(1, TimeUnit.NANOSECONDS), 0.001);
    }

    /**
     * Test {@link SensorCtsHelper#getPeriod(Number, TimeUnit)}.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.SensorCtsHelperTest"	"testGetPeriod"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/SensorCtsHelperTest.java"	""	"public void testGetPeriod() {
        assertEquals(1.0, SensorCtsHelper.getPeriod(1, TimeUnit.SECONDS), 0.001);
        assertEquals(0.1, SensorCtsHelper.getPeriod(10, TimeUnit.SECONDS), 0.001);
        assertEquals(100, SensorCtsHelper.getPeriod(10, TimeUnit.MILLISECONDS), 0.001);
        assertEquals(1, SensorCtsHelper.getPeriod(1000, TimeUnit.MILLISECONDS), 0.001);
        assertEquals(0.1, SensorCtsHelper.getPeriod(10000, TimeUnit.MILLISECONDS), 0.001);
        assertEquals(100, SensorCtsHelper.getPeriod(10000, TimeUnit.MICROSECONDS), 0.001);
        assertEquals(1, SensorCtsHelper.getPeriod(1000000, TimeUnit.MICROSECONDS), 0.001);
        assertEquals(0.1, SensorCtsHelper.getPeriod(10000000, TimeUnit.MICROSECONDS), 0.001);
        assertEquals(100, SensorCtsHelper.getPeriod(10000000, TimeUnit.NANOSECONDS), 0.001);
        assertEquals(1, SensorCtsHelper.getPeriod(1000000000, TimeUnit.NANOSECONDS), 0.001);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.biometrics.AbstractBaseTest"	"isOnPauseAllowed"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/biometrics/AbstractBaseTest.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.biometrics;

import android.content.Intent;
import android.hardware.biometrics.BiometricManager;
import android.hardware.biometrics.BiometricManager.Authenticators;
import android.os.Bundle;
import android.os.Handler;
import android.os.Looper;
import android.provider.Settings;
import android.util.Log;
import android.widget.Button;
import android.widget.Toast;

import com.android.cts.verifier.PassFailButtons;

import java.util.concurrent.Executor;

/**
 * Abstract base class for tests in this directory.
 */
public abstract class AbstractBaseTest extends PassFailButtons.Activity {

    private static final int REQUEST_ENROLL_WHEN_NONE_ENROLLED = 1;

    abstract protected String getTag();
    abstract protected boolean isOnPauseAllowed();

    protected final Handler mHandler = new Handler(Looper.getMainLooper());
    protected final Executor mExecutor = mHandler::post;

    protected boolean mCurrentlyEnrolling;

    BiometricManager mBiometricManager;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        mBiometricManager = getSystemService(BiometricManager.class);
    }

    @Override
    protected void onPause() {
        super.onPause();

        // Assume we only enable the pass button when all tests pass. There actually  isn't a way
        // to easily do something like `this.isTestPassed()`
        if (!getPassButton().isEnabled() && !isOnPauseAllowed()) {
            showToastAndLog(""This test must be completed without pausing the app"");
            // Do not allow the test to continue if it loses foreground. Testers must start over.
            // 1) This is to avoid any potential change to the current enrollment / biometric state.
            // 2) The authentication UI must not affect the caller's activity lifecycle.
            finish();
        }
    }

    @Override
    public void onActivityResult(int requestCode, int resultCode, Intent data) {
        mCurrentlyEnrolling = false;

        if (requestCode == REQUEST_ENROLL_WHEN_NONE_ENROLLED) {
            onBiometricEnrollFinished();
        }
    }

    void showToastAndLog(String s) {
        Log.d(getTag(), s);
        Toast.makeText(this, s, Toast.LENGTH_SHORT).show();
    }

    void showToastAndLog(String s, Exception e) {
        Log.d(getTag(), s, e);
        Toast.makeText(this, s, Toast.LENGTH_SHORT).show();
    }

    protected void onBiometricEnrollFinished() {
    }

    void checkAndEnroll(Button enrollButton, int requestedStrength) {
        // Check that no biometrics (of any strength) are enrolled
        int result = mBiometricManager.canAuthenticate(Authenticators.BIOMETRIC_WEAK);
        if (result == BiometricManager.BIOMETRIC_SUCCESS) {
            showToastAndLog(""Please ensure that all biometrics are removed before starting""
                    + "" this test"");
            return;
        }

        result = mBiometricManager.canAuthenticate(requestedStrength);
        if (result == BiometricManager.BIOMETRIC_SUCCESS) {
            showToastAndLog(""Please ensure that all biometrics are removed before starting""
                    + "" this test"");
        } else if (result == BiometricManager.BIOMETRIC_ERROR_NO_HARDWARE) {
            // Multi-sensor cases are more thoroughly tested in regular CTS (not CTS-V), this
            // should be fine for the purposes of CTS-V.
            showToastAndLog(""This device does not have a sensor meeting the requested strength,""
                    + "" you may pass this test"");
            enrollButton.setEnabled(false);
            getPassButton().setEnabled(true);
        } else if (result == BiometricManager.BIOMETRIC_ERROR_NONE_ENROLLED) {
            startBiometricEnroll(REQUEST_ENROLL_WHEN_NONE_ENROLLED, requestedStrength);
        } else {
            showToastAndLog(""Unexpected result: "" + result + "". Please ensure you have removed""
                    + ""all biometric enrollments."");
        }
    }

    private void startBiometricEnroll(int requestCode, int requestedStrength) {
        mCurrentlyEnrolling = true;
        final Intent enrollIntent = new Intent(Settings.ACTION_BIOMETRIC_ENROLL);
        enrollIntent.putExtra(Settings.EXTRA_BIOMETRIC_AUTHENTICATORS_ALLOWED,
                requestedStrength);

        startActivityForResult(enrollIntent, requestCode);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.OffBodySensorTestActivity"	"getTestLogger"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/OffBodySensorTestActivity.java"	""	"public void test/*
 *
 */
package com.android.cts.verifier.sensors;

import android.app.AlarmManager;
import android.app.PendingIntent;
import android.content.BroadcastReceiver;
import android.content.Context;
import android.content.Intent;
import android.content.IntentFilter;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.hardware.cts.helpers.SensorNotSupportedException;
import android.hardware.cts.helpers.SuspendStateMonitor;
import android.os.PowerManager;
import android.os.SystemClock;
import androidx.localbroadcastmanager.content.LocalBroadcastManager;
import android.util.Log;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.helpers.SensorTestScreenManipulator;
import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;

import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

import junit.framework.Assert;
import static junit.framework.Assert.fail;


/**
 * Manual test for testing the low-latency offbody detect sensor. This test consists of 3
 * sub-tests designed to verify the sensor event data, verify event trigger response times
 * are within spec for the sensor type, and to verify that the sensor can wake the device.
 */
public class OffBodySensorTestActivity
        extends SensorCtsVerifierTestActivity {
    private static final String TAG=""OffbodySensorTest"";
    private static String ACTION_ALARM = ""OffBodySensorTestActivity.ACTION_ALARM"";
    private static final int MAX_OFF_BODY_EVENT_LATENCY_MS = 1000;
    private static final int MAX_ON_BODY_EVENT_LATENCY_MS = 5000;
    private static final int COUNTDOWN_INTERVAL_MS = 1000;
    private static final int LLOB_EVENT_MAX_DELAY_SEC = 20;
    private static final long MAX_ALLOWED_DELAY_MS = TimeUnit.SECONDS.toMillis(1);
    private static final long RESULT_REPORT_SHOW_TIME_MS = TimeUnit.SECONDS.toMillis(5);
    private static final int OFFBODY_EVENT_VALUES_LENGTH = 1;
    private static final int COUNTDOWN_NUM_INTERVALS = 3;

    private static final float OFF_BODY_EVENT_VALUE = 0;
    private static final float ON_BODY_EVENT_VALUE = 1;
    private static final float BAD_VALUE_SEEN_INIT = 0;
    private static float mBadValueSeen = BAD_VALUE_SEEN_INIT;

    private enum State {
        OFF_BODY, ON_BODY, UNKNOWN
    }

    // time to wait for offbody event after the device has gone into suspend. Even after
    // 45 secs if LLOB sensor does not trigger, the test will fail.
    private static final long ALARM_WAKE_UP_AP_DELAY_MS = TimeUnit.SECONDS.toMillis(45);

    // acceptable time difference between event time and AP wake up time.
    private static final long MAX_ACCEPTABLE_DELAY_EVENT_AP_WAKE_UP_NS =
            TimeUnit.MILLISECONDS.toNanos(1200);

    private static final int NANOSECONDS_PER_MILLISECOND = 1000000;
    private AlarmManager mAlarmManager;
    private SensorManager mSensorManager;
    private Sensor mOffBodySensor;
    private boolean mOffBodySensorRegistered;
    private long mTestStartTimestampMs;
    private State mPreviousSensorState;
    private PendingIntent mPendingIntent;
    private PowerManager.WakeLock mDeviceSuspendLock;
    private SensorEventVerifier mVerifier;
    private SensorTestScreenManipulator mScreenManipulator;

    public class SensorEventRegistry {
        public final SensorEvent event;
        public final long receiveTimestampNanos;

        public SensorEventRegistry(SensorEvent event, long realtimeTimestampNanos) {
            this.event = event;
            this.receiveTimestampNanos = realtimeTimestampNanos;
        }
    }

    private class SensorEventVerifier implements SensorEventListener {
        private volatile CountDownLatch mCountDownLatch;
        private volatile SensorEventRegistry mEventRegistry;
        private volatile long mTimestampForLastSensorEvent = 0;

        @Override
        public void onAccuracyChanged(Sensor sensor, int accuracy) {}

        @Override
        public void onSensorChanged(SensorEvent event) {
            long elapsedRealtimeNanos = SystemClock.elapsedRealtimeNanos();
            int type = event.sensor.getType();

            if (type == Sensor.TYPE_LOW_LATENCY_OFFBODY_DETECT) {
                switch((int) event.values[0]) {
                    case (int) OFF_BODY_EVENT_VALUE:
                        Log.i(TAG, ""onSensorChanged(): OFF_BODY ts=""+event.timestamp+
                                "", now=""+elapsedRealtimeNanos+"", delta=""+
                                (elapsedRealtimeNanos-event.timestamp)/1000000+""mS"");
                        mPreviousSensorState = State.OFF_BODY;
                        break;
                    case (int) ON_BODY_EVENT_VALUE:
                        Log.i(TAG, ""onSensorChanged(): ON_BODY ts = ""+event.timestamp+
                                "", now=""+elapsedRealtimeNanos+"", delta=""+
                                (elapsedRealtimeNanos-event.timestamp)/1000000+""mS"");
                        mPreviousSensorState = State.ON_BODY;
                        break;
                    default:
                        Log.e(TAG, ""onSensorChanged(): invalid value ""+event.values[0]+
                                "" received"");
                        mBadValueSeen = event.values[0];
                        break;
                }
                mEventRegistry = new SensorEventRegistry(event, elapsedRealtimeNanos);
                getTestLogger().logMessage(
                        R.string.snsr_offbody_state_change,
                        (int) event.values[0],
                        elapsedRealtimeNanos);
                releaseLatch();
            }
        }

        public void releaseLatch() {
            if (mCountDownLatch != null) {
                mCountDownLatch.countDown();
            }
        }

        public long getTimeStampForSensorEvent() {
            return mTimestampForLastSensorEvent;
        }

        public String awaitAndVerifyEvent(float expectedResponseValue) throws Throwable {
            return awaitAndVerifyEvent(expectedResponseValue, 0);
        }

        public String awaitAndVerifyEvent(float expectedResponseValue, int maxEventLatencyMs)
                throws Throwable {
            SensorEventRegistry registry = waitForEvent();
            String eventArrivalMessage;
            if ((registry == null) || (registry.event == null)) {
                eventArrivalMessage = getString(R.string.snsr_offbody_event_arrival, false);
                Assert.fail(eventArrivalMessage);
            }

            // verify an event arrived, and it is indeed a Low Latency Offbody Detect event
            SensorEvent event = registry.event;
            eventArrivalMessage = getString(R.string.snsr_offbody_event_arrival, event != null);
            Assert.assertNotNull(eventArrivalMessage, event);

            String result = verifyEvent(registry, expectedResponseValue, maxEventLatencyMs);
            return result;
        }

        public String verifyEvent(SensorEventRegistry registry, float expectedResponseValue,
                int maxEventLatencyMs) throws Throwable {
            int eventType = registry.event.sensor.getType();
            String eventTypeMessage = getString(
                    R.string.snsr_offbody_event_type,
                    Sensor.TYPE_LOW_LATENCY_OFFBODY_DETECT,
                    eventType);
            Assert.assertEquals(eventTypeMessage,
                    Sensor.TYPE_LOW_LATENCY_OFFBODY_DETECT,
                    eventType);

            float value = registry.event.values[0];
            String sensorName = registry.event.sensor.getName();
            String eventName = (value == ON_BODY_EVENT_VALUE) ? ""ON-BODY"" : ""OFF-BODY"";

            long eventLatencyMs = (registry.receiveTimestampNanos/NANOSECONDS_PER_MILLISECOND)
                    - mTestStartTimestampMs;

            int valuesLength = registry.event.values.length;
            String valuesLengthMessage = getString(
                    R.string.snsr_event_length,
                    OFFBODY_EVENT_VALUES_LENGTH,
                    valuesLength,
                    sensorName);
            Assert.assertEquals(valuesLengthMessage, OFFBODY_EVENT_VALUES_LENGTH, valuesLength);

            String valuesMessage = getString(
                    R.string.snsr_event_value,
                    expectedResponseValue,
                    value,
                    sensorName);
            Assert.assertEquals(valuesMessage, expectedResponseValue, value);

            if (maxEventLatencyMs != 0) {
                Log.i(TAG, ""event latency was ""+eventLatencyMs+"" ms for ""+
                        eventName+"" event"");
                String responseViolationMessage = getString(
                    R.string.snsr_offbody_response_timing_violation,
                    eventName,
                    maxEventLatencyMs,
                    eventLatencyMs);
                boolean violation = (eventLatencyMs > maxEventLatencyMs);
                Assert.assertFalse(responseViolationMessage, violation);
            }
            return null;
        }

        private void verifyOffbodyEventNotInvalid() throws InterruptedException {
            if (mBadValueSeen != BAD_VALUE_SEEN_INIT) {
                Assert.fail(
                    String.format(getString(R.string.snsr_offbody_event_invalid_value),
                    OFF_BODY_EVENT_VALUE,
                    ON_BODY_EVENT_VALUE,
                    mBadValueSeen));
            }
        }

        private SensorEventRegistry waitForEvent() throws InterruptedException {
            return waitForEvent(null);
        }

        private SensorEventRegistry waitForEvent(PowerManager.WakeLock suspendLock)
                throws InterruptedException {
            mCountDownLatch = new CountDownLatch(1);

            if ((suspendLock != null) && suspendLock.isHeld()) {
                suspendLock.release();
            }

            mCountDownLatch.await(LLOB_EVENT_MAX_DELAY_SEC, TimeUnit.SECONDS);

            if ((suspendLock != null) && !suspendLock.isHeld()) {
                suspendLock.acquire();
            }

            SensorEventRegistry registry = mEventRegistry;

            // Save the last timestamp when the event triggered.
            if (mEventRegistry != null && mEventRegistry.event != null) {
                mTimestampForLastSensorEvent = mEventRegistry.event.timestamp;
            }

            mEventRegistry = null;
            verifyOffbodyEventNotInvalid();
            return registry != null ? registry : new SensorEventRegistry(null, 0);
        }

        public SensorEvent waitForSensorEvent() throws InterruptedException {
            SensorEvent event = null;
            mCountDownLatch = new CountDownLatch(1);
            mCountDownLatch.await(LLOB_EVENT_MAX_DELAY_SEC, TimeUnit.SECONDS);

            if (mEventRegistry != null && mEventRegistry.event != null) {
                event = mEventRegistry.event;
            }

            mEventRegistry = null;
            verifyOffbodyEventNotInvalid();
            return event;
        }
    }

    public OffBodySensorTestActivity() {
        super(OffBodySensorTestActivity.class);
    }


    @Override
    protected void activitySetUp() throws InterruptedException {
        PowerManager pm = (PowerManager) getSystemService(Context.POWER_SERVICE);
        mDeviceSuspendLock = pm.newWakeLock(PowerManager.PARTIAL_WAKE_LOCK,
                                            ""OffBodySensorTestActivity"");
        mDeviceSuspendLock.acquire();
        mOffBodySensorRegistered = false;
        mSensorManager = (SensorManager) getSystemService(Context.SENSOR_SERVICE);
        mOffBodySensor = mSensorManager.getDefaultSensor(Sensor.TYPE_LOW_LATENCY_OFFBODY_DETECT,
                true);
        if (mOffBodySensor == null) {
            setTestResultAndFinish(true);
            return;
        }
        LocalBroadcastManager.getInstance(this).registerReceiver(myBroadCastReceiver,
                                        new IntentFilter(ACTION_ALARM));
        Intent intent = new Intent(this, AlarmReceiver.class);
        mPendingIntent = PendingIntent.getBroadcast(this, 0, intent, PendingIntent.FLAG_MUTABLE_UNAUDITED);
        mAlarmManager = (AlarmManager) getSystemService(ALARM_SERVICE);
        mScreenManipulator = new SensorTestScreenManipulator(this);
        try {
            mScreenManipulator.initialize(this);
        } catch (InterruptedException e) {
        }
    }

    private void startTimeoutTimer(long delayMs) {
        mAlarmManager.setExact(AlarmManager.ELAPSED_REALTIME_WAKEUP,
                                SystemClock.elapsedRealtime() + delayMs,
                                mPendingIntent);
    }

    private void stopTimeoutTimer() {
        mAlarmManager.cancel(mPendingIntent);
    }

    private void stopOffbodySensorListener(SensorEventVerifier verifier) {
        if (mOffBodySensorRegistered) {
            mSensorManager.unregisterListener(verifier);
            mOffBodySensorRegistered = false;
        }
    }

    private boolean startOffbodySensorListener(SensorEventVerifier verifier) {
        if (!mOffBodySensorRegistered) {
            if (!mSensorManager.registerListener(verifier, mOffBodySensor,
                        SensorManager.SENSOR_DELAY_FASTEST)) {
                Log.e(TAG, ""error registering listener for LLOB"");
                setTestResultAndFinish(true);
                return false;
            }
            mOffBodySensorRegistered = true;
        }
        return true;
    }

    public static class AlarmReceiver extends BroadcastReceiver {
        @Override
        public void onReceive(Context context, Intent intent) {
            Intent alarm_intent = new Intent(context, OffBodySensorTestActivity.class);
            alarm_intent.setAction(OffBodySensorTestActivity.ACTION_ALARM);
            LocalBroadcastManager.getInstance(context).sendBroadcastSync(alarm_intent);
        }
    }

    public BroadcastReceiver myBroadCastReceiver = new BroadcastReceiver() {
        @Override
        public void onReceive(Context context, Intent intent) {
            mVerifier.releaseLatch();
            mScreenManipulator.turnScreenOn();
            if (!mDeviceSuspendLock.isHeld()) {
                mDeviceSuspendLock.acquire();
            }
        }
    };

    public String testOffbodyDetectResponseTime() throws Throwable {
        Sensor wakeUpSensor = mSensorManager.getDefaultSensor(
                Sensor.TYPE_LOW_LATENCY_OFFBODY_DETECT, true);
        if (wakeUpSensor == null) {
            throw new SensorNotSupportedException(Sensor.TYPE_LOW_LATENCY_OFFBODY_DETECT, true);
        }
        return runOffbodyDetectResponseTimeTest(wakeUpSensor);
    }

    public String testOnbodyDetectResponseTime() throws Throwable {
        Sensor wakeUpSensor = mSensorManager.getDefaultSensor(
                Sensor.TYPE_LOW_LATENCY_OFFBODY_DETECT, true);
        if (wakeUpSensor == null) {
            throw new SensorNotSupportedException(Sensor.TYPE_LOW_LATENCY_OFFBODY_DETECT, true);
        }
        return runOnbodyDetectResponseTimeTest(wakeUpSensor);
    }

    public String testWakeAPOffbodyDetect() throws Throwable {
        Sensor wakeUpSensor = mSensorManager.getDefaultSensor(
                Sensor.TYPE_LOW_LATENCY_OFFBODY_DETECT, true);
        if (wakeUpSensor == null) {
            throw new SensorNotSupportedException(Sensor.TYPE_LOW_LATENCY_OFFBODY_DETECT, true);
        }
        return runWakeAPOffbodyDetectTest(wakeUpSensor);
    }

    public String runOffbodyDetectResponseTimeTest(Sensor sensor) throws Throwable {
        boolean success;
        String eventArrivalMessage;
        mOffBodySensor = sensor;
        mBadValueSeen = BAD_VALUE_SEEN_INIT;

        try {
            // If device not currently on-body, instruct user to put it on wrist
            mTestStartTimestampMs = 0;
            mVerifier = new SensorEventVerifier();
            success = startOffbodySensorListener(mVerifier);
            Assert.assertTrue(
                    getString(R.string.snsr_offbody_sensor_registration, success),
                    success);
            SensorEvent event = mVerifier.waitForSensorEvent();
            eventArrivalMessage = getString(R.string.snsr_offbody_event_arrival, event != null);
            Assert.assertNotNull(eventArrivalMessage, event);

            SensorTestLogger logger = getTestLogger();
            if (event.values[0] != ON_BODY_EVENT_VALUE) {
                // Instruct user on how to perform offbody detect test
                logger.logInstructions(R.string.snsr_start_offbody_sensor_test_instr);
                waitForUserToBegin();
                if (mPreviousSensorState != State.ON_BODY) {
                    event = mVerifier.waitForSensorEvent();
                    eventArrivalMessage = getString(R.string.snsr_offbody_event_arrival,
                            event != null);
                    Assert.assertNotNull(eventArrivalMessage, event);
                    if (event.values[0] != ON_BODY_EVENT_VALUE) {
                        Assert.fail(
                            String.format(getString(R.string.snsr_offbody_event_wrong_value),
                            ON_BODY_EVENT_VALUE,
                            event.values[0]));
                    }
                }
            }

            // Instruct user on how to perform offbody detect test
            logger.logInstructions(R.string.snsr_offbody_detect_test_instr);
            waitForUserToBegin();

            // Count down before actually starting, leaving time to react after pressing the Next
            // button.
            for (int i = 0; i < COUNTDOWN_NUM_INTERVALS; i++) {
                try {
                    Thread.sleep(COUNTDOWN_INTERVAL_MS);
                } catch (InterruptedException e) {
                    // Ignore the interrupt and continue counting down.
                }
                logger.logInstructions(R.string.snsr_offbody_detect_test_countdown,
                        COUNTDOWN_NUM_INTERVALS - i - 1);
            }
            mTestStartTimestampMs = SystemClock.elapsedRealtime();

            // Verify off-body event latency is within spec
            mVerifier.awaitAndVerifyEvent(OFF_BODY_EVENT_VALUE, MAX_OFF_BODY_EVENT_LATENCY_MS);
        } finally {
            stopOffbodySensorListener(mVerifier);
        }
        return null;
    }

    public String runOnbodyDetectResponseTimeTest(Sensor sensor) throws Throwable {
        mOffBodySensor = sensor;
        SensorTestLogger logger = getTestLogger();
        mBadValueSeen = BAD_VALUE_SEEN_INIT;

        try {
            // If device not currently off-body, instruct user to remove it from wrist
            mTestStartTimestampMs = 0;
            mVerifier = new SensorEventVerifier();
            boolean success = startOffbodySensorListener(mVerifier);
            Assert.assertTrue(
                    getString(R.string.snsr_offbody_sensor_registration, success),
                    success);
            SensorEvent event = mVerifier.waitForSensorEvent();
            String eventArrivalMessage = getString(R.string.snsr_offbody_event_arrival,
                    event != null);
            Assert.assertNotNull(eventArrivalMessage, event);
            if (event.values[0] != OFF_BODY_EVENT_VALUE) {
                // Instruct user on how to perform offbody detect test
                logger.logInstructions(R.string.snsr_start_onbody_sensor_test_instr);
                waitForUserToBegin();
                if (mPreviousSensorState != State.OFF_BODY) {
                    event = mVerifier.waitForSensorEvent();
                    eventArrivalMessage = getString(R.string.snsr_offbody_event_arrival,
                            event != null);
                    Assert.assertNotNull(eventArrivalMessage, event);
                    if (event.values[0] != OFF_BODY_EVENT_VALUE) {
                        Assert.fail(
                            String.format(getString(R.string.snsr_offbody_event_wrong_value),
                            OFF_BODY_EVENT_VALUE,
                            event.values[0]));
                    }
                }
            }

            // Display on-body latency test instructions
            logger.logInstructions(R.string.snsr_onbody_detect_test_instr);
            waitForUserToBegin();
            mTestStartTimestampMs = SystemClock.elapsedRealtime();
            mVerifier.awaitAndVerifyEvent(ON_BODY_EVENT_VALUE, MAX_ON_BODY_EVENT_LATENCY_MS);
        } finally {
            stopOffbodySensorListener(mVerifier);
        }
        return null;
    }

    public String runWakeAPOffbodyDetectTest(Sensor sensor) throws Throwable {
        final long ALARM_WAKE_UP_DELAY_MS = 40000;
        String eventArrivalMessage;
        SensorEventRegistry registry;
        SensorTestLogger logger = getTestLogger();
        mBadValueSeen = BAD_VALUE_SEEN_INIT;
        mVerifier = new SensorEventVerifier();
        mOffBodySensor = sensor;
        mTestStartTimestampMs = 0;

        mTestStartTimestampMs = SystemClock.elapsedRealtime();
        SuspendStateMonitor suspendStateMonitor = new SuspendStateMonitor();
        try {
            boolean success = startOffbodySensorListener(mVerifier);
            Assert.assertTrue(
                    getString(R.string.snsr_offbody_sensor_registration, success),
                    success);

            // grab the current off-body state, which should be ON-BODY
            if (mPreviousSensorState != State.ON_BODY) {
                registry = mVerifier.waitForEvent();
                if ((registry == null) || (registry.event == null) ||
                        (registry.event.values[0] != ON_BODY_EVENT_VALUE)) {
                    eventArrivalMessage = getString(R.string.snsr_offbody_event_arrival, false);
                    Assert.fail(eventArrivalMessage);

                    // Tell user to put watch on wrist
                    logger.logInstructions(R.string.snsr_start_offbody_sensor_test_instr);
                    waitForUserToBegin();
                    if (mPreviousSensorState != State.ON_BODY) {
                        registry = mVerifier.waitForEvent();
                        if ((registry == null) || (registry.event == null)) {
                            eventArrivalMessage = getString(R.string.snsr_offbody_event_arrival, false);
                            Assert.fail(eventArrivalMessage);
                        } else {
                            Assert.assertTrue(
                                String.format(getString(R.string.snsr_offbody_event_wrong_value),
                                ON_BODY_EVENT_VALUE,
                                registry.event.values[0]),
                                ON_BODY_EVENT_VALUE == registry.event.values[0]);
                        }
                    }
                }
            }

            // Instruct user on how to perform offbody detect sleep test
            logger.logInstructions(R.string.snsr_ap_wake_offbody_detect_test_instr);
            waitForUserToBegin();

            long testStartTimeNs = SystemClock.elapsedRealtimeNanos();
            startTimeoutTimer(ALARM_WAKE_UP_AP_DELAY_MS);

            // Wait for the first event to trigger. Device is expected to go into suspend here.
            registry = mVerifier.waitForEvent(mDeviceSuspendLock);
            if ((registry == null) || (registry.event == null)) {
                eventArrivalMessage = getString(R.string.snsr_offbody_event_arrival, false);
                Assert.fail(eventArrivalMessage);
            }

            mVerifier.verifyEvent(registry, OFF_BODY_EVENT_VALUE, 0);

            long eventTimeStampNs = registry.event.timestamp;
            long endTimeNs = SystemClock.elapsedRealtimeNanos();
            long lastWakeupTimeNs = TimeUnit.MILLISECONDS.toNanos(
                    suspendStateMonitor.getLastWakeUpTime());
            Assert.assertTrue(getString(R.string.snsr_device_did_not_go_into_suspend),
                              testStartTimeNs < lastWakeupTimeNs && lastWakeupTimeNs < endTimeNs);
            long timestampDelta = Math.abs(lastWakeupTimeNs - eventTimeStampNs);
            Assert.assertTrue(
                    String.format(getString(R.string.snsr_device_did_not_wake_up_at_trigger),
                              TimeUnit.NANOSECONDS.toMillis(lastWakeupTimeNs),
                              TimeUnit.NANOSECONDS.toMillis(eventTimeStampNs)),
                              timestampDelta < MAX_ACCEPTABLE_DELAY_EVENT_AP_WAKE_UP_NS);
        } finally {
            stopTimeoutTimer();
            suspendStateMonitor.cancel();
            mScreenManipulator.turnScreenOn();
            playSound();
        }
        return null;
    }

    @Override
    protected void activityCleanUp() {
        if (mOffBodySensorRegistered) {
            stopOffbodySensorListener(mVerifier);
        }
        stopTimeoutTimer();
        LocalBroadcastManager.getInstance(this).unregisterReceiver(myBroadCastReceiver);
        if (mOffBodySensor != null) {
            mOffBodySensor = null;
        }
        if (mScreenManipulator != null){
            mScreenManipulator.close();
        }
        if ((mDeviceSuspendLock != null) && mDeviceSuspendLock.isHeld()) {
            mDeviceSuspendLock.release();
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensoroperations.AlarmOperation"	"currentTimeMillis"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensoroperations/AlarmOperation.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers.sensoroperations;

import android.app.AlarmManager;
import android.app.PendingIntent;
import android.content.BroadcastReceiver;
import android.content.Context;
import android.content.Intent;
import android.content.IntentFilter;
import android.hardware.cts.helpers.reporting.ISensorTestNode;
import android.os.PowerManager;
import android.os.PowerManager.WakeLock;

import java.util.concurrent.TimeUnit;

/**
 * An {@link SensorOperation} which performs another {@link SensorOperation} and then wakes up
 * after a specified period of time and waits for the child operation to complete.
 * <p>
 * This operation can be used to allow the device to go to sleep and wake it up after a specified
 * period of time. After the device wakes up, this operation will hold a wake lock until the child
 * operation finishes. This operation will not force the device into suspend, so if another
 * operation is holding a wake lock, the device will stay awake.  Also, if the child operation
 * finishes before the specified period, this operation return when the child operation finishes
 * but wake the device one time at the specified period.
 * </p>
 */
public class AlarmOperation extends SensorOperation {
    private static final String ACTION = ""AlarmOperationAction"";
    private static final String WAKE_LOCK_TAG = ""AlarmOperationWakeLock"";

    private final SensorOperation mOperation;
    private final Context mContext;
    private final long mSleepDuration;
    private final TimeUnit mTimeUnit;

    private boolean mCompleted = false;
    private WakeLock mWakeLock = null;

    /**
     * Constructor for {@link DelaySensorOperation}
     *
     * @param operation the child {@link SensorOperation} to perform after the delay
     * @param context the context used to access the alarm manager
     * @param sleepDuration the amount of time to sleep
     * @param timeUnit the unit of the duration
     */
    public AlarmOperation(
            SensorOperation operation,
            Context context,
            long sleepDuration,
            TimeUnit timeUnit) {
        super(operation.getStats());
        mOperation = operation;
        mContext = context;
        mSleepDuration = sleepDuration;
        mTimeUnit = timeUnit;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public void execute(ISensorTestNode parent) throws Exception {
        // Start alarm
        IntentFilter intentFilter = new IntentFilter(ACTION);
        BroadcastReceiver receiver = new BroadcastReceiver() {
            @Override
            public void onReceive(Context context, Intent intent) {
                acquireWakeLock();
            }
        };
        mContext.registerReceiver(receiver, intentFilter);

        AlarmManager am = (AlarmManager) mContext.getSystemService(Context.ALARM_SERVICE);
        long wakeupTimeMs = (System.currentTimeMillis()
                + TimeUnit.MILLISECONDS.convert(mSleepDuration, mTimeUnit));
        Intent intent = new Intent(ACTION);
        PendingIntent pendingIntent = PendingIntent.getBroadcast(mContext, 0, intent, PendingIntent.FLAG_MUTABLE_UNAUDITED);
        am.setExact(AlarmManager.RTC_WAKEUP, wakeupTimeMs, pendingIntent);

        // Execute operation
        try {
            mOperation.execute(asTestNode(parent));
        } finally {
            releaseWakeLock();
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public AlarmOperation clone() {
        return new AlarmOperation(mOperation, mContext, mSleepDuration, mTimeUnit);
    }

    /**
     * Method that acquires a wake lock if a wake lock has not already been acquired and if the
     * operation has not yet completed.
     */
    private synchronized void acquireWakeLock() {
        // Don't acquire wake lock if the operation has already completed.
        if (mCompleted || mWakeLock != null) {
            return;
        }
        PowerManager pm = (PowerManager) mContext.getSystemService(Context.POWER_SERVICE);
        mWakeLock = pm.newWakeLock(PowerManager.PARTIAL_WAKE_LOCK, WAKE_LOCK_TAG);
    }

    /**
     * Method that releases the wake lock if it has been acquired.
     */
    private synchronized void releaseWakeLock() {
        mCompleted = true;
        if (mWakeLock != null) {
            mWakeLock.release();
        }
        mWakeLock = null;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testSensorsWithSeveralClients"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testSensorsWithSeveralClients() throws Throwable {
        SensorCtsHelper.sleep(3, TimeUnit.SECONDS);
        final int ITERATIONS = 50;
        final int MAX_REPORTING_LATENCY_US = (int) TimeUnit.SECONDS.toMicros(5);
        final Context context = getContext();

        int sensorTypes[] = {
                Sensor.TYPE_ACCELEROMETER,
                Sensor.TYPE_MAGNETIC_FIELD,
                Sensor.TYPE_GYROSCOPE };

        ParallelSensorOperation operation = new ParallelSensorOperation();
        for(int sensorType : sensorTypes) {
            TestSensorEnvironment environment = new TestSensorEnvironment(
                    context,
                    sensorType,
                    shouldEmulateSensorUnderLoad(),
                    SensorManager.SENSOR_DELAY_FASTEST);
            TestSensorOperation continuousOperation =
                    TestSensorOperation.createOperation(environment, 100 /* eventCount */);
            continuousOperation.addVerification(new EventOrderingVerification());
            operation.add(new RepeatingSensorOperation(continuousOperation, ITERATIONS));

            Sensor sensor = TestSensorEnvironment.getSensor(context, sensorType);
            TestSensorEnvironment batchingEnvironment = new TestSensorEnvironment(
                    context,
                    sensorType,
                    shouldEmulateSensorUnderLoad(),
                    true, /* isIntegrationTest */
                    sensor.getMinDelay(),
                    MAX_REPORTING_LATENCY_US);
            TestSensorOperation batchingOperation =
                    TestSensorOperation.createOperation(batchingEnvironment, 100 /* eventCount */);
            batchingOperation.addVerification(new EventOrderingVerification());
            operation.add(new RepeatingSensorOperation(batchingOperation, ITERATIONS));
        }
        operation.execute(getCurrentTestNode());
        operation.getStats().log(TAG);
    }

    /**
     * This test focuses in the interaction of several sensor Clients. The test characterizes by
     * using clients for different Sensors under Test that vary the sampling rates and report
     * latencies for the requests.
     * The verification ensures that the sensor clients can vary the parameters of their requests
     * without affecting other clients.
     *
     * The test verifies for each client that a set of sampled data arrives in order. However each
     * client in the test has different set of parameters that represent different types of clients
     * in the real world.
     *
     * The test can be susceptible to issues when several clients interacting with the system
     * actually affect the operation of other clients.
     *
     * The assertion associated with the test failure provides:
     * - the thread id on which the failure occurred
     * - the sensor type and sensor handle that caused the failure
     * - the event that caused the issue
     * It is important to look at the internals of the Sensor HAL to identify how the interaction
     * of several clients can lead to the failing state.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testSensorsMovingRates"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testSensorsMovingRates() throws Throwable {
        SensorCtsHelper.sleep(3, TimeUnit.SECONDS);
        // use at least two instances to ensure more than one client of any given sensor is in play
        final int INSTANCES_TO_USE = 5;
        final int ITERATIONS_TO_EXECUTE = 100;

        ParallelSensorOperation operation = new ParallelSensorOperation();
        int sensorTypes[] = {
                Sensor.TYPE_ACCELEROMETER,
                Sensor.TYPE_MAGNETIC_FIELD,
                Sensor.TYPE_GYROSCOPE };

        Context context = getContext();
        for(int sensorType : sensorTypes) {
            for(int instance = 0; instance < INSTANCES_TO_USE; ++instance) {
                SequentialSensorOperation sequentialOperation = new SequentialSensorOperation();
                for(int iteration = 0; iteration < ITERATIONS_TO_EXECUTE; ++iteration) {
                    TestSensorEnvironment environment = new TestSensorEnvironment(
                            context,
                            sensorType,
                            shouldEmulateSensorUnderLoad(),
                            true, /* isIntegrationTest */
                            generateSamplingRateInUs(sensorType),
                            generateReportLatencyInUs());
                    TestSensorOperation sensorOperation =
                            TestSensorOperation.createOperation(environment, 100 /* eventCount */);
                    sensorOperation.addVerification(new EventOrderingVerification());
                    sequentialOperation.add(sensorOperation);
                }
                operation.add(sequentialOperation);
            }
        }

        operation.execute(getCurrentTestNode());
        operation.getStats().log(TAG);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testAccelerometerReconfigureWhileActive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testAccelerometerReconfigureWhileActive() throws Throwable {
        verifySensorReconfigureWhileActive(Sensor.TYPE_ACCELEROMETER);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testUncalibratedAccelerometerReconfigureWhileActive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testUncalibratedAccelerometerReconfigureWhileActive() throws Throwable {
        verifySensorReconfigureWhileActive(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testMagneticFieldReconfigureWhileActive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testMagneticFieldReconfigureWhileActive() throws Throwable {
        verifySensorReconfigureWhileActive(Sensor.TYPE_MAGNETIC_FIELD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testUncalibratedMagneticFieldReconfigureWhileActive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testUncalibratedMagneticFieldReconfigureWhileActive() throws Throwable {
        verifySensorReconfigureWhileActive(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testOrientationReconfigureWhileActive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testOrientationReconfigureWhileActive() throws Throwable {
        verifySensorReconfigureWhileActive(Sensor.TYPE_ORIENTATION);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testGyroscopeReconfigureWhileActive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testGyroscopeReconfigureWhileActive() throws Throwable {
        verifySensorReconfigureWhileActive(Sensor.TYPE_GYROSCOPE);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testUncalibratedGyroscopeReconfigureWhileActive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testUncalibratedGyroscopeReconfigureWhileActive() throws Throwable {
        verifySensorReconfigureWhileActive(Sensor.TYPE_GYROSCOPE_UNCALIBRATED);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testPressureReconfigureWhileActive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testPressureReconfigureWhileActive() throws Throwable {
        verifySensorReconfigureWhileActive(Sensor.TYPE_PRESSURE);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testGravityReconfigureWhileActive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testGravityReconfigureWhileActive() throws Throwable {
        verifySensorReconfigureWhileActive(Sensor.TYPE_GRAVITY);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testLinearAccelerationReconfigureWhileActive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testLinearAccelerationReconfigureWhileActive() throws Throwable {
        verifySensorReconfigureWhileActive(Sensor.TYPE_LINEAR_ACCELERATION);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testRotationVectorReconfigureWhileActive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testRotationVectorReconfigureWhileActive() throws Throwable {
        verifySensorReconfigureWhileActive(Sensor.TYPE_ROTATION_VECTOR);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testGameRotationVectorReconfigureWhileActive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testGameRotationVectorReconfigureWhileActive() throws Throwable {
        verifySensorReconfigureWhileActive(Sensor.TYPE_GAME_ROTATION_VECTOR);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testGeomagneticRotationVectorReconfigureWhileActive"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testGeomagneticRotationVectorReconfigureWhileActive() throws Throwable {
        verifySensorReconfigureWhileActive(Sensor.TYPE_GEOMAGNETIC_ROTATION_VECTOR);
    }

    /**
     * This test focuses on ensuring that an active sensor is able to be reconfigured when a new
     * client requests a different sampling rate.
     *
     * The test verifies that if a sensor is active with a slow sampling rate and a new client
     * requests a faster sampling rate, the sensor begins returning data at the faster sampling
     * rate.
     *
     * The assertion associated with the test failure provides:
     * - the thread id on which the failure occurred
     * - the sensor type and sensor handle that caused the failure
     * - the event that caused the issue
     * It is important to look at the internals of the Sensor HAL to identify how the interaction
     * of several clients can lead to the failing state.
     */
    public void verifySensorReconfigureWhileActive(int sensorType) throws Throwable {
        SensorCtsHelper.sleep(3, TimeUnit.SECONDS);

        final int DELAY_BEFORE_CHANGING_RATE_SEC = 2;
        final int EVENTS_FOR_VERIFICATION = 200;
        Context context = getContext();
        SensorManager sensorManager =
                (SensorManager) context.getSystemService(Context.SENSOR_SERVICE);
        assertNotNull(""SensorService is not present in the system"", sensorManager);

        Sensor sensor = sensorManager.getDefaultSensor(sensorType);
        if(sensor == null) {
            throw new SensorNotSupportedException(sensorType);
        }

        // Request for the sensor rate to be set to the slowest rate.
        ParallelSensorOperation operation = new ParallelSensorOperation();
        TestSensorEnvironment environmentSlow = new TestSensorEnvironment(
                context,
                sensor,
                shouldEmulateSensorUnderLoad(),
                true, /* isIntegrationTest */
                sensor.getMaxDelay(),
                (int)TimeUnit.SECONDS.toMicros(20));
        TestSensorOperation sensorOperationSlow = TestSensorOperation.createOperation(
                environmentSlow, 2 * DELAY_BEFORE_CHANGING_RATE_SEC, TimeUnit.SECONDS);
        operation.add(sensorOperationSlow);

        // Create a second operation that will run in parallel and request the fastest rate after
        // an initial delay. The delay is to ensure that the first operation has enabled the sensor.
        // The sensor should begin reporting at the newly requested rate. Execute a flush prior to
        // the reconfiguration to ensure that the lower frequency events are not received after the
        // reconfiguration of the sensor.
        SequentialSensorOperation sequentialSensorOperation = new SequentialSensorOperation();
        TestSensorEnvironment environmentFast = new TestSensorEnvironment(
                context,
                sensor,
                shouldEmulateSensorUnderLoad(),
                true, /* isIntegrationTest */
                sensor.getMinDelay(),
                0 /* max reporting latency */);

        // Create the flush operation with a delay to ensure the low frequency configuration was
        // handled and executed. Use the original environment since the flush operation will
        // register a new listener and reconfigure the sensor.
        TestSensorOperation flushOperation = TestSensorOperation.createFlushOperation(
                environmentSlow, DELAY_BEFORE_CHANGING_RATE_SEC, TimeUnit.SECONDS);
        sequentialSensorOperation.add(flushOperation);

        // Create the reconfiguration request and add it after the flush
        TestSensorOperation sensorOperationFast = TestSensorOperation.createOperation(
                environmentFast, EVENTS_FOR_VERIFICATION);
        sensorOperationFast.addVerification(FrequencyVerification.getDefault(environmentFast));
        sequentialSensorOperation.add(sensorOperationFast);

        // Add the sequential operation containing the flush and high frequency request to the
        // existing parallel operation that already contains the low frequency request.
        operation.add(sequentialSensorOperation);
        operation.execute(getCurrentTestNode());
        operation.getStats().log(TAG);
    }

    /**
     * Regress:
     * - b/10641388
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testAccelerometerAccelerometerStopping"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testAccelerometerAccelerometerStopping()  throws Throwable {
        verifySensorStoppingInteraction(Sensor.TYPE_ACCELEROMETER, Sensor.TYPE_ACCELEROMETER);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testAccelerometerGyroscopeStopping"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testAccelerometerGyroscopeStopping()  throws Throwable {
        verifySensorStoppingInteraction(Sensor.TYPE_ACCELEROMETER, Sensor.TYPE_GYROSCOPE);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testAccelerometerMagneticFieldStopping"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testAccelerometerMagneticFieldStopping()  throws Throwable {
        verifySensorStoppingInteraction(Sensor.TYPE_ACCELEROMETER, Sensor.TYPE_MAGNETIC_FIELD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testGyroscopeAccelerometerStopping"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testGyroscopeAccelerometerStopping()  throws Throwable {
        verifySensorStoppingInteraction(Sensor.TYPE_GYROSCOPE, Sensor.TYPE_ACCELEROMETER);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testGyroscopeGyroscopeStopping"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testGyroscopeGyroscopeStopping()  throws Throwable {
        verifySensorStoppingInteraction(Sensor.TYPE_GYROSCOPE, Sensor.TYPE_GYROSCOPE);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testGyroscopeMagneticFieldStopping"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testGyroscopeMagneticFieldStopping()  throws Throwable {
        verifySensorStoppingInteraction(Sensor.TYPE_GYROSCOPE, Sensor.TYPE_MAGNETIC_FIELD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testMagneticFieldAccelerometerStopping"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testMagneticFieldAccelerometerStopping()  throws Throwable {
        verifySensorStoppingInteraction(Sensor.TYPE_MAGNETIC_FIELD, Sensor.TYPE_ACCELEROMETER);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testMagneticFieldGyroscopeStopping"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testMagneticFieldGyroscopeStopping()  throws Throwable {
        verifySensorStoppingInteraction(Sensor.TYPE_MAGNETIC_FIELD, Sensor.TYPE_GYROSCOPE);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorIntegrationTests"	"testMagneticFieldMagneticFieldStopping"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorIntegrationTests.java"	""	"public void testMagneticFieldMagneticFieldStopping()  throws Throwable {
        verifySensorStoppingInteraction(Sensor.TYPE_MAGNETIC_FIELD, Sensor.TYPE_MAGNETIC_FIELD);
    }

    /**
     * This test verifies that starting/stopping a particular Sensor client in the System does not
     * affect other sensor clients.
     * the test is used to validate that starting/stopping operations are independent on several
     * sensor clients.
     *
     * The test verifies for each client that the a set of sampled data arrives in order. However
     * each client in the test has different set of parameters that represent different types of
     * clients in the real world.
     *
     * The test can be susceptible to issues when several clients interacting with the system
     * actually affect the operation of other clients.
     *
     * The assertion associated with the test failure provides:
     * - the thread id on which the failure occurred
     * - the sensor type and sensor handle that caused the failure
     * - the event that caused the issue
     * It is important to look at the internals of the Sensor HAL to identify how the interaction
     * of several clients can lead to the failing state.
     */
    public void verifySensorStoppingInteraction(
            int sensorTypeTestee,
            int sensorTypeTester) throws Throwable {
        SensorCtsHelper.sleep(3, TimeUnit.SECONDS);
        Context context = getContext();

        TestSensorEnvironment testerEnvironment = new TestSensorEnvironment(
                context,
                sensorTypeTester,
                shouldEmulateSensorUnderLoad(),
                SensorManager.SENSOR_DELAY_FASTEST);
        TestSensorOperation tester =
                TestSensorOperation.createOperation(testerEnvironment, 100 /* event count */);
        tester.addVerification(new EventOrderingVerification());

        TestSensorEnvironment testeeEnvironment = new TestSensorEnvironment(
                context,
                sensorTypeTestee,
                shouldEmulateSensorUnderLoad(),
                SensorManager.SENSOR_DELAY_FASTEST);
        TestSensorOperation testee =
                TestSensorOperation.createOperation(testeeEnvironment, 100 /* event count */);
        testee.addVerification(new EventOrderingVerification());

        ParallelSensorOperation operation = new ParallelSensorOperation();
        operation.add(tester, testee);
        operation.execute(getCurrentTestNode());
        operation.getStats().log(TAG);

        testee = testee.clone();
        testee.execute(getCurrentTestNode());
        testee.getStats().log(TAG);
    }

    /**
     * Private helpers.
     */
    private final Random mGenerator = new Random();

    private int generateSamplingRateInUs(int sensorType) {
        int rate;
        switch(mGenerator.nextInt(5)) {
            case 0:
                rate = SensorManager.SENSOR_DELAY_FASTEST;
                break;
            default:
                Sensor sensor = TestSensorEnvironment.getSensor(getContext(), sensorType);
                int maxSamplingRate = sensor.getMinDelay();
                rate = maxSamplingRate * mGenerator.nextInt(10);
        }
        return rate;
    }

    private int generateReportLatencyInUs() {
        long reportLatencyUs = TimeUnit.SECONDS.toMicros(mGenerator.nextInt(5) + 1);
        return (int) reportLatencyUs;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.LogicalCameraDeviceTest"	"testActivePhysicalId"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/LogicalCameraDeviceTest.java"	""	"public void testActivePhysicalId() throws Exception {
        final int AVAILABILITY_TIMEOUT_MS = 10;
        final LinkedBlockingQueue<Pair<String, String>> unavailablePhysicalCamEventQueue =
                new LinkedBlockingQueue<>();
        CameraManager.AvailabilityCallback ac = new CameraManager.AvailabilityCallback() {
             @Override
            public void onPhysicalCameraUnavailable(String cameraId, String physicalCameraId) {
                unavailablePhysicalCamEventQueue.offer(new Pair<>(cameraId, physicalCameraId));
            }
        };

        mCameraManager.registerAvailabilityCallback(ac, mHandler);
        Set<Pair<String, String>> unavailablePhysicalCameras = new HashSet<Pair<String, String>>();
        Pair<String, String> candidatePhysicalIds =
                unavailablePhysicalCamEventQueue.poll(AVAILABILITY_TIMEOUT_MS,
                java.util.concurrent.TimeUnit.MILLISECONDS);
        while (candidatePhysicalIds != null) {
            unavailablePhysicalCameras.add(candidatePhysicalIds);
            candidatePhysicalIds =
                unavailablePhysicalCamEventQueue.poll(AVAILABILITY_TIMEOUT_MS,
                java.util.concurrent.TimeUnit.MILLISECONDS);
        }
        mCameraManager.unregisterAvailabilityCallback(ac);

        for (String id : mCameraIdsUnderTest) {
            try {
                Log.i(TAG, ""Testing Camera "" + id);

                StaticMetadata staticInfo = mAllStaticInfo.get(id);
                if (!staticInfo.isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + id + "" does not support color outputs, skipping"");
                    continue;
                }

                if (!staticInfo.isLogicalMultiCamera()) {
                    Log.i(TAG, ""Camera "" + id + "" is not a logical multi-camera, skipping"");
                    continue;
                }

                if (!staticInfo.isActivePhysicalCameraIdSupported()) {
                    continue;
                }

                final Set<String> physicalIds =
                        staticInfo.getCharacteristics().getPhysicalCameraIds();
                openDevice(id);
                Size previewSz =
                        getMaxPreviewSize(mCamera.getId(), mCameraManager,
                        getPreviewSizeBound(mWindowManager, PREVIEW_SIZE_BOUND));

                String storedActiveId = null;
                for (int template : sTemplates) {
                    try {
                        CaptureRequest.Builder requestBuilder =
                                mCamera.createCaptureRequest(template);
                        SimpleCaptureCallback listener = new SimpleCaptureCallback();
                        startPreview(requestBuilder, previewSz, listener);
                        waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

                        CaptureResult result = listener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
                        String activePhysicalId = result.get(
                                CaptureResult.LOGICAL_MULTI_CAMERA_ACTIVE_PHYSICAL_ID);

                        assertNotNull(""activePhysicalId must not be null"", activePhysicalId);
                        if (storedActiveId == null) {
                            storedActiveId = activePhysicalId;
                            assertTrue(
                                  ""Camera device reported invalid activePhysicalId: "" +
                                  activePhysicalId, physicalIds.contains(activePhysicalId));
                        } else {
                            assertTrue(
                                  ""Camera device reported different activePhysicalId "" +
                                  activePhysicalId + "" vs "" + storedActiveId +
                                  "" for different capture templates"",
                                  storedActiveId.equals(activePhysicalId));
                        }
                    } catch (IllegalArgumentException e) {
                        if (template == CameraDevice.TEMPLATE_MANUAL &&
                                !staticInfo.isCapabilitySupported(CameraCharacteristics.
                                REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                            // OK
                        } else if (template == CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG &&
                                !staticInfo.isCapabilitySupported(CameraCharacteristics.
                                REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING)) {
                            // OK.
                        } else {
                            throw e; // rethrow
                        }
                    }
                }

                // Query unavailable physical cameras, and make sure the active physical id
                // isn't an unavailable physical camera.
                for (Pair<String, String> unavailPhysicalCamera: unavailablePhysicalCameras) {
                    assertFalse(unavailPhysicalCamera.first.equals(id) &&
                           unavailPhysicalCamera.second.equals(storedActiveId));
                }
            } finally {
                closeDevice();
            }
        }

    }

    /**
     * Test that for logical multi-camera of a Handheld device, the default FOV is
     * between 50 and 90 degrees for all capture templates.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.LogicalCameraDeviceTest"	"testDefaultFov"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/LogicalCameraDeviceTest.java"	""	"@CddTest(requirement=""7.5.4/C-1-1"")
    public void testDefaultFov() throws Exception {
        final double MIN_FOV = 50;
        final double MAX_FOV = 90;
        if (!isHandheldDevice()) {
            return;
        }
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.i(TAG, ""Testing Camera "" + id);

                StaticMetadata staticInfo = mAllStaticInfo.get(id);
                if (!staticInfo.isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + id + "" does not support color outputs, skipping"");
                    continue;
                }

                if (!staticInfo.isLogicalMultiCamera()) {
                    Log.i(TAG, ""Camera "" + id + "" is not a logical multi-camera, skipping"");
                    continue;
                }

                SizeF physicalSize = staticInfo.getCharacteristics().get(
                        CameraCharacteristics.SENSOR_INFO_PHYSICAL_SIZE);
                double physicalDiag = Math.sqrt(Math.pow(physicalSize.getWidth(), 2)
                        + Math.pow(physicalSize.getHeight(), 2));
                Rect activeArraySize = staticInfo.getCharacteristics().get(
                        CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE);

                openDevice(id);
                for (int template : sTemplates) {
                    try {
                        CaptureRequest.Builder requestBuilder =
                                mCamera.createCaptureRequest(template);
                        Float requestFocalLength = requestBuilder.get(
                                CaptureRequest.LENS_FOCAL_LENGTH);
                        assertNotNull(""LENS_FOCAL_LENGTH must not be null"", requestFocalLength);

                        Float requestZoomRatio = requestBuilder.get(
                                CaptureRequest.CONTROL_ZOOM_RATIO);
                        assertNotNull(""CONTROL_ZOOM_RATIO must not be null"", requestZoomRatio);
                        Rect requestCropRegion = requestBuilder.get(
                                CaptureRequest.SCALER_CROP_REGION);
                        assertNotNull(""SCALER_CROP_REGION must not be null"", requestCropRegion);
                        float totalZoomRatio = Math.min(
                                1.0f * activeArraySize.width() / requestCropRegion.width(),
                                1.0f * activeArraySize.height() / requestCropRegion.height()) *
                                requestZoomRatio;

                        double fov = 2 *
                                Math.toDegrees(Math.atan2(physicalDiag/(2 * totalZoomRatio),
                                requestFocalLength));

                        Log.v(TAG, ""Camera "" +  id + "" template "" + template +
                                ""'s default FOV is "" + fov);
                        mCollector.expectInRange(""Camera "" +  id + "" template "" + template +
                                ""'s default FOV must fall between [50, 90] degrees"",
                                fov, MIN_FOV, MAX_FOV);
                    } catch (IllegalArgumentException e) {
                        if (template == CameraDevice.TEMPLATE_MANUAL &&
                                !staticInfo.isCapabilitySupported(CameraCharacteristics.
                                REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                            // OK
                        } else if (template == CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG &&
                                !staticInfo.isCapabilitySupported(CameraCharacteristics.
                                REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING)) {
                            // OK.
                        } else {
                            throw e; // rethrow
                        }
                    }
                }
            } finally {
                closeDevice();
            }
        }
    }

    /**
     * Find a common preview size that's supported by both the logical camera and
     * two of the underlying physical cameras.
     */
    private Size findCommonPreviewSize(String cameraId,
            List<String> dualPhysicalCameraIds) throws Exception {

        Set<String> physicalCameraIds =
                mStaticInfo.getCharacteristics().getPhysicalCameraIds();
        assertTrue(""Logical camera must contain at least 2 physical camera ids"",
                physicalCameraIds.size() >= 2);

        List<Size> previewSizes = getSupportedPreviewSizes(
                cameraId, mCameraManager, PREVIEW_SIZE_BOUND);
        HashMap<String, List<Size>> physicalPreviewSizesMap = new HashMap<String, List<Size>>();
        HashMap<String, StreamConfigurationMap> physicalConfigs = new HashMap<>();
        for (String physicalCameraId : physicalCameraIds) {
            CameraCharacteristics properties =
                    mCameraManager.getCameraCharacteristics(physicalCameraId);
            assertNotNull(""Can't get camera characteristics!"", properties);
            if (!mAllStaticInfo.get(physicalCameraId).isColorOutputSupported()) {
                // No color output support, skip.
                continue;
            }
            StreamConfigurationMap configMap =
                properties.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
            physicalConfigs.put(physicalCameraId, configMap);
            physicalPreviewSizesMap.put(physicalCameraId,
                    getSupportedPreviewSizes(physicalCameraId, mCameraManager, PREVIEW_SIZE_BOUND));
        }

        // Find display size from window service.
        Context context = mActivityRule.getActivity().getApplicationContext();
        WindowManager windowManager =
                (WindowManager) context.getSystemService(Context.WINDOW_SERVICE);
        Display display = windowManager.getDefaultDisplay();

        int displayWidth = display.getWidth();
        int displayHeight = display.getHeight();

        if (displayHeight > displayWidth) {
            displayHeight = displayWidth;
            displayWidth = display.getHeight();
        }

        StreamConfigurationMap config = mStaticInfo.getCharacteristics().get(
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
        for (Size previewSize : previewSizes) {
            dualPhysicalCameraIds.clear();
            // Skip preview sizes larger than screen size
            if (previewSize.getWidth() > displayWidth ||
                    previewSize.getHeight() > displayHeight) {
                continue;
            }

            final long minFrameDuration = config.getOutputMinFrameDuration(
                   ImageFormat.YUV_420_888, previewSize);

            ArrayList<String> supportedPhysicalCameras = new ArrayList<String>();
            for (String physicalCameraId : physicalCameraIds) {
                List<Size> physicalPreviewSizes = physicalPreviewSizesMap.get(physicalCameraId);
                if (physicalPreviewSizes != null && physicalPreviewSizes.contains(previewSize)) {
                   long minDurationPhysical =
                           physicalConfigs.get(physicalCameraId).getOutputMinFrameDuration(
                           ImageFormat.YUV_420_888, previewSize);
                   if (minDurationPhysical <= minFrameDuration) {
                        dualPhysicalCameraIds.add(physicalCameraId);
                        if (dualPhysicalCameraIds.size() == 2) {
                            return previewSize;
                        }
                   }
                }
            }
        }
        return null;
    }

    /**
     * Validate that physical cameras are not cropping too much.
     *
     * This is to make sure physical processed streams have at least the same field of view as
     * the logical stream, or the maximum field of view of the physical camera, whichever is
     * smaller.
     *
     * Note that the FOV is calculated in the directio of sensor width.
     */
    private void validatePhysicalCamerasFov(TotalCaptureResult totalCaptureResult,
            List<String> physicalCameraIds) {
        Rect cropRegion = totalCaptureResult.get(CaptureResult.SCALER_CROP_REGION);
        Float focalLength = totalCaptureResult.get(CaptureResult.LENS_FOCAL_LENGTH);
        Float zoomRatio = totalCaptureResult.get(CaptureResult.CONTROL_ZOOM_RATIO);
        Rect activeArraySize = mStaticInfo.getActiveArraySizeChecked();
        SizeF sensorSize = mStaticInfo.getValueFromKeyNonNull(
                CameraCharacteristics.SENSOR_INFO_PHYSICAL_SIZE);

        // Assume subject distance >> focal length, and subject distance >> camera baseline.
        double fov = 2 * Math.toDegrees(Math.atan2(sensorSize.getWidth() * cropRegion.width() /
                (2 * zoomRatio * activeArraySize.width()),  focalLength));

        Map<String, CaptureResult> physicalResultsDual =
                    totalCaptureResult.getPhysicalCameraResults();
        for (String physicalId : physicalCameraIds) {
            StaticMetadata physicalStaticInfo = mAllStaticInfo.get(physicalId);
            CaptureResult physicalResult = physicalResultsDual.get(physicalId);
            Rect physicalCropRegion = physicalResult.get(CaptureResult.SCALER_CROP_REGION);
            Float physicalFocalLength = physicalResult.get(CaptureResult.LENS_FOCAL_LENGTH);
            Float physicalZoomRatio = physicalResult.get(CaptureResult.CONTROL_ZOOM_RATIO);
            Rect physicalActiveArraySize = physicalStaticInfo.getActiveArraySizeChecked();
            SizeF physicalSensorSize = mStaticInfo.getValueFromKeyNonNull(
                    CameraCharacteristics.SENSOR_INFO_PHYSICAL_SIZE);

            // Physical result metadata's ZOOM_RATIO is 1.0f.
            assertTrue(""Physical result metadata ZOOM_RATIO should be 1.0f, but is "" +
                    physicalZoomRatio, Math.abs(physicalZoomRatio - 1.0f) < ZOOM_RATIO_THRESHOLD);

            double physicalFov = 2 * Math.toDegrees(Math.atan2(
                    physicalSensorSize.getWidth() * physicalCropRegion.width() /
                    (2 * physicalZoomRatio * physicalActiveArraySize.width()), physicalFocalLength));

            double maxPhysicalFov = 2 * Math.toDegrees(Math.atan2(physicalSensorSize.getWidth() / 2,
                    physicalFocalLength));
            double expectedPhysicalFov = Math.min(maxPhysicalFov, fov);

            if (VERBOSE) {
                Log.v(TAG, ""Logical camera Fov: "" + fov + "", maxPhyiscalFov: "" + maxPhysicalFov +
                        "", physicalFov: "" + physicalFov);
            }
            assertTrue(""Physical stream FOV (Field of view) should be greater or equal to""
                    + "" min(logical stream FOV, max physical stream FOV). Physical FOV: ""
                    + physicalFov + "" vs min("" + fov + "", "" + maxPhysicalFov,
                    physicalFov - expectedPhysicalFov > -FOV_THRESHOLD);
        }
    }

    /**
     * Test physical camera YUV streaming within a particular logical camera.
     *
     * Use 2 YUV streams with PREVIEW or smaller size.
     */
    private void testBasicPhysicalStreamingForCamera(String logicalCameraId,
            List<String> physicalCameraIds, Size previewSize) throws Exception {
        List<OutputConfiguration> outputConfigs = new ArrayList<>();
        List<ImageReader> imageReaders = new ArrayList<>();

        // Add 1 logical YUV stream
        ImageReader logicalTarget = CameraTestUtils.makeImageReader(previewSize,
                ImageFormat.YUV_420_888, MAX_IMAGE_COUNT,
                new ImageDropperListener(), mHandler);
        imageReaders.add(logicalTarget);
        outputConfigs.add(new OutputConfiguration(logicalTarget.getSurface()));

        // Add physical YUV streams
        if (physicalCameraIds.size() != 2) {
            throw new IllegalArgumentException(""phyiscalCameraIds must contain 2 camera ids"");
        }
        List<ImageReader> physicalTargets = new ArrayList<>();
        for (String physicalCameraId : physicalCameraIds) {
            ImageReader physicalTarget = CameraTestUtils.makeImageReader(previewSize,
                    ImageFormat.YUV_420_888, MAX_IMAGE_COUNT,
                    new ImageDropperListener(), mHandler);
            OutputConfiguration config = new OutputConfiguration(physicalTarget.getSurface());
            config.setPhysicalCameraId(physicalCameraId);
            outputConfigs.add(config);
            physicalTargets.add(physicalTarget);
        }

        SessionConfigSupport sessionConfigSupport = isSessionConfigSupported(
                mCamera, mHandler, outputConfigs, /*inputConfig*/ null,
                SessionConfiguration.SESSION_REGULAR, false/*defaultSupport*/);
        assertTrue(""Session configuration query for logical camera failed with error"",
                !sessionConfigSupport.error);
        if (!sessionConfigSupport.callSupported) {
            return;
        }

        mSessionListener = new BlockingSessionCallback();
        mSessionWaiter = mSessionListener.getStateWaiter();
        mSession = configureCameraSessionWithConfig(mCamera, outputConfigs,
                mSessionListener, mHandler);
        if (!sessionConfigSupport.configSupported) {
            mSessionWaiter.waitForState(BlockingSessionCallback.SESSION_CONFIGURE_FAILED,
                    SESSION_CONFIGURE_TIMEOUT_MS);
            return;
        }

        // Stream logical YUV stream and note down the FPS
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        requestBuilder.addTarget(logicalTarget.getSurface());

        SimpleCaptureCallback simpleResultListener =
                new SimpleCaptureCallback();
        StreamConfigurationMap config = mStaticInfo.getCharacteristics().get(
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
        final long minFrameDuration = config.getOutputMinFrameDuration(
                ImageFormat.YUV_420_888, previewSize);
        if (minFrameDuration > 0) {
            Range<Integer> targetRange = getSuitableFpsRangeForDuration(logicalCameraId,
                    minFrameDuration);
            requestBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, targetRange);
        }
        mSession.setRepeatingRequest(requestBuilder.build(),
                simpleResultListener, mHandler);

        // Converge AE
        waitForAeStable(simpleResultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

        if (mStaticInfo.isAeLockSupported()) {
            // Lock AE if supported.
            requestBuilder.set(CaptureRequest.CONTROL_AE_LOCK, true);
            mSession.setRepeatingRequest(requestBuilder.build(), simpleResultListener,
                    mHandler);
            waitForResultValue(simpleResultListener, CaptureResult.CONTROL_AE_STATE,
                    CaptureResult.CONTROL_AE_STATE_LOCKED, NUM_RESULTS_WAIT_TIMEOUT);
        }

        // Verify results
        CaptureResultTest.validateCaptureResult(mCollector, simpleResultListener,
                mStaticInfo, mAllStaticInfo, null/*requestedPhysicalIds*/,
                requestBuilder, NUM_FRAMES_CHECKED);

        // Collect timestamps for one logical stream only.
        long prevTimestamp = -1;
        long[] logicalTimestamps = new long[NUM_FRAMES_CHECKED];
        for (int i = 0; i < NUM_FRAMES_CHECKED; i++) {
            TotalCaptureResult totalCaptureResult =
                    simpleResultListener.getTotalCaptureResult(
                    CameraTestUtils.CAPTURE_RESULT_TIMEOUT_MS);
            logicalTimestamps[i] = totalCaptureResult.get(CaptureResult.SENSOR_TIMESTAMP);
        }

        double logicalAvgDurationMs = (logicalTimestamps[NUM_FRAMES_CHECKED-1] -
                logicalTimestamps[0])/(NS_PER_MS*(NUM_FRAMES_CHECKED-1));

        // Request one logical stream and one physical stream
        simpleResultListener = new SimpleCaptureCallback();
        requestBuilder.addTarget(physicalTargets.get(1).getSurface());
        mSession.setRepeatingRequest(requestBuilder.build(), simpleResultListener,
                mHandler);

        // Verify results for physical streams request.
        CaptureResultTest.validateCaptureResult(mCollector, simpleResultListener,
                mStaticInfo, mAllStaticInfo, physicalCameraIds.subList(1, 2), requestBuilder,
                NUM_FRAMES_CHECKED);


        // Start requesting on both logical and physical streams
        SimpleCaptureCallback simpleResultListenerDual =
                new SimpleCaptureCallback();
        for (ImageReader physicalTarget : physicalTargets) {
            requestBuilder.addTarget(physicalTarget.getSurface());
        }
        mSession.setRepeatingRequest(requestBuilder.build(), simpleResultListenerDual,
                mHandler);

        // Verify results for physical streams request.
        CaptureResultTest.validateCaptureResult(mCollector, simpleResultListenerDual,
                mStaticInfo, mAllStaticInfo, physicalCameraIds, requestBuilder,
                NUM_FRAMES_CHECKED);

        // Acquire the timestamps of the physical camera.
        long[] logicalTimestamps2 = new long[NUM_FRAMES_CHECKED];
        long [][] physicalTimestamps = new long[physicalTargets.size()][];
        for (int i = 0; i < physicalTargets.size(); i++) {
            physicalTimestamps[i] = new long[NUM_FRAMES_CHECKED];
        }
        for (int i = 0; i < NUM_FRAMES_CHECKED; i++) {
            TotalCaptureResult totalCaptureResultDual =
                    simpleResultListenerDual.getTotalCaptureResult(
                    CameraTestUtils.CAPTURE_RESULT_TIMEOUT_MS);
            logicalTimestamps2[i] = totalCaptureResultDual.get(CaptureResult.SENSOR_TIMESTAMP);

            int index = 0;
            Map<String, CaptureResult> physicalResultsDual =
                    totalCaptureResultDual.getPhysicalCameraResults();
            for (String physicalId : physicalCameraIds) {
                assertTrue(""Physical capture result camera ID must match the right camera"",
                        physicalResultsDual.get(physicalId).getCameraId().equals(physicalId));
                if (physicalResultsDual.containsKey(physicalId)) {
                    physicalTimestamps[index][i] = physicalResultsDual.get(physicalId).get(
                        CaptureResult.SENSOR_TIMESTAMP);
                } else {
                    physicalTimestamps[index][i] = -1;
                }
                index++;
            }
        }

        // Check both logical and physical streams' crop region, and make sure their FOVs
        // are similar.
        TotalCaptureResult totalCaptureResult =
                simpleResultListenerDual.getTotalCaptureResult(
                CameraTestUtils.CAPTURE_RESULT_TIMEOUT_MS);
        validatePhysicalCamerasFov(totalCaptureResult, physicalCameraIds);

        // Check timestamp monolithity for individual camera and across cameras
        for (int i = 0; i < NUM_FRAMES_CHECKED-1; i++) {
            assertTrue(""Logical camera timestamp must monolithically increase"",
                    logicalTimestamps2[i] < logicalTimestamps2[i+1]);
        }
        for (int i = 0; i < physicalCameraIds.size(); i++) {
            for (int j = 0 ; j < NUM_FRAMES_CHECKED-1; j++) {
                if (physicalTimestamps[i][j] != -1 && physicalTimestamps[i][j+1] != -1) {
                    assertTrue(""Physical camera timestamp must monolithically increase"",
                            physicalTimestamps[i][j] < physicalTimestamps[i][j+1]);
                }
                if (j > 0 && physicalTimestamps[i][j] != -1) {
                    assertTrue(""Physical camera's timestamp N must be greater than logical "" +
                            ""camera's timestamp N-1"",
                            physicalTimestamps[i][j] > logicalTimestamps[j-1]);
                }
                if (physicalTimestamps[i][j] != -1) {
                    assertTrue(""Physical camera's timestamp N must be less than logical camera's "" +
                            ""timestamp N+1"", physicalTimestamps[i][j] > logicalTimestamps[j+1]);
                }
            }
        }

        double logicalAvgDurationMs2 = (logicalTimestamps2[NUM_FRAMES_CHECKED-1] -
                logicalTimestamps2[0])/(NS_PER_MS*(NUM_FRAMES_CHECKED-1));
        // Check CALIBRATED synchronization between physical cameras
        Integer syncType = mStaticInfo.getCharacteristics().get(
                CameraCharacteristics.LOGICAL_MULTI_CAMERA_SENSOR_SYNC_TYPE);
        double fpsRatio = (logicalAvgDurationMs2 - logicalAvgDurationMs)/logicalAvgDurationMs;
        if (syncType == CameraCharacteristics.LOGICAL_MULTI_CAMERA_SENSOR_SYNC_TYPE_CALIBRATED) {
            // Check framerate doesn't slow down with physical streams
            mCollector.expectTrue(
                    ""The average frame duration with concurrent physical streams is"" +
                    logicalAvgDurationMs2 + "" ms vs "" + logicalAvgDurationMs +
                    "" ms for logical streams only"", fpsRatio <= FRAME_DURATION_THRESHOLD);

            long maxTimestampDelta = 0;
            for (int i = 0; i < NUM_FRAMES_CHECKED; i++) {
                long delta = Math.abs(physicalTimestamps[0][i] - physicalTimestamps[1][i]);
                if (delta > maxTimestampDelta) {
                    maxTimestampDelta = delta;
                }
            }

            Log.i(TAG, ""Maximum difference between physical camera timestamps: ""
                    + maxTimestampDelta);

            // The maximum timestamp difference should not be larger than the threshold.
            mCollector.expectTrue(
                    ""The maximum timestamp deltas between the physical cameras ""
                    + maxTimestampDelta + "" is larger than "" + MAX_TIMESTAMP_DIFFERENCE_THRESHOLD,
                    maxTimestampDelta <= MAX_TIMESTAMP_DIFFERENCE_THRESHOLD);
        } else {
            // Do not enforce fps check for APPROXIMATE synced device.
            if (fpsRatio > FRAME_DURATION_THRESHOLD) {
                Log.w(TAG, ""The average frame duration with concurrent physical streams is"" +
                        logicalAvgDurationMs2 + "" ms vs "" + logicalAvgDurationMs +
                        "" ms for logical streams only"");
            }
        }

        if (VERBOSE) {
            while (simpleResultListenerDual.hasMoreFailures()) {
                ArrayList<CaptureFailure> failures =
                    simpleResultListenerDual.getCaptureFailures(/*maxNumFailures*/ 1);
                for (CaptureFailure failure : failures) {
                    String physicalCameraId = failure.getPhysicalCameraId();
                    if (physicalCameraId != null) {
                        Log.v(TAG, ""Capture result failure for physical camera id: "" +
                                physicalCameraId);
                    }
                }
            }
        }

        // Stop preview
        if (mSession != null) {
            mSession.close();
        }
    }

    /**
     * The CDD defines a handheld device as one that has a battery and a screen size between
     * 2.5 and 8 inches.
     */
    private boolean isHandheldDevice() throws Exception {
        double screenInches = getScreenSizeInInches();
        return deviceHasBattery() && screenInches >= 2.5 && screenInches <= 8.0;
    }

    private boolean deviceHasBattery() {
        final Intent batteryInfo = mContext.registerReceiver(null,
                new IntentFilter(Intent.ACTION_BATTERY_CHANGED));
        return batteryInfo != null && batteryInfo.getBooleanExtra(BatteryManager.EXTRA_PRESENT, true);
    }

    private double getScreenSizeInInches() {
        DisplayMetrics dm = new DisplayMetrics();
        mWindowManager.getDefaultDisplay().getMetrics(dm);
        double widthInInchesSquared = Math.pow(dm.widthPixels/dm.xdpi,2);
        double heightInInchesSquared = Math.pow(dm.heightPixels/dm.ydpi,2);
        return Math.sqrt(widthInInchesSquared + heightInInchesSquared);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.location.cts.none.NoLocationPermissionTest"	"testAddProximityAlert"	"CtsLocationNoneTestCases"	"/home/gpoor/cts-12-source/cts/tests/location/location_none/src/android/location/cts/none/NoLocationPermissionTest.java"	""	"public void testAddProximityAlert() {
        try (ProximityPendingIntentCapture capture = new ProximityPendingIntentCapture(mContext)) {
            mLocationManager.addProximityAlert(0, 0, 100, -1, capture.getPendingIntent());
            fail(""Should throw SecurityException"");
        } catch (SecurityException e) {
            // expected
        }
    }"	""	""	"proximity"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Dialogs.Lap2Dialog"	"OnClickListener"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Dialogs/Lap2Dialog.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Dialogs;

import com.android.cts.verifier.R;

import android.app.Activity;
import android.app.Dialog;
import android.content.DialogInterface;
import android.os.Bundle;
import android.app.DialogFragment;
import android.app.AlertDialog;

/**
 * Dialog for instructions on what to to on lap 2
 */
public class Lap2Dialog extends DialogFragment {
    Lap2DialogListener mListener;

    public static Lap2Dialog newInstance() {
        Lap2Dialog dialog = new Lap2Dialog();
        return dialog;
    }

    public interface Lap2DialogListener {
        void onLap2Start();
    }

    @Override
    public Dialog onCreateDialog(Bundle savedInstanceState) {
        // Use the Builder class for convenient dialog construction.
        AlertDialog.Builder builder = new AlertDialog.Builder(getActivity());

        // Inflate and set the layout for the dialog.
        // Pass null as the parent view because its going in the dialog layout.
        builder.setTitle(R.string.test1_pass2)
                .setMessage(R.string.lap2_instructions)
                .setNegativeButton(R.string.got_it, new DialogInterface.OnClickListener() {
                    public void onClick(DialogInterface dialog, int which) {
                        mListener.onLap2Start();
                    }
                });

        // Create the AlertDialog object and return it.
        return builder.create();
    }

    @Override
    public void onAttach(Activity activity) {
        super.onAttach(activity);
        // Verify that the host fragment implements the callback interface.
        try {
            mListener = (Lap2DialogListener) getTargetFragment();
            mListener.onLap2Start();
        } catch (ClassCastException e) {
            // The activity doesn't implement the interface, throw exception.
            throw new ClassCastException(activity.toString()
                    + "" must implement Lap2DialogListener"");
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.StepSensorPermissionTestActivity"	"StepSensorPermissionTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/StepSensorPermissionTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;

import android.Manifest;
import com.android.cts.verifier.R;
import android.content.Context;
import android.content.Intent;
import android.content.pm.PackageManager;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.net.Uri;
import android.provider.Settings;

import java.util.ArrayList;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;

/**
 * Test cases to verify step sensor permissions
 */
public class StepSensorPermissionTestActivity extends SensorCtsVerifierTestActivity
        implements SensorEventListener {
    private static final int STEP_DETECT_DELAY_SECONDS = 30;
    private static final int STEP_COUNT_DELAY_SECONDS = 30;
    // Additional amount of time to give for receiving either a step detect or
    // count event in case the user hasn't started walking at the time the test
    // starts.
    private static final int ADDITIONAL_EVENT_DELAY_SECONDS = 2;

    private SensorManager mSensorManager;

    private boolean mHasAccelFeature = false;
    private boolean mHasStepCounterFeature = false;
    private boolean mHasStepDetectorFeature = false;
    private CountDownLatch mEventReceivedLatch = null;
    private Sensor mSensorUnderTest = null;
    private AccelRecorder mAccelRecorder = null;

    public StepSensorPermissionTestActivity() {
        super(StepSensorPermissionTestActivity.class);
    }

    @Override
    protected void activitySetUp() {
        mSensorManager = (SensorManager) getApplicationContext()
                .getSystemService(Context.SENSOR_SERVICE);

        mHasAccelFeature = getApplicationContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_SENSOR_ACCELEROMETER);
        mHasStepCounterFeature = getApplicationContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_SENSOR_STEP_COUNTER);
        mHasStepDetectorFeature = getApplicationContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_SENSOR_STEP_DETECTOR);

        mAccelRecorder = new AccelRecorder(mSensorManager);
    }

    @Override
    protected void activityCleanUp() {
        mSensorManager.unregisterListener(this);
        mAccelRecorder.stop();

        // Notify the user that the test has concluded. This will play in both the pass
        // and fail case
        try {
            playSound();
        } catch (InterruptedException e) {
            // Ignored
        }
    }

    /**
     * Test cases.
     */
    @SuppressWarnings(""unused"")
    public String testStepEvents() throws Throwable {
        if (mHasStepCounterFeature || mHasStepDetectorFeature) {
            // Verify that sensors cannot be registered when the permission is not granted
            runTest(false /* permissionGranted */);

            // Signal to the user that the first part of the test is over
            try {
                playSound();
            } catch (InterruptedException e) {
                // Ignored
            }

            // Verify that the sensors can be registered when the permission is not granted
            runTest(true /* permissionGranted */);
        }

        return ""Pass"";
    }

    private void runTest(boolean permissionGranted) throws InterruptedException {
        if (hasPermission(Manifest.permission.ACTIVITY_RECOGNITION) != permissionGranted) {
            requestChangePermission(permissionGranted);
        }

        waitForUser(R.string.snsr_step_permission_walk);
        checkPermission(Manifest.permission.ACTIVITY_RECOGNITION, permissionGranted);

        if (mHasStepDetectorFeature) {
            checkSensor(Sensor.TYPE_STEP_DETECTOR, permissionGranted, STEP_DETECT_DELAY_SECONDS);
        }

        if (mHasStepCounterFeature) {
            checkSensor(Sensor.TYPE_STEP_COUNTER, permissionGranted, STEP_COUNT_DELAY_SECONDS);
        }
    }

    private void requestChangePermission(boolean enable) throws InterruptedException {
        SensorTestLogger logger = getTestLogger();
        if (enable) {
            logger.logInstructions(R.string.snsr_step_permission_enable);
        } else {
            logger.logInstructions(R.string.snsr_step_permission_disable);
        }
        waitForUserToContinue();
        Intent intent = new Intent();
        intent.setAction(Settings.ACTION_APPLICATION_DETAILS_SETTINGS);
        Uri uri = Uri.fromParts(""package"", getPackageName(), null);
        intent.setData(uri);
        startActivity(intent);
    }

    private boolean hasPermission(String permission) {
        return getApplicationContext().checkSelfPermission(permission) ==
                PackageManager.PERMISSION_GRANTED;
    }

    private void checkPermission(String permission, boolean expected) {
        if (expected && !hasPermission(permission)) {
            throw new AssertionError(String.format(""Should not have '%s' permission"", permission));
        } else if (!expected && hasPermission(permission)) {
            throw new AssertionError(String.format(""Should have '%s' permission"", permission));
        }
    }

    private void checkSensor(int sensorType, boolean expected, int eventDelaySeconds)
            throws InterruptedException {
        if (mHasAccelFeature && !expected) {
            // Record accel when no events are expected to ensure that the device is moving during
            // the test.
            mAccelRecorder.start();
        }

        mEventReceivedLatch = new CountDownLatch(1);
        Sensor sensor = mSensorManager.getDefaultSensor(sensorType);
        mSensorUnderTest = sensor;

        String msg = String.format(""Should %sbe able to register for '%s' events"",
                expected ? """" : ""not "", sensor.getName());
        assertTrue(msg, mSensorManager.registerListener(this, sensor, 0, 0) == expected);

        boolean eventReceived = mEventReceivedLatch.await(
                eventDelaySeconds + ADDITIONAL_EVENT_DELAY_SECONDS, TimeUnit.SECONDS);

        // Ensure that events are only received when the application has permission
        if (expected) {
            assertTrue(""Failed to receive event for "" + sensor.getName(), eventReceived);
        } else {
            assertFalse(""Should not have received event for "" + sensor.getName(), eventReceived);

            if (mHasAccelFeature) {
                // Verify that the device was moving during the test
                mAccelRecorder.stop();
                assertTrue(""Walking not detected"", mAccelRecorder.variance() > 1.0f);
            }
        }
    }

    @Override
    public void onSensorChanged(SensorEvent sensorEvent) {
        if (sensorEvent.sensor == mSensorUnderTest) {
            mEventReceivedLatch.countDown();
        }
    }

    @Override
    public void onAccuracyChanged(Sensor sensor, int i) {
    }

    class AccelRecorder implements SensorEventListener {

        private SensorManager mSensorManager;
        private Sensor mAccel;
        private ArrayList<Float> mMagnitudes = new ArrayList<>();

        public AccelRecorder(SensorManager sensorManager) {
            mSensorManager = sensorManager;
            mAccel = mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER);
        }

        public void start() {
            mMagnitudes.clear();
            mSensorManager.registerListener(
                    this, mAccel, (int)TimeUnit.MILLISECONDS.toMicros(20), 0);
        }

        public void stop() {
            mSensorManager.unregisterListener(this);
        }

        public float variance() {
            if (mMagnitudes.size() <= 1) {
                return 0.0f;
            }

            float mean = 0;
            for (float val : mMagnitudes) {
                mean += val;
            }
            mean /= mMagnitudes.size();

            float var = 0;
            for (float val : mMagnitudes) {
                var += (val - mean) * (val - mean);
            }
            return var / (mMagnitudes.size() - 1);
        }

        @Override
        public void onSensorChanged(SensorEvent sensorEvent) {
            if (sensorEvent.sensor == mAccel) {
                float magnitude = sensorEvent.values[0] * sensorEvent.values[0] +
                        sensorEvent.values[1] * sensorEvent.values[1] +
                        sensorEvent.values[2] * sensorEvent.values[2];
                mMagnitudes.add((float)Math.sqrt(magnitude));
            }
        }

        @Override
        public void onAccuracyChanged(Sensor sensor, int i) {

        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.camera.its.ItsService"	"doCheckSensorExistence"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/camera/its/ItsService.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.camera.its;

import android.app.Notification;
import android.app.NotificationChannel;
import android.app.NotificationManager;
import android.app.Service;
import android.content.Context;
import android.content.Intent;
import android.content.pm.ServiceInfo;
import android.graphics.ImageFormat;
import android.graphics.Rect;
import android.hardware.SensorPrivacyManager;
import android.hardware.camera2.CameraCaptureSession;
import android.hardware.camera2.CameraAccessException;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.CameraDevice;
import android.hardware.camera2.CameraManager;
import android.hardware.camera2.CaptureFailure;
import android.hardware.camera2.CaptureRequest;
import android.hardware.camera2.CaptureResult;
import android.hardware.camera2.DngCreator;
import android.hardware.camera2.TotalCaptureResult;
import android.hardware.camera2.cts.PerformanceTest;
import android.hardware.camera2.params.InputConfiguration;
import android.hardware.camera2.params.MeteringRectangle;
import android.hardware.camera2.params.OutputConfiguration;
import android.hardware.camera2.params.SessionConfiguration;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.media.AudioAttributes;
import android.media.Image;
import android.media.ImageReader;
import android.media.ImageWriter;
import android.media.Image.Plane;
import android.net.Uri;
import android.os.Build;
import android.os.Bundle;
import android.os.ConditionVariable;
import android.os.Handler;
import android.os.HandlerThread;
import android.os.IBinder;
import android.os.Message;
import android.os.SystemClock;
import android.os.Vibrator;
import android.util.Log;
import android.util.Rational;
import android.util.Size;
import android.util.SparseArray;
import android.view.Surface;

import androidx.test.InstrumentationRegistry;

import com.android.ex.camera2.blocking.BlockingCameraManager;
import com.android.ex.camera2.blocking.BlockingCameraManager.BlockingOpenException;
import com.android.ex.camera2.blocking.BlockingStateCallback;
import com.android.ex.camera2.blocking.BlockingSessionCallback;

import com.android.compatibility.common.util.ReportLog.Metric;
import com.android.cts.verifier.camera.its.StatsImage;
import com.android.cts.verifier.camera.performance.CameraTestInstrumentation;
import com.android.cts.verifier.camera.performance.CameraTestInstrumentation.MetricListener;
import com.android.cts.verifier.R;

import org.json.JSONArray;
import org.json.JSONObject;
import org.junit.runner.JUnitCore;
import org.junit.runner.Request;
import org.junit.runner.Result;

import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.OutputStreamWriter;
import java.io.PrintWriter;
import java.math.BigInteger;
import java.net.ServerSocket;
import java.net.Socket;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.nio.FloatBuffer;
import java.nio.charset.Charset;
import java.security.MessageDigest;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Locale;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.Executor;
import java.util.concurrent.LinkedBlockingDeque;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

public class ItsService extends Service implements SensorEventListener {
    public static final String TAG = ItsService.class.getSimpleName();

    // Version number to keep host/server communication in sync
    // This string must be in sync with python side device.py
    // Updated when interface between script and ItsService is changed
    private final String ITS_SERVICE_VERSION = ""1.0"";

    private final int SERVICE_NOTIFICATION_ID = 37; // random int that is unique within app
    private NotificationChannel mChannel;

    // Timeouts, in seconds.
    private static final int TIMEOUT_CALLBACK = 20;
    private static final int TIMEOUT_3A = 10;

    // Time given for background requests to warm up pipeline
    private static final long PIPELINE_WARMUP_TIME_MS = 2000;

    // State transition timeouts, in ms.
    private static final long TIMEOUT_IDLE_MS = 2000;
    private static final long TIMEOUT_STATE_MS = 500;
    private static final long TIMEOUT_SESSION_CLOSE = 3000;

    // Timeout to wait for a capture result after the capture buffer has arrived, in ms.
    private static final long TIMEOUT_CAP_RES = 2000;

    private static final int MAX_CONCURRENT_READER_BUFFERS = 10;

    // Supports at most RAW+YUV+JPEG, one surface each, plus optional background stream
    private static final int MAX_NUM_OUTPUT_SURFACES = 4;

    // Performance class R version number
    private static final int PERFORMANCE_CLASS_R = Build.VERSION_CODES.R;
    // Performance class S version number
    private static final int PERFORMANCE_CLASS_S = Build.VERSION_CODES.R + 1;

    public static final int SERVERPORT = 6000;

    public static final String REGION_KEY = ""regions"";
    public static final String REGION_AE_KEY = ""ae"";
    public static final String REGION_AWB_KEY = ""awb"";
    public static final String REGION_AF_KEY = ""af"";
    public static final String LOCK_AE_KEY = ""aeLock"";
    public static final String LOCK_AWB_KEY = ""awbLock"";
    public static final String TRIGGER_KEY = ""triggers"";
    public static final String PHYSICAL_ID_KEY = ""physicalId"";
    public static final String TRIGGER_AE_KEY = ""ae"";
    public static final String TRIGGER_AF_KEY = ""af"";
    public static final String VIB_PATTERN_KEY = ""pattern"";
    public static final String EVCOMP_KEY = ""evComp"";
    public static final String AUDIO_RESTRICTION_MODE_KEY = ""mode"";

    private CameraManager mCameraManager = null;
    private HandlerThread mCameraThread = null;
    private Handler mCameraHandler = null;
    private BlockingCameraManager mBlockingCameraManager = null;
    private BlockingStateCallback mCameraListener = null;
    private CameraDevice mCamera = null;
    private CameraCaptureSession mSession = null;
    private ImageReader[] mOutputImageReaders = null;
    private SparseArray<String> mPhysicalStreamMap = new SparseArray<String>();
    private ImageReader mInputImageReader = null;
    private CameraCharacteristics mCameraCharacteristics = null;
    private HashMap<String, CameraCharacteristics> mPhysicalCameraChars =
            new HashMap<String, CameraCharacteristics>();
    private ItsUtils.ItsCameraIdList mItsCameraIdList = null;

    private Vibrator mVibrator = null;

    private HandlerThread mSaveThreads[] = new HandlerThread[MAX_NUM_OUTPUT_SURFACES];
    private Handler mSaveHandlers[] = new Handler[MAX_NUM_OUTPUT_SURFACES];
    private HandlerThread mResultThread = null;
    private Handler mResultHandler = null;

    private volatile boolean mThreadExitFlag = false;

    private volatile ServerSocket mSocket = null;
    private volatile SocketRunnable mSocketRunnableObj = null;
    private Semaphore mSocketQueueQuota = null;
    private int mMemoryQuota = -1;
    private LinkedList<Integer> mInflightImageSizes = new LinkedList<>();
    private volatile BlockingQueue<ByteBuffer> mSocketWriteQueue =
            new LinkedBlockingDeque<ByteBuffer>();
    private final Object mSocketWriteEnqueueLock = new Object();
    private final Object mSocketWriteDrainLock = new Object();

    private volatile BlockingQueue<Object[]> mSerializerQueue =
            new LinkedBlockingDeque<Object[]>();

    private AtomicInteger mCountCallbacksRemaining = new AtomicInteger();
    private AtomicInteger mCountRawOrDng = new AtomicInteger();
    private AtomicInteger mCountRaw10 = new AtomicInteger();
    private AtomicInteger mCountRaw12 = new AtomicInteger();
    private AtomicInteger mCountJpg = new AtomicInteger();
    private AtomicInteger mCountYuv = new AtomicInteger();
    private AtomicInteger mCountCapRes = new AtomicInteger();
    private boolean mCaptureRawIsDng;
    private boolean mCaptureRawIsStats;
    private int mCaptureStatsGridWidth;
    private int mCaptureStatsGridHeight;
    private CaptureResult mCaptureResults[] = null;

    private volatile ConditionVariable mInterlock3A = new ConditionVariable(true);

    final Object m3AStateLock = new Object();
    private volatile boolean mConvergedAE = false;
    private volatile boolean mConvergedAF = false;
    private volatile boolean mConvergedAWB = false;
    private volatile boolean mLockedAE = false;
    private volatile boolean mLockedAWB = false;
    private volatile boolean mNeedsLockedAE = false;
    private volatile boolean mNeedsLockedAWB = false;

    class MySensorEvent {
        public Sensor sensor;
        public int accuracy;
        public long timestamp;
        public float values[];
    }

    // For capturing motion sensor traces.
    private SensorManager mSensorManager = null;
    private Sensor mAccelSensor = null;
    private Sensor mMagSensor = null;
    private Sensor mGyroSensor = null;
    private volatile LinkedList<MySensorEvent> mEvents = null;
    private volatile Object mEventLock = new Object();
    private volatile boolean mEventsEnabled = false;
    private HandlerThread mSensorThread = null;
    private Handler mSensorHandler = null;

    private SensorPrivacyManager mSensorPrivacyManager;

    // Camera test instrumentation
    private CameraTestInstrumentation mCameraInstrumentation;
    // Camera PerformanceTest metric
    private final ArrayList<Metric> mResults = new ArrayList<Metric>();

    private static final int SERIALIZER_SURFACES_ID = 2;
    private static final int SERIALIZER_PHYSICAL_METADATA_ID = 3;

    public interface CaptureCallback {
        void onCaptureAvailable(Image capture, String physicalCameraId);
    }

    public abstract class CaptureResultListener extends CameraCaptureSession.CaptureCallback {}

    @Override
    public IBinder onBind(Intent intent) {
        return null;
    }

    @Override
    public void onCreate() {
        try {
            mThreadExitFlag = false;

            // Get handle to camera manager.
            mCameraManager = (CameraManager) this.getSystemService(Context.CAMERA_SERVICE);
            if (mCameraManager == null) {
                throw new ItsException(""Failed to connect to camera manager"");
            }
            mBlockingCameraManager = new BlockingCameraManager(mCameraManager);
            mCameraListener = new BlockingStateCallback();

            // Register for motion events.
            mEvents = new LinkedList<MySensorEvent>();
            mSensorManager = (SensorManager)getSystemService(Context.SENSOR_SERVICE);
            mAccelSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER);
            mMagSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_MAGNETIC_FIELD);
            mGyroSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_GYROSCOPE);
            mSensorThread = new HandlerThread(""SensorThread"");
            mSensorThread.start();
            mSensorHandler = new Handler(mSensorThread.getLooper());
            mSensorManager.registerListener(this, mAccelSensor,
                    /*100hz*/ 10000, mSensorHandler);
            mSensorManager.registerListener(this, mMagSensor,
                    SensorManager.SENSOR_DELAY_NORMAL, mSensorHandler);
            mSensorManager.registerListener(this, mGyroSensor,
                    /*200hz*/5000, mSensorHandler);

            // Get a handle to the system vibrator.
            mVibrator = (Vibrator)getSystemService(Context.VIBRATOR_SERVICE);

            // Create threads to receive images and save them.
            for (int i = 0; i < MAX_NUM_OUTPUT_SURFACES; i++) {
                mSaveThreads[i] = new HandlerThread(""SaveThread"" + i);
                mSaveThreads[i].start();
                mSaveHandlers[i] = new Handler(mSaveThreads[i].getLooper());
            }

            // Create a thread to handle object serialization.
            (new Thread(new SerializerRunnable())).start();;

            // Create a thread to receive capture results and process them.
            mResultThread = new HandlerThread(""ResultThread"");
            mResultThread.start();
            mResultHandler = new Handler(mResultThread.getLooper());

            // Create a thread for the camera device.
            mCameraThread = new HandlerThread(""ItsCameraThread"");
            mCameraThread.start();
            mCameraHandler = new Handler(mCameraThread.getLooper());

            // Create a thread to process commands, listening on a TCP socket.
            mSocketRunnableObj = new SocketRunnable();
            (new Thread(mSocketRunnableObj)).start();
        } catch (ItsException e) {
            Logt.e(TAG, ""Service failed to start: "", e);
        }

        NotificationManager notificationManager =
                (NotificationManager) getSystemService(Context.NOTIFICATION_SERVICE);
        mChannel = new NotificationChannel(
                ""ItsServiceChannel"", ""ItsService"", NotificationManager.IMPORTANCE_LOW);
        // Configure the notification channel.
        mChannel.setDescription(""ItsServiceChannel"");
        mChannel.enableVibration(false);
        notificationManager.createNotificationChannel(mChannel);

        mSensorPrivacyManager = getSystemService(SensorPrivacyManager.class);
    }

    @Override
    public int onStartCommand(Intent intent, int flags, int startId) {
        try {
            // Just log a message indicating that the service is running and is able to accept
            // socket connections.
            while (!mThreadExitFlag && mSocket==null) {
                Thread.sleep(1);
            }
            if (!mThreadExitFlag){
                Logt.i(TAG, ""ItsService ready"");
            } else {
                Logt.e(TAG, ""Starting ItsService in bad state"");
            }

            Notification notification = new Notification.Builder(this, mChannel.getId())
                    .setContentTitle(""CameraITS Service"")
                    .setContentText(""CameraITS Service is running"")
                    .setSmallIcon(R.drawable.icon)
                    .setOngoing(true).build();
            startForeground(SERVICE_NOTIFICATION_ID, notification,
                    ServiceInfo.FOREGROUND_SERVICE_TYPE_CAMERA);
        } catch (java.lang.InterruptedException e) {
            Logt.e(TAG, ""Error starting ItsService (interrupted)"", e);
        }
        return START_STICKY;
    }

    @Override
    public void onDestroy() {
        mThreadExitFlag = true;
        for (int i = 0; i < MAX_NUM_OUTPUT_SURFACES; i++) {
            if (mSaveThreads[i] != null) {
                mSaveThreads[i].quit();
                mSaveThreads[i] = null;
            }
        }
        if (mSensorThread != null) {
            mSensorThread.quitSafely();
            mSensorThread = null;
        }
        if (mResultThread != null) {
            mResultThread.quitSafely();
            mResultThread = null;
        }
        if (mCameraThread != null) {
            mCameraThread.quitSafely();
            mCameraThread = null;
        }
    }

    public void openCameraDevice(String cameraId) throws ItsException {
        Logt.i(TAG, String.format(""Opening camera %s"", cameraId));

        try {
            if (mMemoryQuota == -1) {
                // Initialize memory quota on this device
                if (mItsCameraIdList == null) {
                    mItsCameraIdList = ItsUtils.getItsCompatibleCameraIds(mCameraManager);
                }
                if (mItsCameraIdList.mCameraIds.size() == 0) {
                    throw new ItsException(""No camera devices"");
                }
                for (String camId : mItsCameraIdList.mCameraIds) {
                    CameraCharacteristics chars =  mCameraManager.getCameraCharacteristics(camId);
                    Size maxYuvSize = ItsUtils.getMaxOutputSize(
                            chars, ImageFormat.YUV_420_888);
                    // 4 bytes per pixel for RGBA8888 Bitmap and at least 3 Bitmaps per CDD
                    int quota = maxYuvSize.getWidth() * maxYuvSize.getHeight() * 4 * 3;
                    if (quota > mMemoryQuota) {
                        mMemoryQuota = quota;
                    }
                }
            }
        } catch (CameraAccessException e) {
            throw new ItsException(""Failed to get device ID list"", e);
        }

        try {
            mCamera = mBlockingCameraManager.openCamera(cameraId, mCameraListener, mCameraHandler);
            mCameraCharacteristics = mCameraManager.getCameraCharacteristics(cameraId);

            boolean isLogicalCamera = hasCapability(
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_LOGICAL_MULTI_CAMERA);
            if (isLogicalCamera) {
                Set<String> physicalCameraIds = mCameraCharacteristics.getPhysicalCameraIds();
                for (String id : physicalCameraIds) {
                    mPhysicalCameraChars.put(id, mCameraManager.getCameraCharacteristics(id));
                }
            }
            mSocketQueueQuota = new Semaphore(mMemoryQuota, true);
        } catch (CameraAccessException e) {
            throw new ItsException(""Failed to open camera"", e);
        } catch (BlockingOpenException e) {
            throw new ItsException(""Failed to open camera (after blocking)"", e);
        }
        mSocketRunnableObj.sendResponse(""cameraOpened"", """");
    }

    public void closeCameraDevice() throws ItsException {
        try {
            if (mCamera != null) {
                Logt.i(TAG, ""Closing camera"");
                mCamera.close();
                mCamera = null;
            }
        } catch (Exception e) {
            throw new ItsException(""Failed to close device"");
        }
        mSocketRunnableObj.sendResponse(""cameraClosed"", """");
    }

    class SerializerRunnable implements Runnable {
        // Use a separate thread to perform JSON serialization (since this can be slow due to
        // the reflection).
        @Override
        public void run() {
            Logt.i(TAG, ""Serializer thread starting"");
            while (! mThreadExitFlag) {
                try {
                    Object objs[] = mSerializerQueue.take();
                    JSONObject jsonObj = new JSONObject();
                    String tag = null;
                    for (int i = 0; i < objs.length; i++) {
                        Object obj = objs[i];
                        if (obj instanceof String) {
                            if (tag != null) {
                                throw new ItsException(""Multiple tags for socket response"");
                            }
                            tag = (String)obj;
                        } else if (obj instanceof CameraCharacteristics) {
                            jsonObj.put(""cameraProperties"", ItsSerializer.serialize(
                                    (CameraCharacteristics)obj));
                        } else if (obj instanceof CaptureRequest) {
                            jsonObj.put(""captureRequest"", ItsSerializer.serialize(
                                    (CaptureRequest)obj));
                        } else if (obj instanceof CaptureResult) {
                            jsonObj.put(""captureResult"", ItsSerializer.serialize(
                                    (CaptureResult)obj));
                        } else if (obj instanceof JSONArray) {
                            if (tag == ""captureResults"") {
                                if (i == SERIALIZER_SURFACES_ID) {
                                    jsonObj.put(""outputs"", (JSONArray)obj);
                                } else if (i == SERIALIZER_PHYSICAL_METADATA_ID) {
                                    jsonObj.put(""physicalResults"", (JSONArray)obj);
                                } else {
                                    throw new ItsException(
                                            ""Unsupported JSONArray for captureResults"");
                                }
                            } else {
                                jsonObj.put(""outputs"", (JSONArray)obj);
                            }
                        } else {
                            throw new ItsException(""Invalid object received for serialization"");
                        }
                    }
                    if (tag == null) {
                        throw new ItsException(""No tag provided for socket response"");
                    }
                    mSocketRunnableObj.sendResponse(tag, null, jsonObj, null);
                    Logt.i(TAG, String.format(""Serialized %s"", tag));
                } catch (org.json.JSONException e) {
                    Logt.e(TAG, ""Error serializing object"", e);
                    break;
                } catch (ItsException e) {
                    Logt.e(TAG, ""Error serializing object"", e);
                    break;
                } catch (java.lang.InterruptedException e) {
                    Logt.e(TAG, ""Error serializing object (interrupted)"", e);
                    break;
                }
            }
            Logt.i(TAG, ""Serializer thread terminated"");
        }
    }

    class SocketWriteRunnable implements Runnable {

        // Use a separate thread to service a queue of objects to be written to the socket,
        // writing each sequentially in order. This is needed since different handler functions
        // (called on different threads) will need to send data back to the host script.

        public Socket mOpenSocket = null;
        private Thread mThread = null;

        public SocketWriteRunnable(Socket openSocket) {
            mOpenSocket = openSocket;
        }

        public void setOpenSocket(Socket openSocket) {
            mOpenSocket = openSocket;
        }

        @Override
        public void run() {
            Logt.i(TAG, ""Socket writer thread starting"");
            while (true) {
                try {
                    ByteBuffer b = mSocketWriteQueue.take();
                    synchronized(mSocketWriteDrainLock) {
                        if (mOpenSocket == null) {
                            Logt.e(TAG, ""No open socket connection!"");
                            continue;
                        }
                        if (b.hasArray()) {
                            mOpenSocket.getOutputStream().write(b.array(), 0, b.capacity());
                        } else {
                            byte[] barray = new byte[b.capacity()];
                            b.get(barray);
                            mOpenSocket.getOutputStream().write(barray);
                        }
                        mOpenSocket.getOutputStream().flush();
                        Logt.i(TAG, String.format(""Wrote to socket: %d bytes"", b.capacity()));
                        Integer imgBufSize = mInflightImageSizes.peek();
                        if (imgBufSize != null && imgBufSize == b.capacity()) {
                            mInflightImageSizes.removeFirst();
                            if (mSocketQueueQuota != null) {
                                mSocketQueueQuota.release(imgBufSize);
                            }
                        }
                    }
                } catch (IOException e) {
                    Logt.e(TAG, ""Error writing to socket"", e);
                    mOpenSocket = null;
                    break;
                } catch (java.lang.InterruptedException e) {
                    Logt.e(TAG, ""Error writing to socket (interrupted)"", e);
                    mOpenSocket = null;
                    break;
                }
            }
            Logt.i(TAG, ""Socket writer thread terminated"");
        }

        public synchronized void checkAndStartThread() {
            if (mThread == null || mThread.getState() == Thread.State.TERMINATED) {
                mThread = new Thread(this);
            }
            if (mThread.getState() == Thread.State.NEW) {
                mThread.start();
            }
        }

    }

    class SocketRunnable implements Runnable {

        // Format of sent messages (over the socket):
        // * Serialized JSON object on a single line (newline-terminated)
        // * For byte buffers, the binary data then follows
        //
        // Format of received messages (from the socket):
        // * Serialized JSON object on a single line (newline-terminated)

        private Socket mOpenSocket = null;
        private SocketWriteRunnable mSocketWriteRunnable = null;

        @Override
        public void run() {
            Logt.i(TAG, ""Socket thread starting"");
            try {
                mSocket = new ServerSocket(SERVERPORT);
            } catch (IOException e) {
                Logt.e(TAG, ""Failed to create socket"", e);
            }

            // Create a new thread to handle writes to this socket.
            mSocketWriteRunnable = new SocketWriteRunnable(null);

            while (!mThreadExitFlag) {
                // Receive the socket-open request from the host.
                try {
                    Logt.i(TAG, ""Waiting for client to connect to socket"");
                    mOpenSocket = mSocket.accept();
                    if (mOpenSocket == null) {
                        Logt.e(TAG, ""Socket connection error"");
                        break;
                    }
                    mSocketWriteQueue.clear();
                    mInflightImageSizes.clear();
                    mSocketWriteRunnable.setOpenSocket(mOpenSocket);
                    mSocketWriteRunnable.checkAndStartThread();
                    Logt.i(TAG, ""Socket connected"");
                } catch (IOException e) {
                    Logt.e(TAG, ""Socket open error: "", e);
                    break;
                }

                // Process commands over the open socket.
                while (!mThreadExitFlag) {
                    try {
                        BufferedReader input = new BufferedReader(
                                new InputStreamReader(mOpenSocket.getInputStream()));
                        if (input == null) {
                            Logt.e(TAG, ""Failed to get socket input stream"");
                            break;
                        }
                        String line = input.readLine();
                        if (line == null) {
                            Logt.i(TAG, ""Socket readline returned null (host disconnected)"");
                            break;
                        }
                        processSocketCommand(line);
                    } catch (IOException e) {
                        Logt.e(TAG, ""Socket read error: "", e);
                        break;
                    } catch (ItsException e) {
                        Logt.e(TAG, ""Script error: "", e);
                        break;
                    }
                }

                // Close socket and go back to waiting for a new connection.
                try {
                    synchronized(mSocketWriteDrainLock) {
                        mSocketWriteQueue.clear();
                        mInflightImageSizes.clear();
                        mOpenSocket.close();
                        mOpenSocket = null;
                        mSocketWriteRunnable.setOpenSocket(null);
                        Logt.i(TAG, ""Socket disconnected"");
                    }
                } catch (java.io.IOException e) {
                    Logt.e(TAG, ""Exception closing socket"");
                }
            }

            // It's an overall error state if the code gets here; no recevery.
            // Try to do some cleanup, but the service probably needs to be restarted.
            Logt.i(TAG, ""Socket server loop exited"");
            mThreadExitFlag = true;
            try {
                synchronized(mSocketWriteDrainLock) {
                    if (mOpenSocket != null) {
                        mOpenSocket.close();
                        mOpenSocket = null;
                        mSocketWriteRunnable.setOpenSocket(null);
                    }
                }
            } catch (java.io.IOException e) {
                Logt.w(TAG, ""Exception closing socket"");
            }
            try {
                if (mSocket != null) {
                    mSocket.close();
                    mSocket = null;
                }
            } catch (java.io.IOException e) {
                Logt.w(TAG, ""Exception closing socket"");
            }
        }

        public void processSocketCommand(String cmd)
                throws ItsException {
            // Default locale must be set to ""en-us""
            Locale locale = Locale.getDefault();
            if (!Locale.US.equals(locale)) {
                Logt.e(TAG, ""Default language is not set to "" + Locale.US + ""!"");
                stopSelf();
            }

            // Each command is a serialized JSON object.
            try {
                JSONObject cmdObj = new JSONObject(cmd);
                Logt.i(TAG, ""Start processing command"" + cmdObj.getString(""cmdName""));
                if (""open"".equals(cmdObj.getString(""cmdName""))) {
                    String cameraId = cmdObj.getString(""cameraId"");
                    openCameraDevice(cameraId);
                } else if (""close"".equals(cmdObj.getString(""cmdName""))) {
                    closeCameraDevice();
                } else if (""getCameraProperties"".equals(cmdObj.getString(""cmdName""))) {
                    doGetProps();
                } else if (""getCameraPropertiesById"".equals(cmdObj.getString(""cmdName""))) {
                    doGetPropsById(cmdObj);
                } else if (""startSensorEvents"".equals(cmdObj.getString(""cmdName""))) {
                    doStartSensorEvents();
                } else if (""checkSensorExistence"".equals(cmdObj.getString(""cmdName""))) {
                    doCheckSensorExistence();
                } else if (""getSensorEvents"".equals(cmdObj.getString(""cmdName""))) {
                    doGetSensorEvents();
                } else if (""do3A"".equals(cmdObj.getString(""cmdName""))) {
                    do3A(cmdObj);
                } else if (""doCapture"".equals(cmdObj.getString(""cmdName""))) {
                    doCapture(cmdObj);
                } else if (""doVibrate"".equals(cmdObj.getString(""cmdName""))) {
                    doVibrate(cmdObj);
                } else if (""setAudioRestriction"".equals(cmdObj.getString(""cmdName""))) {
                    doSetAudioRestriction(cmdObj);
                } else if (""getCameraIds"".equals(cmdObj.getString(""cmdName""))) {
                    doGetCameraIds();
                } else if (""doReprocessCapture"".equals(cmdObj.getString(""cmdName""))) {
                    doReprocessCapture(cmdObj);
                } else if (""getItsVersion"".equals(cmdObj.getString(""cmdName""))) {
                    mSocketRunnableObj.sendResponse(""ItsVersion"", ITS_SERVICE_VERSION);
                } else if (""isStreamCombinationSupported"".equals(cmdObj.getString(""cmdName""))) {
                    doCheckStreamCombination(cmdObj);
                } else if (""isCameraPrivacyModeSupported"".equals(cmdObj.getString(""cmdName""))) {
                    doCheckCameraPrivacyModeSupport();
                } else if (""isPerformanceClassPrimaryCamera"".equals(cmdObj.getString(""cmdName""))) {
                    String cameraId = cmdObj.getString(""cameraId"");
                    doCheckPerformanceClassPrimaryCamera(cameraId);
                } else if (""measureCameraLaunchMs"".equals(cmdObj.getString(""cmdName""))) {
                    String cameraId = cmdObj.getString(""cameraId"");
                    doMeasureCameraLaunchMs(cameraId);
                } else if (""measureCamera1080pJpegCaptureMs"".equals(cmdObj.getString(""cmdName""))) {
                    String cameraId = cmdObj.getString(""cameraId"");
                    doMeasureCamera1080pJpegCaptureMs(cameraId);
                } else {
                    throw new ItsException(""Unknown command: "" + cmd);
                }
                Logt.i(TAG, ""Finish processing command"" + cmdObj.getString(""cmdName""));
            } catch (org.json.JSONException e) {
                Logt.e(TAG, ""Invalid command: "", e);
            }
        }

        public void sendResponse(String tag, String str, JSONObject obj, ByteBuffer bbuf)
                throws ItsException {
            try {
                JSONObject jsonObj = new JSONObject();
                jsonObj.put(""tag"", tag);
                if (str != null) {
                    jsonObj.put(""strValue"", str);
                }
                if (obj != null) {
                    jsonObj.put(""objValue"", obj);
                }
                if (bbuf != null) {
                    jsonObj.put(""bufValueSize"", bbuf.capacity());
                }
                ByteBuffer bstr = ByteBuffer.wrap(
                        (jsonObj.toString()+""\n"").getBytes(Charset.defaultCharset()));
                synchronized(mSocketWriteEnqueueLock) {
                    if (bstr != null) {
                        mSocketWriteQueue.put(bstr);
                    }
                    if (bbuf != null) {
                        mInflightImageSizes.add(bbuf.capacity());
                        mSocketWriteQueue.put(bbuf);
                    }
                }
            } catch (org.json.JSONException e) {
                throw new ItsException(""JSON error: "", e);
            } catch (java.lang.InterruptedException e) {
                throw new ItsException(""Socket error: "", e);
            }
        }

        public void sendResponse(String tag, String str)
                throws ItsException {
            sendResponse(tag, str, null, null);
        }

        public void sendResponse(String tag, JSONObject obj)
                throws ItsException {
            sendResponse(tag, null, obj, null);
        }

        public void sendResponseCaptureBuffer(String tag, ByteBuffer bbuf)
                throws ItsException {
            sendResponse(tag, null, null, bbuf);
        }

        public void sendResponse(LinkedList<MySensorEvent> events)
                throws ItsException {
            Logt.i(TAG, ""Sending "" + events.size() + "" sensor events"");
            try {
                JSONArray accels = new JSONArray();
                JSONArray mags = new JSONArray();
                JSONArray gyros = new JSONArray();
                for (MySensorEvent event : events) {
                    JSONObject obj = new JSONObject();
                    obj.put(""time"", event.timestamp);
                    obj.put(""x"", event.values[0]);
                    obj.put(""y"", event.values[1]);
                    obj.put(""z"", event.values[2]);
                    if (event.sensor.getType() == Sensor.TYPE_ACCELEROMETER) {
                        accels.put(obj);
                    } else if (event.sensor.getType() == Sensor.TYPE_MAGNETIC_FIELD) {
                        mags.put(obj);
                    } else if (event.sensor.getType() == Sensor.TYPE_GYROSCOPE) {
                        gyros.put(obj);
                    }
                }
                JSONObject obj = new JSONObject();
                obj.put(""accel"", accels);
                obj.put(""mag"", mags);
                obj.put(""gyro"", gyros);
                sendResponse(""sensorEvents"", null, obj, null);
            } catch (org.json.JSONException e) {
                throw new ItsException(""JSON error: "", e);
            }
            Logt.i(TAG, ""Sent sensor events"");
        }

        public void sendResponse(CameraCharacteristics props)
                throws ItsException {
            try {
                Object objs[] = new Object[2];
                objs[0] = ""cameraProperties"";
                objs[1] = props;
                mSerializerQueue.put(objs);
            } catch (InterruptedException e) {
                throw new ItsException(""Interrupted: "", e);
            }
        }

        public void sendResponseCaptureResult(CameraCharacteristics props,
                                              CaptureRequest request,
                                              TotalCaptureResult result,
                                              ImageReader[] readers)
                throws ItsException {
            try {
                JSONArray jsonSurfaces = new JSONArray();
                for (int i = 0; i < readers.length; i++) {
                    JSONObject jsonSurface = new JSONObject();
                    jsonSurface.put(""width"", readers[i].getWidth());
                    jsonSurface.put(""height"", readers[i].getHeight());
                    int format = readers[i].getImageFormat();
                    if (format == ImageFormat.RAW_SENSOR) {
                        if (mCaptureRawIsStats) {
                            int aaw = ItsUtils.getActiveArrayCropRegion(mCameraCharacteristics)
                                              .width();
                            int aah = ItsUtils.getActiveArrayCropRegion(mCameraCharacteristics)
                                              .height();
                            jsonSurface.put(""format"", ""rawStats"");
                            jsonSurface.put(""width"", aaw/mCaptureStatsGridWidth);
                            jsonSurface.put(""height"", aah/mCaptureStatsGridHeight);
                        } else if (mCaptureRawIsDng) {
                            jsonSurface.put(""format"", ""dng"");
                        } else {
                            jsonSurface.put(""format"", ""raw"");
                        }
                    } else if (format == ImageFormat.RAW10) {
                        jsonSurface.put(""format"", ""raw10"");
                    } else if (format == ImageFormat.RAW12) {
                        jsonSurface.put(""format"", ""raw12"");
                    } else if (format == ImageFormat.JPEG) {
                        jsonSurface.put(""format"", ""jpeg"");
                    } else if (format == ImageFormat.YUV_420_888) {
                        jsonSurface.put(""format"", ""yuv"");
                    } else if (format == ImageFormat.Y8) {
                        jsonSurface.put(""format"", ""y8"");
                    } else {
                        throw new ItsException(""Invalid format"");
                    }
                    jsonSurfaces.put(jsonSurface);
                }

                Map<String, CaptureResult> physicalMetadata =
                        result.getPhysicalCameraResults();
                JSONArray jsonPhysicalMetadata = new JSONArray();
                for (Map.Entry<String, CaptureResult> pair : physicalMetadata.entrySet()) {
                    JSONObject jsonOneMetadata = new JSONObject();
                    jsonOneMetadata.put(pair.getKey(), ItsSerializer.serialize(pair.getValue()));
                    jsonPhysicalMetadata.put(jsonOneMetadata);
                }
                Object objs[] = new Object[4];
                objs[0] = ""captureResults"";
                objs[1] = result;
                objs[SERIALIZER_SURFACES_ID] = jsonSurfaces;
                objs[SERIALIZER_PHYSICAL_METADATA_ID] = jsonPhysicalMetadata;
                mSerializerQueue.put(objs);
            } catch (org.json.JSONException e) {
                throw new ItsException(""JSON error: "", e);
            } catch (InterruptedException e) {
                throw new ItsException(""Interrupted: "", e);
            }
        }
    }

    public ImageReader.OnImageAvailableListener
            createAvailableListener(final CaptureCallback listener) {
        return new ImageReader.OnImageAvailableListener() {
            @Override
            public void onImageAvailable(ImageReader reader) {
                Image i = null;
                try {
                    i = reader.acquireNextImage();
                    String physicalCameraId = new String();
                    for (int idx = 0; idx < mOutputImageReaders.length; idx++) {
                        if (mOutputImageReaders[idx] == reader) {
                            physicalCameraId = mPhysicalStreamMap.get(idx);
                        }
                    }
                    listener.onCaptureAvailable(i, physicalCameraId);
                } finally {
                    if (i != null) {
                        i.close();
                    }
                }
            }
        };
    }

    private ImageReader.OnImageAvailableListener
            createAvailableListenerDropper() {
        return new ImageReader.OnImageAvailableListener() {
            @Override
            public void onImageAvailable(ImageReader reader) {
                Image i = reader.acquireNextImage();
                i.close();
            }
        };
    }

    private void doStartSensorEvents() throws ItsException {
        synchronized(mEventLock) {
            mEventsEnabled = true;
        }
        mSocketRunnableObj.sendResponse(""sensorEventsStarted"", """");
    }

    private void doCheckSensorExistence() throws ItsException {
        try {
            JSONObject obj = new JSONObject();
            obj.put(""accel"", mAccelSensor != null);
            obj.put(""mag"", mMagSensor != null);
            obj.put(""gyro"", mGyroSensor != null);
            obj.put(""vibrator"", mVibrator.hasVibrator());
            mSocketRunnableObj.sendResponse(""sensorExistence"", null, obj, null);
        } catch (org.json.JSONException e) {
            throw new ItsException(""JSON error: "", e);
        }
    }

    private void doGetSensorEvents() throws ItsException {
        synchronized(mEventLock) {
            mSocketRunnableObj.sendResponse(mEvents);
            mEvents.clear();
            mEventsEnabled = false;
        }
    }

    private void doGetProps() throws ItsException {
        mSocketRunnableObj.sendResponse(mCameraCharacteristics);
    }

    private void doGetPropsById(JSONObject params) throws ItsException {
        String[] devices;
        try {
            // Intentionally not using ItsUtils.getItsCompatibleCameraIds here so it's possible to
            // write some simple script to query camera characteristics even for devices exempted
            // from ITS today.
            devices = mCameraManager.getCameraIdList();
            if (devices == null || devices.length == 0) {
                throw new ItsException(""No camera devices"");
            }
        } catch (CameraAccessException e) {
            throw new ItsException(""Failed to get device ID list"", e);
        }

        try {
            String cameraId = params.getString(""cameraId"");
            CameraCharacteristics characteristics =
                    mCameraManager.getCameraCharacteristics(cameraId);
            mSocketRunnableObj.sendResponse(characteristics);
        } catch (org.json.JSONException e) {
            throw new ItsException(""JSON error: "", e);
        } catch (IllegalArgumentException e) {
            throw new ItsException(""Illegal argument error:"", e);
        } catch (CameraAccessException e) {
            throw new ItsException(""Access error: "", e);
        }
    }

    private void doGetCameraIds() throws ItsException {
        if (mItsCameraIdList == null) {
            mItsCameraIdList = ItsUtils.getItsCompatibleCameraIds(mCameraManager);
        }
        if (mItsCameraIdList.mCameraIdCombos.size() == 0) {
            throw new ItsException(""No camera devices"");
        }

        try {
            JSONObject obj = new JSONObject();
            JSONArray array = new JSONArray();
            for (String id : mItsCameraIdList.mCameraIdCombos) {
                array.put(id);
            }
            obj.put(""cameraIdArray"", array);
            mSocketRunnableObj.sendResponse(""cameraIds"", obj);
        } catch (org.json.JSONException e) {
            throw new ItsException(""JSON error: "", e);
        }
    }

    private static class HandlerExecutor implements Executor {
        private final Handler mHandler;

        public HandlerExecutor(Handler handler) {
            mHandler = handler;
        }

        @Override
        public void execute(Runnable runCmd) {
            mHandler.post(runCmd);
        }
    }

    private void doCheckStreamCombination(JSONObject params) throws ItsException {
        try {
            JSONObject obj = new JSONObject();
            JSONArray jsonOutputSpecs = ItsUtils.getOutputSpecs(params);
            prepareImageReadersWithOutputSpecs(jsonOutputSpecs, /*inputSize*/null,
                    /*inputFormat*/0, /*maxInputBuffers*/0, /*backgroundRequest*/false);
            int numSurfaces = mOutputImageReaders.length;
            List<OutputConfiguration> outputConfigs =
                    new ArrayList<OutputConfiguration>(numSurfaces);
            for (int i = 0; i < numSurfaces; i++) {
                OutputConfiguration config = new OutputConfiguration(
                        mOutputImageReaders[i].getSurface());
                if (mPhysicalStreamMap.get(i) != null) {
                    config.setPhysicalCameraId(mPhysicalStreamMap.get(i));
                }
                outputConfigs.add(config);
            }

            BlockingSessionCallback sessionListener = new BlockingSessionCallback();
            SessionConfiguration sessionConfig = new SessionConfiguration(
                SessionConfiguration.SESSION_REGULAR, outputConfigs,
                new HandlerExecutor(mCameraHandler), sessionListener);
            boolean supported = mCamera.isSessionConfigurationSupported(sessionConfig);

            String supportString = supported ? ""supportedCombination"" : ""unsupportedCombination"";
            mSocketRunnableObj.sendResponse(""streamCombinationSupport"", supportString);

        } catch (UnsupportedOperationException e) {
            mSocketRunnableObj.sendResponse(""streamCombinationSupport"", ""unsupportedOperation"");
        } catch (IllegalArgumentException e) {
            throw new ItsException(""Error checking stream combination"", e);
        } catch (CameraAccessException e) {
            throw new ItsException(""Error checking stream combination"", e);
        }
    }

    private void doCheckCameraPrivacyModeSupport() throws ItsException {
        boolean hasPrivacySupport = mSensorPrivacyManager
                .supportsSensorToggle(SensorPrivacyManager.Sensors.CAMERA);
        mSocketRunnableObj.sendResponse(""cameraPrivacyModeSupport"",
                hasPrivacySupport ? ""true"" : ""false"");
    }

    private void doCheckPerformanceClassPrimaryCamera(String cameraId) throws ItsException {
        boolean  isPerfClass = (Build.VERSION.MEDIA_PERFORMANCE_CLASS == PERFORMANCE_CLASS_S
                || Build.VERSION.MEDIA_PERFORMANCE_CLASS == PERFORMANCE_CLASS_R);

        if (mItsCameraIdList == null) {
            mItsCameraIdList = ItsUtils.getItsCompatibleCameraIds(mCameraManager);
        }
        if (mItsCameraIdList.mCameraIds.size() == 0) {
            throw new ItsException(""No camera devices"");
        }
        if (!mItsCameraIdList.mCameraIds.contains(cameraId)) {
            throw new ItsException(""Invalid cameraId "" + cameraId);
        }

        boolean isPrimaryCamera = false;
        try {
            CameraCharacteristics c = mCameraManager.getCameraCharacteristics(cameraId);
            Integer cameraFacing = c.get(CameraCharacteristics.LENS_FACING);
            for (String id : mItsCameraIdList.mCameraIds) {
                c = mCameraManager.getCameraCharacteristics(id);
                Integer facing = c.get(CameraCharacteristics.LENS_FACING);
                if (cameraFacing.equals(facing)) {
                    if (cameraId.equals(id)) {
                        isPrimaryCamera = true;
                    } else {
                        isPrimaryCamera = false;
                    }
                    break;
                }
            }
        } catch (CameraAccessException e) {
            throw new ItsException(""Failed to get camera characteristics"", e);
        }

        mSocketRunnableObj.sendResponse(""performanceClassPrimaryCamera"",
                (isPerfClass && isPrimaryCamera) ? ""true"" : ""false"");
    }

    private double invokeCameraPerformanceTest(Class testClass, String testName,
            String cameraId, String metricName) throws ItsException {
        mResults.clear();
        mCameraInstrumentation = new CameraTestInstrumentation();
        MetricListener metricListener = new MetricListener() {
            @Override
            public void onResultMetric(Metric metric) {
                mResults.add(metric);
            }
        };
        mCameraInstrumentation.initialize(this, metricListener);

        Bundle bundle = new Bundle();
        bundle.putString(""camera-id"", cameraId);
        bundle.putString(""perf-measure"", ""on"");
        bundle.putString(""perf-class-test"", ""on"");
        InstrumentationRegistry.registerInstance(mCameraInstrumentation, bundle);

        JUnitCore testRunner = new JUnitCore();
        Log.v(TAG, String.format(""Execute Test: %s#%s"", testClass.getSimpleName(), testName));
        Request request = Request.method(testClass, testName);
        Result runResult = testRunner.run(request);
        if (!runResult.wasSuccessful()) {
            throw new ItsException(""Camera PerformanceTest "" + testClass.getSimpleName() +
                    ""#"" + testName + "" failed"");
        }

        for (Metric m : mResults) {
            if (m.getMessage().equals(metricName) && m.getValues().length == 1) {
                return m.getValues()[0];
            }
        }

        throw new ItsException(""Failed to look up "" + metricName +
                "" in Camera PerformanceTest result!"");
    }

    private void doMeasureCameraLaunchMs(String cameraId) throws ItsException {
        double launchMs = invokeCameraPerformanceTest(PerformanceTest.class,
                ""testCameraLaunch"", cameraId, ""camera_launch_average_time_for_all_cameras"");
        mSocketRunnableObj.sendResponse(""cameraLaunchMs"", Double.toString(launchMs));
    }

    private void doMeasureCamera1080pJpegCaptureMs(String cameraId) throws ItsException {
        double jpegCaptureMs = invokeCameraPerformanceTest(PerformanceTest.class,
                ""testSingleCapture"", cameraId,
                ""camera_capture_average_latency_for_all_cameras_jpeg"");
        mSocketRunnableObj.sendResponse(""camera1080pJpegCaptureMs"", Double.toString(jpegCaptureMs));
    }

    private void prepareImageReaders(Size[] outputSizes, int[] outputFormats, Size inputSize,
            int inputFormat, int maxInputBuffers) {
        closeImageReaders();
        mOutputImageReaders = new ImageReader[outputSizes.length];
        for (int i = 0; i < outputSizes.length; i++) {
            // Check if the output image reader can be shared with the input image reader.
            if (outputSizes[i].equals(inputSize) && outputFormats[i] == inputFormat) {
                mOutputImageReaders[i] = ImageReader.newInstance(outputSizes[i].getWidth(),
                        outputSizes[i].getHeight(), outputFormats[i],
                        MAX_CONCURRENT_READER_BUFFERS + maxInputBuffers);
                mInputImageReader = mOutputImageReaders[i];
            } else {
                mOutputImageReaders[i] = ImageReader.newInstance(outputSizes[i].getWidth(),
                        outputSizes[i].getHeight(), outputFormats[i],
                        MAX_CONCURRENT_READER_BUFFERS);
            }
        }

        if (inputSize != null && mInputImageReader == null) {
            mInputImageReader = ImageReader.newInstance(inputSize.getWidth(), inputSize.getHeight(),
                    inputFormat, maxInputBuffers);
        }
    }

    private void closeImageReaders() {
        if (mOutputImageReaders != null) {
            for (int i = 0; i < mOutputImageReaders.length; i++) {
                if (mOutputImageReaders[i] != null) {
                    mOutputImageReaders[i].close();
                    mOutputImageReaders[i] = null;
                }
            }
        }
        if (mInputImageReader != null) {
            mInputImageReader.close();
            mInputImageReader = null;
        }
    }

    private void do3A(JSONObject params) throws ItsException {
        ThreeAResultListener threeAListener = new ThreeAResultListener();
        try {
            // Start a 3A action, and wait for it to converge.
            // Get the converged values for each ""A"", and package into JSON result for caller.

            // Configure streams on physical sub-camera if PHYSICAL_ID_KEY is specified.
            String physicalId = null;
            CameraCharacteristics c = mCameraCharacteristics;
            if (params.has(PHYSICAL_ID_KEY)) {
                physicalId = params.getString(PHYSICAL_ID_KEY);
                c = mPhysicalCameraChars.get(physicalId);
            }

            // 3A happens on full-res frames.
            Size sizes[] = ItsUtils.getYuvOutputSizes(c);
            int outputFormats[] = new int[1];
            outputFormats[0] = ImageFormat.YUV_420_888;
            Size[] outputSizes = new Size[1];
            outputSizes[0] = sizes[0];
            int width = outputSizes[0].getWidth();
            int height = outputSizes[0].getHeight();

            prepareImageReaders(outputSizes, outputFormats, /*inputSize*/null, /*inputFormat*/0,
                    /*maxInputBuffers*/0);

            List<OutputConfiguration> outputConfigs = new ArrayList<OutputConfiguration>(1);
            OutputConfiguration config =
                    new OutputConfiguration(mOutputImageReaders[0].getSurface());
            if (physicalId != null) {
                config.setPhysicalCameraId(physicalId);
            }
            outputConfigs.add(config);
            BlockingSessionCallback sessionListener = new BlockingSessionCallback();
            mCamera.createCaptureSessionByOutputConfigurations(
                    outputConfigs, sessionListener, mCameraHandler);
            mSession = sessionListener.waitAndGetSession(TIMEOUT_IDLE_MS);

            // Add a listener that just recycles buffers; they aren't saved anywhere.
            ImageReader.OnImageAvailableListener readerListener =
                    createAvailableListenerDropper();
            mOutputImageReaders[0].setOnImageAvailableListener(readerListener, mSaveHandlers[0]);

            // Get the user-specified regions for AE, AWB, AF.
            // Note that the user specifies normalized [x,y,w,h], which is converted below
            // to an [x0,y0,x1,y1] region in sensor coords. The capture request region
            // also has a fifth ""weight"" element: [x0,y0,x1,y1,w].
            // Use logical camera's active array size for 3A regions.
            Rect activeArray = mCameraCharacteristics.get(
                    CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE);
            int aaWidth = activeArray.right - activeArray.left;
            int aaHeight = activeArray.bottom - activeArray.top;
            MeteringRectangle[] regionAE = new MeteringRectangle[]{
                    new MeteringRectangle(0,0,aaWidth,aaHeight,1)};
            MeteringRectangle[] regionAF = new MeteringRectangle[]{
                    new MeteringRectangle(0,0,aaWidth,aaHeight,1)};
            MeteringRectangle[] regionAWB = new MeteringRectangle[]{
                    new MeteringRectangle(0,0,aaWidth,aaHeight,1)};
            if (params.has(REGION_KEY)) {
                JSONObject regions = params.getJSONObject(REGION_KEY);
                if (regions.has(REGION_AE_KEY)) {
                    regionAE = ItsUtils.getJsonWeightedRectsFromArray(
                            regions.getJSONArray(REGION_AE_KEY), true, aaWidth, aaHeight);
                }
                if (regions.has(REGION_AF_KEY)) {
                    regionAF = ItsUtils.getJsonWeightedRectsFromArray(
                            regions.getJSONArray(REGION_AF_KEY), true, aaWidth, aaHeight);
                }
                if (regions.has(REGION_AWB_KEY)) {
                    regionAWB = ItsUtils.getJsonWeightedRectsFromArray(
                            regions.getJSONArray(REGION_AWB_KEY), true, aaWidth, aaHeight);
                }
            }

            // An EV compensation can be specified as part of AE convergence.
            int evComp = params.optInt(EVCOMP_KEY, 0);
            if (evComp != 0) {
                Logt.i(TAG, String.format(""Running 3A with AE exposure compensation value: %d"", evComp));
            }

            // By default, AE and AF both get triggered, but the user can optionally override this.
            // Also, AF won't get triggered if the lens is fixed-focus.
            boolean doAE = true;
            boolean doAF = true;
            if (params.has(TRIGGER_KEY)) {
                JSONObject triggers = params.getJSONObject(TRIGGER_KEY);
                if (triggers.has(TRIGGER_AE_KEY)) {
                    doAE = triggers.getBoolean(TRIGGER_AE_KEY);
                }
                if (triggers.has(TRIGGER_AF_KEY)) {
                    doAF = triggers.getBoolean(TRIGGER_AF_KEY);
                }
            }
            Float minFocusDistance = c.get(
                    CameraCharacteristics.LENS_INFO_MINIMUM_FOCUS_DISTANCE);
            boolean isFixedFocusLens = minFocusDistance != null && minFocusDistance == 0.0;
            if (doAF && isFixedFocusLens) {
                // Send a fake result back for the code that is waiting for this message to see
                // that AF has converged.
                Logt.i(TAG, ""Ignoring request for AF on fixed-focus camera"");
                mSocketRunnableObj.sendResponse(""afResult"", ""0.0"");
                doAF = false;
            }

            mInterlock3A.open();
            synchronized(m3AStateLock) {
                // If AE or AWB lock is specified, then the 3A will converge first and then lock these
                // values, waiting until the HAL has reported that the lock was successful.
                mNeedsLockedAE = params.optBoolean(LOCK_AE_KEY, false);
                mNeedsLockedAWB = params.optBoolean(LOCK_AWB_KEY, false);
                mConvergedAE = false;
                mConvergedAWB = false;
                mConvergedAF = false;
                mLockedAE = false;
                mLockedAWB = false;
            }
            long tstart = System.currentTimeMillis();
            boolean triggeredAE = false;
            boolean triggeredAF = false;

            Logt.i(TAG, String.format(""Initiating 3A: AE:%d, AF:%d, AWB:1, AELOCK:%d, AWBLOCK:%d"",
                    doAE?1:0, doAF?1:0, mNeedsLockedAE?1:0, mNeedsLockedAWB?1:0));

            // Keep issuing capture requests until 3A has converged.
            while (true) {

                // Block until can take the next 3A frame. Only want one outstanding frame
                // at a time, to simplify the logic here.
                if (!mInterlock3A.block(TIMEOUT_3A * 1000) ||
                        System.currentTimeMillis() - tstart > TIMEOUT_3A * 1000) {
                    throw new ItsException(
                            ""3A failed to converge after "" + TIMEOUT_3A + "" seconds.\n"" +
                            ""AE converge state: "" + mConvergedAE + "", \n"" +
                            ""AF convergence state: "" + mConvergedAF + "", \n"" +
                            ""AWB convergence state: "" + mConvergedAWB + ""."");
                }
                mInterlock3A.close();

                synchronized(m3AStateLock) {
                    // If not converged yet, issue another capture request.
                    if (       (doAE && (!triggeredAE || !mConvergedAE))
                            || !mConvergedAWB
                            || (doAF && (!triggeredAF || !mConvergedAF))
                            || (doAE && mNeedsLockedAE && !mLockedAE)
                            || (mNeedsLockedAWB && !mLockedAWB)) {

                        // Baseline capture request for 3A.
                        CaptureRequest.Builder req = mCamera.createCaptureRequest(
                                CameraDevice.TEMPLATE_PREVIEW);
                        req.set(CaptureRequest.FLASH_MODE, CaptureRequest.FLASH_MODE_OFF);
                        req.set(CaptureRequest.CONTROL_MODE, CaptureRequest.CONTROL_MODE_AUTO);
                        req.set(CaptureRequest.CONTROL_CAPTURE_INTENT,
                                CaptureRequest.CONTROL_CAPTURE_INTENT_PREVIEW);
                        req.set(CaptureRequest.CONTROL_AE_MODE,
                                CaptureRequest.CONTROL_AE_MODE_ON);
                        req.set(CaptureRequest.CONTROL_AE_EXPOSURE_COMPENSATION, 0);
                        req.set(CaptureRequest.CONTROL_AE_LOCK, false);
                        req.set(CaptureRequest.CONTROL_AE_REGIONS, regionAE);
                        req.set(CaptureRequest.CONTROL_AF_MODE,
                                CaptureRequest.CONTROL_AF_MODE_AUTO);
                        req.set(CaptureRequest.CONTROL_AF_REGIONS, regionAF);
                        req.set(CaptureRequest.CONTROL_AWB_MODE,
                                CaptureRequest.CONTROL_AWB_MODE_AUTO);
                        req.set(CaptureRequest.CONTROL_AWB_LOCK, false);
                        req.set(CaptureRequest.CONTROL_AWB_REGIONS, regionAWB);
                        // ITS only turns OIS on when it's explicitly requested
                        req.set(CaptureRequest.LENS_OPTICAL_STABILIZATION_MODE,
                                CaptureRequest.LENS_OPTICAL_STABILIZATION_MODE_OFF);

                        if (evComp != 0) {
                            req.set(CaptureRequest.CONTROL_AE_EXPOSURE_COMPENSATION, evComp);
                        }

                        if (mConvergedAE && mNeedsLockedAE) {
                            req.set(CaptureRequest.CONTROL_AE_LOCK, true);
                        }
                        if (mConvergedAWB && mNeedsLockedAWB) {
                            req.set(CaptureRequest.CONTROL_AWB_LOCK, true);
                        }

                        boolean triggering = false;
                        // Trigger AE first.
                        if (doAE && !triggeredAE) {
                            Logt.i(TAG, ""Triggering AE"");
                            req.set(CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER,
                                    CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_START);
                            triggeredAE = true;
                            triggering = true;
                        }

                        // After AE has converged, trigger AF.
                        if (doAF && !triggeredAF && (!doAE || (triggeredAE && mConvergedAE))) {
                            Logt.i(TAG, ""Triggering AF"");
                            req.set(CaptureRequest.CONTROL_AF_TRIGGER,
                                    CaptureRequest.CONTROL_AF_TRIGGER_START);
                            triggeredAF = true;
                            triggering = true;
                        }

                        req.addTarget(mOutputImageReaders[0].getSurface());

                        if (triggering) {
                            // Send single request for AE/AF trigger
                            mSession.capture(req.build(),
                                    threeAListener, mResultHandler);
                        } else {
                            // Use repeating request for non-trigger requests
                            mSession.setRepeatingRequest(req.build(),
                                    threeAListener, mResultHandler);
                        }
                    } else {
                        mSocketRunnableObj.sendResponse(""3aConverged"", """");
                        Logt.i(TAG, ""3A converged"");
                        break;
                    }
                }
            }
        } catch (android.hardware.camera2.CameraAccessException e) {
            throw new ItsException(""Access error: "", e);
        } catch (org.json.JSONException e) {
            throw new ItsException(""JSON error: "", e);
        } finally {
            mSocketRunnableObj.sendResponse(""3aDone"", """");
            // stop listener from updating 3A states
            threeAListener.stop();
            if (mSession != null) {
                mSession.close();
            }
        }
    }

    private void doVibrate(JSONObject params) throws ItsException {
        try {
            if (mVibrator == null) {
                throw new ItsException(""Unable to start vibrator"");
            }
            JSONArray patternArray = params.getJSONArray(VIB_PATTERN_KEY);
            int len = patternArray.length();
            long pattern[] = new long[len];
            for (int i = 0; i < len; i++) {
                pattern[i] = patternArray.getLong(i);
            }
            Logt.i(TAG, String.format(""Starting vibrator, pattern length %d"",len));

            // Mark the vibrator as alarm to test the audio restriction API
            // TODO: consider making this configurable
            AudioAttributes audioAttributes = new AudioAttributes.Builder()
                    .setUsage(AudioAttributes.USAGE_ALARM).build();
            mVibrator.vibrate(pattern, -1, audioAttributes);
            mSocketRunnableObj.sendResponse(""vibrationStarted"", """");
        } catch (org.json.JSONException e) {
            throw new ItsException(""JSON error: "", e);
        }
    }

    private void doSetAudioRestriction(JSONObject params) throws ItsException {
        try {
            if (mCamera == null) {
                throw new ItsException(""Camera is closed"");
            }
            int mode = params.getInt(AUDIO_RESTRICTION_MODE_KEY);
            mCamera.setCameraAudioRestriction(mode);
            Logt.i(TAG, String.format(""Set audio restriction mode to %d"", mode));

            mSocketRunnableObj.sendResponse(""audioRestrictionSet"", """");
        } catch (org.json.JSONException e) {
            throw new ItsException(""JSON error: "", e);
        } catch (android.hardware.camera2.CameraAccessException e) {
            throw new ItsException(""Access error: "", e);
        }
    }

    /**
     * Parse jsonOutputSpecs to get output surface sizes and formats. Create input and output
     * image readers for the parsed output surface sizes, output formats, and the given input
     * size and format.
     */
    private void prepareImageReadersWithOutputSpecs(JSONArray jsonOutputSpecs, Size inputSize,
            int inputFormat, int maxInputBuffers, boolean backgroundRequest) throws ItsException {
        Size outputSizes[];
        int outputFormats[];
        int numSurfaces = 0;
        mPhysicalStreamMap.clear();

        if (jsonOutputSpecs != null) {
            try {
                numSurfaces = jsonOutputSpecs.length();
                if (backgroundRequest) {
                    numSurfaces += 1;
                }
                if (numSurfaces > MAX_NUM_OUTPUT_SURFACES) {
                    throw new ItsException(""Too many output surfaces"");
                }

                outputSizes = new Size[numSurfaces];
                outputFormats = new int[numSurfaces];
                for (int i = 0; i < numSurfaces; i++) {
                    // Append optional background stream at the end
                    if (backgroundRequest && i == numSurfaces - 1) {
                        outputFormats[i] = ImageFormat.YUV_420_888;
                        outputSizes[i] = new Size(640, 480);
                        continue;
                    }
                    // Get the specified surface.
                    JSONObject surfaceObj = jsonOutputSpecs.getJSONObject(i);
                    String physicalCameraId = surfaceObj.optString(""physicalCamera"");
                    CameraCharacteristics cameraCharacteristics =  mCameraCharacteristics;
                    mPhysicalStreamMap.put(i, physicalCameraId);
                    if (!physicalCameraId.isEmpty()) {
                        cameraCharacteristics = mPhysicalCameraChars.get(physicalCameraId);
                    }

                    String sformat = surfaceObj.optString(""format"");
                    Size sizes[];
                    if (""yuv"".equals(sformat) || """".equals(sformat)) {
                        // Default to YUV if no format is specified.
                        outputFormats[i] = ImageFormat.YUV_420_888;
                        sizes = ItsUtils.getYuvOutputSizes(cameraCharacteristics);
                    } else if (""jpg"".equals(sformat) || ""jpeg"".equals(sformat)) {
                        outputFormats[i] = ImageFormat.JPEG;
                        sizes = ItsUtils.getJpegOutputSizes(cameraCharacteristics);
                    } else if (""raw"".equals(sformat)) {
                        outputFormats[i] = ImageFormat.RAW_SENSOR;
                        sizes = ItsUtils.getRaw16OutputSizes(cameraCharacteristics);
                    } else if (""raw10"".equals(sformat)) {
                        outputFormats[i] = ImageFormat.RAW10;
                        sizes = ItsUtils.getRaw10OutputSizes(cameraCharacteristics);
                    } else if (""raw12"".equals(sformat)) {
                        outputFormats[i] = ImageFormat.RAW12;
                        sizes = ItsUtils.getRaw12OutputSizes(cameraCharacteristics);
                    } else if (""dng"".equals(sformat)) {
                        outputFormats[i] = ImageFormat.RAW_SENSOR;
                        sizes = ItsUtils.getRaw16OutputSizes(cameraCharacteristics);
                        mCaptureRawIsDng = true;
                    } else if (""rawStats"".equals(sformat)) {
                        outputFormats[i] = ImageFormat.RAW_SENSOR;
                        sizes = ItsUtils.getRaw16OutputSizes(cameraCharacteristics);
                        mCaptureRawIsStats = true;
                        mCaptureStatsGridWidth = surfaceObj.optInt(""gridWidth"");
                        mCaptureStatsGridHeight = surfaceObj.optInt(""gridHeight"");
                    } else if (""y8"".equals(sformat)) {
                        outputFormats[i] = ImageFormat.Y8;
                        sizes = ItsUtils.getY8OutputSizes(cameraCharacteristics);
                    } else {
                        throw new ItsException(""Unsupported format: "" + sformat);
                    }
                    // If the size is omitted, then default to the largest allowed size for the
                    // format.
                    int width = surfaceObj.optInt(""width"");
                    int height = surfaceObj.optInt(""height"");
                    if (width <= 0) {
                        if (sizes == null || sizes.length == 0) {
                            throw new ItsException(String.format(
                                    ""Zero stream configs available for requested format: %s"",
                                    sformat));
                        }
                        width = ItsUtils.getMaxSize(sizes).getWidth();
                    }
                    if (height <= 0) {
                        height = ItsUtils.getMaxSize(sizes).getHeight();
                    }
                    // The stats computation only applies to the active array region.
                    int aaw = ItsUtils.getActiveArrayCropRegion(cameraCharacteristics).width();
                    int aah = ItsUtils.getActiveArrayCropRegion(cameraCharacteristics).height();
                    if (mCaptureStatsGridWidth <= 0 || mCaptureStatsGridWidth > aaw) {
                        mCaptureStatsGridWidth = aaw;
                    }
                    if (mCaptureStatsGridHeight <= 0 || mCaptureStatsGridHeight > aah) {
                        mCaptureStatsGridHeight = aah;
                    }

                    outputSizes[i] = new Size(width, height);
                }
            } catch (org.json.JSONException e) {
                throw new ItsException(""JSON error"", e);
            }
        } else {
            // No surface(s) specified at all.
            // Default: a single output surface which is full-res YUV.
            Size maxYuvSize = ItsUtils.getMaxOutputSize(
                    mCameraCharacteristics, ImageFormat.YUV_420_888);
            numSurfaces = backgroundRequest ? 2 : 1;

            outputSizes = new Size[numSurfaces];
            outputFormats = new int[numSurfaces];
            outputSizes[0] = maxYuvSize;
            outputFormats[0] = ImageFormat.YUV_420_888;
            if (backgroundRequest) {
                outputSizes[1] = new Size(640, 480);
                outputFormats[1] = ImageFormat.YUV_420_888;
            }
        }

        prepareImageReaders(outputSizes, outputFormats, inputSize, inputFormat, maxInputBuffers);
    }

    /**
     * Wait until mCountCallbacksRemaining is 0 or a specified amount of time has elapsed between
     * each callback.
     */
    private void waitForCallbacks(long timeoutMs) throws ItsException {
        synchronized(mCountCallbacksRemaining) {
            int currentCount = mCountCallbacksRemaining.get();
            while (currentCount > 0) {
                try {
                    mCountCallbacksRemaining.wait(timeoutMs);
                } catch (InterruptedException e) {
                    throw new ItsException(""Waiting for callbacks was interrupted."", e);
                }

                int newCount = mCountCallbacksRemaining.get();
                if (newCount == currentCount) {
                    throw new ItsException(""No callback received within timeout "" +
                            timeoutMs + ""ms"");
                }
                currentCount = newCount;
            }
        }
    }

    private void doCapture(JSONObject params) throws ItsException {
        try {
            // Parse the JSON to get the list of capture requests.
            List<CaptureRequest.Builder> requests = ItsSerializer.deserializeRequestList(
                    mCamera, params, ""captureRequests"");

            // optional background preview requests
            List<CaptureRequest.Builder> backgroundRequests = ItsSerializer.deserializeRequestList(
                    mCamera, params, ""repeatRequests"");
            boolean backgroundRequest = backgroundRequests.size() > 0;

            int numSurfaces = 0;
            int numCaptureSurfaces = 0;
            BlockingSessionCallback sessionListener = new BlockingSessionCallback();
            try {
                mCountRawOrDng.set(0);
                mCountJpg.set(0);
                mCountYuv.set(0);
                mCountRaw10.set(0);
                mCountRaw12.set(0);
                mCountCapRes.set(0);
                mCaptureRawIsDng = false;
                mCaptureRawIsStats = false;
                mCaptureResults = new CaptureResult[requests.size()];

                JSONArray jsonOutputSpecs = ItsUtils.getOutputSpecs(params);

                prepareImageReadersWithOutputSpecs(jsonOutputSpecs, /*inputSize*/null,
                        /*inputFormat*/0, /*maxInputBuffers*/0, backgroundRequest);
                numSurfaces = mOutputImageReaders.length;
                numCaptureSurfaces = numSurfaces - (backgroundRequest ? 1 : 0);

                List<OutputConfiguration> outputConfigs =
                        new ArrayList<OutputConfiguration>(numSurfaces);
                for (int i = 0; i < numSurfaces; i++) {
                    OutputConfiguration config = new OutputConfiguration(
                            mOutputImageReaders[i].getSurface());
                    if (mPhysicalStreamMap.get(i) != null) {
                        config.setPhysicalCameraId(mPhysicalStreamMap.get(i));
                    }
                    outputConfigs.add(config);
                }
                mCamera.createCaptureSessionByOutputConfigurations(outputConfigs,
                        sessionListener, mCameraHandler);
                mSession = sessionListener.waitAndGetSession(TIMEOUT_IDLE_MS);

                for (int i = 0; i < numSurfaces; i++) {
                    ImageReader.OnImageAvailableListener readerListener;
                    if (backgroundRequest && i == numSurfaces - 1) {
                        readerListener = createAvailableListenerDropper();
                    } else {
                        readerListener = createAvailableListener(mCaptureCallback);
                    }
                    mOutputImageReaders[i].setOnImageAvailableListener(readerListener,
                            mSaveHandlers[i]);
                }

                // Plan for how many callbacks need to be received throughout the duration of this
                // sequence of capture requests. There is one callback per image surface, and one
                // callback for the CaptureResult, for each capture.
                int numCaptures = requests.size();
                mCountCallbacksRemaining.set(numCaptures * (numCaptureSurfaces + 1));

            } catch (CameraAccessException e) {
                throw new ItsException(""Error configuring outputs"", e);
            }

            // Start background requests and let it warm up pipeline
            if (backgroundRequest) {
                List<CaptureRequest> bgRequestList =
                        new ArrayList<CaptureRequest>(backgroundRequests.size());
                for (int i = 0; i < backgroundRequests.size(); i++) {
                    CaptureRequest.Builder req = backgroundRequests.get(i);
                    req.addTarget(mOutputImageReaders[numCaptureSurfaces].getSurface());
                    bgRequestList.add(req.build());
                }
                mSession.setRepeatingBurst(bgRequestList, null, null);
                // warm up the pipeline
                Thread.sleep(PIPELINE_WARMUP_TIME_MS);
            }

            // Initiate the captures.
            long maxExpTimeNs = -1;
            List<CaptureRequest> requestList =
                    new ArrayList<>(requests.size());
            for (int i = 0; i < requests.size(); i++) {
                CaptureRequest.Builder req = requests.get(i);
                // For DNG captures, need the LSC map to be available.
                if (mCaptureRawIsDng) {
                    req.set(CaptureRequest.STATISTICS_LENS_SHADING_MAP_MODE, 1);
                }
                Long expTimeNs = req.get(CaptureRequest.SENSOR_EXPOSURE_TIME);
                if (expTimeNs != null && expTimeNs > maxExpTimeNs) {
                    maxExpTimeNs = expTimeNs;
                }

                for (int j = 0; j < numCaptureSurfaces; j++) {
                    req.addTarget(mOutputImageReaders[j].getSurface());
                }
                requestList.add(req.build());
            }
            mSession.captureBurst(requestList, mCaptureResultListener, mResultHandler);

            long timeout = TIMEOUT_CALLBACK * 1000;
            if (maxExpTimeNs > 0) {
                timeout += maxExpTimeNs / 1000000; // ns to ms
            }
            // Make sure all callbacks have been hit (wait until captures are done).
            // If no timeouts are received after a timeout, then fail.
            waitForCallbacks(timeout);

            // Close session and wait until session is fully closed
            mSession.close();
            sessionListener.getStateWaiter().waitForState(
                    BlockingSessionCallback.SESSION_CLOSED, TIMEOUT_SESSION_CLOSE);

        } catch (android.hardware.camera2.CameraAccessException e) {
            throw new ItsException(""Access error: "", e);
        } catch (InterruptedException e) {
            throw new ItsException(""Unexpected InterruptedException: "", e);
        }
    }

    /**
     * Perform reprocess captures.
     *
     * It takes captureRequests in a JSON object and perform capture requests in two steps:
     * regular capture request to get reprocess input and reprocess capture request to get
     * reprocess outputs.
     *
     * Regular capture requests:
     *   1. For each capture request in the JSON object, create a full-size capture request with
     *      the settings in the JSON object.
     *   2. Remember and clear noise reduction, edge enhancement, and effective exposure factor
     *      from the regular capture requests. (Those settings will be used for reprocess requests.)
     *   3. Submit the regular capture requests.
     *
     * Reprocess capture requests:
     *   4. Wait for the regular capture results and use them to create reprocess capture requests.
     *   5. Wait for the regular capture output images and queue them to the image writer.
     *   6. Set the noise reduction, edge enhancement, and effective exposure factor from #2.
     *   7. Submit the reprocess capture requests.
     *
     * The output images and results for the regular capture requests won't be written to socket.
     * The output images and results for the reprocess capture requests will be written to socket.
     */
    private void doReprocessCapture(JSONObject params) throws ItsException {
        ImageWriter imageWriter = null;
        ArrayList<Integer> noiseReductionModes = new ArrayList<>();
        ArrayList<Integer> edgeModes = new ArrayList<>();
        ArrayList<Float> effectiveExposureFactors = new ArrayList<>();

        mCountRawOrDng.set(0);
        mCountJpg.set(0);
        mCountYuv.set(0);
        mCountRaw10.set(0);
        mCountRaw12.set(0);
        mCountCapRes.set(0);
        mCaptureRawIsDng = false;
        mCaptureRawIsStats = false;

        try {
            // Parse the JSON to get the list of capture requests.
            List<CaptureRequest.Builder> inputRequests =
                    ItsSerializer.deserializeRequestList(mCamera, params, ""captureRequests"");

            // Prepare the image readers for reprocess input and reprocess outputs.
            int inputFormat = getReprocessInputFormat(params);
            Size inputSize = ItsUtils.getMaxOutputSize(mCameraCharacteristics, inputFormat);
            JSONArray jsonOutputSpecs = ItsUtils.getOutputSpecs(params);
            prepareImageReadersWithOutputSpecs(jsonOutputSpecs, inputSize, inputFormat,
                    inputRequests.size(), /*backgroundRequest*/false);

            // Prepare a reprocessable session.
            int numOutputSurfaces = mOutputImageReaders.length;
            InputConfiguration inputConfig = new InputConfiguration(inputSize.getWidth(),
                    inputSize.getHeight(), inputFormat);
            List<Surface> outputSurfaces = new ArrayList<Surface>();
            boolean addSurfaceForInput = true;
            for (int i = 0; i < numOutputSurfaces; i++) {
                outputSurfaces.add(mOutputImageReaders[i].getSurface());
                if (mOutputImageReaders[i] == mInputImageReader) {
                    // If input and one of the outputs share the same image reader, avoid
                    // adding the same surfaces twice.
                    addSurfaceForInput = false;
                }
            }

            if (addSurfaceForInput) {
                // Besides the output surfaces specified in JSON object, add an additional one
                // for reprocess input.
                outputSurfaces.add(mInputImageReader.getSurface());
            }

            BlockingSessionCallback sessionListener = new BlockingSessionCallback();
            mCamera.createReprocessableCaptureSession(inputConfig, outputSurfaces, sessionListener,
                    mCameraHandler);
            mSession = sessionListener.waitAndGetSession(TIMEOUT_IDLE_MS);

            // Create an image writer for reprocess input.
            Surface inputSurface = mSession.getInputSurface();
            imageWriter = ImageWriter.newInstance(inputSurface, inputRequests.size());

            // Set up input reader listener and capture callback listener to get
            // reprocess input buffers and the results in order to create reprocess capture
            // requests.
            ImageReaderListenerWaiter inputReaderListener = new ImageReaderListenerWaiter();
            mInputImageReader.setOnImageAvailableListener(inputReaderListener, mSaveHandlers[0]);

            CaptureCallbackWaiter captureCallbackWaiter = new CaptureCallbackWaiter();
            // Prepare the reprocess input request
            for (CaptureRequest.Builder inputReqest : inputRequests) {
                // Remember and clear noise reduction, edge enhancement, and effective exposure
                // factors.
                noiseReductionModes.add(inputReqest.get(CaptureRequest.NOISE_REDUCTION_MODE));
                edgeModes.add(inputReqest.get(CaptureRequest.EDGE_MODE));
                effectiveExposureFactors.add(inputReqest.get(
                        CaptureRequest.REPROCESS_EFFECTIVE_EXPOSURE_FACTOR));

                inputReqest.set(CaptureRequest.NOISE_REDUCTION_MODE,
                        CaptureRequest.NOISE_REDUCTION_MODE_ZERO_SHUTTER_LAG);
                inputReqest.set(CaptureRequest.EDGE_MODE, CaptureRequest.EDGE_MODE_ZERO_SHUTTER_LAG);
                inputReqest.set(CaptureRequest.REPROCESS_EFFECTIVE_EXPOSURE_FACTOR, null);
                inputReqest.addTarget(mInputImageReader.getSurface());
                mSession.capture(inputReqest.build(), captureCallbackWaiter, mResultHandler);
            }

            // Wait for reprocess input images
            ArrayList<CaptureRequest.Builder> reprocessOutputRequests = new ArrayList<>();
            for (int i = 0; i < inputRequests.size(); i++) {
                TotalCaptureResult result =
                        captureCallbackWaiter.getResult(TIMEOUT_CALLBACK * 1000);
                reprocessOutputRequests.add(mCamera.createReprocessCaptureRequest(result));
                imageWriter.queueInputImage(inputReaderListener.getImage(TIMEOUT_CALLBACK * 1000));
            }

            // Start performing reprocess captures.

            mCaptureResults = new CaptureResult[inputRequests.size()];

            // Prepare reprocess capture requests.
            for (int i = 0; i < numOutputSurfaces; i++) {
                ImageReader.OnImageAvailableListener outputReaderListener =
                        createAvailableListener(mCaptureCallback);
                mOutputImageReaders[i].setOnImageAvailableListener(outputReaderListener,
                        mSaveHandlers[i]);
            }

            // Plan for how many callbacks need to be received throughout the duration of this
            // sequence of capture requests. There is one callback per image surface, and one
            // callback for the CaptureResult, for each capture.
            int numCaptures = reprocessOutputRequests.size();
            mCountCallbacksRemaining.set(numCaptures * (numOutputSurfaces + 1));

            // Initiate the captures.
            for (int i = 0; i < reprocessOutputRequests.size(); i++) {
                CaptureRequest.Builder req = reprocessOutputRequests.get(i);
                for (ImageReader outputImageReader : mOutputImageReaders) {
                    req.addTarget(outputImageReader.getSurface());
                }

                req.set(CaptureRequest.NOISE_REDUCTION_MODE, noiseReductionModes.get(i));
                req.set(CaptureRequest.EDGE_MODE, edgeModes.get(i));
                req.set(CaptureRequest.REPROCESS_EFFECTIVE_EXPOSURE_FACTOR,
                        effectiveExposureFactors.get(i));

                mSession.capture(req.build(), mCaptureResultListener, mResultHandler);
            }

            // Make sure all callbacks have been hit (wait until captures are done).
            // If no timeouts are received after a timeout, then fail.
            waitForCallbacks(TIMEOUT_CALLBACK * 1000);
        } catch (android.hardware.camera2.CameraAccessException e) {
            throw new ItsException(""Access error: "", e);
        } finally {
            closeImageReaders();
            if (mSession != null) {
                mSession.close();
                mSession = null;
            }
            if (imageWriter != null) {
                imageWriter.close();
            }
        }
    }

    @Override
    public final void onAccuracyChanged(Sensor sensor, int accuracy) {
        Logt.i(TAG, ""Sensor "" + sensor.getName() + "" accuracy changed to "" + accuracy);
    }

    @Override
    public final void onSensorChanged(SensorEvent event) {
        synchronized(mEventLock) {
            if (mEventsEnabled) {
                MySensorEvent ev2 = new MySensorEvent();
                ev2.sensor = event.sensor;
                ev2.accuracy = event.accuracy;
                ev2.timestamp = event.timestamp;
                ev2.values = new float[event.values.length];
                System.arraycopy(event.values, 0, ev2.values, 0, event.values.length);
                mEvents.add(ev2);
            }
        }
    }

    private final CaptureCallback mCaptureCallback = new CaptureCallback() {
        @Override
        public void onCaptureAvailable(Image capture, String physicalCameraId) {
            try {
                int format = capture.getFormat();
                if (format == ImageFormat.JPEG) {
                    Logt.i(TAG, ""Received JPEG capture"");
                    byte[] img = ItsUtils.getDataFromImage(capture, mSocketQueueQuota);
                    ByteBuffer buf = ByteBuffer.wrap(img);
                    int count = mCountJpg.getAndIncrement();
                    mSocketRunnableObj.sendResponseCaptureBuffer(""jpegImage""+physicalCameraId, buf);
                } else if (format == ImageFormat.YUV_420_888) {
                    Logt.i(TAG, ""Received YUV capture"");
                    byte[] img = ItsUtils.getDataFromImage(capture, mSocketQueueQuota);
                    ByteBuffer buf = ByteBuffer.wrap(img);
                    mSocketRunnableObj.sendResponseCaptureBuffer(
                            ""yuvImage""+physicalCameraId, buf);
                } else if (format == ImageFormat.RAW10) {
                    Logt.i(TAG, ""Received RAW10 capture"");
                    byte[] img = ItsUtils.getDataFromImage(capture, mSocketQueueQuota);
                    ByteBuffer buf = ByteBuffer.wrap(img);
                    int count = mCountRaw10.getAndIncrement();
                    mSocketRunnableObj.sendResponseCaptureBuffer(
                            ""raw10Image""+physicalCameraId, buf);
                } else if (format == ImageFormat.RAW12) {
                    Logt.i(TAG, ""Received RAW12 capture"");
                    byte[] img = ItsUtils.getDataFromImage(capture, mSocketQueueQuota);
                    ByteBuffer buf = ByteBuffer.wrap(img);
                    int count = mCountRaw12.getAndIncrement();
                    mSocketRunnableObj.sendResponseCaptureBuffer(""raw12Image""+physicalCameraId, buf);
                } else if (format == ImageFormat.RAW_SENSOR) {
                    Logt.i(TAG, ""Received RAW16 capture"");
                    int count = mCountRawOrDng.getAndIncrement();
                    if (! mCaptureRawIsDng) {
                        byte[] img = ItsUtils.getDataFromImage(capture, mSocketQueueQuota);
                        if (! mCaptureRawIsStats) {
                            ByteBuffer buf = ByteBuffer.wrap(img);
                            mSocketRunnableObj.sendResponseCaptureBuffer(
                                    ""rawImage"" + physicalCameraId, buf);
                        } else {
                            // Compute the requested stats on the raw frame, and return the results
                            // in a new ""stats image"".
                            long startTimeMs = SystemClock.elapsedRealtime();
                            int w = capture.getWidth();
                            int h = capture.getHeight();
                            int aaw = ItsUtils.getActiveArrayCropRegion(mCameraCharacteristics)
                                              .width();
                            int aah = ItsUtils.getActiveArrayCropRegion(mCameraCharacteristics)
                                              .height();
                            int aax = ItsUtils.getActiveArrayCropRegion(mCameraCharacteristics)
                                              .left;
                            int aay = ItsUtils.getActiveArrayCropRegion(mCameraCharacteristics)
                                              .top;

                            if (w == aaw) {
                                aax = 0;
                            }
                            if (h == aah) {
                                aay = 0;
                            }

                            int gw = mCaptureStatsGridWidth;
                            int gh = mCaptureStatsGridHeight;
                            float[] stats = StatsImage.computeStatsImage(
                                                             img, w, h, aax, aay, aaw, aah, gw, gh);
                            long endTimeMs = SystemClock.elapsedRealtime();
                            Log.e(TAG, ""Raw stats computation takes "" + (endTimeMs - startTimeMs) + "" ms"");
                            int statsImgSize = stats.length * 4;
                            if (mSocketQueueQuota != null) {
                                mSocketQueueQuota.release(img.length);
                                mSocketQueueQuota.acquire(statsImgSize);
                            }
                            ByteBuffer bBuf = ByteBuffer.allocate(statsImgSize);
                            bBuf.order(ByteOrder.nativeOrder());
                            FloatBuffer fBuf = bBuf.asFloatBuffer();
                            fBuf.put(stats);
                            fBuf.position(0);
                            mSocketRunnableObj.sendResponseCaptureBuffer(
                                    ""rawStatsImage""+physicalCameraId, bBuf);
                        }
                    } else {
                        // Wait until the corresponding capture result is ready, up to a timeout.
                        long t0 = android.os.SystemClock.elapsedRealtime();
                        while (! mThreadExitFlag
                                && android.os.SystemClock.elapsedRealtime()-t0 < TIMEOUT_CAP_RES) {
                            if (mCaptureResults[count] != null) {
                                Logt.i(TAG, ""Writing capture as DNG"");
                                DngCreator dngCreator = new DngCreator(
                                        mCameraCharacteristics, mCaptureResults[count]);
                                ByteArrayOutputStream dngStream = new ByteArrayOutputStream();
                                dngCreator.writeImage(dngStream, capture);
                                byte[] dngArray = dngStream.toByteArray();
                                if (mSocketQueueQuota != null) {
                                    // Ideally we should acquire before allocating memory, but
                                    // here the DNG size is unknown before toByteArray call, so
                                    // we have to register the size afterward. This should still
                                    // works most of the time since all DNG images are handled by
                                    // the same handler thread, so we are at most one buffer over
                                    // the quota.
                                    mSocketQueueQuota.acquire(dngArray.length);
                                }
                                ByteBuffer dngBuf = ByteBuffer.wrap(dngArray);
                                mSocketRunnableObj.sendResponseCaptureBuffer(""dngImage"", dngBuf);
                                break;
                            } else {
                                Thread.sleep(1);
                            }
                        }
                    }
                } else if (format == ImageFormat.Y8) {
                    Logt.i(TAG, ""Received Y8 capture"");
                    byte[] img = ItsUtils.getDataFromImage(capture, mSocketQueueQuota);
                    ByteBuffer buf = ByteBuffer.wrap(img);
                    mSocketRunnableObj.sendResponseCaptureBuffer(
                            ""y8Image""+physicalCameraId, buf);
                } else {
                    throw new ItsException(""Unsupported image format: "" + format);
                }

                synchronized(mCountCallbacksRemaining) {
                    mCountCallbacksRemaining.decrementAndGet();
                    mCountCallbacksRemaining.notify();
                }
            } catch (IOException e) {
                Logt.e(TAG, ""Script error: "", e);
            } catch (InterruptedException e) {
                Logt.e(TAG, ""Script error: "", e);
            } catch (ItsException e) {
                Logt.e(TAG, ""Script error: "", e);
            }
        }
    };

    private static float r2f(Rational r) {
        return (float)r.getNumerator() / (float)r.getDenominator();
    }

    private boolean hasCapability(int capability) throws ItsException {
        int[] capabilities = mCameraCharacteristics.get(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
        if (capabilities == null) {
            throw new ItsException(""Failed to get capabilities"");
        }
        for (int c : capabilities) {
            if (c == capability) {
                return true;
            }
        }
        return false;
    }

    private String buildLogString(CaptureResult result) throws ItsException {
        StringBuilder logMsg = new StringBuilder();
        logMsg.append(String.format(
                ""Capt result: AE=%d, AF=%d, AWB=%d, "",
                result.get(CaptureResult.CONTROL_AE_STATE),
                result.get(CaptureResult.CONTROL_AF_STATE),
                result.get(CaptureResult.CONTROL_AWB_STATE)));

        boolean readSensorSettings = hasCapability(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_READ_SENSOR_SETTINGS);

        if (readSensorSettings) {
            logMsg.append(String.format(
                    ""sens=%d, exp=%.1fms, dur=%.1fms, "",
                    result.get(CaptureResult.SENSOR_SENSITIVITY),
                    result.get(CaptureResult.SENSOR_EXPOSURE_TIME).longValue() / 1000000.0f,
                    result.get(CaptureResult.SENSOR_FRAME_DURATION).longValue() /
                                1000000.0f));
        }
        if (result.get(CaptureResult.COLOR_CORRECTION_GAINS) != null) {
            logMsg.append(String.format(
                    ""gains=[%.1f, %.1f, %.1f, %.1f], "",
                    result.get(CaptureResult.COLOR_CORRECTION_GAINS).getRed(),
                    result.get(CaptureResult.COLOR_CORRECTION_GAINS).getGreenEven(),
                    result.get(CaptureResult.COLOR_CORRECTION_GAINS).getGreenOdd(),
                    result.get(CaptureResult.COLOR_CORRECTION_GAINS).getBlue()));
        } else {
            logMsg.append(""gains=[], "");
        }
        if (result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM) != null) {
            logMsg.append(String.format(
                    ""xform=[%.1f, %.1f, %.1f, %.1f, %.1f, %.1f, %.1f, %.1f, %.1f], "",
                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).getElement(0,0)),
                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).getElement(1,0)),
                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).getElement(2,0)),
                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).getElement(0,1)),
                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).getElement(1,1)),
                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).getElement(2,1)),
                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).getElement(0,2)),
                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).getElement(1,2)),
                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).getElement(2,2))));
        } else {
            logMsg.append(""xform=[], "");
        }
        logMsg.append(String.format(
                ""foc=%.1f"",
                result.get(CaptureResult.LENS_FOCUS_DISTANCE)));
        return logMsg.toString();
    }

    private class ThreeAResultListener extends CaptureResultListener {
        private volatile boolean stopped = false;
        private boolean aeResultSent = false;
        private boolean awbResultSent = false;
        private boolean afResultSent = false;

        @Override
        public void onCaptureStarted(CameraCaptureSession session, CaptureRequest request,
                long timestamp, long frameNumber) {
        }

        @Override
        public void onCaptureCompleted(CameraCaptureSession session, CaptureRequest request,
                TotalCaptureResult result) {
            try {
                if (stopped) {
                    return;
                }

                if (request == null || result == null) {
                    throw new ItsException(""Request/result is invalid"");
                }

                Logt.i(TAG, buildLogString(result));

                synchronized(m3AStateLock) {
                    if (result.get(CaptureResult.CONTROL_AE_STATE) != null) {
                        mConvergedAE = result.get(CaptureResult.CONTROL_AE_STATE) ==
                                                  CaptureResult.CONTROL_AE_STATE_CONVERGED ||
                                       result.get(CaptureResult.CONTROL_AE_STATE) ==
                                                  CaptureResult.CONTROL_AE_STATE_FLASH_REQUIRED ||
                                       result.get(CaptureResult.CONTROL_AE_STATE) ==
                                                  CaptureResult.CONTROL_AE_STATE_LOCKED;
                        mLockedAE = result.get(CaptureResult.CONTROL_AE_STATE) ==
                                               CaptureResult.CONTROL_AE_STATE_LOCKED;
                    }
                    if (result.get(CaptureResult.CONTROL_AF_STATE) != null) {
                        mConvergedAF = result.get(CaptureResult.CONTROL_AF_STATE) ==
                                                  CaptureResult.CONTROL_AF_STATE_FOCUSED_LOCKED;
                    }
                    if (result.get(CaptureResult.CONTROL_AWB_STATE) != null) {
                        mConvergedAWB = result.get(CaptureResult.CONTROL_AWB_STATE) ==
                                                   CaptureResult.CONTROL_AWB_STATE_CONVERGED ||
                                        result.get(CaptureResult.CONTROL_AWB_STATE) ==
                                                   CaptureResult.CONTROL_AWB_STATE_LOCKED;
                        mLockedAWB = result.get(CaptureResult.CONTROL_AWB_STATE) ==
                                                CaptureResult.CONTROL_AWB_STATE_LOCKED;
                    }

                    if (mConvergedAE && (!mNeedsLockedAE || mLockedAE) && !aeResultSent) {
                        aeResultSent = true;
                        if (result.get(CaptureResult.SENSOR_SENSITIVITY) != null
                                && result.get(CaptureResult.SENSOR_EXPOSURE_TIME) != null) {
                            mSocketRunnableObj.sendResponse(""aeResult"", String.format(""%d %d"",
                                    result.get(CaptureResult.SENSOR_SENSITIVITY).intValue(),
                                    result.get(CaptureResult.SENSOR_EXPOSURE_TIME).intValue()
                                    ));
                        } else {
                            Logt.i(TAG, String.format(
                                    ""AE converged but NULL exposure values, sensitivity:%b, expTime:%b"",
                                    result.get(CaptureResult.SENSOR_SENSITIVITY) == null,
                                    result.get(CaptureResult.SENSOR_EXPOSURE_TIME) == null));
                        }
                    }

                    if (mConvergedAF && !afResultSent) {
                        afResultSent = true;
                        if (result.get(CaptureResult.LENS_FOCUS_DISTANCE) != null) {
                            mSocketRunnableObj.sendResponse(""afResult"", String.format(""%f"",
                                    result.get(CaptureResult.LENS_FOCUS_DISTANCE)
                                    ));
                        } else {
                            Logt.i(TAG, ""AF converged but NULL focus distance values"");
                        }
                    }

                    if (mConvergedAWB && (!mNeedsLockedAWB || mLockedAWB) && !awbResultSent) {
                        awbResultSent = true;
                        if (result.get(CaptureResult.COLOR_CORRECTION_GAINS) != null
                                && result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM) != null) {
                            mSocketRunnableObj.sendResponse(""awbResult"", String.format(
                                    ""%f %f %f %f %f %f %f %f %f %f %f %f %f"",
                                    result.get(CaptureResult.COLOR_CORRECTION_GAINS).getRed(),
                                    result.get(CaptureResult.COLOR_CORRECTION_GAINS).getGreenEven(),
                                    result.get(CaptureResult.COLOR_CORRECTION_GAINS).getGreenOdd(),
                                    result.get(CaptureResult.COLOR_CORRECTION_GAINS).getBlue(),
                                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).
                                            getElement(0,0)),
                                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).
                                            getElement(1,0)),
                                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).
                                            getElement(2,0)),
                                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).
                                            getElement(0,1)),
                                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).
                                            getElement(1,1)),
                                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).
                                            getElement(2,1)),
                                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).
                                            getElement(0,2)),
                                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).
                                            getElement(1,2)),
                                    r2f(result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM).
                                            getElement(2,2))));
                        } else {
                            Logt.i(TAG, String.format(
                                    ""AWB converged but NULL color correction values, gains:%b, ccm:%b"",
                                    result.get(CaptureResult.COLOR_CORRECTION_GAINS) == null,
                                    result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM) == null));
                        }
                    }
                }

                mInterlock3A.open();
            } catch (ItsException e) {
                Logt.e(TAG, ""Script error: "", e);
            } catch (Exception e) {
                Logt.e(TAG, ""Script error: "", e);
            }
        }

        @Override
        public void onCaptureFailed(CameraCaptureSession session, CaptureRequest request,
                CaptureFailure failure) {
            Logt.e(TAG, ""Script error: capture failed"");
        }

        public void stop() {
            stopped = true;
        }
    }

    private final CaptureResultListener mCaptureResultListener = new CaptureResultListener() {
        @Override
        public void onCaptureStarted(CameraCaptureSession session, CaptureRequest request,
                long timestamp, long frameNumber) {
        }

        @Override
        public void onCaptureCompleted(CameraCaptureSession session, CaptureRequest request,
                TotalCaptureResult result) {
            try {
                if (request == null || result == null) {
                    throw new ItsException(""Request/result is invalid"");
                }

                Logt.i(TAG, buildLogString(result));

                int count = mCountCapRes.getAndIncrement();
                mCaptureResults[count] = result;
                mSocketRunnableObj.sendResponseCaptureResult(mCameraCharacteristics,
                        request, result, mOutputImageReaders);
                synchronized(mCountCallbacksRemaining) {
                    mCountCallbacksRemaining.decrementAndGet();
                    mCountCallbacksRemaining.notify();
                }
            } catch (ItsException e) {
                Logt.e(TAG, ""Script error: "", e);
            } catch (Exception e) {
                Logt.e(TAG, ""Script error: "", e);
            }
        }

        @Override
        public void onCaptureFailed(CameraCaptureSession session, CaptureRequest request,
                CaptureFailure failure) {
            Logt.e(TAG, ""Script error: capture failed"");
        }
    };

    private class CaptureCallbackWaiter extends CameraCaptureSession.CaptureCallback {
        private final LinkedBlockingQueue<TotalCaptureResult> mResultQueue =
                new LinkedBlockingQueue<>();

        @Override
        public void onCaptureStarted(CameraCaptureSession session, CaptureRequest request,
                long timestamp, long frameNumber) {
        }

        @Override
        public void onCaptureCompleted(CameraCaptureSession session, CaptureRequest request,
                TotalCaptureResult result) {
            try {
                mResultQueue.put(result);
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(
                        ""Can't handle InterruptedException in onImageAvailable"");
            }
        }

        @Override
        public void onCaptureFailed(CameraCaptureSession session, CaptureRequest request,
                CaptureFailure failure) {
            Logt.e(TAG, ""Script error: capture failed"");
        }

        public TotalCaptureResult getResult(long timeoutMs) throws ItsException {
            TotalCaptureResult result;
            try {
                result = mResultQueue.poll(timeoutMs, TimeUnit.MILLISECONDS);
            } catch (InterruptedException e) {
                throw new ItsException(e);
            }

            if (result == null) {
                throw new ItsException(""Getting an image timed out after "" + timeoutMs +
                        ""ms"");
            }

            return result;
        }
    }

    private static class ImageReaderListenerWaiter implements ImageReader.OnImageAvailableListener {
        private final LinkedBlockingQueue<Image> mImageQueue = new LinkedBlockingQueue<>();

        @Override
        public void onImageAvailable(ImageReader reader) {
            try {
                mImageQueue.put(reader.acquireNextImage());
            } catch (InterruptedException e) {
                throw new UnsupportedOperationException(
                        ""Can't handle InterruptedException in onImageAvailable"");
            }
        }

        public Image getImage(long timeoutMs) throws ItsException {
            Image image;
            try {
                image = mImageQueue.poll(timeoutMs, TimeUnit.MILLISECONDS);
            } catch (InterruptedException e) {
                throw new ItsException(e);
            }

            if (image == null) {
                throw new ItsException(""Getting an image timed out after "" + timeoutMs +
                        ""ms"");
            }
            return image;
        }
    }

    private int getReprocessInputFormat(JSONObject params) throws ItsException {
        String reprocessFormat;
        try {
            reprocessFormat = params.getString(""reprocessFormat"");
        } catch (org.json.JSONException e) {
            throw new ItsException(""Error parsing reprocess format: "" + e);
        }

        if (reprocessFormat.equals(""yuv"")) {
            return ImageFormat.YUV_420_888;
        } else if (reprocessFormat.equals(""private"")) {
            return ImageFormat.PRIVATE;
        }

        throw new ItsException(""Uknown reprocess format: "" + reprocessFormat);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.RotationVectorTestActivity"	"RotationVectorTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/RotationVectorTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;
import com.android.cts.verifier.sensors.renderers.GLArrowSensorTestRenderer;

import junit.framework.Assert;

import android.content.Context;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.hardware.cts.helpers.SensorNotSupportedException;
import android.hardware.cts.helpers.SensorTestStateNotSupportedException;
import android.os.Bundle;
import android.util.Log;

import java.util.concurrent.TimeUnit;

/**
 * This test verifies that mobile device can detect it's orientation in space and after device
 * movement in space it correctly detects original (reference) position.
 * All three rotation vectors are tested:
 * - ROTATION_VECTOR,
 * - GEOMAGNETIC_ROTATION_VECTOR,
 * - GAME_ROTATION_VECTOR.
 */
public class RotationVectorTestActivity
        extends SensorCtsVerifierTestActivity
        implements SensorEventListener {
    public RotationVectorTestActivity() {
        super(RotationVectorTestActivity.class);
    }

    private SensorManager mSensorManager;
    private SensorEventListener mListener;

    /**
     * Defines the thresholds for each rotation vector in degrees.
     */
    private static final double[] MAX_DEVIATION_DEGREES = {
        10.0, // ROTATION_VECTOR
        10.0, // GEOMAGNETIC ROTATION_VECTOR
        40.0, // GAME_ROTATION_VECTOR
    };

    private static final int MAX_SENSORS_AVAILABLE = 3;
    private static final int ROTATION_VECTOR_INDEX = 0;
    private static final int GEOMAGNETIC_ROTATION_VECTOR_INDEX = 1;
    private static final int GAME_ROTATION_VECTOR_INDEX = 2;

    private float[][] mLastEvent = new float[3][5];
    private final float[][] mReference = new float[3][16];
    private final float[][] mAngularChange = new float[3][3];
    private final Sensor[] mSensor = new Sensor[3];

    /**
     * The activity setup collects all the required data for test cases.
     * This approach allows to test all sensors at once.
     */
    @Override
    protected void activitySetUp() throws InterruptedException {
        if (mSensor[ROTATION_VECTOR_INDEX] == null
                && mSensor[GEOMAGNETIC_ROTATION_VECTOR_INDEX] == null
                && mSensor[GAME_ROTATION_VECTOR_INDEX] == null) {
            // if none of the sensors is supported, skip the test by throwing an exception
            throw new SensorTestStateNotSupportedException(""Rotation vectors are not supported."");
        }

        // TODO: take reference value automatically when device is 'still'
        clearText();
        appendText(R.string.snsr_rotation_vector_set_reference);
        waitForUserToContinue();

        clearText();
        for (int i = 0; i < MAX_SENSORS_AVAILABLE; ++i) {
            SensorManager.getRotationMatrixFromVector(mReference[i], mLastEvent[i].clone());
        }

        // TODO: check the user actually moved the device during the test
        appendText(R.string.snsr_rotation_vector_reference_set);
        appendText(R.string.snsr_rotation_vector_move_info);
        appendText(R.string.snsr_test_play_sound);
        Thread.sleep(TimeUnit.SECONDS.toMillis(30));
        playSound();

        // TODO: take final value automatically when device becomes 'still' at the end
        clearText();
        appendText(R.string.snsr_rotation_vector_set_final);
        waitForUserToContinue();

        clearText();
        closeGlSurfaceView();

        float[] finalVector = new float[16];
        for (int i = 0; i < MAX_SENSORS_AVAILABLE; ++i) {
            SensorManager.getRotationMatrixFromVector(finalVector, mLastEvent[i].clone());
            SensorManager.getAngleChange(mAngularChange[i], mReference[i], finalVector);
        }
    }

    /**
     * Verifies that a given 'Rotation Vector' sensor does not drift over time.
     * The test takes in consideration a reference measurement, and a final measurement. It then
     * calculates its angular change.
     */
    private String verifyVector(int sensorIndex, int sensorType)
            throws Throwable {
        Sensor sensor = mSensor[sensorIndex];
        if (sensor == null) {
            throw new SensorNotSupportedException(sensorType);
        }

        float[] angularChange = mAngularChange[sensorIndex];
        double maxDeviationDegrees = MAX_DEVIATION_DEGREES[sensorIndex];
        double maxComponentDegrees = findMaxComponentDegrees(angularChange);
        String message = getString(
                R.string.snsr_rotation_vector_verification,
                Math.toDegrees(angularChange[0]),
                Math.toDegrees(angularChange[1]),
                Math.toDegrees(angularChange[2]),
                maxComponentDegrees,
                maxDeviationDegrees);

        Assert.assertEquals(message, 0, maxComponentDegrees, maxDeviationDegrees);
        return message;
    }

    /**
     * Test cases.
     */
    public String testRotationVector() throws Throwable {
        return verifyVector(ROTATION_VECTOR_INDEX, Sensor.TYPE_ROTATION_VECTOR);
    }

    public String testGeomagneticRotationVector() throws Throwable {
        return verifyVector(
                GEOMAGNETIC_ROTATION_VECTOR_INDEX,
                Sensor.TYPE_GEOMAGNETIC_ROTATION_VECTOR);
    }

    public String testGameRotationVector() throws Throwable {
        return verifyVector(GAME_ROTATION_VECTOR_INDEX, Sensor.TYPE_GAME_ROTATION_VECTOR);
    }

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        // set up sensors first, so activitySetUp has the state in place
        mSensorManager = (SensorManager) getApplicationContext().getSystemService(
                Context.SENSOR_SERVICE);
        mSensor[ROTATION_VECTOR_INDEX] =
                mSensorManager.getDefaultSensor(Sensor.TYPE_ROTATION_VECTOR);
        mSensor[GEOMAGNETIC_ROTATION_VECTOR_INDEX] =
                mSensorManager.getDefaultSensor(Sensor.TYPE_GEOMAGNETIC_ROTATION_VECTOR);
        mSensor[GAME_ROTATION_VECTOR_INDEX] =
                mSensorManager.getDefaultSensor(Sensor.TYPE_GAME_ROTATION_VECTOR);

        super.onCreate(savedInstanceState);

        GLArrowSensorTestRenderer renderer =
                new GLArrowSensorTestRenderer(this, Sensor.TYPE_ROTATION_VECTOR);
        mListener = renderer;

        initializeGlSurfaceView(renderer);
    }

    @Override
    protected void onPause() {
        super.onPause();
        mSensorManager.unregisterListener(mListener);
        mSensorManager.unregisterListener(this);
    }

    @Override
    protected void onResume() {
        super.onResume();

        // listener for rendering
        boolean renderListenerRegistered = false;
        for (int i = 0; (!renderListenerRegistered && i < MAX_SENSORS_AVAILABLE); ++i) {
            Sensor sensor = mSensor[i];
            if (sensor != null) {
                renderListenerRegistered = mSensorManager
                        .registerListener(mListener, sensor, SensorManager.SENSOR_DELAY_GAME);
                Log.v(LOG_TAG, ""Renderer using sensor: "" + sensor.getName());
            }
        }

        // listeners for testing
        for (int i = 0; i < MAX_SENSORS_AVAILABLE; ++i) {
            mSensorManager.registerListener(this, mSensor[i], SensorManager.SENSOR_DELAY_GAME);
        }
    }

    @Override
    public void onSensorChanged(SensorEvent event) {
        if (event.sensor.getType() == Sensor.TYPE_ROTATION_VECTOR) {
            mLastEvent[ROTATION_VECTOR_INDEX] = event.values.clone();
        }
        if (event.sensor.getType() == Sensor.TYPE_GEOMAGNETIC_ROTATION_VECTOR) {
            mLastEvent[GEOMAGNETIC_ROTATION_VECTOR_INDEX] = event.values.clone();
        }
        if (event.sensor.getType() == Sensor.TYPE_GAME_ROTATION_VECTOR) {
            mLastEvent[GAME_ROTATION_VECTOR_INDEX] = event.values.clone();
        }
    }

    @Override
    public void onAccuracyChanged(Sensor sensor, int accuracy) {
    }

    private static double findMaxComponentDegrees(float[] vec) {
        float maxComponent = 0;
        for (int i = 0; i < vec.length; i++) {
            float absComp = Math.abs(vec[i]);
            if (maxComponent < absComp) {
                maxComponent = absComp;
            }
        }
        return Math.toDegrees(maxComponent);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.BurstCaptureTest"	"testYuvBurst"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/BurstCaptureTest.java"	""	"public void testYuvBurst() throws Exception {
        final int YUV_BURST_SIZE = 100;
        testBurst(ImageFormat.YUV_420_888, YUV_BURST_SIZE, true/*checkFrameRate*/,
                false/*testStillBokeh*/);
    }

    /**
     * Test JPEG burst capture with full-AUTO control.
     *
     * Also verifies sensor settings operation if READ_SENSOR_SETTINGS is available.
     * Compared to testYuvBurst, this test uses STILL_CAPTURE intent, and exercises path where
     * enableZsl is enabled.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.BurstCaptureTest"	"testJpegBurst"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/BurstCaptureTest.java"	""	"public void testJpegBurst() throws Exception {
        final int JPEG_BURST_SIZE = 10;
        testBurst(ImageFormat.JPEG, JPEG_BURST_SIZE, false/*checkFrameRate*/,
                false/*testStillBokeh*/);
    }

    /**
     * Test YUV burst capture with full-AUTO control and STILL_CAPTURE bokeh mode.
     * Also verifies sensor settings operation if READ_SENSOR_SETTINGS is available.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.BurstCaptureTest"	"testYuvBurstWithStillBokeh"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/BurstCaptureTest.java"	""	"public void testYuvBurstWithStillBokeh() throws Exception {
        final int YUV_BURST_SIZE = 100;
        testBurst(ImageFormat.YUV_420_888, YUV_BURST_SIZE, true/*checkFrameRate*/,
                true/*testStillBokeh*/);
    }

    private void testBurst(int fmt, int burstSize, boolean checkFrameRate, boolean testStillBokeh)
            throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                String id = mCameraIdsUnderTest[i];

                StaticMetadata staticInfo = mAllStaticInfo.get(id);
                if (!staticInfo.isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + id + "" does not support color outputs, skipping"");
                }
                if (!staticInfo.isAeLockSupported() || !staticInfo.isAwbLockSupported()) {
                    Log.i(TAG, ""AE/AWB lock is not supported in camera "" + id +
                            "". Skip the test"");
                    continue;
                }

                if (staticInfo.isHardwareLevelLegacy()) {
                    Log.i(TAG, ""Legacy camera doesn't report min frame duration"" +
                            "". Skip the test"");
                    continue;
                }

                Capability[] extendedSceneModeCaps =
                        staticInfo.getAvailableExtendedSceneModeCapsChecked();
                boolean supportStillBokeh = false;
                for (Capability cap : extendedSceneModeCaps) {
                    if (cap.getMode() ==
                            CameraMetadata.CONTROL_EXTENDED_SCENE_MODE_BOKEH_STILL_CAPTURE) {
                        supportStillBokeh = true;
                        break;
                    }
                }
                if (testStillBokeh && !supportStillBokeh) {
                    Log.v(TAG, ""Device doesn't support STILL_CAPTURE bokeh. Skip the test"");
                    continue;
                }

                openDevice(id);
                burstTestByCamera(id, fmt, burstSize, checkFrameRate, testStillBokeh);
            } finally {
                closeDevice();
                closeImageReader();
            }
        }
    }

    private void burstTestByCamera(String cameraId, int fmt, int burstSize,
            boolean checkFrameRate, boolean testStillBokeh) throws Exception {
        // Parameters
        final int MAX_CONVERGENCE_FRAMES = 150; // 5 sec at 30fps
        final long MAX_PREVIEW_RESULT_TIMEOUT_MS = 2000;
        final float FRAME_DURATION_MARGIN_FRACTION = 0.1f;

        // Find a good preview size (bound to 1080p)
        final Size previewSize = mOrderedPreviewSizes.get(0);

        // Get maximum size for fmt
        final Size stillSize = getSortedSizesForFormat(
                cameraId, mCameraManager, fmt, /*bound*/null).get(0);

        // Find max pipeline depth and sync latency
        final int maxPipelineDepth = mStaticInfo.getCharacteristics().get(
            CameraCharacteristics.REQUEST_PIPELINE_MAX_DEPTH);
        final int maxSyncLatency = mStaticInfo.getCharacteristics().get(
            CameraCharacteristics.SYNC_MAX_LATENCY);

        // Find minimum frame duration for full-res resolution
        StreamConfigurationMap config = mStaticInfo.getCharacteristics().get(
            CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
        final long minStillFrameDuration =
                config.getOutputMinFrameDuration(fmt, stillSize);


        Range<Integer> targetRange = getSuitableFpsRangeForDuration(cameraId, minStillFrameDuration);

        Log.i(TAG, String.format(""Selected frame rate range %d - %d for YUV burst"",
                        targetRange.getLower(), targetRange.getUpper()));

        // Check if READ_SENSOR_SETTINGS is supported
        final boolean checkSensorSettings = mStaticInfo.isCapabilitySupported(
            CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_READ_SENSOR_SETTINGS);

        // Configure basic preview and burst settings

        CaptureRequest.Builder previewBuilder =
            mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        int burstTemplate = (fmt == ImageFormat.JPEG) ?
                CameraDevice.TEMPLATE_STILL_CAPTURE : CameraDevice.TEMPLATE_PREVIEW;
        CaptureRequest.Builder burstBuilder = mCamera.createCaptureRequest(burstTemplate);
        Boolean enableZsl = burstBuilder.get(CaptureRequest.CONTROL_ENABLE_ZSL);
        boolean zslStillEnabled = enableZsl != null && enableZsl &&
                burstTemplate == CameraDevice.TEMPLATE_STILL_CAPTURE;

        previewBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE,
                targetRange);
        burstBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE,
                targetRange);
        burstBuilder.set(CaptureRequest.CONTROL_AE_LOCK, true);
        burstBuilder.set(CaptureRequest.CONTROL_AWB_LOCK, true);
        if (testStillBokeh) {
            previewBuilder.set(CaptureRequest.CONTROL_EXTENDED_SCENE_MODE,
                    CameraMetadata.CONTROL_EXTENDED_SCENE_MODE_BOKEH_STILL_CAPTURE);
            burstBuilder.set(CaptureRequest.CONTROL_EXTENDED_SCENE_MODE,
                    CameraMetadata.CONTROL_EXTENDED_SCENE_MODE_BOKEH_STILL_CAPTURE);
        }

        // Create session and start up preview

        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        SimpleCaptureCallback burstResultListener = new SimpleCaptureCallback();
        ImageDropperListener imageDropper = new ImageDropperListener();

        prepareCaptureAndStartPreview(
            previewBuilder, burstBuilder,
            previewSize, stillSize,
            fmt, resultListener,
            /*maxNumImages*/ 3, imageDropper);

        // Create burst

        List<CaptureRequest> burst = new ArrayList<>();
        for (int i = 0; i < burstSize; i++) {
            burst.add(burstBuilder.build());
        }

        // Converge AE/AWB

        int frameCount = 0;
        while (true) {
            CaptureResult result = resultListener.getCaptureResult(MAX_PREVIEW_RESULT_TIMEOUT_MS);
            int aeState = result.get(CaptureResult.CONTROL_AE_STATE);
            int awbState = result.get(CaptureResult.CONTROL_AWB_STATE);

            if (DEBUG) {
                Log.d(TAG, ""aeState: "" + aeState + "". awbState: "" + awbState);
            }

            if ((aeState == CaptureResult.CONTROL_AE_STATE_CONVERGED ||
                    aeState == CaptureResult.CONTROL_AE_STATE_FLASH_REQUIRED) &&
                    awbState == CaptureResult.CONTROL_AWB_STATE_CONVERGED) {
                break;
            }
            frameCount++;
            assertTrue(String.format(""Cam %s: Can not converge AE and AWB within %d frames"",
                    cameraId, MAX_CONVERGENCE_FRAMES),
                frameCount < MAX_CONVERGENCE_FRAMES);
        }

        // Lock AF if there's a focuser

        if (mStaticInfo.hasFocuser()) {
            previewBuilder.set(CaptureRequest.CONTROL_AF_TRIGGER,
                CaptureRequest.CONTROL_AF_TRIGGER_START);
            mSession.capture(previewBuilder.build(), resultListener, mHandler);
            previewBuilder.set(CaptureRequest.CONTROL_AF_TRIGGER,
                CaptureRequest.CONTROL_AF_TRIGGER_IDLE);

            frameCount = 0;
            while (true) {
                CaptureResult result = resultListener.getCaptureResult(MAX_PREVIEW_RESULT_TIMEOUT_MS);
                int afState = result.get(CaptureResult.CONTROL_AF_STATE);

                if (DEBUG) {
                    Log.d(TAG, ""afState: "" + afState);
                }

                if (afState == CaptureResult.CONTROL_AF_STATE_FOCUSED_LOCKED ||
                    afState == CaptureResult.CONTROL_AF_STATE_NOT_FOCUSED_LOCKED) {
                    break;
                }
                frameCount++;
                assertTrue(String.format(""Cam %s: Cannot lock AF within %d frames"", cameraId,
                        MAX_CONVERGENCE_FRAMES),
                    frameCount < MAX_CONVERGENCE_FRAMES);
            }
        }

        // Lock AE/AWB

        previewBuilder.set(CaptureRequest.CONTROL_AE_LOCK, true);
        previewBuilder.set(CaptureRequest.CONTROL_AWB_LOCK, true);

        CaptureRequest lockedRequest = previewBuilder.build();
        mSession.setRepeatingRequest(lockedRequest, resultListener, mHandler);

        // Wait for first result with locking
        resultListener.drain();
        CaptureResult lockedResult =
                resultListener.getCaptureResultForRequest(lockedRequest, maxPipelineDepth);

        int pipelineDepth = lockedResult.get(CaptureResult.REQUEST_PIPELINE_DEPTH);

        // Then start waiting on results to get the first result that should be synced
        // up, and also fire the burst as soon as possible

        if (maxSyncLatency == CameraCharacteristics.SYNC_MAX_LATENCY_PER_FRAME_CONTROL) {
            // The locked result we have is already synchronized so start the burst
            mSession.captureBurst(burst, burstResultListener, mHandler);
        } else {
            // Need to get a synchronized result, and may need to start burst later to
            // be synchronized correctly

            boolean burstSent = false;

            // Calculate how many requests we need to still send down to camera before we
            // know the settings have settled for the burst

            int numFramesWaited = maxSyncLatency;
            if (numFramesWaited == CameraCharacteristics.SYNC_MAX_LATENCY_UNKNOWN) {
                numFramesWaited = NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY;
            }

            int requestsNeededToSync = numFramesWaited - pipelineDepth;
            for (int i = 0; i < numFramesWaited; i++) {
                if (!burstSent && requestsNeededToSync <= 0) {
                    mSession.captureBurst(burst, burstResultListener, mHandler);
                    burstSent = true;
                }
                lockedResult = resultListener.getCaptureResult(MAX_PREVIEW_RESULT_TIMEOUT_MS);
                requestsNeededToSync--;
            }

            assertTrue(""Cam "" + cameraId + "": Burst failed to fire!"", burstSent);
        }

        // Read in locked settings if supported

        long burstExposure = 0;
        long burstFrameDuration = 0;
        int burstSensitivity = 0;
        if (checkSensorSettings) {
            burstExposure = lockedResult.get(CaptureResult.SENSOR_EXPOSURE_TIME);
            burstFrameDuration = lockedResult.get(CaptureResult.SENSOR_FRAME_DURATION);
            burstSensitivity = lockedResult.get(CaptureResult.SENSOR_SENSITIVITY);

            assertTrue(String.format(""Cam %s: Frame duration %d ns too short compared to "" +
                    ""exposure time %d ns"", cameraId, burstFrameDuration, burstExposure),
                burstFrameDuration >= burstExposure);

            assertTrue(String.format(""Cam %s: Exposure time is not valid: %d"",
                    cameraId, burstExposure),
                burstExposure > 0);
            assertTrue(String.format(""Cam %s: Frame duration is not valid: %d"",
                    cameraId, burstFrameDuration),
                burstFrameDuration > 0);
            assertTrue(String.format(""Cam %s: Sensitivity is not valid: %d"",
                    cameraId, burstSensitivity),
                burstSensitivity > 0);
        }

        // Process burst results
        int burstIndex = 0;
        CaptureResult burstResult =
                burstResultListener.getCaptureResult(MAX_PREVIEW_RESULT_TIMEOUT_MS);
        long prevTimestamp = -1;
        final long frameDurationBound = (long)
                (minStillFrameDuration * (1 + FRAME_DURATION_MARGIN_FRACTION) );

        long burstStartTimestamp = burstResult.get(CaptureResult.SENSOR_TIMESTAMP);
        long burstEndTimeStamp = 0;

        List<Long> frameDurations = new ArrayList<>();

        while(true) {
            // Verify the result
            assertTrue(""Cam "" + cameraId + "": Result doesn't match expected request"",
                    burstResult.getRequest() == burst.get(burstIndex));

            // Verify locked settings
            if (checkSensorSettings) {
                long exposure = burstResult.get(CaptureResult.SENSOR_EXPOSURE_TIME);
                int sensitivity = burstResult.get(CaptureResult.SENSOR_SENSITIVITY);
                assertTrue(""Cam "" + cameraId + "": Exposure not locked!"",
                    exposure == burstExposure);
                assertTrue(""Cam "" + cameraId + "": Sensitivity not locked!"",
                    sensitivity == burstSensitivity);
            }

            // Collect inter-frame durations
            long timestamp = burstResult.get(CaptureResult.SENSOR_TIMESTAMP);
            if (prevTimestamp != -1) {
                long frameDuration = timestamp - prevTimestamp;
                frameDurations.add(frameDuration);
                if (DEBUG) {
                    Log.i(TAG, String.format(""Frame %03d    Duration %.2f ms"", burstIndex,
                            frameDuration/1e6));
                }
            }
            prevTimestamp = timestamp;

            // Get next result
            burstIndex++;
            if (burstIndex == burstSize) {
                burstEndTimeStamp = burstResult.get(CaptureResult.SENSOR_TIMESTAMP);
                break;
            }
            burstResult = burstResultListener.getCaptureResult(MAX_PREVIEW_RESULT_TIMEOUT_MS);
        }

        // Verify no preview frames interleaved in burst results
        while (true) {
            CaptureResult previewResult =
                    resultListener.getCaptureResult(MAX_PREVIEW_RESULT_TIMEOUT_MS);
            long previewTimestamp = previewResult.get(CaptureResult.SENSOR_TIMESTAMP);
            if (!zslStillEnabled && previewTimestamp >= burstStartTimestamp
                    && previewTimestamp <= burstEndTimeStamp) {
                fail(""Preview frame is interleaved with burst frames! Preview timestamp:"" +
                        previewTimestamp + "", burst ["" + burstStartTimestamp + "", "" +
                        burstEndTimeStamp + ""]"");
            } else if (previewTimestamp > burstEndTimeStamp) {
                break;
            }
        }

        // Verify inter-frame durations
        if (checkFrameRate) {
            long meanFrameSum = 0;
            for (Long duration : frameDurations) {
                meanFrameSum += duration;
            }
            float meanFrameDuration = (float) meanFrameSum / frameDurations.size();

            float stddevSum = 0;
            for (Long duration : frameDurations) {
                stddevSum += (duration - meanFrameDuration) * (duration - meanFrameDuration);
            }
            float stddevFrameDuration = (float)
                    Math.sqrt(1.f / (frameDurations.size() - 1 ) * stddevSum);

            Log.i(TAG, String.format(""Cam %s: Burst frame duration mean: %.1f, stddev: %.1f"",
                    cameraId, meanFrameDuration, stddevFrameDuration));

            assertTrue(
                String.format(""Cam %s: Burst frame duration mean %.1f ns is larger than "" +
                    ""acceptable, expecting below %d ns, allowing below %d"", cameraId,
                    meanFrameDuration, minStillFrameDuration, frameDurationBound),
                meanFrameDuration <= frameDurationBound);

            // Calculate upper 97.5% bound (assuming durations are normally distributed...)
            float limit95FrameDuration = meanFrameDuration + 2 * stddevFrameDuration;

            // Don't enforce this yet, but warn
            if (limit95FrameDuration > frameDurationBound) {
                Log.w(TAG,
                    String.format(""Cam %s: Standard deviation is too large compared to limit: "" +
                        ""mean: %.1f ms, stddev: %.1f ms: 95%% bound: %f ms"", cameraId,
                        meanFrameDuration/1e6, stddevFrameDuration/1e6,
                        limit95FrameDuration/1e6));
            }
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.MeanLargerThanVerificationTest"	"testVerify"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/MeanLargerThanVerificationTest.java"	""	"public void testVerify() {
    float[][] values = {
        {2, 1, 2},
        {1, 1.5f, 2},
        {3, 2.5f, 3},
        {2, 1, 3},
        {2, 2.5f, 5},
    };

    // Test the means all equal and larger than the expected + thresholds.
    float[] expected = {2.0f, 1.7f, 2.5f};
    float[] thresholds = {0.0f, 0.0f, 0.0f};
    SensorStats stats = new SensorStats();
    MeanLargerThanVerification verification = getVerification(expected, thresholds, values);
    verification.verify(stats);
    verifyStats(stats, true, MEANS);

    // Test only one means is equal than the expected + thresholds.
    expected = new float[] {2.5f, 1.5f, 3.5f};
    thresholds = new float[] {0.0f, 0.2f, 0.0f};
    stats = new SensorStats();
    verification = getVerification(expected, thresholds, values);
    verification.verify(stats);
    verifyStats(stats, true, MEANS);

    // Test only one means is equal than expected, thresholds is 0f.
    expected = new float[] {2.5f, 2.0f, 3.0f};
    thresholds = new float[] {0.0f, 0.0f, 0.0f};
    stats = new SensorStats();
    verification = getVerification(expected, thresholds, values);
    verification.verify(stats);
    verifyStats(stats, true, MEANS);

    // Test all means is smaller than the expected + thresholds.
    thresholds = new float[] {2.5f, 2.0f, 3.5f};
    stats = new SensorStats();
    verification = getVerification(expected, thresholds, values);
    try {
      verification.verify(stats);
      throw new Error(""Expected an AssertionError"");
    } catch (AssertionError e) {
      // Expected;
    }
    verifyStats(stats, false, MEANS);
  }

  private static MeanLargerThanVerification getVerification(
      float[] expected, float[] thresholds, float[]... values) {
    Collection<TestSensorEvent> events = new ArrayList<>(values.length);
    for (float[] value : values) {
      events.add(new TestSensorEvent(null, 0, 0, value));
    }
    MeanLargerThanVerification verification =
        new MeanLargerThanVerification(expected, thresholds);
    verification.addSensorEvents(events);
    return verification;
  }

  private void verifyStats(SensorStats stats, boolean passed, float[] means) {
    assertEquals(passed, stats.getValue(MeanLargerThanVerification.PASSED_KEY));
    float[] actual = (float[]) stats.getValue(SensorStats.MEAN_KEY);
    assertEquals(means.length, actual.length);
    for (int i = 0; i < means.length; i++) {
      assertEquals(means[i], actual[i], 0.1);
    }
  }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorManagerStaticTest"	"isHeld"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorManagerStaticTest.java"	""	"public void test/*
 *.
 */

package android.hardware.cts;

import junit.framework.Assert;

import android.content.Context;
import android.hardware.SensorManager;
import android.os.PowerManager;

import java.util.Random;

public class SensorManagerStaticTest extends SensorTestCase {
    private static final String TAG = ""SensorManagerTest"";

    // local float version of PI
    private static final float FLOAT_PI = (float) Math.PI;


    private PowerManager.WakeLock mWakeLock;

    @Override
    protected void setUp() throws Exception {
        Context context = getContext();
        PowerManager pm = (PowerManager) context.getSystemService(Context.POWER_SERVICE);
        mWakeLock = pm.newWakeLock(PowerManager.PARTIAL_WAKE_LOCK, TAG);

        mWakeLock.acquire();
    }

    @Override
    protected void tearDown(){
        if (mWakeLock != null && mWakeLock.isHeld()) {
            mWakeLock.release();
        }
    }

    // SensorManager Tests"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorManagerStaticTest"	"testGetAltitude"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorManagerStaticTest.java"	""	"public void testGetAltitude() throws Exception {
        float r, q;
        float altitude;

        // identity property
        for (r = 0.5f; r < 1.3f; r += 0.1f) {

            altitude = SensorManager.getAltitude(r * SensorManager.PRESSURE_STANDARD_ATMOSPHERE,
                                                 r * SensorManager.PRESSURE_STANDARD_ATMOSPHERE);
            assertRoughlyEqual(""getAltitude identity property violated."", altitude, 0.0f, 0.1f);
        }

        // uniform increasing as pressure decreases property
        float prevAltitude = 1e5f; // 100km ceiling
        for (r = 0.5f; r < 1.3f; r += 0.01f) {
            altitude = SensorManager.getAltitude(SensorManager.PRESSURE_STANDARD_ATMOSPHERE,
                                                 r * SensorManager.PRESSURE_STANDARD_ATMOSPHERE);

            assertTrue(""getAltitude result has to decrease as p increase."", prevAltitude > altitude);
            prevAltitude = altitude;
        }

        // compare to a reference algorithm
        final float coef = 1.0f / 5.255f;
        for (r = 0.8f; r < 1.3f; r += 0.1f) {
            for (q = 1.1f * r; q > 0.5f * r; q -= 0.1f * r) {
                float p0 = r * SensorManager.PRESSURE_STANDARD_ATMOSPHERE;
                float p  = q * SensorManager.PRESSURE_STANDARD_ATMOSPHERE;

                float t1 = SensorManager.getAltitude(p0, p);
                float t2 = 44330.f*(1.0f- (float) Math.pow(p/p0, coef));

                assertRoughlyEqual(
                      String.format(""getAltitude comparing to reference algorithm failed. "" +
                          ""Detail: getAltitude(%f, %f) => %f, reference => %f"",
                          p0, p, t1, t2),
                      t1, t2, 100.f);
            }
        }

    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorManagerStaticTest"	"testGetAngleChange"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorManagerStaticTest.java"	""	"public void testGetAngleChange() throws Exception {
        TestDataGenerator data = new TestDataGenerator();

        int i;
        float [] rotv = new float[3];
        float [] rotv2 = new float[3];

        // test many instances
        for (i=0; i<100; ++i) {
            float [] R1, R12, R2;
            // azimuth(yaw) pitch roll
            data.nextRotationAngles(rotv);
            R1 = mat9VRot(rotv); // random base

            // azimuth(yaw) pitch roll
            data.nextRotationAngles(rotv);
            R12 = mat9VRot(rotv);
            R2 = mat9Mul(R1, R12); // apply another random rotation

            // test different variations of input matrix format
            switch(i & 3) {
                case 0:
                    SensorManager.getAngleChange(rotv2, R2, R1);
                    break;
                case 1:
                    SensorManager.getAngleChange(rotv2, mat9to16(R2), R1);
                    break;
                case 2:
                    SensorManager.getAngleChange(rotv2, R2, mat9to16(R1));
                    break;
                case 3:
                    SensorManager.getAngleChange(rotv2, mat9to16(R2), mat9to16(R1));
                    break;
            }

            // check range
            assertRotationAnglesValid(""getAngleChange result out of range."", rotv2);

            // avoid directly checking the rotation angles to avoid corner cases
            float [] R12rt = mat9T(mat9VRot(rotv2));
            float [] RI = mat9Mul(R12rt, R12);

            assertRoughlyEqual(
                String.format(""getAngleChange result is incorrect. Details: case %d, "" +
                    ""truth = [%f, %f, %f], result = [%f, %f, %f]"", i, rotv[0], rotv[1], rotv[2],
                    rotv2[0], rotv2[1], rotv2[2]),
                RI[0] + RI[4] + RI[8], 3.f, 1e-4f);
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorManagerStaticTest"	"testGetInclination"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorManagerStaticTest.java"	""	"public void testGetInclination() throws Exception {
        TestDataGenerator data = new TestDataGenerator();

        int i;
        float [] rotv = new float[3];
        float [] rotv2 = new float[3];
        float [] rotv3;

        // test many instances
        for (i = 0; i < 100; ++i) {
            float [] R;
            float angle;
            angle = (data.nextFloat()-0.5f) * FLOAT_PI;
            R = mat9Rot(SensorManager.AXIS_X, -angle);

            float angler = ((i&1) != 0) ?
                    SensorManager.getInclination(mat9to16(R)) : SensorManager.getInclination(R);
            assertRoughlyEqual(
                String.format(
                    ""getInclination return incorrect result. Detail: case %d, truth %f, result %f."",
                    i, angle, angler),
                angle, angler, 1e-4f);
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorManagerStaticTest"	"testGetOrientation"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorManagerStaticTest.java"	""	"public void testGetOrientation() throws Exception {
        TestDataGenerator data = new TestDataGenerator();

        int i;
        float [] rotv = new float[3];
        float [] rotv2 = new float[3];
        float [] rotv3;

        // test many instances
        for (i=0; i<100; ++i) {
            float [] R;
            // yaw pitch roll
            data.nextRotationAngles(rotv);
            R = mat9VRot(rotv);

            rotv3 = SensorManager.getOrientation( ((i&1) != 0) ? R : mat9to16(R), rotv2);
            assertTrue(""getOrientaion has to return the array passed in argument"", rotv3 == rotv2);

            // check range
            assertRotationAnglesValid(""getOrientation result out of range."", rotv2);

            // Avoid directly comparing rotation angles. Instead, compare the rotation matrix.
            float [] Rr = mat9T(mat9VRot(rotv2));
            float [] RI = mat9Mul(Rr, R);

            assertRoughlyEqual(
                String.format(""getOrientation result is incorrect. Details: case %d, "" +
                    ""truth = [%f, %f, %f], result = [%f, %f, %f]"", i, rotv[0], rotv[1], rotv[2],
                    rotv2[0], rotv2[1], rotv2[2]),
                RI[0] + RI[4] + RI[8], 3.f, 1e-4f);
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorManagerStaticTest"	"testGetQuaternionFromVector"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorManagerStaticTest.java"	""	"public void testGetQuaternionFromVector() throws Exception {
        TestDataGenerator data = new TestDataGenerator();

        int i;
        float [] v;
        float [] q = new float[4];
        float [] q2 = new float[4];
        float [] v3 = new float[3];
        float [] v4 = new float[4];
        float [] v5 = new float[5];
        float [][] vs = new float[][] {v3, v4, v5};

        float [] xyzth = new float[4];
        for (i = 0; i < 100; ++i) {
            float c, s;

            data.nextRotationAxisAngle(xyzth);

            c = (float) Math.cos(xyzth[3]);
            s = (float) Math.sin(xyzth[3]);
            if (c < 0.f) {
                c = -c;
                s = -s;
            }

            v = vs[i%3];
            switch(i%3) {
                case 2:
                    v[4] = data.nextBoolean() ? data.nextFloat() : -1.f;
                case 1:
                    v[3] = c;
                case 0:
                    v[0] = s * xyzth[0];
                    v[1] = s * xyzth[1];
                    v[2] = s * xyzth[2];
            }

            q2[0] = c;
            q2[1] = v[0];
            q2[2] = v[1];
            q2[3] = v[2];

            SensorManager.getQuaternionFromVector(q, v);
            assertVectorRoughlyEqual(
                String.format(""getQuaternionFromVector returns wrong results, Details: case %d, "" +
                    ""truth = (%f, %f, %f, %f), result = (%f, %f, %f, %f)."",
                    i, q2[0], q2[1], q2[2], q2[3], q[0], q[1], q[2], q[3]),
                q, q2, 1e-4f);
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorManagerStaticTest"	"testGetRotationMatrix"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorManagerStaticTest.java"	""	"public void testGetRotationMatrix() throws Exception {
        TestDataGenerator data = new TestDataGenerator();
        final float gravity = 9.81f;
        final float magStrength = 50.f;

        int i;
        float [] gm = new float[9];
        float [] rotv = new float[3];
        float [] gI = null;
        float [] mI = null;
        float [] Rr = new float[9];
        float [] Ir = new float[9];

        gm[6] = gravity; // m/s^2, first column gravity

        // test many instances
        for (i=0; i<100; ++i) {
            float [] Rt;
            float incline;
            // yaw pitch roll
            data.nextRotationAngles(rotv);
            Rt = mat9T(mat9VRot(rotv)); // from world frame to phone frame
            //Rt = mat9I();

            incline = -0.9f * (data.nextFloat() - 0.5f) * FLOAT_PI; // ~ +-80 degrees
            //incline = 0.f;
            gm[4] = magStrength * (float) Math.cos(-incline); // positive means rotate downwards
            gm[7] = magStrength * (float) Math.sin(-incline);

            float [] gmb = mat9Mul(Rt, gm); // do not care about right most column
            gI = mat9Axis(gmb, SensorManager.AXIS_X);
            mI = mat9Axis(gmb, SensorManager.AXIS_Y);

            assertTrue(""getRotationMatrix returns false on valid inputs"",
                SensorManager.getRotationMatrix(Rr, Ir, gI, mI));

            float [] n = mat9Mul(Rr, Rt);
            assertRoughlyEqual(
                String.format(""getRotationMatrix returns incorrect R matrix. "" +
                    ""Details: case %d, truth R = %s, result R = %s."",
                    i, mat9ToStr(mat9T(Rt)), mat9ToStr(Rr)),
                n[0] + n[4] + n[8], 3.f, 1e-4f);


            // Magnetic incline is defined so that it means the magnetic field lines is formed
            // by rotate local y axis around -x axis by incline angle. However, I matrix is
            // defined as (according to document):
            //     [0 m 0] = I * R * geomagnetic,
            // which means,
            //     I' * [0 m 0] = R * geomagnetic.
            // Thus, I' = Rot(-x, incline) and I = Rot(-x, incline)' = Rot(x, incline)
            float [] Ix = mat9Rot(SensorManager.AXIS_X, incline);
            assertVectorRoughlyEqual(
                String.format(""getRotationMatrix returns incorrect I matrix. "" +
                    ""Details: case %d, truth I = %s, result I = %s."",
                    i, mat9ToStr(Ix), mat9ToStr(Ir)),
                Ix, Ir, 1e-4f);
        }

        // test 16 element inputs
        float [] Rr2 = new float[16];
        float [] Ir2 = new float[16];

        assertTrue(""getRotationMatrix returns false on valid inputs"",
            SensorManager.getRotationMatrix(Rr2, Ir2, gI, mI));

        assertVectorRoughlyEqual(
            ""getRotationMatrix acts inconsistent with 9- and 16- elements matrix buffer"",
            mat16to9(Rr2), Rr, 1e-4f);

        assertVectorRoughlyEqual(
            ""getRotationMatrix acts inconsistent with 9- and 16- elements matrix buffer"",
            mat16to9(Ir2), Ir, 1e-4f);

        // test null inputs
        assertTrue(""getRotationMatrix does not handle null inputs"",
            SensorManager.getRotationMatrix(Rr, null, gI, mI));

        assertTrue(""getRotationMatrix does not handle null inputs"",
            SensorManager.getRotationMatrix(null, Ir, gI, mI));

        assertTrue(""getRotationMatrix does not handle null inputs"",
            SensorManager.getRotationMatrix(null, null, gI, mI));

        // test fail cases
        // free fall, if the acc reading is less than 10% of gravity
        gI[0] = gI[1] = gI[2] = data.nextFloat() * gravity * 0.05f; // sqrt(3) * 0.05 < 0.1
         assertFalse(""getRotationMatrix does not fail when it supposed to fail (gravity too small)"",
            SensorManager.getRotationMatrix(Rr, Ir, gI, mI));

        // wrong input
        assertFalse(""getRotationMatrix does not fail when it supposed to fail (singular axis)"",
            SensorManager.getRotationMatrix(Rr, Ir, gI, gI));
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorManagerStaticTest"	"testGetRotationMatrixFromVector"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorManagerStaticTest.java"	""	"public void testGetRotationMatrixFromVector() throws Exception {
        TestDataGenerator data = new TestDataGenerator();

        int i;
        float [] v;
        float [] q = new float[4];

        float [] v3 = new float[3];
        float [] v4 = new float[4];
        float [] v5 = new float[5];
        float [][] vs = new float[][]{v3, v4, v5};

        float [] m9 = new float[9];
        float [] m16 = new float[16];

        // format: x y z theta/2
        float [] xyzth = new float[4];
        // test the orthogonal property of returned matrix
        for (i=0; i<20; ++i) {
            float c, s;
            data.nextRotationAxisAngle(xyzth);

            c = (float) Math.cos(xyzth[3]);
            s = (float) Math.sin(xyzth[3]);
            if (c < 0.f) {
                c = -c;
                s = -s;
            }

            v = vs[i%3];
            switch(i%3) {
                case 2:
                    v[4] = data.nextBoolean() ? data.nextFloat() : -1.f;
                case 1:
                    v[3] = c;
                case 0:
                    v[0] = s * xyzth[0];
                    v[1] = s * xyzth[1];
                    v[2] = s * xyzth[2];
            }

            if ((i % 1) != 0) {
                SensorManager.getRotationMatrixFromVector(m16, v);
                m9 = mat16to9(m16);
            }else {
                SensorManager.getRotationMatrixFromVector(m9, v);
            }

            float [] n = mat9Mul(m9, mat9T(m9));
            assertRoughlyEqual(""getRotationMatrixFromVector do not return proper matrix"",
                    n[0]+ n[4] + n[8], 3.f, 1e-4f);
        }

        // test if multiple rotation (total 2pi) about an axis result in identity
        v = v3;
        float [] Rr = new float[9];

        for (i=0; i<20; ++i) {
            float j, halfTheta, residualHalfTheta = FLOAT_PI;
            float [] R = mat9I();
            float c, s;

            data.nextRotationAxisAngle(xyzth);  // half theta is ignored

            j = data.nextInt(5) + 2;  // 2 ~ 6 rotations

            while(j-- > 0) {
                if (j == 0) {
                    halfTheta = residualHalfTheta;
                } else {
                    halfTheta = data.nextFloat() * FLOAT_PI;
                }

                c = (float) Math.cos(halfTheta);
                s = (float) Math.sin(halfTheta);
                if (c < 0.f) {
                    c = -c;
                    s = -s;
                }

                v[0] = s * xyzth[0];
                v[1] = s * xyzth[1];
                v[2] = s * xyzth[2];

                SensorManager.getRotationMatrixFromVector(Rr, v);
                R = mat9Mul(Rr, R);

                residualHalfTheta -= halfTheta;
            }

            assertRoughlyEqual(""getRotationMatrixFromVector returns incorrect matrix"",
                    R[0] + R[4] + R[8], 3.f, 1e-4f);
        }

        // test if rotation about trival axis works
        v = v3;
        for (i=0; i<20; ++i) {
            int axis = (i % 3) + 1;
            float theta = data.nextFloat() * 2.f * FLOAT_PI;
            float [] R;

            v[0] = v[1] = v[2] = 0.f;
            v[axis - 1] = (float) Math.sin(theta / 2.f);
            if ( (float) Math.cos(theta / 2.f) < 0.f) {
                v[axis-1] = -v[axis-1];
            }

            SensorManager.getRotationMatrixFromVector(m9, v);
            R = mat9Rot(axis, theta);

            assertVectorRoughlyEqual(
                String.format(""getRotationMatrixFromVector returns incorrect matrix with ""+
                    ""simple rotation. Details: case %d, truth R = %s, result R = %s."",
                    i, mat9ToStr(R), mat9ToStr(m9)),
                R, m9, 1e-4f);
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorManagerStaticTest"	"testRemapCoordinateSystem"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorManagerStaticTest.java"	""	"public void testRemapCoordinateSystem() throws Exception {
        TestDataGenerator data = new TestDataGenerator();

        int i, j, k;
        float [] rotv = new float[3];
        float [] Rout = new float[9];
        float [] Rout2 = new float[16];
        int a1, a2; // AXIS_X/Y/Z
        int b1, b2, b3; // AXIS_X/Y/Z w/ or w/o MINUS

        // test a few instances
        for (i=0; i<10; ++i) {
            float [] R;
            // yaw pitch roll
            data.nextRotationAngles(rotv);
            R = mat9VRot(rotv);

            // total of 6*4 = 24 variations
            // 6 = A(3,2)
            for (j=0; j<9; ++j) {
                // axis without minus
                a1 = j/3 + 1;
                a2 = j%3 + 1;

                // skip cases when two axis are the same
                if (a1 == a2) continue;

                for (k=0; k<3; ++k) {
                    // test all minus axis combination: ++, +-, -+, --
                    b1 = a1 | (((k & 2) != 0) ? 0x80 : 0);
                    b2 = a2 | (((k & 1) != 0) ? 0x80 : 0);
                    // the third axis
                    b3 = (6 - a1 -a2) |
                         ( (((a2 + 3 - a1) % 3 == 2) ? 0x80 : 0) ^ (b1 & 0x80) ^ (b2 & 0x80));

                    // test both input formats
                    if ( (i & 1) != 0 ) {
                      assertTrue(SensorManager.remapCoordinateSystem(R, b1, b2, Rout));
                    } else {
                      assertTrue(SensorManager.remapCoordinateSystem(mat9to16(R), b1, b2, Rout2));
                      Rout = mat16to9(Rout2);
                    }

                    float [] v1, v2;

                    String detail = String.format(
                            ""Details: case %d (%x %x %x), original R = %s, result R = %s."",
                            i, b1, b2, b3, mat9ToStr(R), mat9ToStr(Rout));

                    v1 = mat9Axis(R, SensorManager.AXIS_X);
                    v2 = mat9Axis(Rout, b1);
                    assertVectorRoughlyEqual(
                        ""remapCoordinateSystem gives incorrect result (x)."" + detail,
                        v1, v2, 1e-4f);

                    v1 = mat9Axis(R, SensorManager.AXIS_Y);
                    v2 = mat9Axis(Rout, b2);
                    assertVectorRoughlyEqual(
                        ""remapCoordinateSystem gives incorrect result (y)."" + detail,
                        v1, v2, 1e-4f);

                    v1 = mat9Axis(R, SensorManager.AXIS_Z);
                    v2 = mat9Axis(Rout, b3);
                    assertVectorRoughlyEqual(
                        ""remapCoordinateSystem gives incorrect result (z)."" + detail,
                        v1, v2, 1e-4f);
                }
            }

        }

        // test cases when false should be returned
        assertTrue(""remapCoordinateSystem should return false with mismatch size input and output"",
                   !SensorManager.remapCoordinateSystem(Rout,
                     SensorManager.AXIS_Y, SensorManager.AXIS_Z, Rout2));
        assertTrue(""remapCoordinateSystem should return false with invalid axis setting"",
                   !SensorManager.remapCoordinateSystem(Rout,
                     SensorManager.AXIS_X, SensorManager.AXIS_X, Rout));
        assertTrue(""remapCoordinateSystem should return false with invalid axis setting"",
                   !SensorManager.remapCoordinateSystem(Rout,
                     SensorManager.AXIS_X, SensorManager.AXIS_MINUS_X, Rout));

    }

    // Utilities class & functions

    private class TestDataGenerator {
        // carry out test deterministically without manually picking numbers
        private final long DEFAULT_SEED = 0xFEDCBA9876543210l;

        private Random mRandom;

        TestDataGenerator(long seed) {
            mRandom = new Random(seed);
        }

        TestDataGenerator() {
            mRandom = new Random(DEFAULT_SEED);
        }

        void nextRotationAngles(float [] rotv) {
            assertTrue(rotv.length == 3);

            rotv[0] = (mRandom.nextFloat()-0.5f) * 2.0f * FLOAT_PI; // azimuth(yaw) -pi ~ pi
            rotv[1] = (mRandom.nextFloat()-0.5f) * FLOAT_PI; // pitch -pi/2 ~ +pi/2
            rotv[2] = (mRandom.nextFloat()-0.5f) * 2.f * FLOAT_PI; // roll -pi ~ +pi
        }

        void nextRotationAxisAngle(float [] aa) {
            assertTrue(aa.length == 4);

            aa[0] = (mRandom.nextFloat() - 0.5f) * 2.f;
            aa[1] = (mRandom.nextFloat() - 0.5f ) * 2.f * (float) Math.sqrt(1.f - aa[0] * aa[0]);
            aa[2] = (mRandom.nextBoolean() ? 1.f : -1.f) *
                        (float) Math.sqrt(1.f - aa[0] * aa[0] - aa[1] * aa[1]);
            aa[3] = mRandom.nextFloat() * FLOAT_PI;
        }

        int nextInt(int i) {
            return mRandom.nextInt(i);
        }

        float nextFloat() {
            return mRandom.nextFloat();
        }

        boolean nextBoolean() {
            return mRandom.nextBoolean();
        }
    }

    private static void assertRotationAnglesValid(String message, float[] ra) {

        assertTrue(message, ra.length == 3 &&
            ra[0] >= -FLOAT_PI && ra[0] <= FLOAT_PI &&         // azimuth
            ra[1] >= -FLOAT_PI / 2.f && ra[1] <= FLOAT_PI / 2.f && // pitch
            ra[2] >= -FLOAT_PI && ra[2] <= FLOAT_PI);          // roll
    }

    private static void assertRoughlyEqual(String message, float a, float b, float bound) {
        assertTrue(message, Math.abs(a-b) < bound);
    }

    private static void assertVectorRoughlyEqual(String message, float [] v1, float [] v2,
                                                 float bound) {
        assertTrue(message, v1.length == v2.length);
        int i;
        float sum = 0.f;
        for (i=0; i<v1.length; ++i) {
            sum += (v1[i] - v2[i]) * (v1[i] - v2[i]);
        }
        assertRoughlyEqual(message, (float)Math.sqrt(sum), 0.f, bound);
    }

    private static float [] mat9to16(float [] m) {
        assertTrue(m.length == 9);

        float [] n  = new float[16];
        int i;
        for (i=0; i<9; ++i) {
            n[i+i/3] = m[i];
        }
        n[15] = 1.f;
        return n;
    }

    private static float [] mat16to9(float [] m) {
        assertTrue(m.length == 16);

        float [] n = new float[9];
        int i;
        for (i=0; i<9; ++i) {
            n[i] = m[i + i/3];
        }
        return n;
    }

    private static float [] mat9Mul(float [] m, float [] n) {
        assertTrue(m.length == 9 && n.length == 9);

        float [] r = new float[9];
        int i, j, k;

        for (i = 0; i < 3; ++i)
            for (j = 0; j < 3; ++j)
                for (k = 0; k < 3; ++k)
                    r[i * 3 + j] += m[i * 3 + k] * n[k * 3 + j];

        return r;
    }

    private static float [] mat9T(float [] m) {
        assertTrue(m.length == 9);

        int i, j;
        float [] n = new float[9];

        for (i = 0; i < 3; ++i)
            for (j = 0; j < 3; ++j)
                n[i * 3 + j] = m[j * 3 + i];

        return n;
    }

    private static float [] mat9I() {
        float [] m = new float[9];
        m[0] = m[4] = m[8] = 1.f;
        return m;
    }

    private static float [] mat9Rot(int axis, float angle) {
        float [] m = new float[9];
        switch (axis) {
            case SensorManager.AXIS_X:
                m[0] = 1.f;
                m[4] = m[8] = (float) Math.cos(angle);
                m[5] = - (m[7] = (float) Math.sin(angle));
                break;
            case SensorManager.AXIS_Y:
                m[4] = 1.f;
                m[0] = m[8] = (float) Math.cos(angle);
                m[6] = - (m[2] = (float) Math.sin(angle));
                break;
            case SensorManager.AXIS_Z:
                m[8] = 1.f;
                m[0] = m[4] = (float) Math.cos(angle);
                m[1] = - (m[3] = (float) Math.sin(angle));
                break;
            default:
                // should never be here
                assertTrue(false);
        }
        return m;
    }

    private static float [] mat9VRot(float [] angles) {
        assertTrue(angles.length == 3);
        // yaw, android yaw rotate to -z
        float [] R = mat9Rot(SensorManager.AXIS_Z, -angles[0]);
        // pitch, android pitch rotate to -x
        R = mat9Mul(R, mat9Rot(SensorManager.AXIS_X, -angles[1]));
        // roll
        R = mat9Mul(R, mat9Rot(SensorManager.AXIS_Y, angles[2]));

        return R;
    }

    private static float [] mat9Axis(float m[], int axis) {
        assertTrue(m.length == 9);

        boolean negative = (axis & 0x80) != 0;
        float [] v = new float[3];
        int offset;

        offset = (axis & ~0x80) - 1;
        v[0] = negative ? -m[offset]   : m[offset];
        v[1] = negative ? -m[offset+3] : m[offset+3];
        v[2] = negative ? -m[offset+6] : m[offset+6];
        return v;
    }

    private static float vecInner(float u[], float v[]) {
        assertTrue(u.length == v.length);

        int i;
        float sum = 0.f;

        for (i=0; i < v.length; ++i) {
            sum += u[i]*v[i];
        }
        return (float)Math.sqrt(sum);
    }

    private static String vecToStr(float u[]) {
        int i;
        String s;
        switch (u.length) {
            case 3:
                return String.format(""[%f, %f, %f]"", u[0], u[1], u[2]);
            case 4:
                return String.format(""(%f, %f, %f, %f)"", u[0], u[1], u[2], u[3]);
            default:
                s = ""["";
                for (i = 0; i < u.length-1; ++i) {
                    s += String.format(""%f, "", u[i]);
                }
                s += String.format(""%f]"", u[i]);
                return s;
        }
    }

    private static String mat9ToStr(float m[]) {
        assertTrue(m.length == 9);
        return String.format(""[%f, %f, %f; %f, %f, %f; %f, %f, %f]"",
            m[0], m[1], m[2],
            m[3], m[4], m[5],
            m[6], m[7], m[8]);
    }

    private static String mat16ToStr(float m[]) {
        assertTrue(m.length == 16);
        return String.format(""[%f, %f, %f, %f; %f, %f, %f, %f; %f, %f, %f, %f; %f, %f, %f, %f]"",
            m[0], m[1], m[2], m[3],
            m[4], m[5], m[6], m[7],
            m[8], m[9], m[10], m[11],
            m[12], m[13], m[14], m[15]);
    }

}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.InitialValueVerificationTest"	"testVerify"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/InitialValueVerificationTest.java"	""	"public void testVerify() {
        float[] initialValues = new float[] {80.4f, 12.3f, -67f};
        verifyStatsWithTwoWindows(initialValues, initialValues, true);

        // Only modify the first element in the array but close enough
        float[] laterValues = new float[] {78.1f, 12.3f, -67f};
        verifyStatsWithTwoWindows(initialValues, laterValues, true);
        // Only modify the first element in the array but by more than the MAX_ABSOLUTE_DELTA
        laterValues = new float[] {70.1f, 12.3f, -67f};
        verifyStatsWithTwoWindows(initialValues, laterValues, false);

        // Only modify the second element in the array but close enough
        laterValues = new float[] {80.4f, 11.3f, -67f};
        verifyStatsWithTwoWindows(initialValues, laterValues, true);
        // Only modify the second element in the array but by more than the MAX_ABSOLUTE_DELTA
        laterValues = new float[] {80.4f, 7.3f, -67f};
        verifyStatsWithTwoWindows(initialValues, laterValues, false);

        // Only modify the third element in the array but close enough
        laterValues = new float[] {80.4f, 12.3f, -65f};
        verifyStatsWithTwoWindows(initialValues, laterValues, true);
        // Only modify the third element in the array but by more than the MAX_ABSOLUTE_DELTA
        laterValues = new float[] {80.4f, 12.3f, 45f};
        verifyStatsWithTwoWindows(initialValues, laterValues, false);
    }

    private static InitialValueVerification getVerification(Collection<TestSensorEvent> events,
            float maxAbsoluteDelta, long initialWindowLength) {
        InitialValueVerification verification =
                new InitialValueVerification(maxAbsoluteDelta, initialWindowLength);
        verification.addSensorEvents(events);
        return verification;
    }

    private static void verifyStatsWithTwoWindows(float[] initialValues, float[] laterValues,
            boolean pass) {
        List<TestSensorEvent> events = new ArrayList<>();
        // Initial window
        for (long timestamp = 0L; timestamp <= INITIAL_WINDOW_LENGTH; timestamp += SENSOR_PERIOD) {
            float[] initialValuesWithNoise = addNoise(initialValues);
            events.add(new TestSensorEvent(null /* sensor */, timestamp, 0 /* accuracy */,
                    initialValuesWithNoise));
        }
        // Later window
        for (long timestamp = INITIAL_WINDOW_LENGTH
                + SENSOR_PERIOD; timestamp <= TOTAL_WINDOW_LENGTH; timestamp += SENSOR_PERIOD) {
            float[] laterValuesWithNoise = addNoise(laterValues);
            events.add(new TestSensorEvent(null /* sensor */, timestamp, 0 /* accuracy */,
                    laterValuesWithNoise));
        }
        SensorStats stats = new SensorStats();
        InitialValueVerification verification =
                getVerification(events, MAX_ABSOLUTE_DELTA, INITIAL_WINDOW_LENGTH);

        try {
            verification.verify(stats);
            assertTrue(pass);
        } catch (AssertionError e) {
            assertFalse(pass);
        }
        verifyStats(stats, pass, initialValues, laterValues);
    }

    private static float[] addNoise(float[] values) {
        float[] valuesWithNoise = new float[values.length];
        for(int i = 0; i < values.length; i++) {
            valuesWithNoise[i] = values[i] + random.nextFloat() * NOISE_STD;
        }
        return valuesWithNoise;
    }

    private static void verifyStats(SensorStats stats, boolean passed, float[] initialMeans,
            float[] laterMeans) {
        assertEquals(passed, stats.getValue(InitialValueVerification.PASSED_KEY));
        float[] actualInitialMeans = (float[]) stats.getValue(SensorStats.INITIAL_MEAN_KEY);
        float[] actualLaterMeans = (float[]) stats.getValue(SensorStats.LATER_MEAN_KEY);
        assertEquals(initialMeans.length, actualInitialMeans.length);
        assertEquals(laterMeans.length, actualLaterMeans.length);
        for (int i = 0; i < initialMeans.length; i++) {
            assertEquals(initialMeans[i], actualInitialMeans[i], 0.1);
            assertEquals(laterMeans[i], actualLaterMeans[i], 0.1);
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.AllocationTest"	"testBlackWhite"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/AllocationTest.java"	""	"public void testBlackWhite() throws CameraAccessException {

        /** low iso + low exposure (first shot) */
        final float THRESHOLD_LOW = 0.025f;
        /** high iso + high exposure (second shot) */
        final float THRESHOLD_HIGH = 0.975f;

        mCameraIterable.forEachCamera(/*fullHwLevel*/false, new CameraBlock() {
            @Override
            public void run(CameraDevice camera) throws CameraAccessException {
                final StaticMetadata staticInfo =
                        new StaticMetadata(mCameraManager.getCameraCharacteristics(camera.getId()));

                // This test requires PFC and manual sensor control
                if (!staticInfo.isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR) ||
                        !staticInfo.isPerFrameControlSupported()) {
                    return;
                }

                final Size maxSize = getMaxSize(
                        getSupportedSizeForFormat(YUV_420_888, camera.getId(), mCameraManager));

                try (ScriptGraph scriptGraph = createGraphForYuvCroppedMeans(maxSize)) {

                    CaptureRequest.Builder req =
                            configureAndCreateRequestForSurface(scriptGraph.getInputSurface());

                    // Take a shot with very low ISO and exposure time. Expect it to be black.
                    int minimumSensitivity = staticInfo.getSensitivityMinimumOrDefault();
                    long minimumExposure = staticInfo.getExposureMinimumOrDefault();
                    setManualCaptureRequest(req, minimumSensitivity, minimumExposure);

                    CaptureRequest lowIsoExposureShot = req.build();
                    captureSingleShotAndExecute(lowIsoExposureShot, scriptGraph);

                    float[] blackMeans = convertPixelYuvToRgb(scriptGraph.getOutputData());

                    // Take a shot with very high ISO and exposure time. Expect it to be white.
                    int maximumSensitivity = staticInfo.getSensitivityMaximumOrDefault();
                    long maximumExposure = staticInfo.getExposureMaximumOrDefault();
                    setManualCaptureRequest(req, maximumSensitivity, maximumExposure);

                    CaptureRequest highIsoExposureShot = req.build();
                    captureSingleShotAndExecute(highIsoExposureShot, scriptGraph);

                    float[] whiteMeans = convertPixelYuvToRgb(scriptGraph.getOutputData());

                    // Low iso + low exposure (first shot), just check and log the error.
                    for (int i = 0; i < blackMeans.length; ++i) {
                        if (blackMeans[i] >= THRESHOLD_LOW) {
                            Log.e(TAG,
                                    String.format(""Black means too high: (%s should be greater""
                                            + "" than %s; item index %d in %s)"", blackMeans[i],
                                            THRESHOLD_LOW, i,
                                            Arrays.toString(blackMeans)));
                        }
                    }

                    // High iso + high exposure (second shot), just check and log the error
                    for (int i = 0; i < whiteMeans.length; ++i) {
                        if (whiteMeans[i] <= THRESHOLD_HIGH) {
                            Log.e(TAG,
                                    String.format(""White means too low: (%s should be less than""
                                            + "" %s; item index %d in %s)"", whiteMeans[i],
                                            THRESHOLD_HIGH, i,
                                            Arrays.toString(whiteMeans)));
                        }
                    }
                }
            }
        });
    }

    /**
     * Test that the android.sensitivity.parameter is applied.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.AllocationTest"	"testParamSensitivity"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/AllocationTest.java"	""	"public void testParamSensitivity() throws CameraAccessException {
        final float THRESHOLD_MAX_MIN_DIFF = 0.3f;
        final float THRESHOLD_MAX_MIN_RATIO = 2.0f;
        final int NUM_STEPS = 5;
        final long EXPOSURE_TIME_NS = 2000000; // 2 ms
        final int RGB_CHANNELS = 3;

        mCameraIterable.forEachCamera(/*fullHwLevel*/false, new CameraBlock() {


            @Override
            public void run(CameraDevice camera) throws CameraAccessException {
                final StaticMetadata staticInfo =
                        new StaticMetadata(mCameraManager.getCameraCharacteristics(camera.getId()));
                // This test requires PFC and manual sensor control
                if (!staticInfo.isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR) ||
                        !staticInfo.isPerFrameControlSupported()) {
                    return;
                }

                final List<float[]> rgbMeans = new ArrayList<float[]>();
                final Size maxSize = getMaxSize(
                        getSupportedSizeForFormat(YUV_420_888, camera.getId(), mCameraManager));

                final int sensitivityMin = staticInfo.getSensitivityMinimumOrDefault();
                final int sensitivityMax = staticInfo.getSensitivityMaximumOrDefault();

                // List each sensitivity from min-max in NUM_STEPS increments
                int[] sensitivities = new int[NUM_STEPS];
                for (int i = 0; i < NUM_STEPS; ++i) {
                    int delta = (sensitivityMax - sensitivityMin) / (NUM_STEPS - 1);
                    sensitivities[i] = sensitivityMin + delta * i;
                }

                try (ScriptGraph scriptGraph = createGraphForYuvCroppedMeans(maxSize)) {

                    CaptureRequest.Builder req =
                            configureAndCreateRequestForSurface(scriptGraph.getInputSurface());

                    // Take burst shots with increasing sensitivity one after other.
                    for (int i = 0; i < NUM_STEPS; ++i) {
                        setManualCaptureRequest(req, sensitivities[i], EXPOSURE_TIME_NS);
                        captureSingleShotAndExecute(req.build(), scriptGraph);
                        float[] means = convertPixelYuvToRgb(scriptGraph.getOutputData());
                        rgbMeans.add(means);

                        if (VERBOSE) {
                            Log.v(TAG, ""testParamSensitivity - captured image "" + i +
                                    "" with RGB means: "" + Arrays.toString(means));
                        }
                    }

                    // Test that every consecutive image gets brighter.
                    for (int i = 0; i < rgbMeans.size() - 1; ++i) {
                        float[] curMeans = rgbMeans.get(i);
                        float[] nextMeans = rgbMeans.get(i+1);

                        float[] left = curMeans;
                        float[] right = nextMeans;
                        String leftString = Arrays.toString(left);
                        String rightString = Arrays.toString(right);

                        String msgHeader =
                                String.format(""Shot with sensitivity %d should not have higher "" +
                                ""average means than shot with sensitivity %d"",
                                sensitivities[i], sensitivities[i+1]);
                        for (int m = 0; m < left.length; ++m) {
                            String msg = String.format(
                                    ""%s: (%s should be less than or equal to %s; item index %d;""
                                    + "" left = %s; right = %s)"",
                                    msgHeader, left[m], right[m], m, leftString, rightString);
                            if (left[m] > right[m]) {
                                Log.e(TAG, msg);
                            }
                        }
                    }

                    // Test the min-max diff and ratios are within expected thresholds
                    float[] lastMeans = rgbMeans.get(NUM_STEPS - 1);
                    float[] firstMeans = rgbMeans.get(/*location*/0);
                    for (int i = 0; i < RGB_CHANNELS; ++i) {
                        if (lastMeans[i] - firstMeans[i] <= THRESHOLD_MAX_MIN_DIFF) {
                            Log.w(TAG, String.format(""Sensitivity max-min diff too small""
                                    + ""(max=%f, min=%f)"", lastMeans[i], firstMeans[i]));
                        }
                        if (lastMeans[i] / firstMeans[i] <= THRESHOLD_MAX_MIN_RATIO) {
                            Log.w(TAG, String.format(""Sensitivity max-min ratio too small""
                                    + ""(max=%f, min=%f)"", lastMeans[i], firstMeans[i]));
                        }
                    }
                }
            }
        });

    }

    /**
     * Common script graph for manual-capture based tests that determine the average pixel
     * values of a cropped sub-region.
     *
     * <p>Processing chain:
     *
     * <pre>
     * input:  YUV_420_888 surface
     * output: mean YUV value of a central section of the image,
     *         YUV 4:4:4 encoded as U8_3
     * steps:
     *      1) crop [0.45,0.45] - [0.55, 0.55]
     *      2) average columns
     *      3) average rows
     * </pre>
     * </p>
     */
    private static ScriptGraph createGraphForYuvCroppedMeans(final Size size) {
        ScriptGraph scriptGraph = ScriptGraph.create()
                .configureInputWithSurface(size, YUV_420_888)
                .configureScript(ScriptYuvCrop.class)
                    .set(ScriptYuvCrop.CROP_WINDOW,
                            new Patch(size, /*x*/0.45f, /*y*/0.45f, /*w*/0.1f, /*h*/0.1f).toRectF())
                    .buildScript()
                .chainScript(ScriptYuvMeans2dTo1d.class)
                .chainScript(ScriptYuvMeans1d.class)
                // TODO: Make a script for YUV 444 -> RGB 888 conversion
                .buildGraph();
        return scriptGraph;
    }

    /*
     * TODO: Refactor below code into separate classes and to not depend on AllocationTest
     * inner variables.
     *
     * TODO: add javadocs to below methods
     *
     * TODO: Figure out if there's some elegant way to compose these forEaches together, so that
     * the callers don't have to do a ton of nesting
     */

    interface CameraBlock {
        void run(CameraDevice camera) throws CameraAccessException;
    }

    class CameraIterable {
        public void forEachCamera(CameraBlock runnable)
                throws CameraAccessException {
            forEachCamera(/*fullHwLevel*/false, runnable);
        }

        public void forEachCamera(boolean fullHwLevel, CameraBlock runnable)
                throws CameraAccessException {
            assertNotNull(""No camera manager"", mCameraManager);
            assertNotNull(""No camera IDs"", mCameraIdsUnderTest);

            for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
                // Don't execute the runnable against non-FULL cameras if FULL is required
                CameraCharacteristics properties =
                        mCameraManager.getCameraCharacteristics(mCameraIdsUnderTest[i]);
                StaticMetadata staticInfo = new StaticMetadata(properties);
                if (fullHwLevel && !staticInfo.isHardwareLevelAtLeastFull()) {
                    Log.i(TAG, String.format(
                            ""Skipping this test for camera %s, needs FULL hw level"",
                            mCameraIdsUnderTest[i]));
                    continue;
                }
                if (!staticInfo.isColorOutputSupported()) {
                    Log.i(TAG, String.format(
                        ""Skipping this test for camera %s, does not support regular outputs"",
                        mCameraIdsUnderTest[i]));
                    continue;
                }
                // Open camera and execute test
                Log.i(TAG, ""Testing Camera "" + mCameraIdsUnderTest[i]);
                try {
                    openDevice(mCameraIdsUnderTest[i]);

                    runnable.run(mCamera);
                } finally {
                    closeDevice(mCameraIdsUnderTest[i]);
                }
            }
        }

        private void openDevice(String cameraId) {
            if (mCamera != null) {
                throw new IllegalStateException(""Already have open camera device"");
            }
            try {
                mCamera = openCamera(
                    mCameraManager, cameraId, mCameraListener, mHandler);
            } catch (CameraAccessException e) {
                fail(""Fail to open camera synchronously, "" + Log.getStackTraceString(e));
            } catch (BlockingOpenException e) {
                fail(""Fail to open camera asynchronously, "" + Log.getStackTraceString(e));
            }
            mCameraListener.waitForState(STATE_OPENED, CAMERA_OPEN_TIMEOUT_MS);
        }

        private void closeDevice(String cameraId) {
            if (mCamera != null) {
                mCamera.close();
                mCameraListener.waitForState(STATE_CLOSED, CAMERA_CLOSE_TIMEOUT_MS);
                mCamera = null;
            }
        }
    }

    interface SizeBlock {
        void run(Size size) throws CameraAccessException;
    }

    class SizeIterable {
        public void forEachSize(int format, SizeBlock runnable) throws CameraAccessException {
            assertNotNull(""No camera opened"", mCamera);
            assertNotNull(""No camera manager"", mCameraManager);

            CameraCharacteristics properties =
                    mCameraManager.getCameraCharacteristics(mCamera.getId());

            assertNotNull(""Can't get camera properties!"", properties);

            StreamConfigurationMap config =
                    properties.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
            int[] availableOutputFormats = config.getOutputFormats();
            assertArrayNotEmpty(availableOutputFormats,
                    ""availableOutputFormats should not be empty"");
            Arrays.sort(availableOutputFormats);
            assertTrue(""Can't find the format "" + format + "" in supported formats "" +
                    Arrays.toString(availableOutputFormats),
                    Arrays.binarySearch(availableOutputFormats, format) >= 0);

            Size[] availableSizes = getSupportedSizeForFormat(format, mCamera.getId(),
                    mCameraManager);
            assertArrayNotEmpty(availableSizes, ""availableSizes should not be empty"");

            for (Size size : availableSizes) {

                if (VERBOSE) {
                    Log.v(TAG, ""Testing size "" + size.toString() +
                            "" for camera "" + mCamera.getId());
                }
                runnable.run(size);
            }
        }
    }

    interface ResultBlock {
        void run(CaptureResult result) throws CameraAccessException;
    }

    class ResultIterable {
        public void forEachResultOnce(CaptureRequest request, ResultBlock block)
                throws CameraAccessException {
            forEachResult(request, /*count*/1, /*repeating*/false, block);
        }

        public void forEachResultRepeating(CaptureRequest request, int count, ResultBlock block)
                throws CameraAccessException {
            forEachResult(request, count, /*repeating*/true, block);
        }

        public void forEachResult(CaptureRequest request, int count, boolean repeating,
                ResultBlock block) throws CameraAccessException {

            // TODO: start capture, i.e. configureOutputs

            SimpleCaptureCallback listener = new SimpleCaptureCallback();

            if (!repeating) {
                for (int i = 0; i < count; ++i) {
                    mSession.capture(request, listener, mHandler);
                }
            } else {
                mSession.setRepeatingRequest(request, listener, mHandler);
            }

            // Assume that the device is already IDLE.
            mSessionListener.getStateWaiter().waitForState(BlockingSessionCallback.SESSION_ACTIVE,
                    CAMERA_ACTIVE_TIMEOUT_MS);

            for (int i = 0; i < count; ++i) {
                if (VERBOSE) {
                    Log.v(TAG, String.format(""Testing with result %d of %d for camera %s"",
                            i, count, mCamera.getId()));
                }

                CaptureResult result = listener.getCaptureResult(CAPTURE_RESULT_TIMEOUT_MS);
                block.run(result);
            }

            if (repeating) {
                mSession.stopRepeating();
                mSessionListener.getStateWaiter().waitForState(
                    BlockingSessionCallback.SESSION_READY, CAMERA_IDLE_TIMEOUT_MS);
            }

            // TODO: Make a Configure decorator or some such for configureOutputs
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.base.ISensorTestStateContainer"	"getTestLogger"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/base/ISensorTestStateContainer.java"	""	"public void test/*
 *
 */

package com.android.cts.verifier.sensors.base;

import android.content.ContentResolver;
import android.content.Intent;

/**
 * An interface that defines a facade for {@link BaseSensorTestActivity}, so it can be consumed by
 * other CtsVerifier Sensor Test Framework helper components.
 */
public interface ISensorTestStateContainer {

    /**
     * @return The current logger.
     */
    BaseSensorTestActivity.SensorTestLogger getTestLogger();

    /**
     * Waits for the operator to acknowledge to continue execution.
     */
    void waitForUserToContinue() throws InterruptedException;

    /**
     * @param resId The resource Id to extract.
     * @return The extracted string.
     */
    String getString(int resId);

    /**
     * @param resId The resource Id to extract.
     * @param params The parameters to format the string represented by the resource contents.
     * @return The formatted extracted string.
     */
    String getString(int resId, Object ... params);

    /**
     * Starts an Activity and blocks until it completes, then it returns its result back to the
     * client.
     *
     * @param action The action to start the Activity.
     * @return The Activity's result code.
     */
    int executeActivity(String action) throws InterruptedException;

    /**
     * Starts an Activity and blocks until it completes, then it returns its result back to the
     * client.
     *
     * @param intent The intent to start the Activity.
     * @return The Activity's result code.
     */
    int executeActivity(Intent intent) throws InterruptedException;

    /**
     * @return The {@link ContentResolver} associated with the test.
     */
    ContentResolver getContentResolver();

    /**
     * @param feature the feature being tested
     * @return true if the specified feature is implemented; false otherwise.
     */
    boolean hasSystemFeature(String feature);

    /**
     * @param action setting in the form of action name
     * @return true if corresponding setting activity exists; false otherwise.
     */
    boolean hasActivity(String action);
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.DeviceSuspendTestActivity"	"DeviceSuspendTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/DeviceSuspendTestActivity.java"	""	"public void testpackage com.android.cts.verifier.sensors;

import java.util.ArrayList;
import java.util.List;
import java.util.Timer;
import java.util.TimerTask;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;
import com.android.cts.verifier.sensors.helpers.SensorTestScreenManipulator;

import android.app.AlarmManager;
import android.app.IntentService;
import android.app.Notification;
import android.app.NotificationChannel;
import android.app.NotificationManager;
import android.app.PendingIntent;
import android.app.Service;
import android.content.BroadcastReceiver;
import android.content.Context;
import android.content.Intent;
import android.content.IntentFilter;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.hardware.TriggerEvent;
import android.hardware.TriggerEventListener;
import android.hardware.cts.helpers.MovementDetectorHelper;
import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.SensorTestStateNotSupportedException;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEvent;
import android.hardware.cts.helpers.TestSensorEventListener;
import android.hardware.cts.helpers.TestSensorManager;
import android.hardware.cts.helpers.sensoroperations.TestSensorOperation;
import android.hardware.cts.helpers.SensorNotSupportedException;
import android.hardware.cts.helpers.sensorverification.BatchArrivalVerification;
import android.hardware.cts.helpers.sensorverification.TimestampClockSourceVerification;
import android.os.IBinder;
import android.os.PowerManager;
import android.os.PowerManager.WakeLock;
import android.os.SystemClock;
import androidx.localbroadcastmanager.content.LocalBroadcastManager;
import android.util.Log;
import android.view.MotionEvent;
import android.view.View;

import junit.framework.Assert;

public class DeviceSuspendTestActivity
            extends SensorCtsVerifierTestActivity {
        public DeviceSuspendTestActivity() {
            super(DeviceSuspendTestActivity.class);
        }

        private SensorTestScreenManipulator mScreenManipulator;
        private PowerManager.WakeLock mDeviceSuspendLock;
        private PendingIntent mPendingIntent;
        private AlarmManager mAlarmManager;
        private static String ACTION_ALARM = ""DeviceSuspendTestActivity.ACTION_ALARM"";
        private static String TAG = ""DeviceSuspendSensorTest"";
        private SensorManager mSensorManager;

        @Override
        protected void activitySetUp() throws InterruptedException {
            mSensorManager = (SensorManager) getSystemService(Context.SENSOR_SERVICE);
            mScreenManipulator = new SensorTestScreenManipulator(this);
            mScreenManipulator.initialize(this);
            LocalBroadcastManager.getInstance(this).registerReceiver(myBroadCastReceiver,
                                            new IntentFilter(ACTION_ALARM));

            Intent intent = new Intent(this, AlarmReceiver.class);
            mPendingIntent = PendingIntent.getBroadcast(this, 0, intent, PendingIntent.FLAG_MUTABLE_UNAUDITED);

            mAlarmManager = (AlarmManager) getSystemService(ALARM_SERVICE);

            PowerManager pm = (PowerManager)getSystemService(Context.POWER_SERVICE);
            mDeviceSuspendLock = pm.newWakeLock(PowerManager.PARTIAL_WAKE_LOCK,
                                                ""DeviceSuspendTestActivity"");

            // Launch a foreground service to ensure that the test remains in the foreground and is
            // able to be woken-up when sensor data is delivered.
            startForegroundService(new Intent(this, DeviceSuspendTestService.class));

            mDeviceSuspendLock.acquire();
            SensorTestLogger logger = getTestLogger();
            logger.logInstructions(R.string.snsr_device_suspend_test_instr);
            waitForUserToBegin();
        }

        @Override
        protected void activityCleanUp() {
            mScreenManipulator.turnScreenOn();
            try {
                playSound();
            } catch(InterruptedException e) {
              // Ignore.
            }
            LocalBroadcastManager.getInstance(this).unregisterReceiver(myBroadCastReceiver);
            if (mDeviceSuspendLock != null && mDeviceSuspendLock.isHeld()) {
                mDeviceSuspendLock.release();
            }

            stopService(new Intent(this, DeviceSuspendTestService.class));
        }

        @Override
        protected void onDestroy() {
            super.onDestroy();
            if (mDeviceSuspendLock != null && mDeviceSuspendLock.isHeld()) {
                mDeviceSuspendLock.release();
            }
            if (mScreenManipulator != null) {
                mScreenManipulator.releaseScreenOn();
                mScreenManipulator.close();
            }
        }

        public static class AlarmReceiver extends BroadcastReceiver {
            @Override
            public void onReceive(Context context, Intent intent) {
                Intent alarm_intent = new Intent(context, DeviceSuspendTestActivity.class);
                alarm_intent.setAction(DeviceSuspendTestActivity.ACTION_ALARM);
                LocalBroadcastManager.getInstance(context).sendBroadcastSync(alarm_intent);
            }
        }

        public BroadcastReceiver myBroadCastReceiver = new BroadcastReceiver() {
            @Override
            public void onReceive(Context context, Intent intent) {
                if (!mDeviceSuspendLock.isHeld()) {
                    mDeviceSuspendLock.acquire();
                }
            }
        };

        public static class DeviceSuspendTestService extends Service {
            private static final String NOTIFICATION_CHANNEL_ID =
                    ""com.android.cts.verifier.sensors.DeviceSuspendTestActivity.Notification"";
            private static final String NOTIFICATION_CHANNEL_NAME = ""Device Suspend Test"";

            @Override
            public IBinder onBind(Intent intent) {
                return null;
            }

            @Override
            public int onStartCommand(Intent intent, int flags, int startId) {
                NotificationChannel channel = new NotificationChannel(
                        NOTIFICATION_CHANNEL_ID,
                        NOTIFICATION_CHANNEL_NAME,
                        NotificationManager.IMPORTANCE_DEFAULT);
                NotificationManager notificationManager =
                        getSystemService(NotificationManager.class);
                notificationManager.createNotificationChannel(channel);
                Notification notification =
                        new Notification.Builder(getApplicationContext(), NOTIFICATION_CHANNEL_ID)
                        .setContentTitle(getString(R.string.snsr_device_suspend_service_active))
                        .setContentText(getString(
                                R.string.snsr_device_suspend_service_notification))
                        .setSmallIcon(R.drawable.icon)
                        .setAutoCancel(true)
                        .build();
                startForeground(1, notification);

                return START_NOT_STICKY;
            }
        }

        public String testAPWakeUpWhenReportLatencyExpiresAccel() throws Throwable {
            Sensor wakeUpSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER, true);
            if (wakeUpSensor == null) {
                throw new SensorNotSupportedException(Sensor.TYPE_ACCELEROMETER, true);
            }
            return runAPWakeUpWhenReportLatencyExpires(wakeUpSensor);
        }

        public String testAPWakeUpWhenReportLatencyExpiresGyro() throws Throwable {
            Sensor wakeUpSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_GYROSCOPE, true);
            if (wakeUpSensor == null) {
                throw new SensorNotSupportedException(Sensor.TYPE_GYROSCOPE, true);
            }
            return runAPWakeUpWhenReportLatencyExpires(wakeUpSensor);
        }

        public String testAPWakeUpWhenReportLatencyExpiresMag() throws Throwable {
            Sensor wakeUpSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_MAGNETIC_FIELD,true);
            if (wakeUpSensor == null) {
                throw new SensorNotSupportedException(Sensor.TYPE_MAGNETIC_FIELD, true);
            }
            return runAPWakeUpWhenReportLatencyExpires(wakeUpSensor);
        }

        public String testAPWakeUpWhenFIFOFullAccel() throws Throwable {
            Sensor wakeUpSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER, true);
            if (wakeUpSensor == null) {
                throw new SensorNotSupportedException(Sensor.TYPE_ACCELEROMETER, true);
            }
            return runAPWakeUpWhenFIFOFull(wakeUpSensor);
        }

        public String testAPWakeUpWhenFIFOFullGyro() throws Throwable {
            Sensor wakeUpSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_GYROSCOPE, true);
            if (wakeUpSensor == null) {
                throw new SensorNotSupportedException(Sensor.TYPE_GYROSCOPE, true);
            }
            return runAPWakeUpWhenFIFOFull(wakeUpSensor);
        }

        public String testAPWakeUpWhenFIFOFullMag() throws Throwable {
            Sensor wakeUpSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_MAGNETIC_FIELD,true);
            if (wakeUpSensor == null) {
                throw new SensorNotSupportedException(Sensor.TYPE_MAGNETIC_FIELD, true);
            }
            return runAPWakeUpWhenFIFOFull(wakeUpSensor);
        }

        public String testAccelBatchingInAPSuspendLargeReportLatency() throws Throwable {
            Sensor accel = mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER);
            if (accel == null) {
                throw new SensorNotSupportedException(Sensor.TYPE_ACCELEROMETER, false);
            }
            return runAPWakeUpByAlarmNonWakeSensor(accel, (int)TimeUnit.SECONDS.toMicros(1000));
        }

        public String testAccelBatchingInAPSuspendZeroReportLatency() throws Throwable {
            Sensor accel = mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER);
           if (accel == null) {
                throw new SensorNotSupportedException(Sensor.TYPE_ACCELEROMETER, false);
            }
            return runAPWakeUpByAlarmNonWakeSensor(accel, 0);
        }

        /**
         * Verify that the device is able to suspend
         */
        public void verifyDeviceCanSuspend() throws Throwable {
            // Make sure clocks are different (i.e. kernel has suspended at least once)
            // so that we can determine if sensors are using correct clocksource timestamp
            final int MAX_SLEEP_ATTEMPTS = 10;
            final int SLEEP_DURATION_MS = 2000;
            int sleep_attempts = 0;
            boolean device_needs_sleep = true;
            boolean wakelock_was_held = false;

            final long ALARM_WAKE_UP_DELAY_MS = TimeUnit.SECONDS.toMillis(20);
            mAlarmManager.setExact(AlarmManager.ELAPSED_REALTIME_WAKEUP,
                                    SystemClock.elapsedRealtime() + ALARM_WAKE_UP_DELAY_MS,
                                    mPendingIntent);

            if (mDeviceSuspendLock != null && mDeviceSuspendLock.isHeld()) {
                wakelock_was_held = true;
                mDeviceSuspendLock.release();
            }

            do {
                try {
                    verifyClockDelta();
                    device_needs_sleep = false;
                } catch(Throwable e) {
                    // Delta between clocks too small, must sleep longer
                    if (sleep_attempts++ > MAX_SLEEP_ATTEMPTS) {
                        mAlarmManager.cancel(mPendingIntent);
                        if (wakelock_was_held) {
                            mDeviceSuspendLock.acquire();
                        }
                        throw e;
                    }
                    Thread.sleep(SLEEP_DURATION_MS);
                }
            } while (device_needs_sleep);

            if (wakelock_was_held) {
                mDeviceSuspendLock.acquire();
            }
            mAlarmManager.cancel(mPendingIntent);
        }

        /**
         * Verify that each continuous sensor is using the correct
         * clock source (CLOCK_BOOTTIME) for timestamps.
         */
        public String testTimestampClockSource() throws Throwable {
            String string = null;
            boolean error_occurred = false;
            List<Sensor> sensorList = mSensorManager.getSensorList(Sensor.TYPE_ALL);
            if (sensorList == null) {
                throw new SensorTestStateNotSupportedException(
                    ""Sensors are not available in the system."");
            }

            boolean needToVerifySuspend = true;

            for (Sensor sensor : sensorList) {
                if (sensor.getReportingMode() != Sensor.REPORTING_MODE_CONTINUOUS) {
                    Log.i(TAG, ""testTimestampClockSource skipping non-continuous sensor: '"" + sensor.getName());
                    continue;
                }
                if (sensor.getType() >= Sensor.TYPE_DEVICE_PRIVATE_BASE) {
                    Log.i(TAG, ""testTimestampClockSource skipping vendor specific sensor: '"" + sensor.getName());
                    continue;
                }

                if (needToVerifySuspend) {
                    verifyDeviceCanSuspend();
                    needToVerifySuspend = false;
                }

                try {
                    string = runVerifySensorTimestampClockbase(sensor, false);
                    if (string != null) {
                        return string;
                    }
                } catch(Throwable e) {
                    Log.e(TAG, e.getMessage());
                    error_occurred = true;
                }
            }
            if (error_occurred) {
                throw new Error(""Sensors must use CLOCK_BOOTTIME as clock source for timestamping events"");
            }
            return null;
        }

        public String runAPWakeUpWhenReportLatencyExpires(Sensor sensor) throws Throwable {

            verifyBatchingSupport(sensor);

            int fifoMaxEventCount = sensor.getFifoMaxEventCount();
            int samplingPeriodUs = sensor.getMaxDelay();
            if (samplingPeriodUs == 0) {
                // If maxDelay is not defined, set the value for 5 Hz.
                samplingPeriodUs = 200000;
            }

            long fifoBasedReportLatencyUs = maxBatchingPeriod(sensor, samplingPeriodUs);
            verifyBatchingPeriod(fifoBasedReportLatencyUs);

            final long MAX_REPORT_LATENCY_US = TimeUnit.SECONDS.toMicros(15); // 15 seconds
            TestSensorEnvironment environment = new TestSensorEnvironment(
                    this,
                    sensor,
                    false,
                    samplingPeriodUs,
                    (int) MAX_REPORT_LATENCY_US,
                    true /*isDeviceSuspendTest*/);

            TestSensorOperation op = TestSensorOperation.createOperation(environment,
                                                                          mDeviceSuspendLock,
                                                                          false);
            final long ALARM_WAKE_UP_DELAY_MS =
                    TimeUnit.MICROSECONDS.toMillis(MAX_REPORT_LATENCY_US) +
                    TimeUnit.SECONDS.toMillis(10);

            op.addVerification(BatchArrivalVerification.getDefault(environment));
            mAlarmManager.setExact(AlarmManager.ELAPSED_REALTIME_WAKEUP,
                                    SystemClock.elapsedRealtime() + ALARM_WAKE_UP_DELAY_MS,
                                    mPendingIntent);
            try {
                Log.i(TAG, ""Running .. "" + getCurrentTestNode().getName() + "" "" + sensor.getName());
                op.execute(getCurrentTestNode());
            } finally {
                mAlarmManager.cancel(mPendingIntent);
            }
            return null;
        }

        public String runAPWakeUpWhenFIFOFull(Sensor sensor) throws Throwable {
            verifyBatchingSupport(sensor);

            // Try to fill the FIFO at the fastest rate and check if the time is enough to run
            // the manual test.
            int samplingPeriodUs = sensor.getMinDelay();

            long fifoBasedReportLatencyUs = maxBatchingPeriod(sensor, samplingPeriodUs);

            final long MIN_LATENCY_US = TimeUnit.SECONDS.toMicros(20);
            // Ensure that FIFO based report latency is at least 20 seconds, we need at least 10
            // seconds of time to allow the device to be in suspend state.
            if (fifoBasedReportLatencyUs < MIN_LATENCY_US) {
                int fifoMaxEventCount = sensor.getFifoMaxEventCount();
                samplingPeriodUs = (int) MIN_LATENCY_US/fifoMaxEventCount;
                fifoBasedReportLatencyUs = MIN_LATENCY_US;
            }

            final int MAX_REPORT_LATENCY_US = Integer.MAX_VALUE;
            final long ALARM_WAKE_UP_DELAY_MS =
                    TimeUnit.MICROSECONDS.toMillis(fifoBasedReportLatencyUs) +
                    TimeUnit.SECONDS.toMillis(10);

            TestSensorEnvironment environment = new TestSensorEnvironment(
                    this,
                    sensor,
                    false,
                    (int) samplingPeriodUs,
                    (int) MAX_REPORT_LATENCY_US,
                    true /*isDeviceSuspendTest*/);

            TestSensorOperation op = TestSensorOperation.createOperation(environment,
                                                                        mDeviceSuspendLock,
                                                                        true);
            mAlarmManager.setExact(AlarmManager.ELAPSED_REALTIME_WAKEUP,
                                    SystemClock.elapsedRealtime() + ALARM_WAKE_UP_DELAY_MS,
                                    mPendingIntent);
            op.addDefaultVerifications();
            try {
                Log.i(TAG, ""Running .. "" + getCurrentTestNode().getName() + "" "" + sensor.getName());
                op.execute(getCurrentTestNode());
            } finally {
                mAlarmManager.cancel(mPendingIntent);
            }
            return null;
        }

        /**
         * Verify the CLOCK_MONOTONIC and CLOCK_BOOTTIME clock sources are different
         * by at least 2 seconds.  Since delta between these two clock sources represents
         * time kernel has spent in suspend, device needs to have gone into suspend for
         * for at least 2 seconds since device was initially booted.
         */
        private void verifyClockDelta() throws Throwable {
            final int MIN_DELTA_BETWEEN_CLOCKS_MS = 2000;
            long uptimeMs = SystemClock.uptimeMillis();
            long realtimeMs = SystemClock.elapsedRealtime();
            long deltaMs = (realtimeMs - uptimeMs);
            if (deltaMs < MIN_DELTA_BETWEEN_CLOCKS_MS) {
                throw new Error(""Delta between clock sources too small (""
                                  + deltaMs + ""mS), device must sleep more than ""
                                  + MIN_DELTA_BETWEEN_CLOCKS_MS/1000 + "" seconds"");
            }
            Log.i(TAG, ""Delta between CLOCK_MONOTONIC and CLOCK_BOOTTIME is "" + deltaMs + "" mS"");
        }


        /**
         * Verify sensor is using the correct clock source (CLOCK_BOOTTIME) for timestamps.
         * To tell the clock sources apart, the kernel must have suspended at least once.
         *
         * @param sensor - sensor to verify
         * @param verify_clock_delta
         *          true to verify that clock sources differ before running test
         *          false to skip verification of sufficient delta between clock sources
         */
        public String runVerifySensorTimestampClockbase(Sensor sensor, boolean verify_clock_delta)
            throws Throwable {
            Log.i(TAG, ""Running .. "" + getCurrentTestNode().getName() + "" "" + sensor.getName());
            if (verify_clock_delta) {
                verifyClockDelta();
            }
            /* Enable a sensor, grab a sample, and then verify timestamp is > realtimeNs
             * to assure the correct clock source is being used for the sensor timestamp.
             */
            final int MIN_TIMESTAMP_BASE_SAMPLES = 1;
            int samplingPeriodUs = sensor.getMinDelay();
            TestSensorEnvironment environment = new TestSensorEnvironment(
                    this,
                    sensor,
                    false,
                    (int) samplingPeriodUs,
                    0,
                    false /*isDeviceSuspendTest*/);
            TestSensorOperation op = TestSensorOperation.createOperation(environment, MIN_TIMESTAMP_BASE_SAMPLES);
            op.addVerification(TimestampClockSourceVerification.getDefault(environment));
            try {
                op.execute(getCurrentTestNode());
            } finally {
            }
            return null;
        }


        public String runAPWakeUpByAlarmNonWakeSensor(Sensor sensor, int maxReportLatencyUs)
            throws  Throwable {
            verifyBatchingSupport(sensor);

            int samplingPeriodUs = sensor.getMaxDelay();
            if (samplingPeriodUs == 0 || samplingPeriodUs > 200000) {
                // If maxDelay is not defined, set the value for 5 Hz.
                samplingPeriodUs = 200000;
            }

            long fifoBasedReportLatencyUs = maxBatchingPeriod(sensor, samplingPeriodUs);
            verifyBatchingPeriod(fifoBasedReportLatencyUs);

            TestSensorEnvironment environment = new TestSensorEnvironment(
                    this,
                    sensor,
                    false,
                    (int) samplingPeriodUs,
                    maxReportLatencyUs,
                    true /*isDeviceSuspendTest*/);

            final long ALARM_WAKE_UP_DELAY_MS = 20000;
            TestSensorOperation op = TestSensorOperation.createOperation(environment,
                                                                         mDeviceSuspendLock,
                                                                         true);
            mAlarmManager.setExact(AlarmManager.ELAPSED_REALTIME_WAKEUP,
                                    SystemClock.elapsedRealtime() + ALARM_WAKE_UP_DELAY_MS,
                                    mPendingIntent);
            try {
                Log.i(TAG, ""Running .. "" + getCurrentTestNode().getName() + "" "" + sensor.getName());
                op.execute(getCurrentTestNode());
            } finally {
                mAlarmManager.cancel(mPendingIntent);
            }
            return null;
        }

        private void verifyBatchingSupport(Sensor sensor)
                throws SensorTestStateNotSupportedException {
            int fifoMaxEventCount = sensor.getFifoMaxEventCount();
            if (fifoMaxEventCount == 0) {
                throw new SensorTestStateNotSupportedException(""Batching not supported."");
            }
        }

        private void verifyBatchingPeriod(long periodUs)
                throws SensorTestStateNotSupportedException {
            // Ensure that FIFO based report latency is at least 20 seconds, we need at least 10
            // seconds of time to allow the device to be in suspend state.
            if (periodUs < TimeUnit.SECONDS.toMicros(20)) {
                throw new SensorTestStateNotSupportedException(""FIFO too small to test reliably"");
            }
        }

        private long maxBatchingPeriod (Sensor sensor, long samplePeriod) {
            long fifoMaxEventCount = sensor.getFifoMaxEventCount();
            return fifoMaxEventCount * samplePeriod;
        }

}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.FastBasicsTest"	"testCamera2"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/FastBasicsTest.java"	""	"public void testCamera2() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                Log.i(TAG, ""Testing camera2 API for camera device "" + mCameraIdsUnderTest[i]);

                if (!mAllStaticInfo.get(mCameraIdsUnderTest[i]).isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support color outputs, skipping"");
                    continue;
                }

                openDevice(mCameraIdsUnderTest[i]);
                camera2TestByCamera();
            } finally {
                closeDevice();
            }
        }
    }

    public void camera2TestByCamera() throws Exception {
        CaptureRequest.Builder previewRequest =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        CaptureRequest.Builder stillCaptureRequest =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
        Size previewSize = mOrderedPreviewSizes.get(0);
        Size stillSize = mOrderedStillSizes.get(0);
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        SimpleImageReaderListener imageListener = new SimpleImageReaderListener();

        prepareStillCaptureAndStartPreview(previewRequest, stillCaptureRequest,
                previewSize, stillSize, resultListener, imageListener, false /*isHeic*/);

        CaptureResult result = resultListener.getCaptureResult(WAIT_FOR_FRAMES_TIMEOUT_MS);

        Long timestamp = result.get(CaptureResult.SENSOR_TIMESTAMP);
        assertNotNull(""Can't read a capture result timestamp"", timestamp);

        CaptureResult result2 = resultListener.getCaptureResult(WAIT_FOR_FRAMES_TIMEOUT_MS);

        Long timestamp2 = result2.get(CaptureResult.SENSOR_TIMESTAMP);
        assertNotNull(""Can't read a capture result 2 timestamp"", timestamp2);

        assertTrue(""Bad timestamps"", timestamp2 > timestamp);

        // If EnableZsl is supported, disable ZSL in order to compare preview and still timestamps.
        if (mStaticInfo.isEnableZslSupported()) {
            stillCaptureRequest.set(CaptureRequest.CONTROL_ENABLE_ZSL, false);
        }

        CaptureRequest capture = stillCaptureRequest.build();
        mSession.capture(capture, resultListener, mHandler);

        CaptureResult stillResult =
                resultListener.getTotalCaptureResultForRequest(capture, FRAMES_TO_WAIT_FOR_CAPTURE);

        Long timestamp3 = stillResult.get(CaptureResult.SENSOR_TIMESTAMP);
        assertNotNull(""Can't read a still capture result timestamp"", timestamp3);

        assertTrue(""Bad timestamps"", timestamp3 > timestamp2);

        Image img = imageListener.getImage(WAIT_FOR_PICTURE_TIMEOUT_MS);

        ByteBuffer jpegBuffer = img.getPlanes()[0].getBuffer();
        byte[] jpegData = new byte[jpegBuffer.remaining()];
        jpegBuffer.get(jpegData);

        Bitmap b = BitmapFactory.decodeByteArray(jpegData, 0, jpegData.length);

        assertNotNull(""Unable to decode still capture JPEG"", b);

        closeImageReader();
    }

    private class Camera1Listener
            implements SurfaceTexture.OnFrameAvailableListener, Camera.PictureCallback {

        private Object mFrameSignal = new Object();
        private boolean mGotFrame = false;

        public boolean waitForFrame() {
            synchronized(mFrameSignal) {
                boolean waited = false;
                while (!waited) {
                    try {
                        mFrameSignal.wait(WAIT_FOR_FRAMES_TIMEOUT_MS);
                        waited = true;
                    } catch (InterruptedException e) {
                    }
                }
                return mGotFrame;
            }
        }

        public void onFrameAvailable(SurfaceTexture s) {
            synchronized(mFrameSignal) {
                mGotFrame = true;
                mFrameSignal.notifyAll();
            }
        }

        private Object mPictureSignal = new Object();
        private boolean mGotPicture = false;
        private byte[] mPictureData = null;

        public byte[] waitForPicture() {
            Log.i(TAG, ""waitForPicture called"");
            synchronized(mPictureSignal) {
                boolean waited = false;
                while (!waited) {
                    try {
                        mPictureSignal.wait(WAIT_FOR_PICTURE_TIMEOUT_MS);
                        waited = true;
                        Log.i(TAG, ""waitForPicture returned with mGotPicture = "" + mGotPicture);
                    } catch (InterruptedException e) {
                        Log.e(TAG, ""waitForPicture gets interrupted exception!"");
                    }
                }
                return mPictureData;
            }
        }

        public void onPictureTaken(byte[] data, Camera camera) {
            Log.i(TAG, ""onPictureTaken called"");
            synchronized(mPictureSignal) {
                mPictureData = data;
                mGotPicture = true;
                mPictureSignal.notifyAll();
            }
        }
    }

    @Presubmit"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.widget.WidgetTestActivity"	"setPassFailButtonClickListeners"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/widget/WidgetTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.widget;

import com.android.cts.verifier.PassFailButtons;
import com.android.cts.verifier.R;

import com.android.compatibility.common.util.CddTest;

import android.content.Context;
import android.hardware.Sensor;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.opengl.GLSurfaceView;
import android.os.Bundle;

/**
 * CTS Verifier case for verifying basic widget framework functionality.
 */
@CddTest(requirement=""3.8.2/C-1-2,C-1-3"")
public class WidgetTestActivity extends PassFailButtons.Activity {

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);

        setContentView(R.layout.pass_fail_widget);
        setPassFailButtonClickListeners();
        setInfoResources(R.string.widget_framework_test, R.string.widget_framework_test_info, -1);
    }

    @Override
    protected void onPause() {
        super.onPause();
    }

    @Override
    protected void onResume() {
        super.onResume();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.helpers.SensorSettingContainer"	"isSettingAvailable"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/helpers/SensorSettingContainer.java"	""	"public void test/*
 *
 */

package com.android.cts.verifier.sensors.helpers;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.base.BaseSensorTestActivity;
import com.android.cts.verifier.sensors.base.ISensorTestStateContainer;

/**
 * A helper class for {@link SensorFeaturesDeactivator}. It abstracts the responsibility of handling
 * device settings that affect sensors.
 *
 * This class is meant to be used only by {@link SensorFeaturesDeactivator}.
 * To keep things simple, this class synchronizes access to its internal state on public methods.
 * This approach is fine, because there is no need for concurrent access.
 */
abstract class SensorSettingContainer {
    private static final int DEFAULT_SETTING_VALUE = -1;

    private final String mAction;
    private final int mSettingNameResId;

    private boolean mInitialized;
    private boolean mSettingAvailable;
    private boolean mCapturedModeOn;

    public SensorSettingContainer(String action, int settingNameResId) {
        mAction = action;
        mSettingNameResId = settingNameResId;
    }

    public synchronized void captureInitialState() {
        if (mInitialized) {
            return;
        }
        mSettingAvailable = getSettingMode(DEFAULT_SETTING_VALUE) != DEFAULT_SETTING_VALUE;
        mCapturedModeOn = getCurrentSettingMode();
        mInitialized = true;
    }

    public synchronized void requestToSetMode(
            ISensorTestStateContainer stateContainer,
            boolean modeOn) throws InterruptedException {
        if (!isSettingAvailable() || !isSettingUiAvailable(stateContainer)) {
            return;
        }
        trySetMode(stateContainer, modeOn);
        if (getCurrentSettingMode() != modeOn) {
            String message = stateContainer.getString(
                    R.string.snsr_setting_mode_not_set,
                    getSettingName(stateContainer),
                    modeOn);
            throw new IllegalStateException(message);
        }
    }

    public synchronized void requestToResetMode(ISensorTestStateContainer stateContainer)
            throws InterruptedException {
        if (!isSettingAvailable() || !isSettingUiAvailable(stateContainer)) {
            return;
        }
        trySetMode(stateContainer, mCapturedModeOn);
    }

    private void trySetMode(ISensorTestStateContainer stateContainer, boolean modeOn)
            throws InterruptedException {
        BaseSensorTestActivity.SensorTestLogger logger = stateContainer.getTestLogger();
        String settingName = getSettingName(stateContainer);
        if (getCurrentSettingMode() == modeOn) {
            logger.logMessage(R.string.snsr_setting_mode_set, settingName, modeOn);
            return;
        }

        logger.logInstructions(R.string.snsr_setting_mode_request, settingName, modeOn);
        logger.logInstructions(R.string.snsr_on_complete_return);
        stateContainer.waitForUserToContinue();
        stateContainer.executeActivity(mAction);
    }

    private boolean getCurrentSettingMode() {
        return getSettingMode(DEFAULT_SETTING_VALUE) != 0;
    }

    private String getSettingName(ISensorTestStateContainer stateContainer) {
        return stateContainer.getString(mSettingNameResId);
    }

    protected boolean isSettingAvailable() {
        if (!mInitialized) {
            throw new IllegalStateException(
                    ""Object must be initialized first by invoking #captureInitialState."");
        }
        return mSettingAvailable;
    }

    protected boolean isSettingUiAvailable(ISensorTestStateContainer stateContainer) {
        return stateContainer.hasActivity(mAction);
    }

    protected abstract int getSettingMode(int defaultValue);
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Utils.PoseProvider.AndroidPoseProvider"	"SensorEventListener"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Utils/PoseProvider/AndroidPoseProvider.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Utils.PoseProvider;

import android.content.Context;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;

/**
 * Provides pose data using Android Sensors.
 */
public class AndroidPoseProvider extends PoseProvider {
    private static final int SENSOR_TYPE_POSE = 26; //28;
    private SensorManager mSensorManager;
    private Sensor m6DoFSensor;

    private SensorEventListener mSensorListener = new SensorEventListener() {
        @Override
        public void onSensorChanged(SensorEvent event) {
            synchronized (POSE_LOCK) {
                mLatestPoseData = new PoseData(event.values, event.timestamp);
            }

            onNewPoseData(mLatestPoseData);
        }

        @Override
        public void onAccuracyChanged(Sensor sensor, int accuracy) {
        }
    };

    public AndroidPoseProvider(Context context, PoseProviderListener poseListener) {
        super(context, poseListener);
        mIntrinsics = new Intrinsics();
    }

    @Override
    public void onStartPoseProviding() {
        mSensorManager = (SensorManager) mContext.getSystemService(Context.SENSOR_SERVICE);

        m6DoFSensor = mSensorManager.getDefaultSensor(SENSOR_TYPE_POSE);
        mSensorManager.registerListener(mSensorListener, m6DoFSensor, SensorManager.SENSOR_DELAY_FASTEST);
    }

    @Override
    public void onStopPoseProviding() {
        mSensorManager.unregisterListener(mSensorListener);
    }

    @Override
    public void setup() {
        // Don't need to do anything here.
        mPoseProviderListener.onSetupComplete();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.SensorPowerTestActivity"	"SensorPowerTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/SensorPowerTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;
import com.android.cts.verifier.sensors.helpers.PowerTestHostLink;
import com.android.cts.verifier.sensors.helpers.SensorTestScreenManipulator;
import com.android.cts.verifier.sensors.reporting.SensorTestDetails;

import junit.framework.Assert;

public class SensorPowerTestActivity
        extends SensorCtsVerifierTestActivity
        implements PowerTestHostLink.HostToDeviceInterface {

    private PowerTestHostLink mHostLink;
    private SensorTestScreenManipulator mScreenManipulator;

    public SensorPowerTestActivity() {
        super(SensorPowerTestActivity.class);
    }

    @Override
    public void waitForUserAcknowledgement(final String message) throws InterruptedException {
        appendText(message);
        waitForUserToContinue();
    }

    @Override
    public void raiseError(String testName, String message) throws Exception {
        getTestLogger().logTestFail(testName, message);
        throw new RuntimeException(message);
    }

    @Override
    public void logText(String text) {
        appendText(text);
    }

    @Override
    public void logTestResult(SensorTestDetails testDetails) {
        getTestLogger().logTestDetails(testDetails);
    }

    @Override
    public void turnScreenOff() {
        mScreenManipulator.turnScreenOffOnNextPowerDisconnect();
    }

    @Override
    protected void activitySetUp() throws InterruptedException {
        mScreenManipulator = new SensorTestScreenManipulator(this);
        mScreenManipulator.initialize(this);
    }

    @Override
    protected void activityCleanUp() throws InterruptedException {
        if (mHostLink != null) {
            mHostLink.close();
        }
        mScreenManipulator.close();
    }

    public String testSensorsPower() throws Throwable {
        if (mHostLink == null) {
            // prepare Activity screen to show instructions to the operator
            clearText();

            // ask the operator to set up the host
            appendText(""Connect the device to the host machine via the USB passthrough."");
            appendText(""Execute the following script (the command is available in CtsVerifier.zip):"");
            appendText(""    # python power/execute_power_tests.py --power_monitor <implementation> --run"");
            appendText(""where \""<implementation>\"" is the power monitor implementation being used, for example \""monsoon\"""");
            try {
                mHostLink = new PowerTestHostLink(this, this);

                appendText(""Waiting for connection from Host..."");

                // this will block until first connection from host,
                // and then allow the host to execute tests one by on
                // until it issues an ""EXIT"" command to break out
                // of the run loop. The host will run all associated tests
                // sequentially here:
                PowerTestHostLink.PowerTestResult testResult = mHostLink.run();

                SensorTestDetails testDetails = new SensorTestDetails(
                        getApplicationContext(),
                        ""SensorPowerTest"",
                        testResult.passedCount,
                        testResult.skippedCount,
                        testResult.failedCount);
                Assert.assertEquals(testDetails.getSummary(), 0, testResult.failedCount);
                return testDetails.getSummary();
            } finally {
                mHostLink.close();
                mHostLink = null;
            }
        } else {
            throw new IllegalStateException(""Attempt to run test twice"");
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.eventconnectionapi31.EventConnectionAPI31Test"	"testSamplingRateMicToggleOn"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/EventConnectionAPI31/src/android/sensorratepermission/cts/eventconnectionapi31/EventConnectionAPI31Test.java"	""	"public void testSamplingRateMicToggleOn() throws InterruptedException {
        mEventConnectionTestHelper.flipAndAssertMicToggleOn(mUserID, mSensorPrivacyManager);

        List<TestSensorEvent> events = mEventConnectionTestHelper.getSensorEvents(true,
                NUM_EVENTS_COUNT);

        double obtainedRate = SensorRatePermissionEventConnectionTestHelper.computeAvgRate(events,
                Long.MIN_VALUE, Long.MAX_VALUE);

        Assert.assertTrue(mEventConnectionTestHelper.errorWhenExceedCappedRate(),
                obtainedRate
                        <= SensorRatePermissionEventConnectionTestHelper.CAPPED_SAMPLE_RATE_HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.eventconnectionapi31.EventConnectionAPI31Test"	"testSamplingRateMicToggleOff"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/EventConnectionAPI31/src/android/sensorratepermission/cts/eventconnectionapi31/EventConnectionAPI31Test.java"	""	"public void testSamplingRateMicToggleOff() throws InterruptedException {
        mEventConnectionTestHelper.flipAndAssertMicToggleOff(mUserID, mSensorPrivacyManager);

        List<TestSensorEvent> events = mEventConnectionTestHelper.getSensorEvents(true,
                NUM_EVENTS_COUNT);
        double obtainedRate = SensorRatePermissionEventConnectionTestHelper.computeAvgRate(events,
                Long.MIN_VALUE, Long.MAX_VALUE);

        Assert.assertTrue(mEventConnectionTestHelper.errorWhenExceedCappedRate(),
                obtainedRate
                        <= SensorRatePermissionEventConnectionTestHelper.CAPPED_SAMPLE_RATE_HZ);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testAccelerometer_fastest_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testAccelerometer_fastest_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_ACCELEROMETER, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testAccelerometer_50hz_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testAccelerometer_50hz_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_ACCELEROMETER, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testAccelerometer_fastest_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testAccelerometer_fastest_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_ACCELEROMETER, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testAccelerometer_50hz_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testAccelerometer_50hz_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_ACCELEROMETER, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testAccelerometerUncalibrated_fastest_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testAccelerometerUncalibrated_fastest_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED,
                              RATE_FASTEST,
                              BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testAccelUncalibrated"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testAccelUncalibrated() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED,
                              RATE_FASTEST,
                              BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testAccelUncalibrated_50hz_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testAccelUncalibrated_50hz_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testAccelUncalibrated_fastest_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testAccelUncalibrated_fastest_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testAccelUncalibrated_50hz_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testAccelUncalibrated_50hz_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testMagneticField_fastest_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testMagneticField_fastest_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_MAGNETIC_FIELD, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testMagneticField_50hz_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testMagneticField_50hz_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_MAGNETIC_FIELD, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testMagneticField_fastest_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testMagneticField_fastest_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_MAGNETIC_FIELD, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testMagneticField_50hz_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testMagneticField_50hz_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_MAGNETIC_FIELD, RATE_50HZ, BATCHING_PERIOD);
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testOrientation_fastest_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testOrientation_fastest_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_ORIENTATION, RATE_FASTEST, BATCHING_PERIOD);
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testOrientation_50hz_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testOrientation_50hz_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_ORIENTATION, RATE_50HZ, BATCHING_PERIOD);
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testOrientation_fastest_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testOrientation_fastest_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_ORIENTATION, RATE_FASTEST, BATCHING_PERIOD);
    }

    @SuppressWarnings(""deprecation"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testOrientation_50hz_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testOrientation_50hz_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_ORIENTATION, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGyroscope_fastest_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGyroscope_fastest_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_GYROSCOPE, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGyroscope_50hz_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGyroscope_50hz_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_GYROSCOPE, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGyroscope_fastest_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGyroscope_fastest_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_GYROSCOPE, SensorManager.SENSOR_DELAY_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGyroscope_50hz_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGyroscope_50hz_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_GYROSCOPE, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testPressure_fastest_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testPressure_fastest_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_PRESSURE, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testPressure_50hz_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testPressure_50hz_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_PRESSURE, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testPressure_fastest_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testPressure_fastest_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_PRESSURE, SensorManager.SENSOR_DELAY_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testPressure_50hz_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testPressure_50hz_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_PRESSURE, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGravity_fastest_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGravity_fastest_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_GRAVITY, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGravity_50hz_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGravity_50hz_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_GRAVITY, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGravity_fastest_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGravity_fastest_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_GRAVITY, SensorManager.SENSOR_DELAY_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGravity_50hz_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGravity_50hz_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_GRAVITY, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testRotationVector_fastest_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testRotationVector_fastest_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_ROTATION_VECTOR, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testRotationVector_50hz_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testRotationVector_50hz_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_ROTATION_VECTOR, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testRotationVector_fastest_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testRotationVector_fastest_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_ROTATION_VECTOR, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testRotationVector_50hz_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testRotationVector_50hz_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_ROTATION_VECTOR, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testMagneticFieldUncalibrated_fastest_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testMagneticFieldUncalibrated_fastest_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testMagneticFieldUncalibrated_50hz_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testMagneticFieldUncalibrated_50hz_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testMagneticFieldUncalibrated_fastest_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testMagneticFieldUncalibrated_fastest_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testMagneticFieldUncalibrated_50hz_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testMagneticFieldUncalibrated_50hz_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGameRotationVector_fastest_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGameRotationVector_fastest_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_GAME_ROTATION_VECTOR, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGameRotationVector_50hz_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGameRotationVector_50hz_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_GAME_ROTATION_VECTOR, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGameRotationVector_fastest_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGameRotationVector_fastest_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_GAME_ROTATION_VECTOR, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGameRotationVector_50hz_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGameRotationVector_50hz_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_GAME_ROTATION_VECTOR, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGyroscopeUncalibrated_fastest_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGyroscopeUncalibrated_fastest_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGyroscopeUncalibrated_50hz_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGyroscopeUncalibrated_50hz_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGyroscopeUncalibrated_fastest_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGyroscopeUncalibrated_fastest_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGyroscopeUncalibrated_50hz_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGyroscopeUncalibrated_50hz_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testLinearAcceleration_fastest_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testLinearAcceleration_fastest_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_LINEAR_ACCELERATION, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testLinearAcceleration_50hz_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testLinearAcceleration_50hz_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_LINEAR_ACCELERATION, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testLinearAcceleration_fastest_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testLinearAcceleration_fastest_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_LINEAR_ACCELERATION, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testLinearAcceleration_50hz_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testLinearAcceleration_50hz_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_LINEAR_ACCELERATION, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGeomagneticRotationVector_fastest_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGeomagneticRotationVector_fastest_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_GEOMAGNETIC_ROTATION_VECTOR, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGeomagneticRotationVector_50hz_batching"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGeomagneticRotationVector_50hz_batching() throws Throwable {
        runBatchingSensorTest(Sensor.TYPE_GEOMAGNETIC_ROTATION_VECTOR, RATE_50HZ, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGeomagneticRotationVector_fastest_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGeomagneticRotationVector_fastest_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_GEOMAGNETIC_ROTATION_VECTOR, RATE_FASTEST, BATCHING_PERIOD);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingTests"	"testGeomagneticRotationVector_50hz_flush"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingTests.java"	""	"public void testGeomagneticRotationVector_50hz_flush() throws Throwable {
        runFlushSensorTest(Sensor.TYPE_GEOMAGNETIC_ROTATION_VECTOR, RATE_50HZ, BATCHING_PERIOD);
    }

    private void runBatchingSensorTest(int sensorType, int rateUs, int maxBatchReportLatencySec)
            throws Throwable {
        int maxBatchReportLatencyUs = (int) TimeUnit.SECONDS.toMicros(maxBatchReportLatencySec);
        int testDurationSec = maxBatchReportLatencySec + BATCHING_PADDING_TIME_S;

        TestSensorEnvironment environment = new TestSensorEnvironment(
                getContext(),
                sensorType,
                shouldEmulateSensorUnderLoad(),
                rateUs,
                maxBatchReportLatencyUs);
        TestSensorOperation operation =
                TestSensorOperation.createOperation(environment, testDurationSec, TimeUnit.SECONDS);

        operation.addVerification(
                EventBasicVerification.getDefault(
                        environment, TimeUnit.SECONDS.toMicros(testDurationSec)
                )
        );
        if (sensorType == Sensor.TYPE_GYROSCOPE_UNCALIBRATED) {
            // Checks gyroscope uncalibrated should not have high pass filter.
            operation.addVerification(
                MeanLargerThanVerification.getDefault(environment)
            );
        }
        executeTest(environment, operation, false /* flushExpected */);
    }

    private void runFlushSensorTest(int sensorType, int rateUs, int maxBatchReportLatencySec)
            throws Throwable {
        int maxBatchReportLatencyUs = (int) TimeUnit.SECONDS.toMicros(maxBatchReportLatencySec);
        int flushDurationSec = maxBatchReportLatencySec / 2;

        TestSensorEnvironment environment = new TestSensorEnvironment(
                getContext(),
                sensorType,
                shouldEmulateSensorUnderLoad(),
                rateUs,
                maxBatchReportLatencyUs);
        TestSensorOperation operation = TestSensorOperation
                .createFlushOperation(environment, flushDurationSec, TimeUnit.SECONDS);

        executeTest(environment, operation, true /* flushExpected */);
    }

    private void executeTest(
            TestSensorEnvironment environment,
            TestSensorOperation operation,
            boolean flushExpected) throws Throwable {
        SensorCtsHelper.sleep(3, TimeUnit.SECONDS);
        operation.addDefaultVerifications();

        try {
            operation.execute(getCurrentTestNode());
        } finally {
            SensorStats stats = operation.getStats();
            stats.log(TAG);

            String sensorRate;
            if (environment.getRequestedSamplingPeriodUs() == SensorManager.SENSOR_DELAY_FASTEST) {
                sensorRate = ""fastest"";
            } else {
                sensorRate = String.format(""%.0fhz"", environment.getFrequencyHz());
            }
            String batching = environment.getMaxReportLatencyUs() > 0 ? ""_batching"" : """";
            String flush = flushExpected ? ""_flush"" : """";
            String fileName = String.format(
                    ""batching_%s_%s%s%s.txt"",
                    SensorStats.getSanitizedSensorName(environment.getSensor()),
                    sensorRate,
                    batching,
                    flush);
            stats.logToFile(environment.getContext(), fileName);
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.HeartRateMonitorTestActivity"	"setPassFailButtonClickListeners"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/HeartRateMonitorTestActivity.java"	""	"public void test/*
 *
 */

package com.android.cts.verifier.sensors;

import android.app.AlertDialog;
import android.content.Context;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.os.Bundle;
import android.view.View;
import android.widget.TextView;

import com.android.cts.verifier.PassFailButtons;
import com.android.cts.verifier.R;

/**
 * CTS Verifier case for verifying correct integration of heart rate monitor.
 * If a user is wearing a device with an HRM, the value is between <> and <>
 */
public class HeartRateMonitorTestActivity extends PassFailButtons.Activity {
    private SensorManager mSensorManager;
    private Sensor mSensor;
    private SensorListener mSensorListener;
    private AlertDialog mNoHeartRateWarningDialog;
    private TextView mSensorText;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.snsr_hrm);
        setInfoResources(R.string.snsr_heartrate_test, R.string.snsr_heartrate_test_info, 0);
        setPassFailButtonClickListeners();

        mSensorText = (TextView) findViewById(R.id.sensor_value);

        mSensorManager = (SensorManager) getApplicationContext().getSystemService(
                Context.SENSOR_SERVICE);
        mSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_HEART_RATE);
        mSensorListener = new SensorListener();
    }

    @Override
    protected void onResume() {
        super.onResume();
        if (!mSensorManager.registerListener(mSensorListener, mSensor,
                SensorManager.SENSOR_DELAY_UI)) {
            showNoHeartRateWarningDialog();
            setTestResultAndFinish(true);
        }
    }

    @Override
    protected void onPause() {
        super.onPause();
        mSensorManager.unregisterListener(mSensorListener, mSensor);
    }

    private void showNoHeartRateWarningDialog() {
        if (mNoHeartRateWarningDialog == null) {
            mNoHeartRateWarningDialog = new AlertDialog.Builder(this)
                    .setIcon(android.R.drawable.ic_dialog_alert)
                    .setTitle(R.string.snsr_heartrate_test_no_heartrate_title)
                    .setMessage(R.string.snsr_heartrate_test_no_heartrate_message)
                    .setPositiveButton(android.R.string.ok, null)
                    .create();
        }
        if (!mNoHeartRateWarningDialog.isShowing()) {
            mNoHeartRateWarningDialog.show();
        }
    }

    private class SensorListener implements SensorEventListener {
        private static final double MIN_HEART_RATE = 40;
        private static final double MAX_HEART_RATE = 200;
        @Override
        public void onSensorChanged(SensorEvent sensorEvent) {
            float value = sensorEvent.values[0];
            if (value > MAX_HEART_RATE || value < MIN_HEART_RATE) {
                updateWidgets(value, sensorEvent.accuracy, R.drawable.fs_error);
            } else {
                updateWidgets(value, sensorEvent.accuracy, R.drawable.fs_good);
            }
        }

        void updateWidgets(float value, float accuracy, int icon) {
            TextView sensorText = (TextView) findViewById(R.id.sensor_value);
            TextView sensorAccuracyText = (TextView) findViewById(R.id.sensor_accuracy_value);

            sensorText.setText(String.format(""%+.2f"", value));
            sensorText.setCompoundDrawablesWithIntrinsicBounds(0, 0, icon, 0);
            sensorAccuracyText.setText(String.format(""%+.2f"", accuracy));
        }

        @Override
        public void onAccuracyChanged(Sensor sensor, int i) {
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.MultiResolutionReprocessCaptureTest"	"testMultiResolutionReprocessCharacteristics"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/MultiResolutionReprocessCaptureTest.java"	""	"public void testMultiResolutionReprocessCharacteristics() {
        for (String id : mCameraIdsUnderTest) {
            if (VERBOSE) {
                Log.v(TAG, ""Testing multi-resolution reprocess characteristics for Camera "" + id);
            }
            StaticMetadata info = mAllStaticInfo.get(id);
            CameraCharacteristics c = info.getCharacteristics();
            StreamConfigurationMap config = c.get(
                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
            int[] inputFormats = config.getInputFormats();
            int[] capabilities = CameraTestUtils.getValueNotNull(
                    c, CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
            boolean isLogicalCamera = CameraTestUtils.contains(capabilities,
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_LOGICAL_MULTI_CAMERA);
            boolean isUltraHighResCamera = info.isUltraHighResolutionSensor();
            Set<String> physicalCameraIds = c.getPhysicalCameraIds();

            MultiResolutionStreamConfigurationMap multiResolutionMap = c.get(
                    CameraCharacteristics.SCALER_MULTI_RESOLUTION_STREAM_CONFIGURATION_MAP);
            if (multiResolutionMap == null) {
                Log.i(TAG, ""Camera "" + id + "" doesn't support multi-resolution reprocessing."");
                continue;
            }
            if (VERBOSE) {
                Log.v(TAG, ""MULTI_RESOLUTION_STREAM_CONFIGURATION_MAP: ""
                        + multiResolutionMap.toString());
            }

            // Find multi-resolution input and output formats
            int[] multiResolutionInputFormats = multiResolutionMap.getInputFormats();
            int[] multiResolutionOutputFormats = multiResolutionMap.getOutputFormats();

            assertTrue(""Camera "" + id + "" must be a logical multi-camera or ultra high res camera ""
                    + ""to support multi-resolution reprocessing."",
                    isLogicalCamera || isUltraHighResCamera);

            for (int format : multiResolutionInputFormats) {
                assertTrue(String.format(""Camera %s: multi-resolution input format %d ""
                        + ""isn't a supported format"", id, format),
                        CameraTestUtils.contains(inputFormats, format));

                Collection<MultiResolutionStreamInfo> multiResolutionStreams =
                        multiResolutionMap.getInputInfo(format);
                assertTrue(String.format(""Camera %s supports %d multi-resolution ""
                        + ""input stream info, expected at least 2"", id,
                        multiResolutionStreams.size()),
                        multiResolutionStreams.size() >= 2);

                // Make sure that each multi-resolution input stream info has the maximum size
                // for that format.
                for (MultiResolutionStreamInfo streamInfo : multiResolutionStreams) {
                    String physicalCameraId = streamInfo.getPhysicalCameraId();
                    Size streamSize = new Size(streamInfo.getWidth(), streamInfo.getHeight());
                    if (!isLogicalCamera) {
                        assertTrue(""Camera "" + id + "" is ultra high resolution camera, but ""
                                + ""the multi-resolution reprocessing stream info camera Id ""
                                + physicalCameraId + "" doesn't match"",
                                physicalCameraId.equals(id));
                    } else {
                        assertTrue(""Camera "" + id + ""'s multi-resolution input info ""
                                + ""physical camera id "" + physicalCameraId + "" isn't valid"",
                                physicalCameraIds.contains(physicalCameraId));
                    }

                    StaticMetadata pInfo = mAllStaticInfo.get(physicalCameraId);
                    CameraCharacteristics pChar = pInfo.getCharacteristics();
                    StreamConfigurationMap pConfig = pChar.get(
                            CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
                    Size[] sizes = pConfig.getInputSizes(format);

                    assertTrue(String.format(""Camera %s must ""
                            + ""support at least one input size for multi-resolution input ""
                            + ""format %d."", physicalCameraId, format),
                             sizes != null && sizes.length > 0);

                    List<Size> maxSizes = new ArrayList<Size>();
                    maxSizes.add(CameraTestUtils.getMaxSize(sizes));
                    StreamConfigurationMap pMaxResConfig = pChar.get(CameraCharacteristics.
                            SCALER_STREAM_CONFIGURATION_MAP_MAXIMUM_RESOLUTION);
                    if (pMaxResConfig != null) {
                        Size[] maxResSizes = pMaxResConfig.getInputSizes(format);
                        if (maxResSizes != null && maxResSizes.length > 0) {
                            maxSizes.add(CameraTestUtils.getMaxSize(maxResSizes));
                        }
                    }

                    assertTrue(String.format(""Camera %s's supported multi-resolution""
                           + "" input size %s for physical camera %s is not one of the largest ""
                           + ""supported input sizes %s for format %d"", id, streamSize,
                           physicalCameraId, maxSizes, format), maxSizes.contains(streamSize));
                }
            }

            // YUV reprocessing capabilities check
            if (CameraTestUtils.contains(multiResolutionOutputFormats, ImageFormat.YUV_422_888) &&
                    CameraTestUtils.contains(multiResolutionInputFormats,
                    ImageFormat.YUV_420_888)) {
                assertTrue(""The camera device must have YUV_REPROCESSING capability if it ""
                        + ""supports multi-resolution YUV input and YUV output"",
                        CameraTestUtils.contains(capabilities,
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_YUV_REPROCESSING));

                assertTrue(""The camera device must supports multi-resolution JPEG output if ""
                        + ""supports multi-resolution YUV input and YUV output"",
                        CameraTestUtils.contains(multiResolutionOutputFormats, ImageFormat.JPEG));
            }

            // OPAQUE reprocessing capabilities check
            if (CameraTestUtils.contains(multiResolutionOutputFormats, ImageFormat.PRIVATE) &&
                    CameraTestUtils.contains(multiResolutionInputFormats, ImageFormat.PRIVATE)) {
                assertTrue(""The camera device must have PRIVATE_REPROCESSING capability if it ""
                        + ""supports multi-resolution PRIVATE input and PRIVATE output"",
                        CameraTestUtils.contains(capabilities,
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING));

                assertTrue(""The camera device must supports multi-resolution JPEG output if ""
                        + ""supports multi-resolution PRIVATE input and PRIVATE output"",
                        CameraTestUtils.contains(multiResolutionOutputFormats, ImageFormat.JPEG));
                assertTrue(""The camera device must supports multi-resolution YUV output if ""
                        + ""supports multi-resolution PRIVATE input and PRIVATE output"",
                        CameraTestUtils.contains(multiResolutionOutputFormats,
                        ImageFormat.YUV_420_888));
            }
        }
    }

    /**
     * Test YUV_420_888 -> YUV_420_888 multi-resolution reprocessing
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.MultiResolutionReprocessCaptureTest"	"testMultiResolutionMandatoryStreamCombinationTest"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/MultiResolutionReprocessCaptureTest.java"	""	"public void testMultiResolutionMandatoryStreamCombinationTest() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            StaticMetadata info = mAllStaticInfo.get(id);
            CameraCharacteristics c = info.getCharacteristics();
            MandatoryStreamCombination[] combinations = c.get(
                            CameraCharacteristics.SCALER_MANDATORY_STREAM_COMBINATIONS);
            if (combinations == null) {
                Log.i(TAG, ""No mandatory stream combinations for camera: "" + id + "" skip test"");
                continue;
            }
            MultiResolutionStreamConfigurationMap multiResolutionMap = c.get(
                    CameraCharacteristics.SCALER_MULTI_RESOLUTION_STREAM_CONFIGURATION_MAP);
            if (multiResolutionMap == null) {
                Log.i(TAG, ""Camera "" + id + "" doesn't support multi-resolution capture."");
                continue;
            }
            int[] multiResolutionInputFormats = multiResolutionMap.getInputFormats();
            int[] multiResolutionOutputFormats = multiResolutionMap.getOutputFormats();
            if (multiResolutionInputFormats.length == 0
                    || multiResolutionOutputFormats.length == 0) {
                Log.i(TAG, ""Camera "" + id + "" doesn't support multi-resolution reprocess ""
                        + ""input/output."");
                continue;
            }

            try {
                openDevice(id);
                for (MandatoryStreamCombination combination : combinations) {
                    if (!combination.isReprocessable()) {
                        continue;
                    }

                    MandatoryStreamCombination.MandatoryStreamInformation firstStreamInfo =
                            combination.getStreamsInformation().get(0);
                    int inputFormat = firstStreamInfo.getFormat();
                    boolean supportMultiResReprocess = firstStreamInfo.isInput() &&
                            CameraTestUtils.contains(multiResolutionOutputFormats, inputFormat) &&
                            CameraTestUtils.contains(multiResolutionInputFormats, inputFormat);
                    if (!supportMultiResReprocess)  {
                        continue;
                    }

                    testMultiResolutionMandatoryStreamCombination(id, info, combination,
                            multiResolutionMap);
                }
            } finally {
                closeDevice(id);
            }
        }
    }

    private void testMultiResolutionMandatoryStreamCombination(String cameraId,
            StaticMetadata staticInfo, MandatoryStreamCombination combination,
            MultiResolutionStreamConfigurationMap multiResStreamConfig) throws Exception {
        String log = ""Testing multi-resolution mandatory stream combination: "" +
                combination.getDescription() + "" on camera: "" + cameraId;
        Log.i(TAG, log);

        final int TIMEOUT_FOR_RESULT_MS = 5000;
        final int NUM_REPROCESS_CAPTURES_PER_CONFIG = 3;

        // Set up outputs
        List<OutputConfiguration> outputConfigs = new ArrayList<OutputConfiguration>();
        List<Surface> outputSurfaces = new ArrayList<Surface>();
        StreamCombinationTargets targets = new StreamCombinationTargets();
        MultiResolutionImageReader inputReader = null;
        ImageWriter inputWriter = null;
        SimpleImageReaderListener inputReaderListener = new SimpleImageReaderListener();
        SimpleCaptureCallback inputCaptureListener = new SimpleCaptureCallback();
        SimpleCaptureCallback reprocessOutputCaptureListener = new SimpleCaptureCallback();

        List<MandatoryStreamInformation> streamInfo = combination.getStreamsInformation();
        assertTrue(""Reprocessable stream combinations should have at least 3 or more streams"",
                    (streamInfo != null) && (streamInfo.size() >= 3));
        assertTrue(""The first mandatory stream information in a reprocessable combination must "" +
                ""always be input"", streamInfo.get(0).isInput());

        int inputFormat = streamInfo.get(0).getFormat();

        CameraTestUtils.setupConfigurationTargets(streamInfo.subList(2, streamInfo.size()),
                targets, outputConfigs, outputSurfaces, NUM_REPROCESS_CAPTURES_PER_CONFIG,
                /*substituteY8*/false, /*substituteHeic*/false, /*physicalCameraId*/null,
                multiResStreamConfig, mHandler);

        Collection<MultiResolutionStreamInfo> multiResInputs =
                multiResStreamConfig.getInputInfo(inputFormat);
        InputConfiguration inputConfig = new InputConfiguration(multiResInputs, inputFormat);

        try {
            // For each config, YUV and JPEG outputs will be tested. (For YUV reprocessing,
            // the YUV ImageReader for input is also used for output.)
            final boolean inputIsYuv = inputConfig.getFormat() == ImageFormat.YUV_420_888;
            final boolean useYuv = inputIsYuv || targets.mYuvTargets.size() > 0 ||
                    targets.mYuvMultiResTargets.size() > 0;
            final int totalNumReprocessCaptures =  NUM_REPROCESS_CAPTURES_PER_CONFIG * (
                    (inputIsYuv ? 1 : 0) + targets.mJpegMultiResTargets.size() +
                    targets.mJpegTargets.size() +
                    (useYuv ? targets.mYuvMultiResTargets.size() + targets.mYuvTargets.size() : 0));

            // It needs 1 input buffer for each reprocess capture + the number of buffers
            // that will be used as outputs.
            inputReader = new MultiResolutionImageReader(multiResInputs, inputFormat,
                    totalNumReprocessCaptures + NUM_REPROCESS_CAPTURES_PER_CONFIG);
            inputReader.setOnImageAvailableListener(
                    inputReaderListener, new HandlerExecutor(mHandler));
            outputConfigs.addAll(
                    OutputConfiguration.createInstancesForMultiResolutionOutput(inputReader));
            outputSurfaces.add(inputReader.getSurface());

            CameraCaptureSession.CaptureCallback mockCaptureCallback =
                    mock(CameraCaptureSession.CaptureCallback.class);

            checkSessionConfigurationSupported(mCamera, mHandler, outputConfigs,
                    inputConfig, SessionConfiguration.SESSION_REGULAR,
                    true/*defaultSupport*/, String.format(
                    ""Session configuration query for multi-res combination: %s failed"",
                    combination.getDescription()));

            // Verify we can create a reprocessable session with the input and all outputs.
            BlockingSessionCallback sessionListener = new BlockingSessionCallback();
            CameraCaptureSession session = configureReprocessableCameraSessionWithConfigurations(
                    mCamera, inputConfig, outputConfigs, sessionListener, mHandler);
            inputWriter = ImageWriter.newInstance(
                    session.getInputSurface(), totalNumReprocessCaptures);

            // Prepare a request for reprocess input
            CaptureRequest.Builder builder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_ZERO_SHUTTER_LAG);
            builder.addTarget(inputReader.getSurface());

            for (int i = 0; i < totalNumReprocessCaptures; i++) {
                session.capture(builder.build(), inputCaptureListener, mHandler);
            }

            List<CaptureRequest> reprocessRequests = new ArrayList<>();
            List<Surface> reprocessOutputs = new ArrayList<>();

            if (inputIsYuv) {
                reprocessOutputs.add(inputReader.getSurface());
            }
            for (MultiResolutionImageReader reader : targets.mJpegMultiResTargets) {
                reprocessOutputs.add(reader.getSurface());
            }
            for (ImageReader reader : targets.mJpegTargets) {
                reprocessOutputs.add(reader.getSurface());
            }
            for (MultiResolutionImageReader reader : targets.mYuvMultiResTargets) {
                reprocessOutputs.add(reader.getSurface());
            }
            for (ImageReader reader : targets.mYuvTargets) {
                reprocessOutputs.add(reader.getSurface());
            }

            for (int i = 0; i < NUM_REPROCESS_CAPTURES_PER_CONFIG; i++) {
                for (Surface output : reprocessOutputs) {
                    TotalCaptureResult result = inputCaptureListener.getTotalCaptureResult(
                            TIMEOUT_FOR_RESULT_MS);
                    Map<String, TotalCaptureResult> physicalResults =
                            result.getPhysicalCameraTotalResults();
                    for (Map.Entry<String, TotalCaptureResult> entry : physicalResults.entrySet()) {
                        String physicalCameraId = entry.getKey();
                        TotalCaptureResult physicalResult = entry.getValue();
                        String activePhysicalId = physicalResult.get(
                                CaptureResult.LOGICAL_MULTI_CAMERA_ACTIVE_PHYSICAL_ID);
                        mCollector.expectEquals(String.format(
                                ""Physical camera result metadata must contain activePhysicalId "" +
                                ""(%s) matching with physical camera Id (%s)."", activePhysicalId,
                                physicalCameraId), physicalCameraId, activePhysicalId);
                    }

                    String activePhysicalCameraId = result.get(
                            CaptureResult.LOGICAL_MULTI_CAMERA_ACTIVE_PHYSICAL_ID);
                    if (activePhysicalCameraId != null) {
                        result = physicalResults.get(activePhysicalCameraId);
                    }

                    builder = mCamera.createReprocessCaptureRequest(result);
                    inputWriter.queueInputImage(
                            inputReaderListener.getImage(TIMEOUT_FOR_RESULT_MS));
                    builder.addTarget(output);
                    reprocessRequests.add(builder.build());
                }
            }

            session.captureBurst(reprocessRequests, reprocessOutputCaptureListener, mHandler);

            for (int i = 0; i < reprocessOutputs.size() * NUM_REPROCESS_CAPTURES_PER_CONFIG; i++) {
                TotalCaptureResult result = reprocessOutputCaptureListener.getTotalCaptureResult(
                        TIMEOUT_FOR_RESULT_MS);
            }
        } catch (Throwable e) {
            mCollector.addMessage(
                    String.format(""Mandatory multi-res stream combination: %s failed due: %s"",
                    combination.getDescription(), e.getMessage()));
        } finally {
            inputReaderListener.drain();
            reprocessOutputCaptureListener.drain();
            targets.close();

            if (inputReader != null) {
                inputReader.close();
            }

            if (inputWriter != null) {
                inputWriter.close();
            }
        }
    }

    /**
     * Test multi-resolution reprocessing from the input format to the output format
     */
    private void testMultiResolutionReprocessing(String cameraId, int inputFormat,
            int outputFormat) throws Exception {
        if (VERBOSE) {
            Log.v(TAG, ""testMultiResolutionReprocessing: cameraId: "" + cameraId + "" inputFormat: ""
                    + inputFormat + "" outputFormat: "" + outputFormat);
        }

        Collection<MultiResolutionStreamInfo> inputStreamInfo =
                getMultiResReprocessInfo(cameraId, inputFormat, /*input*/ true);
        Collection<MultiResolutionStreamInfo> regularOutputStreamInfo =
                getMultiResReprocessInfo(cameraId, inputFormat, /*input*/ false);
        Collection<MultiResolutionStreamInfo> reprocessOutputStreamInfo =
                getMultiResReprocessInfo(cameraId, outputFormat, /*input*/ false);
        if (inputStreamInfo == null || regularOutputStreamInfo == null ||
                reprocessOutputStreamInfo == null) {
            return;
        }
        assertTrue(""The multi-resolution stream info for format "" + inputFormat
                + "" must be equal between input and output"",
                inputStreamInfo.containsAll(regularOutputStreamInfo)
                && regularOutputStreamInfo.containsAll(inputStreamInfo));

        try {
            openDevice(cameraId);

            testMultiResolutionReprocessWithStreamInfo(cameraId, inputFormat, inputStreamInfo,
                    outputFormat, reprocessOutputStreamInfo);
        } finally {
            closeDevice(cameraId);
        }
    }

    /**
     * Test multi-resolution reprocess with multi-resolution stream info lists for a particular
     * format combination.
     */
    private void testMultiResolutionReprocessWithStreamInfo(String cameraId,
            int inputFormat, Collection<MultiResolutionStreamInfo> inputInfo,
            int outputFormat, Collection<MultiResolutionStreamInfo> outputInfo)
            throws Exception {
        try {
            setupMultiResImageReaders(inputFormat, inputInfo, outputFormat, outputInfo,
                    /*maxImages*/1);
            setupReprocessableSession(inputFormat, inputInfo, outputInfo,
                    /*numImageWriterImages*/1);

            List<Float> zoomRatioList = CameraTestUtils.getCandidateZoomRatios(mStaticInfo);
            for (Float zoomRatio :  zoomRatioList) {
                ImageResultSizeHolder imageResultSizeHolder = null;

                try {
                    imageResultSizeHolder = doMultiResReprocessCapture(zoomRatio);
                    Image reprocessedImage = imageResultSizeHolder.getImage();
                    Size outputSize = imageResultSizeHolder.getExpectedSize();
                    TotalCaptureResult result = imageResultSizeHolder.getTotalCaptureResult();

                    mCollector.expectImageProperties(""testMultiResolutionReprocess"",
                            reprocessedImage, outputFormat, outputSize,
                            result.get(CaptureResult.SENSOR_TIMESTAMP));

                    if (DEBUG) {
                        Log.d(TAG, String.format(""camera %s %d zoom %f out %dx%d %d"",
                                cameraId, inputFormat, zoomRatio,
                                outputSize.getWidth(), outputSize.getHeight(),
                                outputFormat));

                        dumpImage(reprocessedImage,
                                ""/testMultiResolutionReprocess_camera"" + cameraId
                                + ""_"" + mDumpFrameCount);
                        mDumpFrameCount++;
                    }
                } finally {
                    if (imageResultSizeHolder != null) {
                        imageResultSizeHolder.getImage().close();
                    }
                }
            }
        } finally {
            closeReprossibleSession();
            closeMultiResImageReaders();
        }
    }

    /**
     * Set up multi-resolution image readers for regular and reprocess output
     *
     * <p>If the reprocess input format is equal to output format, share one multi-resolution
     * image reader.</p>
     */
    private void setupMultiResImageReaders(int inputFormat,
            Collection<MultiResolutionStreamInfo> inputInfo, int outputFormat,
            Collection<MultiResolutionStreamInfo> outputInfo, int maxImages) {

        mShareOneReader = false;
        // If the regular output and reprocess output have the same format,
        // they can share one MultiResolutionImageReader.
        if (inputFormat == outputFormat) {
            maxImages *= 2;
            mShareOneReader = true;
        }

        // create an MultiResolutionImageReader for the regular capture
        mMultiResImageReader = new MultiResolutionImageReader(inputInfo,
                inputFormat, maxImages);
        mMultiResImageReaderListener = new SimpleMultiResolutionImageReaderListener(
                mMultiResImageReader, 1, /*repeating*/false);
        mMultiResImageReader.setOnImageAvailableListener(mMultiResImageReaderListener,
                new HandlerExecutor(mHandler));

        if (!mShareOneReader) {
            // create an MultiResolutionImageReader for the reprocess capture
            mSecondMultiResImageReader = new MultiResolutionImageReader(
                    outputInfo, outputFormat, maxImages);
            mSecondMultiResImageReaderListener = new SimpleMultiResolutionImageReaderListener(
                    mSecondMultiResImageReader, maxImages, /*repeating*/ false);
            mSecondMultiResImageReader.setOnImageAvailableListener(
                    mSecondMultiResImageReaderListener, new HandlerExecutor(mHandler));
        }
    }

    /**
     * Close two multi-resolution image readers.
     */
    private void closeMultiResImageReaders() {
        mMultiResImageReader.close();
        mMultiResImageReader = null;

        if (!mShareOneReader) {
            mSecondMultiResImageReader.close();
            mSecondMultiResImageReader = null;
        }
    }

    /**
     * Get the MultiResolutionImageReader for reprocess output.
     */
    private MultiResolutionImageReader getOutputMultiResImageReader() {
        if (mShareOneReader) {
            return mMultiResImageReader;
        } else {
            return mSecondMultiResImageReader;
        }
    }

    /**
     * Get the MultiResolutionImageReaderListener for reprocess output.
     */
    private SimpleMultiResolutionImageReaderListener getOutputMultiResImageReaderListener() {
        if (mShareOneReader) {
            return mMultiResImageReaderListener;
        } else {
            return mSecondMultiResImageReaderListener;
        }
    }

    /**
     * Set up a reprocessable session and create an ImageWriter with the session's input surface.
     */
    private void setupReprocessableSession(int inputFormat,
            Collection<MultiResolutionStreamInfo> inputInfo,
            Collection<MultiResolutionStreamInfo> outputInfo,
            int numImageWriterImages) throws Exception {
        // create a reprocessable capture session
        Collection<OutputConfiguration> outConfigs =
                OutputConfiguration.createInstancesForMultiResolutionOutput(
                        mMultiResImageReader);
        ArrayList<OutputConfiguration> outputConfigsList = new ArrayList<OutputConfiguration>(
                outConfigs);

        if (!mShareOneReader) {
            Collection<OutputConfiguration> secondOutputConfigs =
                    OutputConfiguration.createInstancesForMultiResolutionOutput(
                            mSecondMultiResImageReader);
            outputConfigsList.addAll(secondOutputConfigs);
        }

        InputConfiguration inputConfig = new InputConfiguration(inputInfo, inputFormat);
        if (VERBOSE) {
            String inputConfigString = inputConfig.toString();
            Log.v(TAG, ""InputConfiguration: "" + inputConfigString);
        }

        mCameraSessionListener = new BlockingSessionCallback();
        mCameraSession = configureReprocessableCameraSessionWithConfigurations(
                mCamera, inputConfig, outputConfigsList, mCameraSessionListener, mHandler);

        // create an ImageWriter
        mInputSurface = mCameraSession.getInputSurface();
        mImageWriter = ImageWriter.newInstance(mInputSurface,
                numImageWriterImages);

        mImageWriterListener = new SimpleImageWriterListener(mImageWriter);
        mImageWriter.setOnImageReleasedListener(mImageWriterListener, mHandler);
    }

    /**
     * Close the reprocessable session and ImageWriter.
     */
    private void closeReprossibleSession() {
        mInputSurface = null;

        if (mCameraSession != null) {
            mCameraSession.close();
            mCameraSession = null;
        }

        if (mImageWriter != null) {
            mImageWriter.close();
            mImageWriter = null;
        }
    }

    /**
     * Do one multi-resolution reprocess capture for the specified zoom ratio
     */
    private ImageResultSizeHolder doMultiResReprocessCapture(float zoomRatio) throws Exception {
        // submit a regular capture and get the result
        TotalCaptureResult totalResult = submitCaptureRequest(
                zoomRatio, mMultiResImageReader.getSurface(), /*inputResult*/null);
        Map<String, TotalCaptureResult> physicalResults =
                totalResult.getPhysicalCameraTotalResults();

        ImageAndMultiResStreamInfo inputImageAndInfo =
                mMultiResImageReaderListener.getAnyImageAndInfoAvailable(CAPTURE_TIMEOUT_MS);
        assertNotNull(""Failed to capture input image"", inputImageAndInfo);
        Image inputImage = inputImageAndInfo.image;
        MultiResolutionStreamInfo inputStreamInfo = inputImageAndInfo.streamInfo;
        TotalCaptureResult inputSettings =
                physicalResults.get(inputStreamInfo.getPhysicalCameraId());
        assertTrue(""Regular capture's TotalCaptureResult doesn't contain capture result for ""
                + ""physical camera id "" + inputStreamInfo.getPhysicalCameraId(),
                inputSettings != null);

        // Submit a reprocess capture and get the result
        mImageWriter.queueInputImage(inputImage);

        TotalCaptureResult finalResult = submitCaptureRequest(zoomRatio,
                getOutputMultiResImageReader().getSurface(), inputSettings);

        ImageAndMultiResStreamInfo outputImageAndInfo =
                getOutputMultiResImageReaderListener().getAnyImageAndInfoAvailable(
                CAPTURE_TIMEOUT_MS);
        Image outputImage = outputImageAndInfo.image;
        MultiResolutionStreamInfo outputStreamInfo = outputImageAndInfo.streamInfo;

        assertTrue(""The regular output and reprocess output's stream info must be the same"",
                outputStreamInfo.equals(inputStreamInfo));

        ImageResultSizeHolder holder = new ImageResultSizeHolder(outputImageAndInfo.image,
                finalResult, new Size(outputStreamInfo.getWidth(), outputStreamInfo.getHeight()));

        return holder;
    }

    /**
     * Issue a capture request and return the result for a particular zoom ratio.
     *
     * <p>If inputResult is null, it's a regular request. Otherwise, it's a reprocess request.</p>
     */
    private TotalCaptureResult submitCaptureRequest(float zoomRatio,
            Surface output, TotalCaptureResult inputResult) throws Exception {

        SimpleCaptureCallback captureCallback = new SimpleCaptureCallback();

        // Prepare a list of capture requests. Whether it's a regular or reprocess capture request
        // is based on inputResult.
        CaptureRequest.Builder builder;
        boolean isReprocess = (inputResult != null);
        if (isReprocess) {
            builder = mCamera.createReprocessCaptureRequest(inputResult);
        } else {
            builder = mCamera.createCaptureRequest(CAPTURE_TEMPLATE);
            builder.set(CaptureRequest.CONTROL_ZOOM_RATIO, zoomRatio);
        }
        builder.addTarget(output);
        CaptureRequest request = builder.build();
        assertTrue(""Capture request reprocess type "" + request.isReprocess() + "" is wrong."",
            request.isReprocess() == isReprocess);

        mCameraSession.capture(request, captureCallback, mHandler);

        TotalCaptureResult result = captureCallback.getTotalCaptureResultForRequest(
                request, CAPTURE_TIMEOUT_FRAMES);

        // make sure all input surfaces are released.
        if (isReprocess) {
            mImageWriterListener.waitForImageReleased(CAPTURE_TIMEOUT_MS);
        }

        return result;
    }

    private Size getMaxSize(int format, StaticMetadata.StreamDirection direction) {
        Size[] sizes = mStaticInfo.getAvailableSizesForFormatChecked(format, direction);
        return getAscendingOrderSizes(Arrays.asList(sizes), /*ascending*/false).get(0);
    }

    private Collection<MultiResolutionStreamInfo> getMultiResReprocessInfo(String cameraId,
            int format, boolean input) throws Exception {
        StaticMetadata staticInfo = mAllStaticInfo.get(cameraId);
        CameraCharacteristics characteristics = staticInfo.getCharacteristics();
        MultiResolutionStreamConfigurationMap configs = characteristics.get(
                CameraCharacteristics.SCALER_MULTI_RESOLUTION_STREAM_CONFIGURATION_MAP);
        if (configs == null) {
            Log.i(TAG, ""Camera "" + cameraId + "" doesn't support multi-resolution streams"");
            return null;
        }

        String streamType = input ? ""input"" : ""output"";
        int[] formats = input ? configs.getInputFormats() :
                configs.getOutputFormats();
        if (!CameraTestUtils.contains(formats, format)) {
            Log.i(TAG, ""Camera "" + cameraId + "" doesn't support multi-resolution ""
                    + streamType + "" stream for format "" + format + "". Supported formats are ""
                    + Arrays.toString(formats));
            return null;
        }
        Collection<MultiResolutionStreamInfo> streams =
                input ? configs.getInputInfo(format) : configs.getOutputInfo(format);
        mCollector.expectTrue(String.format(""Camera %s supported 0 multi-resolution ""
                + streamType + "" stream info, expected at least 1"", cameraId),
                streams.size() > 0);

        return streams;
    }

    private void dumpImage(Image image, String name) {
        String filename = mDebugFileNameBase + name;
        switch(image.getFormat()) {
            case ImageFormat.JPEG:
                filename += "".jpg"";
                break;
            case ImageFormat.YUV_420_888:
                filename += "".yuv"";
                break;
            default:
                filename += ""."" + image.getFormat();
                break;
        }

        Log.d(TAG, ""dumping an image to "" + filename);
        dumpFile(filename , getDataFromImage(image));
    }

    /**
     * A class that holds an Image, a TotalCaptureResult, and expected image size.
     */
    public static class ImageResultSizeHolder {
        private final Image mImage;
        private final TotalCaptureResult mResult;
        private final Size mExpectedSize;

        public ImageResultSizeHolder(Image image, TotalCaptureResult result, Size expectedSize) {
            mImage = image;
            mResult = result;
            mExpectedSize = expectedSize;
        }

        public Image getImage() {
            return mImage;
        }

        public TotalCaptureResult getTotalCaptureResult() {
            return mResult;
        }

        public Size getExpectedSize() {
            return mExpectedSize;
        }
    }

}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.RVCVRecordActivity"	"getDefaultDisplay"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/RVCVRecordActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import android.app.Activity;
import android.content.Context;
import android.content.Intent;
import android.hardware.Camera;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.media.AudioManager;
import android.media.CamcorderProfile;
import android.media.MediaRecorder;
import android.media.SoundPool;
import android.net.Uri;
import android.os.Bundle;
import android.os.Environment;
import android.util.JsonWriter;
import android.util.Log;
import android.view.Surface;
import android.view.Window;
import android.view.WindowManager;
import android.widget.ImageView;
import android.widget.Toast;

import com.android.cts.verifier.R;

import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.OutputStreamWriter;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

// ----------------------------------------------------------------------

/**
 *  An activity that does recording of the camera video and rotation vector data at the same time.
 */
public class RVCVRecordActivity extends Activity {
    private static final String TAG = ""RVCVRecordActivity"";
    private static final boolean LOCAL_LOGV = false;

    private MotionIndicatorView mIndicatorView;

    private SoundPool mSoundPool;
    private Map<String, Integer> mSoundMap;

    private File mRecordDir;
    private RecordProcedureController mController;
    private VideoRecorder           mVideoRecorder;
    private RVSensorLogger          mRVSensorLogger;
    private CoverageManager         mCoverManager;
    private CameraContext mCameraContext;
    private int mDeviceRotation = Surface.ROTATION_0;

    public static final int AXIS_NONE = 0;
    public static final int AXIS_ALL = SensorManager.AXIS_X +
                                       SensorManager.AXIS_Y +
                                       SensorManager.AXIS_Z;

    // For Rotation Vector algorithm research use
    private final static boolean     LOG_RAW_SENSORS = false;
    private RawSensorLogger          mRawSensorLogger;

    public final RecordProcedureControllerCallback mRecordProcedureControllerCallback =
            new RecordProcedureControllerCallback() {
        public void startRecordProcedureController() {
            startRecordcontroller();
        }
        public void stopRecordProcedureController() {
            stopRecordcontroller();
        }
    };

    public void startRecordcontroller() {
        if (mController != null) {
            Log.v(TAG, ""startRecordcontroller is working. stop it"");
            mController.quit();
        }
        Log.v(TAG, ""startRecordcontroller"");
        mController = new RecordProcedureController(this);
    }

    public void stopRecordcontroller() {
        if (mController != null) {
            Log.v(TAG, ""startRecordcontroller is working. stop it"");
            mController.quit();
        }
        Log.v(TAG, ""stopRecordcontroller"");
    }

    @Override
    public void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);

        // Hide the window title.
        requestWindowFeature(Window.FEATURE_NO_TITLE);

        // inflate xml
        setContentView(R.layout.cam_preview_overlay);

        // locate views
        mIndicatorView = (MotionIndicatorView) findViewById(R.id.cam_indicator);
        WindowManager windowManager =
                (WindowManager)getSystemService(Context.WINDOW_SERVICE);
        if (windowManager != null) {
            mDeviceRotation = windowManager.getDefaultDisplay().getRotation();
            mIndicatorView.setDeviceRotation(mDeviceRotation);
        }

        initStoragePath();
    }

    @Override
    protected void onPause() {
        super.onPause();
        if (mController != null) {
            mController.quit();
        }

        mCameraContext.end();
        endSoundPool();
    }

    @Override
    protected void onResume() {
        super.onResume();
        // delay the initialization as much as possible
        init();
    }

    /** display toast message
     *
     * @param msg Message content
     */
    private void message(String msg) {

        Context context = getApplicationContext();
        int duration = Toast.LENGTH_SHORT;

        Toast toast = Toast.makeText(context, msg, duration);
        toast.show();
    }

    /**
     *  Initialize components
     *
     */
    private void init() {
        mCameraContext = new CameraContext();
        mCameraContext.init(mRecordProcedureControllerCallback);

        mCoverManager = new CoverageManager();
        mIndicatorView.setDataProvider(
                mCoverManager.getAxis(SensorManager.AXIS_X),
                mCoverManager.getAxis(SensorManager.AXIS_Y),
                mCoverManager.getAxis(SensorManager.AXIS_Z)  );

        initSoundPool();
        mRVSensorLogger = new RVSensorLogger(this);

        mVideoRecorder = new VideoRecorder(mCameraContext.getCamera(), mCameraContext.getProfile());

        if (LOG_RAW_SENSORS) {
            mRawSensorLogger = new RawSensorLogger(mRecordDir);
        }
    }

    /**
     * Notify recording is completed. This is the successful exit.
     */
    public void notifyComplete() {
        message(""Capture completed!"");

        Uri resultUri = Uri.fromFile(mRecordDir);
        Intent result = new Intent();
        result.setData(resultUri);
        setResult(Activity.RESULT_OK, result);

        finish();
    }

    /**
     * Notify the user what to do next in text
     *
     * @param axis SensorManager.AXIS_X or SensorManager.AXIS_Y or SensorManager.AXIS_Z
     */
    private void notifyPrompt(int axis) {
        // It is not XYZ because of earlier design have different definition of
        // X and Y
        final String axisName = ""YXZ"";

        message(""Manipulate the device in "" + axisName.charAt(axis - 1) +
                "" axis (as illustrated) about the pattern."");
    }

    /**
     *  Ask indicator view to redraw
     */
    private void redrawIndicator() {
        mIndicatorView.invalidate();
    }

    /**
     * Switch to a different axis for display and logging
     * @param axis
     */
    private void switchAxis(int axis) {
        ImageView imageView = (ImageView) findViewById(R.id.cam_overlay);

        final int [] prompts = {R.drawable.prompt_x, R.drawable.prompt_y, R.drawable.prompt_z};

        if (axis >=SensorManager.AXIS_X && axis <=SensorManager.AXIS_Z) {
            imageView.setImageResource(prompts[axis-1]);
            if (mDeviceRotation != Surface.ROTATION_0 && mDeviceRotation != Surface.ROTATION_180) {
                imageView.setRotation(90);
            }
            mIndicatorView.enableAxis(axis);
            mRVSensorLogger.updateRegister(mCoverManager.getAxis(axis), axis);
            notifyPrompt(axis);
        } else {
            imageView.setImageDrawable(null);
            mIndicatorView.enableAxis(AXIS_NONE);
        }
        redrawIndicator();
    }

    /**
     * Asynchronized way to call switchAxis. Use this if caller is not on UI thread.
     * @param axis @param axis SensorManager.AXIS_X or SensorManager.AXIS_Y or SensorManager.AXIS_Z
     */
    public void switchAxisAsync(int axis) {
        // intended to be called from a non-UI thread
        final int fAxis = axis;
        runOnUiThread(new Runnable() {
            public void run() {
                // UI code goes here
                switchAxis(fAxis);
            }
        });
    }

    /**
     * Initialize sound pool for user notification
     */
    private void initSoundPool() {
        mSoundPool = new SoundPool(1 /*maxStreams*/, AudioManager.STREAM_MUSIC, 0);
        mSoundMap = new HashMap<>();

        // TODO: add different sound into this
        mSoundMap.put(""start"", mSoundPool.load(this, R.raw.start_axis, 1));
        mSoundMap.put(""end"", mSoundPool.load(this, R.raw.next_axis, 1));
        mSoundMap.put(""half-way"", mSoundPool.load(this, R.raw.half_way, 1));
    }
    private void endSoundPool() {
        mSoundPool.release();
    }

    /**
     * Play notify sound to user
     * @param name name of the sound to be played
     */
    public void playNotifySound(String name) {
        Integer id = mSoundMap.get(name);
        if (id != null) {
            mSoundPool.play(id.intValue(), 0.75f/*left vol*/, 0.75f/*right vol*/, 0 /*priority*/,
                    0/*loop play*/, 1/*rate*/);
        }
    }

    /**
     * Start the sensor recording
     */
    public void startRecordSensor() {
        runOnUiThread(new Runnable() {
            public void run() {
                mRVSensorLogger.init();
                if (LOG_RAW_SENSORS) {
                    mRawSensorLogger.init();
                }
            }
        });
    }

    /**
     * Stop the sensor recording
     */
    public void stopRecordSensor() {
        runOnUiThread(new Runnable() {
            public void run() {
                mRVSensorLogger.end();
                if (LOG_RAW_SENSORS) {
                    mRawSensorLogger.end();
                }
            }
        });
    }

    /**
     * Start video recording
     */
    public void startRecordVideo() {
        mVideoRecorder.init();
    }

    /**
     * Stop video recording
     */
    public void stopRecordVideo() {
        mVideoRecorder.end();
    }

    /**
     * Wait until a sensor recording for a certain axis is fully covered
     * @param axis
     */
    public void waitUntilCovered(int axis) {
        mCoverManager.waitUntilCovered(axis);
    }

    /**
     * Wait until a sensor recording for a certain axis is halfway covered
     * @param axis
     */
    public void waitUntilHalfCovered(int axis) {
        mCoverManager.waitUntilHalfCovered(axis);
    }

    /**
     *
     */
    private void initStoragePath() {
        File rxcvRecDataDir = new File(getExternalFilesDir(null),""RVCVRecData"");

        // Create the storage directory if it does not exist
        if (! rxcvRecDataDir.exists()) {
            if (! rxcvRecDataDir.mkdirs()) {
                Log.e(TAG, ""failed to create main data directory"");
            }
        }

        mRecordDir = new File(rxcvRecDataDir, new SimpleDateFormat(""yyMMdd-hhmmss"").format(new Date()));

        if (! mRecordDir.mkdirs()) {
            Log.e(TAG, ""failed to create rec data directory"");
        }
    }

    /**
     * Get the sensor log file path
     * @return Path of the sensor log file
     */
    public String getSensorLogFilePath() {
        return new File(mRecordDir, ""sensor.log"").getPath();
    }

    /**
     * Get the video recording file path
     * @return Path of the video recording file
     */
    public String getVideoRecFilePath() {
        return new File(mRecordDir, ""video.mp4"").getPath();
    }

    /**
     * Write out important camera/video information to a JSON file
     * @param width         width of frame
     * @param height        height of frame
     * @param frameRate     frame rate in fps
     * @param fovW          field of view in width direction
     * @param fovH          field of view in height direction
     */
    public void writeVideoMetaInfo(int width, int height, float frameRate, float fovW, float fovH) {
        try {
            JsonWriter writer =
                    new JsonWriter(
                        new OutputStreamWriter(
                                new FileOutputStream(
                                        new File(mRecordDir, ""videometa.json"").getPath()
                                )
                        )
                    );
            writer.beginObject();
            writer.name(""fovW"").value(fovW);
            writer.name(""fovH"").value(fovH);
            writer.name(""width"").value(width);
            writer.name(""height"").value(height);
            writer.name(""frameRate"").value(frameRate);
            writer.endObject();

            writer.close();
        }catch (FileNotFoundException e) {
            // Not very likely to happen
            e.printStackTrace();
        }catch (IOException e) {
            // do nothing
            e.printStackTrace();
            Log.e(TAG, ""Writing video meta data failed."");
        }
    }

    public interface RecordProcedureControllerCallback {
        public void startRecordProcedureController();
        public void stopRecordProcedureController();
    }

    /**
     * Camera preview control class
     */
    class CameraContext {
        private Camera mCamera;
        private CamcorderProfile mProfile;
        private Camera.CameraInfo mCameraInfo;
        private RVCVCameraPreview mCameraPreview;

        private int [] mPreferredProfiles = {
                CamcorderProfile.QUALITY_480P,  // smaller -> faster
                CamcorderProfile.QUALITY_720P,
                CamcorderProfile.QUALITY_1080P,
                CamcorderProfile.QUALITY_HIGH // existence guaranteed
        };

        private String [] mPreferredFocusMode = {
                Camera.Parameters.FOCUS_MODE_FIXED,
                Camera.Parameters.FOCUS_MODE_INFINITY,
                // the following two modes are more likely to mess up recording
                // but they are still better than FOCUS_MODE_AUTO, which requires
                // calling autoFocus explicitly to focus.
                Camera.Parameters.FOCUS_MODE_CONTINUOUS_VIDEO,
                Camera.Parameters.FOCUS_MODE_CONTINUOUS_PICTURE
        };

        CameraContext() {
            try {
                mCamera = Camera.open(); // attempt to get a default Camera instance (0)
                mProfile = null;
                if (mCamera != null) {
                    mCameraInfo = new Camera.CameraInfo();
                    Camera.getCameraInfo(0, mCameraInfo);
                    setupCamera();
                }
            }
            catch (Exception e){
                // Camera is not available (in use or does not exist)
                Log.e(TAG, ""Cannot obtain Camera!"");
            }
        }

        /**
         * Find a preferred camera profile and set preview and picture size property accordingly.
         */
        void setupCamera() {
            CamcorderProfile profile = null;
            boolean isSetNeeded = false;
            Camera.Parameters param = mCamera.getParameters();
            List<Camera.Size> pre_sz = param.getSupportedPreviewSizes();
            List<Camera.Size> pic_sz = param.getSupportedPictureSizes();

            for (int i : mPreferredProfiles) {
                if (CamcorderProfile.hasProfile(i)) {
                    profile = CamcorderProfile.get(i);

                    int valid = 0;
                    for (Camera.Size j : pre_sz) {
                        if (j.width == profile.videoFrameWidth &&
                                j.height == profile.videoFrameHeight) {
                            ++valid;
                            break;
                        }
                    }
                    for (Camera.Size j : pic_sz) {
                        if (j.width == profile.videoFrameWidth &&
                                j.height == profile.videoFrameHeight) {
                            ++valid;
                            break;
                        }
                    }
                    if (valid == 2) {
                        param.setPreviewSize(profile.videoFrameWidth, profile.videoFrameHeight);
                        param.setPictureSize(profile.videoFrameWidth, profile.videoFrameHeight);
                        isSetNeeded = true;
                        break;
                    } else {
                        profile = null;
                    }
                }
            }

            for (String i : mPreferredFocusMode) {
                if (param.getSupportedFocusModes().contains(i)){
                    param.setFocusMode(i);
                    isSetNeeded = true;
                    break;
                }
            }

            if (isSetNeeded) {
                mCamera.setParameters(param);
            }

            if (profile != null) {
                param = mCamera.getParameters(); //acquire proper fov after change the picture size
                float fovW = param.getHorizontalViewAngle();
                float fovH = param.getVerticalViewAngle();
                writeVideoMetaInfo(profile.videoFrameWidth, profile.videoFrameHeight,
                        profile.videoFrameRate, fovW, fovH);
            } else {
                Log.e(TAG, ""Cannot find a proper video profile"");
            }
            mProfile = profile;

        }


        /**
         * Get sensor information of the camera being used
         */
        public Camera.CameraInfo getCameraInfo() {
            return mCameraInfo;
        }

        /**
         * Get the camera to be previewed
         * @return Reference to Camera used
         */
        public Camera getCamera() {
            return mCamera;
        }

        /**
         * Get the camera profile to be used
         * @return Reference to Camera profile
         */
        public CamcorderProfile getProfile() {
            return mProfile;
        }

        /**
         * Setup the camera
         */
        public void init(RVCVRecordActivity.RecordProcedureControllerCallback callback) {
            if (mCamera != null) {
                double alpha = mCamera.getParameters().getHorizontalViewAngle()*Math.PI/180.0;
                int width = mProfile.videoFrameWidth;
                double fx = width/2/Math.tan(alpha/2.0);

                if (LOCAL_LOGV) Log.v(TAG, ""View angle=""
                        + mCamera.getParameters().getHorizontalViewAngle() +""  Estimated fx = ""+fx);

                mCameraPreview =
                        (RVCVCameraPreview) findViewById(R.id.cam_preview);
                mCameraPreview.setRecordProcedureControllerCallback(callback);
                mCameraPreview.init(mCamera,
                        (float)mProfile.videoFrameWidth/mProfile.videoFrameHeight,
                        mCameraInfo.orientation);
            } else {
                message(""Cannot open camera!"");
                finish();
            }
        }

        /**
         * End the camera preview
         */
        public void end() {
            if (mCamera != null) {
                mCamera.release();        // release the camera for other applications
                mCamera = null;
            }
        }
    }

    /**
     * Manage a set of RangeCoveredRegister objects
     */
    class CoverageManager {
        // settings
        private final int MAX_TILT_ANGLE = 50; // +/- 50
        //private final int REQUIRED_TILT_ANGLE = 50; // +/- 50
        private final int TILT_ANGLE_STEP = 5; // 5 degree(s) per step
        private final int YAW_ANGLE_STEP = 10; // 10 degree(s) per step

        RangeCoveredRegister[] mAxisCovered;

        CoverageManager() {
            mAxisCovered = new RangeCoveredRegister[3];
            // X AXIS
            mAxisCovered[0] = new RangeCoveredRegister(
                    -MAX_TILT_ANGLE, +MAX_TILT_ANGLE, TILT_ANGLE_STEP);
            // Y AXIS
            mAxisCovered[1] = new RangeCoveredRegister(
                    -MAX_TILT_ANGLE, +MAX_TILT_ANGLE, TILT_ANGLE_STEP);
            // Z AXIS
            mAxisCovered[2] = new RangeCoveredRegister(YAW_ANGLE_STEP);
        }

        public RangeCoveredRegister getAxis(int axis) {
            // SensorManager.AXIS_X = 1, need offset -1 for mAxisCovered array
            return mAxisCovered[axis-1];
        }

        public void waitUntilHalfCovered(int axis) {
            if (axis == SensorManager.AXIS_Z) {
                waitUntilCovered(axis);
            }

            // SensorManager.AXIS_X = 1, need offset -1 for mAxisCovered array
            while(!(mAxisCovered[axis-1].isRangeCovered(-MAX_TILT_ANGLE, -MAX_TILT_ANGLE/2) ||
                        mAxisCovered[axis-1].isRangeCovered(MAX_TILT_ANGLE/2, MAX_TILT_ANGLE) ) ) {
                try {
                    Thread.sleep(500);
                } catch (InterruptedException e) {
                    if (LOCAL_LOGV) {
                        Log.v(TAG, ""waitUntilHalfCovered axis = ""+ axis + "" is interrupted"");
                    }
                    Thread.currentThread().interrupt();
                }
            }
        }

        public void waitUntilCovered(int axis) {
            // SensorManager.AXIS_X = 1, need offset -1 for mAxisCovered array
            while(!mAxisCovered[axis-1].isFullyCovered()) {
                try {
                    Thread.sleep(500);
                } catch (InterruptedException e) {
                    if (LOCAL_LOGV) {
                        Log.v(TAG, ""waitUntilCovered axis = ""+ axis + "" is interrupted"");
                    }
                    Thread.currentThread().interrupt();
                }
            }
        }
    }
    ////////////////////////////////////////////////////////////////////////////////////////////////

    /**
     * A class controls the video recording
     */
    class VideoRecorder
    {
        private MediaRecorder mRecorder;
        private CamcorderProfile mProfile;
        private Camera mCamera;
        private boolean mRunning = false;

        VideoRecorder(Camera camera, CamcorderProfile profile){
            mCamera = camera;
            mProfile = profile;
        }

        /**
         * Initialize and start recording
         */
        public void init() {
            if (mCamera == null  || mProfile ==null){
                return;
            }

            mRecorder = new MediaRecorder();
            try {
                mCamera.unlock();
            } catch (RuntimeException e) {
                e.printStackTrace();
                try {
                    mRecorder.reset();
                    mRecorder.release();
                } catch (RuntimeException ex) {
                    e.printStackTrace();
                }
                return;
            }

            try {
                mRecorder.setCamera(mCamera);
                mRecorder.setVideoSource(MediaRecorder.VideoSource.CAMERA);
                mRecorder.setAudioSource(MediaRecorder.AudioSource.DEFAULT);
                mRecorder.setProfile(mProfile);
            } catch (RuntimeException e) {
                e.printStackTrace();
                return;
            }

            try {
                mRecorder.setOutputFile(getVideoRecFilePath());
                mRecorder.prepare();
            } catch (IOException e) {
                Log.e(TAG, ""Preparation for recording failed."");
                return;
            }

            try {
                mRecorder.start();
            } catch (RuntimeException e) {
                Log.e(TAG, ""Starting recording failed."");
                try {
                    mRecorder.reset();
                    mRecorder.release();
                    mCamera.lock();
                } catch (RuntimeException ex1) {
                    e.printStackTrace();
                }
                return;
            }
            mRunning = true;
        }

        /**
         * Stop recording
         */
        public void end() {
            if (mRunning) {
                try {
                    mRecorder.stop();
                    mRecorder.reset();
                    mRecorder.release();
                    mCamera.lock();
                } catch (RuntimeException e) {
                    e.printStackTrace();
                    Log.e(TAG, ""Runtime error in stopping recording."");
                }
            }
            mRecorder = null;
        }

    }

    ////////////////////////////////////////////////////////////////////////////////////////////////

    /**
     *  Log all raw sensor readings, for Rotation Vector sensor algorithms research
     */
    class RawSensorLogger implements SensorEventListener {
        private final String TAG = ""RawSensorLogger"";

        private final static int SENSOR_RATE = SensorManager.SENSOR_DELAY_FASTEST;
        private File mRecPath;

        SensorManager mSensorManager;
        Sensor mAccSensor, mGyroSensor, mMagSensor;
        OutputStreamWriter mAccLogWriter, mGyroLogWriter, mMagLogWriter;

        private float[] mRTemp = new float[16];

        RawSensorLogger(File recPath) {
            mRecPath = recPath;
        }

        /**
         * Initialize and start recording
         */
        public void init() {
            mSensorManager = (SensorManager)getSystemService(SENSOR_SERVICE);

            mAccSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER);
            mGyroSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_GYROSCOPE_UNCALIBRATED);
            mMagSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED);

            mSensorManager.registerListener(this, mAccSensor, SENSOR_RATE);
            mSensorManager.registerListener(this, mGyroSensor, SENSOR_RATE);
            mSensorManager.registerListener(this, mMagSensor, SENSOR_RATE);

            try {
                mAccLogWriter= new OutputStreamWriter(
                        new FileOutputStream(new File(mRecPath, ""raw_acc.log"")));
                mGyroLogWriter= new OutputStreamWriter(
                        new FileOutputStream(new File(mRecPath, ""raw_uncal_gyro.log"")));
                mMagLogWriter= new OutputStreamWriter(
                        new FileOutputStream(new File(mRecPath, ""raw_uncal_mag.log"")));

            } catch (FileNotFoundException e) {
                Log.e(TAG, ""Sensor log file open failed: "" + e.toString());
            }
        }

        /**
         * Stop recording and clean up
         */
        public void end() {
            mSensorManager.flush(this);
            mSensorManager.unregisterListener(this);

            try {
                if (mAccLogWriter != null) {
                    OutputStreamWriter writer = mAccLogWriter;
                    mAccLogWriter = null;
                    writer.close();
                }
                if (mGyroLogWriter != null) {
                    OutputStreamWriter writer = mGyroLogWriter;
                    mGyroLogWriter = null;
                    writer.close();
                }
                if (mMagLogWriter != null) {
                    OutputStreamWriter writer = mMagLogWriter;
                    mMagLogWriter = null;
                    writer.close();
                }

            } catch (IOException e) {
                Log.e(TAG, ""Sensor log file close failed: "" + e.toString());
            }
        }

        @Override
        public void onAccuracyChanged(Sensor sensor, int i) {
            // do not care
        }

        @Override
        public void onSensorChanged(SensorEvent event) {
            OutputStreamWriter writer=null;
            switch(event.sensor.getType()) {
                case Sensor.TYPE_ACCELEROMETER:
                    writer = mAccLogWriter;
                    break;
                case Sensor.TYPE_GYROSCOPE_UNCALIBRATED:
                    writer = mGyroLogWriter;
                    break;
                case Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED:
                    writer = mMagLogWriter;
                    break;

            }
            if (writer!=null)  {
                float[] data = event.values;
                try {
                    if (event.sensor.getType() == Sensor.TYPE_ACCELEROMETER) {
                        writer.write(String.format(""%d %f %f %f\r\n"",
                                event.timestamp, data[0], data[1], data[2]));
                    }else // TYPE_GYROSCOPE_UNCALIBRATED and TYPE_MAGNETIC_FIELD_UNCALIBRATED
                    {
                        writer.write(String.format(""%d %f %f %f %f %f %f\r\n"", event.timestamp,
                                data[0], data[1], data[2], data[3], data[4], data[5]));
                    }
                }catch (IOException e)
                {
                    Log.e(TAG, ""Write to raw sensor log file failed."");
                }

            }
        }
    }

    /**
     *  Rotation sensor logger class
     */
    class RVSensorLogger implements SensorEventListener {
        private final String TAG = ""RVSensorLogger"";

        private final static int SENSOR_RATE = SensorManager.SENSOR_DELAY_FASTEST;
        RangeCoveredRegister mRegister;
        int mAxis;
        RVCVRecordActivity mActivity;

        SensorManager mSensorManager;
        Sensor mRVSensor;
        OutputStreamWriter mLogWriter;

        private float[] mRTemp = new float[16];

        RVSensorLogger(RVCVRecordActivity activity) {
            mActivity = activity;
        }

        /**
         * Initialize and start recording
         */
        public void init() {
            mSensorManager = (SensorManager)getSystemService(SENSOR_SERVICE);
            if (mSensorManager == null) {
                Log.e(TAG,""SensorManager is null!"");
            }
            mRVSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_ROTATION_VECTOR);
            if (mRVSensor != null) {
                if (LOCAL_LOGV) Log.v(TAG, ""Got RV Sensor"");
            }else {
                Log.e(TAG, ""Did not get RV sensor"");
            }
            if(mSensorManager.registerListener(this, mRVSensor, SENSOR_RATE)) {
                if (LOCAL_LOGV) Log.v(TAG,""Register listener successfull"");
            } else {
                Log.e(TAG,""Register listener failed"");
            }

            try {
                mLogWriter= new OutputStreamWriter(
                        new FileOutputStream(mActivity.getSensorLogFilePath()));
            } catch (FileNotFoundException e) {
                Log.e(TAG, ""Sensor log file open failed: "" + e.toString());
            }
        }

        /**
         * Stop recording and clean up
         */
        public void end() {
            mSensorManager.flush(this);
            mSensorManager.unregisterListener(this);

            try {
                if (mLogWriter != null) {
                    OutputStreamWriter writer = mLogWriter;
                    mLogWriter = null;
                    writer.close();
                }
            } catch (IOException e) {
                Log.e(TAG, ""Sensor log file close failed: "" + e.toString());
            }

            updateRegister(null, AXIS_NONE);
        }

        private void onNewData(float[] data, long timestamp) {
            // LOG
            try {
                if (mLogWriter != null) {
                    mLogWriter.write(String.format(""%d %f %f %f %f\r\n"", timestamp,
                            data[3], data[0], data[1], data[2]));
                }
            } catch (IOException e) {
                Log.e(TAG, ""Sensor log file write failed: "" + e.toString());
            }

            // Update UI
            if (mRegister != null) {
                int d = 0;
                int dx, dy, dz;
                boolean valid = false;
                SensorManager.getRotationMatrixFromVector(mRTemp, data);

                dx = (int)(Math.asin(mRTemp[8])*(180.0/Math.PI));
                dy = (int)(Math.asin(mRTemp[9])*(180.0/Math.PI));
                dz = (int)((Math.atan2(mRTemp[4], mRTemp[0])+Math.PI)*(180.0/Math.PI));

                switch(mAxis) {
                    case SensorManager.AXIS_X:
                        d = dx;
                        valid = (Math.abs(dy) < 30);
                        break;
                    case SensorManager.AXIS_Y:
                        d = dy;
                        valid = (Math.abs(dx) < 30);
                        break;
                    case SensorManager.AXIS_Z:
                        d = dz;
                        valid = (Math.abs(dx) < 20 && Math.abs(dy) < 20);
                        break;
                }

                if (valid) {
                    mRegister.update(d);
                    mActivity.redrawIndicator();
                }
            }

        }

        public void updateRegister(RangeCoveredRegister reg, int axis) {
            mRegister = reg;
            mAxis = axis;
        }


        @Override
        public void onAccuracyChanged(Sensor sensor, int i) {
            // do not care
        }

        @Override
        public void onSensorChanged(SensorEvent event) {
            if (event.sensor.getType() == Sensor.TYPE_ROTATION_VECTOR) {
                onNewData(event.values, event.timestamp);
            }
        }
    }


    ////////////////////////////////////////////////////////////////////////////////////////////////

    /**
     * Controls the over all logic of record procedure: first x-direction, then y-direction and
     * then z-direction.
     */
    class RecordProcedureController implements Runnable {
        private static final boolean LOCAL_LOGV = false;

        private final RVCVRecordActivity mActivity;
        private Thread mThread = null;

        RecordProcedureController(RVCVRecordActivity activity) {
            mActivity = activity;
            mThread = new Thread(this);
            mThread.start();
        }

        /**
         * Run the record procedure
         */
        public void run() {
            if (LOCAL_LOGV) Log.v(TAG, ""Controller Thread Started."");
            //start recording & logging
            delay(2000);

            init();
            if (LOCAL_LOGV) Log.v(TAG, ""Controller Thread init() finished."");

            // test 3 axis
            // It is in YXZ order because UI element design use opposite definition
            // of XY axis. To ensure the user see X Y Z, it is flipped here.
            recordAxis(SensorManager.AXIS_Y);
            if (LOCAL_LOGV) Log.v(TAG, ""Controller Thread axis 0 finished."");

            recordAxis(SensorManager.AXIS_X);
            if (LOCAL_LOGV) Log.v(TAG, ""Controller Thread axis 1 finished."");

            recordAxis(SensorManager.AXIS_Z);
            if (LOCAL_LOGV) Log.v(TAG, ""Controller Thread axis 2 finished."");

            delay(1000);
            end();
            if (LOCAL_LOGV) Log.v(TAG, ""Controller Thread End."");
        }

        private void delay(int milli) {
            try{
                Thread.sleep(milli);
            } catch(InterruptedException e) {
                if (LOCAL_LOGV) Log.v(TAG, ""Controller Thread Interrupted."");
            }
        }
        private void init() {
            // start video recording
            mActivity.startRecordVideo();

            // start sensor logging & listening
            mActivity.startRecordSensor();
        }

        private void end() {
            // stop video recording
            mActivity.stopRecordVideo();

            // stop sensor logging
            mActivity.stopRecordSensor();

            // notify ui complete
            runOnUiThread(new Runnable(){
                public void run() {
                    mActivity.notifyComplete();
                }
            });
        }

        private void recordAxis(int axis) {
            // delay 2 seconds?
            delay(1000);

            // change ui
            mActivity.switchAxisAsync(axis);

            // play start sound
            mActivity.playNotifySound(""start"");

            if (axis != SensorManager.AXIS_Z) {
                // wait until axis half covered
                mActivity.waitUntilHalfCovered(axis);

                // play half way sound
                mActivity.playNotifySound(""half-way"");
            }

            // wait until axis covered
            mActivity.waitUntilCovered(axis);

            // play stop sound
            mActivity.playNotifySound(""end"");
        }

        /**
         * Force quit
         */
        public void quit() {
            mThread.interrupt();
            try {
                if (LOCAL_LOGV) Log.v(TAG, ""Wait for controller to end"");

                // stop video recording
                mActivity.stopRecordVideo();

                // stop sensor logging
                mActivity.stopRecordSensor();

            } catch (Exception e)
            {
                e.printStackTrace();
            }
        }
    }

}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.GyroscopeTestActivity"	"setPassFailButtonClickListeners"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/GyroscopeTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import com.android.cts.verifier.PassFailButtons;
import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.renderers.GLRotationGuideRenderer;

import android.app.AlertDialog;
import android.content.Intent;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.opengl.GLSurfaceView;
import android.os.Bundle;
import android.view.View;
import android.view.View.OnClickListener;
import android.widget.TextView;

/**
 * Manual test for testing the gyroscope sensor. This test consists of 6 steps for all the
 * different ways to rotate the device along the x, y, and z axis. It also raises a warning
 * if the values seem to high and may be degrees.
 *
 * @deprecated It has been replaced by {@link GyroscopeMeasurementTestActivity}
 */
@Deprecated
public class GyroscopeTestActivity extends PassFailButtons.Activity {

    private static final int NUM_STAGES = 6;
    private static final String STAGE_INDEX_EXTRA = ""stageIndex"";

    private SensorManager mSensorManager;
    private Sensor mSensor;
    private SensorListener mSensorListener;
    private GLSurfaceView mGLSurfaceView;
    private GLRotationGuideRenderer mRenderer;
    private TextView mProgressText;
    private TextView mSensorText;

    private AlertDialog mNoGyroscopeWarningDialog;
    private AlertDialog mDegreesWarningDialog;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.snsr_gyro);
        setInfoResources(R.string.snsr_gyro_test, R.string.snsr_gyro_test_info, 0);
        setPassFailButtonClickListeners();

        // This activity is reused 6 times with different settings to test each rotation direction
        final int stageIndex = getIntent().getIntExtra(STAGE_INDEX_EXTRA, 0);
        Settings settings = getSettings(stageIndex);

        // Hitting the pass button goes to the next test activity. Only the last one ends the test.
        if (stageIndex + 1 < NUM_STAGES) {
            setPassButtonGoesToNextStage(stageIndex);
        }

        mSensorManager = (SensorManager) getSystemService(SENSOR_SERVICE);
        mSensor = mSensorManager.getDefaultSensor(Sensor.TYPE_GYROSCOPE);
        mSensorListener = new SensorListener(settings.mSensorEventIndex,
                settings.mExpectPositiveValue);

        mGLSurfaceView = (GLSurfaceView) findViewById(R.id.gl_surface_view);
        mRenderer = new GLRotationGuideRenderer();
        mRenderer.setRotation(settings.mRotateX, settings.mRotateY, settings.mRotateZ);
        mGLSurfaceView.setRenderer(mRenderer);

        mProgressText = (TextView) findViewById(R.id.progress);
        mProgressText.setText(String.format(getString(R.string.snsr_gyro_test_progress),
                settings.mStageIndex + 1, settings.mTotalStages));

        mSensorText = (TextView) findViewById(R.id.sensor_value);
    }

    private Settings getSettings(int stageIndex) {
        switch (stageIndex) {
            case 0:
                return new Settings(stageIndex, NUM_STAGES, 0, 0, 1, 2, true);
            case 1:
                return new Settings(stageIndex, NUM_STAGES, 0, 0, -1, 2, false);
            case 2:
                return new Settings(stageIndex, NUM_STAGES, 0, 1, 0, 1, true);
            case 3:
                return new Settings(stageIndex, NUM_STAGES, 0, -1, 0, 1, false);
            case 4:
                return new Settings(stageIndex, NUM_STAGES, 1, 0, 0, 0, true);
            case 5:
                return new Settings(stageIndex, NUM_STAGES, -1, 0, 0, 0, false);
            default:
                throw new IllegalArgumentException(""Bad stage index: "" + stageIndex);
        }
    }

    /** Bundle of settings for testing a certain rotation direction. */
    class Settings {
        int mStageIndex;
        int mTotalStages;
        float mRotateX;
        float mRotateY;
        float mRotateZ;
        int mSensorEventIndex;
        boolean mExpectPositiveValue;

        Settings(int stageIndex, int totalStages, float rotateX, float rotateY, float rotateZ,
                int sensorEventIndex, boolean expectPositiveValue) {
            mStageIndex = stageIndex;
            mTotalStages = totalStages;
            mRotateX = rotateX;
            mRotateY = rotateY;
            mRotateZ = rotateZ;
            mSensorEventIndex = sensorEventIndex;
            mExpectPositiveValue = expectPositiveValue;
        }
    }

    private void setPassButtonGoesToNextStage(final int stageIndex) {
        findViewById(R.id.pass_button).setOnClickListener(new OnClickListener() {
            @Override
            public void onClick(View v) {
                Intent intent = new Intent(GyroscopeTestActivity.this,
                        GyroscopeTestActivity.class);
                intent.setFlags(Intent.FLAG_ACTIVITY_CLEAR_TOP
                        | Intent.FLAG_ACTIVITY_FORWARD_RESULT);
                intent.putExtra(STAGE_INDEX_EXTRA, stageIndex + 1);
                startActivity(intent);
            }
        });
    }

    @Override
    protected void onResume() {
        super.onResume();
        if (!mSensorManager.registerListener(mSensorListener, mSensor,
                SensorManager.SENSOR_DELAY_UI)) {
            showNoGyroscopeWarningDialog();
        }
    }

    @Override
    protected void onPause() {
        super.onPause();
        mSensorManager.unregisterListener(mSensorListener, mSensor);
    }

    class SensorListener implements SensorEventListener {

        /** Throw away other events that are smaller than this. */
        private static final double MOVING_AMOUNT = 0.1;

        private final int mEventIndex;

        private final boolean mExpectPositive;

        SensorListener(int eventIndex, boolean expectPositive) {
            mEventIndex = eventIndex;
            mExpectPositive = expectPositive;
        }

        @Override
        public void onSensorChanged(SensorEvent event) {
            float value = event.values[mEventIndex];
            if (value > MOVING_AMOUNT) {
                if (mExpectPositive) {
                    updateWidgets(
                            value,
                            GLRotationGuideRenderer.BACKGROUND_GREEN,
                            R.drawable.fs_good);
                } else {
                    updateWidgets(
                            value,
                            GLRotationGuideRenderer.BACKGROUND_RED,
                            R.drawable.fs_error);
                }
            } else if (value < -MOVING_AMOUNT) {
                if (mExpectPositive) {
                    updateWidgets(
                            value,
                            GLRotationGuideRenderer.BACKGROUND_RED,
                            R.drawable.fs_error);
                } else {
                    updateWidgets(
                            value,
                            GLRotationGuideRenderer.BACKGROUND_GREEN,
                            R.drawable.fs_good);
                }
            } else {
                updateWidgets(
                        value,
                        GLRotationGuideRenderer.BACKGROUND_BLACK,
                        R.drawable.fs_indeterminate);
            }

            if (value > 10) {
                showDegreesWarningDialog();
            }
        }

        void updateWidgets(float sensorValue, int backgroundColor, int icon) {
            synchronized (GyroscopeTestActivity.this) {
                mRenderer.setBackgroundColor(backgroundColor);
            }
            mSensorText.setText(String.format(""%+.2f"", sensorValue));
            mSensorText.setCompoundDrawablesWithIntrinsicBounds(0, 0, icon, 0);
        }

        @Override
        public void onAccuracyChanged(Sensor sensor, int accuracy) {
        }
    }

    private void showNoGyroscopeWarningDialog() {
        if (mNoGyroscopeWarningDialog == null) {
            mNoGyroscopeWarningDialog = new AlertDialog.Builder(GyroscopeTestActivity.this)
                .setIcon(android.R.drawable.ic_dialog_alert)
                .setTitle(R.string.snsr_gyro_test_no_gyro_title)
                .setMessage(R.string.snsr_gyro_test_no_gyro_message)
                .setPositiveButton(android.R.string.ok, null)
                .create();
        }
        if (!mNoGyroscopeWarningDialog.isShowing()) {
            mNoGyroscopeWarningDialog.show();
        }
    }

    private void showDegreesWarningDialog() {
        if (mDegreesWarningDialog == null) {
            mDegreesWarningDialog = new AlertDialog.Builder(GyroscopeTestActivity.this)
                    .setIcon(android.R.drawable.ic_dialog_alert)
                    .setTitle(R.string.snsr_gyro_test_degrees_title)
                    .setMessage(R.string.snsr_gyro_test_degrees_message)
                    .setPositiveButton(android.R.string.ok, null)
                    .create();
        }
        if (!mDegreesWarningDialog.isShowing()) {
            mDegreesWarningDialog.show();
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.FrequencyVerificationTest"	"testVerifification"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/FrequencyVerificationTest.java"	""	"public void testVerifification() {
        long[] timestamps = {0, 1000000, 2000000, 3000000, 4000000};  // 1000Hz

        SensorStats stats = new SensorStats();
        ISensorVerification verification = getVerification(999.0, 1001.0, timestamps);
        verification.verify(getEnvironment(1000), stats);
        verifyStats(stats, true, 1000.0);

        stats = new SensorStats();
        verification = getVerification(850.0, 1050.0, timestamps);
        verification.verify(getEnvironment(950), stats);
        verifyStats(stats, true, 1000.0);

        stats = new SensorStats();
        verification = getVerification(950.0, 1150.0, timestamps);
        verification.verify(getEnvironment(1050), stats);
        verifyStats(stats, true, 1000.0);

        stats = new SensorStats();
        verification = getVerification(850.0, 975.0, timestamps);
        try {
            verification.verify(getEnvironment(950), stats);
            throw new Error(""Expected an AssertionError"");
        } catch (AssertionError e) {
            // Expected;
        }
        verifyStats(stats, false, 1000.0);

        stats = new SensorStats();
        verification = getVerification(1025.0, 1150.0, timestamps);
        try {
            verification.verify(getEnvironment(1050), stats);
            throw new Error(""Expected an AssertionError"");
        } catch (AssertionError e) {
            // Expected;
        }
        verifyStats(stats, false, 1000.0);
    }

    private TestSensorEnvironment getEnvironment(int rateUs) {
        return new TestSensorEnvironment(getContext(), Sensor.TYPE_ALL, rateUs);
    }

    private static FrequencyVerification getVerification(
            double lowerThreshold,
            double upperThreshold,
            long ... timestamps) {
        Collection<TestSensorEvent> events = new ArrayList<>(timestamps.length);
        for (long timestamp : timestamps) {
            events.add(new TestSensorEvent(null, timestamp, 0, null));
        }
        FrequencyVerification verification =
                new FrequencyVerification(lowerThreshold, upperThreshold);
        verification.addSensorEvents(events);
        return verification;
    }

    private void verifyStats(SensorStats stats, boolean passed, double frequency) {
        assertEquals(passed, stats.getValue(FrequencyVerification.PASSED_KEY));
        assertEquals(frequency, stats.getValue(SensorStats.FREQUENCY_KEY));
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.directreportapi30.DirectReportAPI30Test"	"testSamplingRateMicToggleOff"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/DirectReportAPI30/src/android/sensorratepermission/cts/directreportapi30/DirectReportAPI30Test.java"	""	"public void testSamplingRateMicToggleOff() throws InterruptedException {
        // Only run this test if we know for sure that the highest direct report rate level of
        // corresponds to a sampling rate of > 200 Hz
        if (mDirectReportTestHelper.getSensor().getHighestDirectReportRateLevel()
                <= SensorDirectChannel.RATE_FAST) {
            return;
        }

        mDirectReportTestHelper.flipAndAssertMicToggleOff(mUserID, mSensorPrivacyManager);
        List<SensorDirectReportTest.DirectReportSensorEvent> events =
                mDirectReportTestHelper.getSensorEvents(SensorDirectChannel.RATE_VERY_FAST);

        double obtainedRate = SensorRatePermissionDirectReportTestHelper.computeAvgRate(events,
                Long.MIN_VALUE, Long.MAX_VALUE);

        Assert.assertTrue(mDirectReportTestHelper.errorWhenBelowExpectedRate(),
                obtainedRate > SensorRatePermissionDirectReportTestHelper.CAPPED_SAMPLE_RATE_HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.directreportapi30.DirectReportAPI30Test"	"testSamplingRateMicToggleOn"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/DirectReportAPI30/src/android/sensorratepermission/cts/directreportapi30/DirectReportAPI30Test.java"	""	"public void testSamplingRateMicToggleOn() throws InterruptedException {
        mDirectReportTestHelper.flipAndAssertMicToggleOn(mUserID, mSensorPrivacyManager);
        List<SensorDirectReportTest.DirectReportSensorEvent> events =
                mDirectReportTestHelper.getSensorEvents(SensorDirectChannel.RATE_VERY_FAST);

        double obtainedRate = SensorRatePermissionDirectReportTestHelper.computeAvgRate(events,
                Long.MIN_VALUE, Long.MAX_VALUE);

        Assert.assertTrue(mDirectReportTestHelper.errorWhenExceedCappedRate(),
                obtainedRate <= SensorRatePermissionDirectReportTestHelper.CAPPED_SAMPLE_RATE_HZ);
    }

    /**
     * Test the case where a connection is ongoing while the mic toggle changes its state:
     * off -> on -> off. This test is to show that the sensor service is able to cap/uncap the
     * rate of ongoing direct sensor connections when the state of the mic toggle changes.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.directreportapi30.DirectReportAPI30Test"	"testSamplingRateMicToggleOffOnOff"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/DirectReportAPI30/src/android/sensorratepermission/cts/directreportapi30/DirectReportAPI30Test.java"	""	"public void testSamplingRateMicToggleOffOnOff() throws InterruptedException {
        // Only run this test if we know for sure that the highest direct report rate level of
        // the sensor corresponds to a sampling rate of > 200 Hz and that the sensor supports
        // direct channel.
        Sensor s = mDirectReportTestHelper.getSensor();
        if (s.getHighestDirectReportRateLevel() <= SensorDirectChannel.RATE_FAST
                || !s.isDirectChannelTypeSupported(SensorDirectChannel.TYPE_HARDWARE_BUFFER)) {
            return;
        }
        // Start with the mic toggle off
        mDirectReportTestHelper.flipAndAssertMicToggleOff(mUserID, mSensorPrivacyManager);

        // Configure a direct channel.
        int sensorEventCount = 5500; // 800 Hz * 2.5s  + 200 Hz * 2.5s + extra
        int sharedMemorySize = sensorEventCount *
                SensorRatePermissionDirectReportTestHelper.SENSORS_EVENT_SIZE;
        HardwareBuffer hardwareBuffer = HardwareBuffer.create(
                sharedMemorySize, 1, HardwareBuffer.BLOB, 1,
                HardwareBuffer.USAGE_CPU_READ_OFTEN | HardwareBuffer.USAGE_GPU_DATA_BUFFER
                        | HardwareBuffer.USAGE_SENSOR_DIRECT_DATA);
        SensorDirectChannel channel = mSensorManager.createDirectChannel(hardwareBuffer);
        int token = channel.configure(s, SensorDirectChannel.RATE_VERY_FAST);

        // Flip the mic toggle on
        mDirectReportTestHelper.flipAndAssertMicToggleOn(mUserID, mSensorPrivacyManager);
        long startMicToggleOn = SystemClock.elapsedRealtimeNanos();
        SensorCtsHelper.sleep(
                SensorRatePermissionDirectReportTestHelper.TEST_RUN_TIME_PERIOD_MILLISEC / 2,
                TimeUnit.MILLISECONDS);
        long endMicToggleOn = SystemClock.elapsedRealtimeNanos();

        // Flip the mic toggle off
        mDirectReportTestHelper.flipAndAssertMicToggleOff(mUserID, mSensorPrivacyManager);
        long startMicToggleOff = SystemClock.elapsedRealtimeNanos();
        SensorCtsHelper.sleep(
                SensorRatePermissionDirectReportTestHelper.TEST_RUN_TIME_PERIOD_MILLISEC / 2,
                TimeUnit.MILLISECONDS);

        // Read the sensor events out
        channel.configure(s, SensorDirectChannel.RATE_STOP);
        List<SensorDirectReportTest.DirectReportSensorEvent> events =
                mDirectReportTestHelper.readEventsFromHardwareBuffer(token,
                        hardwareBuffer, sensorEventCount);
        channel.close();
        hardwareBuffer.close();

        // Check the sampling rates when the mic toggle were on and off
        double rateWhenMicToggleOn =
                SensorRatePermissionDirectReportTestHelper.computeAvgRate(events,
                        startMicToggleOn, endMicToggleOn);
        Assert.assertTrue(mDirectReportTestHelper.errorWhenExceedCappedRate(),
                rateWhenMicToggleOn
                        <= SensorRatePermissionDirectReportTestHelper.CAPPED_SAMPLE_RATE_HZ);

        double rateWhenMicToggleOff = SensorRatePermissionDirectReportTestHelper.computeAvgRate(
                events, startMicToggleOff, Long.MAX_VALUE);
        Assert.assertTrue(mDirectReportTestHelper.errorWhenBelowExpectedRate(),
                rateWhenMicToggleOff
                        > SensorRatePermissionDirectReportTestHelper.CAPPED_SAMPLE_RATE_HZ);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Utils.Manager"	"stopListening"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Utils/Manager.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Utils;

import com.android.cts.verifier.sensors.sixdof.Dialogs.BaseResultsDialog;
import com.android.cts.verifier.sensors.sixdof.Interfaces.AccuracyListener;
import com.android.cts.verifier.sensors.sixdof.Interfaces.BaseUiListener;
import com.android.cts.verifier.sensors.sixdof.Interfaces.ComplexMovementListener;
import com.android.cts.verifier.sensors.sixdof.Interfaces.RobustnessListener;
import com.android.cts.verifier.sensors.sixdof.Renderer.BaseRenderer;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointAreaCoveredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointDistanceException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointRingNotEnteredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointStartPointException;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.ReferencePath;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Ring;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.RotationData;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Waypoint;
import com.android.cts.verifier.sensors.sixdof.Utils.PoseProvider.PoseData;
import com.android.cts.verifier.sensors.sixdof.Utils.ResultObjects.ResultObject;
import com.android.cts.verifier.sensors.sixdof.Utils.TestPhase.AccuracyTest;
import com.android.cts.verifier.sensors.sixdof.Utils.TestPhase.ComplexMovementTest;
import com.android.cts.verifier.sensors.sixdof.Utils.TestPhase.RobustnessTest;

import android.content.Context;

import java.util.ArrayList;
import java.util.HashMap;

/**
 * Manages all of the tests.
 */
public class Manager {
    private Lap mLap = Lap.LAP_1;
    public static final int MAX_MARKER_NUMBER = 5;
    private ReferencePath mReferencePath = new ReferencePath();
    private AccuracyTest mAccuracyTest;
    private RobustnessTest mRobustnessTest;
    private ComplexMovementTest mComplexMovementTest;
    private TestReport mTestReport;
    private float mRemainingPath;
    private long mTimeRemaining;

    public enum Lap {
        LAP_1,
        LAP_2,
        LAP_3,
        LAP_4,
    }

    private ComplexMovementListener mComplexMovementListener;
    private RobustnessListener mRobustnessListener;
    private AccuracyListener mAccuracyListener;
    private BaseUiListener mBaseUiListener;

    /**
     * Links the listeners to the activity.
     *
     * @param context reference to the activity.
     */
    public void setupListeners(Context context) {
        mAccuracyListener = (AccuracyListener) context;
        mRobustnessListener = (RobustnessListener) context;
        mComplexMovementListener = (ComplexMovementListener) context;
        mBaseUiListener = (BaseUiListener) context;
    }

    /**
     * Removes the references to the activity so that the activity can be properly terminated.
     */
    public void stopListening() {
        mRobustnessListener = null;
        mAccuracyListener = null;
        mBaseUiListener = null;
        mComplexMovementListener = null;
    }

    public void ringEntered(Ring ring) {
        mComplexMovementListener.onRingEntered(ring);
    }

    /**
     * Indicated that the pose provider is ready.
     */
    public void onPoseProviderReady() {
        mBaseUiListener.onPoseProviderReady();
    }

    /**
     * Constructor for the class.
     *
     * @param testReport a reference to the test report to be used to record failures.
     */
    public Manager(TestReport testReport) {
        mTestReport = testReport;
    }

    /**
     * Adds the waypoint data to the appropriate path.
     *
     * @param coordinates   the coordinates to use for the waypoint.
     * @param userGenerated indicates whether the data was user created or system created.
     * @throws WaypointDistanceException    if the location is too close to another.
     * @throws WaypointAreaCoveredException if the area covered by the user is too little.
     * @throws WaypointStartPointException  if the location is not close enough to the start.
     */
    public void addPoseDataToPath(
            float[] coordinates, boolean userGenerated)
            throws WaypointAreaCoveredException, WaypointDistanceException,
            WaypointStartPointException, WaypointRingNotEnteredException {
        switch (mLap) {
            case LAP_1:
                try {
                    mReferencePath.createWaypointAndAddToPath(coordinates, userGenerated, mLap);
                } catch (WaypointStartPointException exception) {
                    float[] initialCoords = mReferencePath.getPathMarkers().get(0).getCoordinates();
                    String initialWaypointCoords =
                            MathsUtils.coordinatesToString(initialCoords);
                    String distance = String.valueOf(
                            MathsUtils.distanceCalculationInXYZSpace(
                                    initialCoords, coordinates));
                    String details = ""Not close enough to initial waypoint:\n""
                            + ""Distance:""
                            + distance
                            + ""\nInitial Waypoint Coordinates: ""
                            + initialWaypointCoords
                            + ""\nAttempted placement coordinates: ""
                            + MathsUtils.coordinatesToString(coordinates);
                    mTestReport.setFailDetails(details);

                    // We still need to give the exception to UI to display message.
                    throw exception;
                }

                if (mReferencePath.getPathMarkersSize() == MAX_MARKER_NUMBER) {
                    mAccuracyListener.lap1Complete();
                }
                break;
            case LAP_2:
                mAccuracyTest.addWaypointDataToPath(coordinates, userGenerated, mLap);
                break;
            case LAP_3:
                mRobustnessTest.addWaypointDataToPath(coordinates, userGenerated, mLap);
                break;
            case LAP_4:
                mComplexMovementTest.addWaypointDataToPath(coordinates, userGenerated, mLap);
                break;
            default:
                throw new AssertionError(""addPoseDataToPath default: Unrecognised lap"", null);
        }
        if (userGenerated) {
            mBaseUiListener.onWaypointPlaced();
        }
    }

    /**
     * Removes the last marker from the current lap.
     */
    public void removeLastAddedMarker() {
        boolean resetTest;
        switch (mLap) {
            case LAP_1:
                resetTest = mReferencePath.removeLastMarker();
                break;
            case LAP_2:
                resetTest = mAccuracyTest.removeLastAddedMarker();
                break;
            case LAP_3:
                resetTest = mRobustnessTest.removeLastAddedMarker();
                break;
            case LAP_4:
                resetTest = mComplexMovementTest.removeLastAddedMarker();
                break;
            default:
                throw new AssertionError(""removeLastAddedMarker default: Unrecognised lap"", null);
        }
        if (resetTest) {
            mAccuracyListener.onReset();
        }
    }

    /**
     * Initiates the accuracy test.
     */
    public void startAccuracyTest() {
        mAccuracyTest = new AccuracyTest(mReferencePath, mTestReport, this);
        mLap = Lap.LAP_2;
    }

    /**
     * Initiates the robustness test.
     */
    public void startRobustnessTest() {
        mRobustnessTest = new RobustnessTest(mReferencePath, mTestReport, this,
                BaseRenderer.getDeviceRotation((Context) mBaseUiListener));
        mLap = Lap.LAP_3;

    }

    /**
     * Initiates the complex movement test.
     */
    public void startComplexMovementTest() {
        mComplexMovementTest = new ComplexMovementTest(mReferencePath, mTestReport, this);
        mLap = Lap.LAP_4;
    }

    /**
     * Indicates that the accuracy test has been completed.
     *
     * @param passList A list to indicate whether the test passes or not.
     */
    public void onAccuracyTestCompleted(HashMap<BaseResultsDialog.ResultType, Boolean> passList) {
        mBaseUiListener.onResult(new ResultObject(passList));
    }

    /**
     * Indicates that the robustness test has been completed.
     *
     * @param robustnessTestResults List containing information about whether the tests failed or
     *                              passed.
     */
    public void onRobustnessTestCompleted(HashMap<BaseResultsDialog.ResultType, Boolean> robustnessTestResults) {
        ResultObject robustnessResult = new ResultObject(robustnessTestResults);
        mBaseUiListener.onResult(robustnessResult);
    }

    /**
     * Indicates that the complex movement test has been completed.
     *
     * @param complexMovementTestResults List containing information about whether the tests failed
     *                                   or passed.
     */
    public void onComplexMovementTestCompleted(HashMap<BaseResultsDialog.ResultType, Boolean> complexMovementTestResults) {
        ResultObject complexMovementResult = new ResultObject(complexMovementTestResults);

        if (complexMovementResult.hasPassed()) {
            mTestReport.setTestState(TestReport.TestStatus.PASS);
        }

        mBaseUiListener.onResult(complexMovementResult);
    }

    /**
     * Sets the path remaining for the user to travel.
     */
    public void calculateRemainingPath() {
        mRemainingPath = mReferencePath.calculatePathRemaining();
    }

    /**
     * Uses the current rotation and location to calculate the rotation detail's. Also gives the UI
     * information about the rotation.
     *
     * @param rotations   Quaternion containing the current rotation.
     * @param translation The location the rotation occurred.
     */
    public void calculateRotationData(float[] rotations, float[] translation) {
        RotationData rotationData = mRobustnessTest.getRotationData(rotations, translation);
        if (rotationData != null) {
            mRobustnessListener.onNewRotationData(rotationData);
        }
    }

    /**
     * Sets the time remaining to place a waypoint.
     */
    public void calculateTimeRemaining() {
        mTimeRemaining = mRobustnessTest.getTimeRemaining();
    }

    /**
     * Handles new pose data.
     *
     * @param currentPose The current pose data.
     */
    public void onNewPoseData(PoseData currentPose) {
        if (mReferencePath.getCurrentPathSize() != 0) {
            switch (mLap) {
                case LAP_1:
                    calculateRemainingPath();
                    break;
                case LAP_2:
                    break;
                case LAP_3:
                    if (mRobustnessTest.getTestPathMarkersSize() > 0) {
                        calculateTimeRemaining();
                        calculateRotationData(currentPose.getRotationAsFloats(), currentPose.getTranslationAsFloats());
                    }
                    break;
                case LAP_4:
                    mComplexMovementTest.checkIfARingHasBeenPassed(currentPose.getTranslationAsFloats());
                    break;
            }
            try {
                addPoseDataToPath(currentPose.getTranslationAsFloats(),
                        false);
            } catch (WaypointException e) {
                throw new AssertionError(
                        ""System added waypoint should not be validated"", e);
            }
        }
    }

    /**
     * Returns the distance remaining to travel by the user.
     */
    public float getRemainingPath() {
        return mRemainingPath;
    }

    /**
     * Returns the makers in the reference path.
     */
    public ArrayList<Waypoint> getReferencePathMarkers() {
        return mReferencePath.getPathMarkers();
    }

    /**
     * Returns the makers in the accuracy test path.
     */
    public ArrayList<Waypoint> getTestPathMarkers() {
        return mAccuracyTest.getTestPathMarkers();
    }

    /**
     * Returns the time remaining to place the marker.
     */
    public long getTimeRemaining() {
        return mTimeRemaining;
    }

    /**
     * Returns the markers in the robustness test path.
     */
    public ArrayList<Waypoint> getRobustnessMarker() {
        return mRobustnessTest.getTestPathMarkers();
    }

    /**
     * Returns the current phase of the test.
     */
    public Lap getLap() {
        return mLap;
    }

    /**
     * Returns the rings in the ComplexMovement path.
     */
    public ArrayList<Ring> getRings() {
        return mComplexMovementTest.getRings();
    }

    /**
     * Returns the makers in the ComplexMovement test path.
     */
    public ArrayList<Waypoint> getComplexMovementTestMarkers() {
        return mComplexMovementTest.getTestPathMarkers();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Utils.TestPhase.Test"	"pathTest"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Utils/TestPhase/Test.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors.sixdof.Utils.TestPhase;

import com.android.cts.verifier.sensors.sixdof.Dialogs.BaseResultsDialog;
import com.android.cts.verifier.sensors.sixdof.Utils.Manager;
import com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils;
import com.android.cts.verifier.sensors.sixdof.Utils.TestReport;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointAreaCoveredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointDistanceException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointRingNotEnteredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointStartPointException;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.AccuracyPath;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.Path;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.ReferencePath;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Waypoint;

import android.util.Log;

import java.util.ArrayList;
import java.util.HashMap;

/**
 * TestPhase generic class will be inherited by the other tests.
 */
public abstract class Test {
    public static final int MAX_MARKER_NUMBER = 5;
    private static final float FAILURE_TOLERANCE_PERCENTAGE = 0.025f; // 2.5%
    private String mTestPhaseName;

    protected ArrayList<Float> mMarkerAccuracy = new ArrayList<>();
    protected ArrayList<Float> mPathAccuracy = new ArrayList<>();
    protected ArrayList<Float> mReferencePathDistances = new ArrayList<>();
    private ArrayList<Float> mTestPathDistances = new ArrayList<>();

    protected ReferencePath mReferencePath;
    protected Path mTestPath;
    protected TestReport mTestReport;
    protected Manager mManager;

    /**
     * Constructor for this class.
     *
     * @param referencePath Reference the the reference path.
     * @param testReport    The test report object to record the tests.
     * @param manager       The manager to call when the test is done.
     */
    public Test(ReferencePath referencePath, TestReport testReport, Manager manager, String testPhase) {
        if (referencePath != null) {
            mReferencePath = referencePath;
        } else {
            throw new AssertionError(""TestPhase received a null referencePath"", null);
        }
        mTestPhaseName = testPhase;
        mTestReport = testReport;
        mManager = manager;
        mTestPath = new AccuracyPath();
        mReferencePathDistances = calculatePathDistance(mReferencePath.getCurrentPath(), mReferencePath.getPathMarkers());
    }

    /**
     * Adds the current waypoint to the test path.
     *
     * @param coordinates   the coordinates to use for the waypoint.
     * @param userGenerated indicates whether the data was user created or system created.
     * @param currentLap    the lap the data was created in.
     * @throws WaypointDistanceException    if the location is too close to another.
     * @throws WaypointAreaCoveredException if the area covered by the user is too little.
     * @throws WaypointStartPointException  if the location is not close enough to the start.
     */
    public void addWaypointDataToPath(
            float[] coordinates, boolean userGenerated, Manager.Lap currentLap)
            throws WaypointAreaCoveredException, WaypointDistanceException,
            WaypointStartPointException, WaypointRingNotEnteredException {
        mTestPath.createWaypointAndAddToPath(coordinates, userGenerated, currentLap);
        runAdditionalMethods();
    }

    /**
     * Abstract method that is used but subclasses.
     */
    protected abstract void runAdditionalMethods();

    /**
     * Removes the last marker from the chosen lap.
     *
     * @return true of the first marker false if any other marker
     */
    public boolean removeLastAddedMarker() {
        return mTestPath.removeLastMarker();
    }

    /**
     * Performs the tests for this test phase.
     *
     * @return the state of the tests, true if they pass false if they fail.
     */
    protected HashMap<BaseResultsDialog.ResultType, Boolean> executeTests(boolean includeMarkerTest, boolean includePathTest) {
        HashMap<BaseResultsDialog.ResultType, Boolean> testResults = new HashMap<>();
        if (includePathTest) {
            testResults.put(BaseResultsDialog.ResultType.PATH, pathTest());
        }
        if (includeMarkerTest) {
            testResults.put(BaseResultsDialog.ResultType.WAYPOINT, markerTest());
        }
        return testResults;
    }

    /**
     * Calculates the difference between the markers of the laps and executes the marker related
     * test.
     *
     * @return true if the test passes and false if the rest fails.
     */
    private boolean markerTest() {
        float distance;
        for (int i = 0; i < mReferencePath.getPathMarkersSize(); i++) {
            distance = MathsUtils.distanceCalculationInXYZSpace(
                    mReferencePath.getPathMarkers().get(i).getCoordinates(),
                    mTestPath.getPathMarkers().get(i).getCoordinates());
            mMarkerAccuracy.add(distance);
        }
        return markerAccuracyTest();
    }

    /**
     * Runs a check to find any markers that have failed the test and adds them to the test report.
     *
     * @return true if the test passes and false if the rest fails
     */
    private boolean markerAccuracyTest() {
        boolean testState = true;
        for (float markerDifference : mMarkerAccuracy) {
            if (markerDifference > mReferencePath.getFailureTolerance()) {
                recordMarkerTestResults(markerDifference);
                testState = false;
            }
        }
        return testState;
    }

    /**
     * Formats the failed markers into a string to add it to the test report.
     *
     * @param markerDifference the difference which caused the marker to fail
     */
    private void recordMarkerTestResults(float markerDifference) {
        int markerNumber = mMarkerAccuracy.indexOf(markerDifference);
        String referenceMarker = MathsUtils.coordinatesToString(
                mReferencePath.getPathMarkers().get(markerNumber).getCoordinates());
        String testMarker = MathsUtils.coordinatesToString(
                mTestPath.getPathMarkers().get(markerNumber).getCoordinates());
        String testDetails = mTestPhaseName +
                "" Marker Accuracy: Distance between the markers too great. Marker: "" + markerNumber +
                "" Difference: "" + markerDifference +
                "" Coordinates "" + referenceMarker + "" "" + testMarker + ""\n"";
        Log.e(""Marker Result"", testDetails);
        mTestReport.setFailDetails(testDetails);
    }

    /**
     * Executes the the path related tests.
     *
     * @return true if the test passes, false if the test fails
     */
    private boolean pathTest() {
        mTestPathDistances = calculatePathDistance(mTestPath.getCurrentPath(), mTestPath.getPathMarkers());
        calculatePathDifferences();
        return pathAccuracyTest();
    }

    /**
     * Calculates the distance between the markers for the given path.
     *
     * @param pathToCalculate The path that we want to calculate the distances for
     * @param markers         The locations of the user generated markers in that path
     * @return the list of distances for that path
     */
    protected ArrayList<Float> calculatePathDistance(ArrayList<Waypoint> pathToCalculate,
                                                     ArrayList<Waypoint> markers) {
        ArrayList<Float> pathDistances = new ArrayList<>();
        float totalDistance, distance;
        int currentLocation = pathToCalculate.indexOf(markers.get(0));

        while (currentLocation < pathToCalculate.size() - 1) {
            totalDistance = 0;
            do {
                distance = MathsUtils.distanceCalculationOnXYPlane(
                        pathToCalculate.get(currentLocation).getCoordinates(),
                        pathToCalculate.get(currentLocation + 1).getCoordinates());
                totalDistance += distance;
                currentLocation++;
            } while (!pathToCalculate.get(currentLocation).isUserGenerated());
            pathDistances.add(Math.abs(totalDistance));
            if (currentLocation == markers.size() - 1) {
                break;
            }
        }
        return pathDistances;
    }

    /**
     * Calculates the difference between paths on different laps.
     */
    private void calculatePathDifferences() {
        float difference;

        if (!mReferencePathDistances.isEmpty() && !mTestPathDistances.isEmpty()) {
            for (int i = 0; i < mReferencePathDistances.size(); i++) {
                difference = mReferencePathDistances.get(i) - mTestPathDistances.get(i);
                mPathAccuracy.add(Math.abs(difference));
            }
        } else {
            throw new AssertionError(""calculatePathDifference has one of the arrays empty"", null);
        }
    }

    /**
     * Checks to see if any of the path differences have failed the test and adds them to the test
     * report.
     *
     * @return True if the test passes and false if there is a fail
     */
    private boolean pathAccuracyTest() {
        boolean testState = true;
        for (float path : mPathAccuracy) {
            if (path > mReferencePath.getFailureTolerance()) {
                recordPathTestResults(path);
                testState = false;
            }
        }
        return testState;
    }

    /**
     * Formats the failed paths into a string to add it to the test report.
     *
     * @param difference The distance that failed the test
     */
    private void recordPathTestResults(float difference) {
        int pathNumber = mPathAccuracy.indexOf(difference);
        String referencePath = String.valueOf(mReferencePathDistances.get(pathNumber));
        String testPath = String.valueOf(mTestPathDistances.get(pathNumber));
        String testDetails = mTestPhaseName +
                "" Path Length: Path length difference was too great. Path: "" + pathNumber +
                "" Difference: "" + difference +
                "" Paths: "" + referencePath + "" "" + testPath + ""\n"";
        Log.e(""Path Result"", testDetails);
        mTestReport.setFailDetails(testDetails);
    }

    /**
     * Returns the makers in the test path.
     */
    public ArrayList<Waypoint> getTestPathMarkers() {
        return mTestPath.getPathMarkers();
    }

    /**
     * Returns the size of the current path.
     */
    public int getTestPathMarkersSize() {
        return mTestPath.getPathMarkers().size();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.location.cts.coarse.LocationManagerCoarseTest"	"currentTimeMillis"	"CtsLocationCoarseTestCases"	"/home/gpoor/cts-12-source/cts/tests/location/location_coarse/src/android/location/cts/coarse/LocationManagerCoarseTest.java"	""	"/*
 *.
 */

package android.location.cts.coarse;

import static android.location.LocationManager.FUSED_PROVIDER;
import static android.location.LocationManager.GPS_PROVIDER;
import static android.location.LocationManager.NETWORK_PROVIDER;
import static android.location.LocationManager.PASSIVE_PROVIDER;
import static android.location.LocationRequest.PASSIVE_INTERVAL;
import static android.provider.Settings.Secure.LOCATION_COARSE_ACCURACY_M;

import static androidx.test.ext.truth.location.LocationSubject.assertThat;

import static com.android.compatibility.common.util.LocationUtils.createLocation;

import static com.google.common.truth.Truth.assertThat;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;

import android.content.Context;
import android.content.pm.PackageManager;
import android.location.Criteria;
import android.location.Location;
import android.location.LocationManager;
import android.location.LocationRequest;
import android.location.cts.common.LocationListenerCapture;
import android.location.cts.common.LocationPendingIntentCapture;
import android.location.cts.common.ProximityPendingIntentCapture;
import android.os.Build;
import android.os.Bundle;
import android.os.SystemClock;
import android.platform.test.annotations.AppModeFull;
import android.provider.Settings;
import android.util.Log;

import androidx.test.core.app.ApplicationProvider;
import androidx.test.ext.junit.runners.AndroidJUnit4;
import androidx.test.platform.app.InstrumentationRegistry;

import com.android.compatibility.common.util.LocationUtils;

import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import org.junit.runner.RunWith;

import java.util.List;
import java.util.Random;

@RunWith(AndroidJUnit4.class)
public class LocationManagerCoarseTest {

    private static final String TAG = ""LocationManagerCoarseTest"";

    private static final long TIMEOUT_MS = 5000;

    private static final float MIN_COARSE_FUDGE_DISTANCE_M = 2000f;

    private static final String TEST_PROVIDER = ""test_provider"";

    private Random mRandom;
    private Context mContext;
    private LocationManager mManager;

    private float mMaxCoarseFudgeDistanceM;

    @Before
    public void setUp() throws Exception {
        LocationUtils.registerMockLocationProvider(InstrumentationRegistry.getInstrumentation(),
                true);

        long seed = System.currentTimeMillis();
        Log.i(TAG, ""location random seed: "" + seed);

        mRandom = new Random(seed);
        mContext = ApplicationProvider.getApplicationContext();
        mManager = mContext.getSystemService(LocationManager.class);

        float coarseLocationAccuracyM = Settings.Secure.getFloat(
                mContext.getContentResolver(),
                LOCATION_COARSE_ACCURACY_M,
                MIN_COARSE_FUDGE_DISTANCE_M);
        mMaxCoarseFudgeDistanceM = (float) Math.sqrt(
                2 * coarseLocationAccuracyM * coarseLocationAccuracyM);

        assertNotNull(mManager);

        for (String provider : mManager.getAllProviders()) {
            mManager.removeTestProvider(provider);
        }

        mManager.addTestProvider(TEST_PROVIDER,
                true,
                false,
                true,
                false,
                false,
                false,
                false,
                Criteria.POWER_MEDIUM,
                Criteria.ACCURACY_COARSE);
        mManager.setTestProviderEnabled(TEST_PROVIDER, true);
    }

    @After
    public void tearDown() throws Exception {
        if (mManager != null) {
            for (String provider : mManager.getAllProviders()) {
                mManager.removeTestProvider(provider);
            }
            mManager.removeTestProvider(FUSED_PROVIDER);
        }

        LocationUtils.registerMockLocationProvider(InstrumentationRegistry.getInstrumentation(),
                false);
    }"	""	""	"proximity"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.location.cts.coarse.LocationManagerCoarseTest"	"testAddProximityAlert"	"CtsLocationCoarseTestCases"	"/home/gpoor/cts-12-source/cts/tests/location/location_coarse/src/android/location/cts/coarse/LocationManagerCoarseTest.java"	""	"public void testAddProximityAlert() {
        try (ProximityPendingIntentCapture capture = new ProximityPendingIntentCapture(mContext)) {
            try {
                mManager.addProximityAlert(0, 0, 100, -1, capture.getPendingIntent());
                fail(""addProximityAlert() should fail with only ACCESS_COARSE_LOCATION"");
            } catch (SecurityException e) {
                // pass
            }
        }
    }

    // TODO: this test should probably not be in the location module"	""	""	"proximity"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Activities.TestActivity"	"finish"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Activities/TestActivity.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Activities;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.sixdof.Activities.StartActivity.ResultCode;
import com.android.cts.verifier.sensors.sixdof.Fragments.AccuracyFragment;
import com.android.cts.verifier.sensors.sixdof.Fragments.ComplexMovementFragment;
import com.android.cts.verifier.sensors.sixdof.Fragments.DataFragment;
import com.android.cts.verifier.sensors.sixdof.Fragments.PhaseStartFragment;
import com.android.cts.verifier.sensors.sixdof.Fragments.RobustnessFragment;
import com.android.cts.verifier.sensors.sixdof.Interfaces.AccuracyListener;
import com.android.cts.verifier.sensors.sixdof.Interfaces.BaseUiListener;
import com.android.cts.verifier.sensors.sixdof.Interfaces.ComplexMovementListener;
import com.android.cts.verifier.sensors.sixdof.Interfaces.RobustnessListener;
import com.android.cts.verifier.sensors.sixdof.Utils.ReportExporter;
import com.android.cts.verifier.sensors.sixdof.Utils.TestReport;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointAreaCoveredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointDistanceException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointRingNotEnteredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointStartPointException;
import com.android.cts.verifier.sensors.sixdof.Utils.Manager.Lap;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Ring;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.RotationData;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Waypoint;
import com.android.cts.verifier.sensors.sixdof.Utils.PoseProvider.PoseProvider;
import com.android.cts.verifier.sensors.sixdof.Utils.ResultObjects.ResultObject;

import android.content.Intent;
import android.content.pm.ActivityInfo;
import android.content.res.Configuration;
import android.content.res.Resources;
import android.os.Bundle;
import android.app.Fragment;
import android.app.FragmentManager;
import android.app.FragmentTransaction;
import android.app.AlertDialog;
import android.app.Activity;
import android.util.Log;
import android.view.Display;
import android.view.Menu;
import android.view.MenuItem;
import android.view.Surface;

import java.io.IOException;
import java.util.ArrayList;

/**
 * Main Activity for 6DOF tests Handles calls between UI fragments and the Data fragment. The
 * controller in the MVC structure.
 */
public class TestActivity extends Activity implements BaseUiListener, AccuracyListener,
        RobustnessListener, ComplexMovementListener {

    private static final String TAG = ""TestActivity"";
    private static final String TAG_DATA_FRAGMENT = ""data_fragment"";
    public static final String EXTRA_RESULT_ID = ""extraResult"";
    public static final String EXTRA_REPORT = ""extraReport"";
    public static final String EXTRA_ON_RESTART = ""6dof_verifier_restart"";
    public static final Object POSE_LOCK = new Object();

    private DataFragment mDataFragment;

    private BaseUiListener mUiListener;
    private AccuracyListener mAccuracyListener;
    private RobustnessListener mRobustnessListener;
    private ComplexMovementListener mComplexMovementListener;

    private CTSTest mCurrentTest = CTSTest.ACCURACY;

    private boolean mHasBeenPaused = false;

    public enum CTSTest {
        ACCURACY,
        ROBUSTNESS,
        COMPLEX_MOVEMENT
    }

    /**
     * Initialises camera preview, looks for a retained data fragment if we have one and adds UI
     * fragment.
     */
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);

        // If we are restarting, kill the test as data is invalid.
        if (savedInstanceState != null) {
            if (savedInstanceState.getBoolean(EXTRA_ON_RESTART)) {
                Intent intent = this.getIntent();
                intent.putExtra(EXTRA_RESULT_ID, ResultCode.FAILED_PAUSE_AND_RESUME);
                this.setResult(RESULT_OK, intent);
                finish();
            }
        }

        setContentView(R.layout.activity_cts);

        // Add the first instructions fragment.
        Fragment fragment = PhaseStartFragment.newInstance(CTSTest.ACCURACY);
        FragmentManager fragmentManager = getFragmentManager();
        FragmentTransaction transaction = fragmentManager.beginTransaction();
        transaction.replace(R.id.contentFragment, fragment);
        transaction.commit();

        mDataFragment = new DataFragment();
        fragmentManager.beginTransaction().add(mDataFragment, TAG_DATA_FRAGMENT).commit();

        // Lock the screen to its current rotation
        lockRotation();
    }

    /**
     * Lock the orientation of the device in its current state.
     */
    private void lockRotation() {
        final Display display = getWindowManager().getDefaultDisplay();
        int naturalOrientation = Configuration.ORIENTATION_LANDSCAPE;
        int configOrientation = getResources().getConfiguration().orientation;
        switch (display.getRotation()) {
            case Surface.ROTATION_0:
            case Surface.ROTATION_180:
                // We are currently in the same basic orientation as the natural orientation
                naturalOrientation = configOrientation;
                break;
            case Surface.ROTATION_90:
            case Surface.ROTATION_270:
                // We are currently in the other basic orientation to the natural orientation
                naturalOrientation = (configOrientation == Configuration.ORIENTATION_LANDSCAPE) ?
                        Configuration.ORIENTATION_PORTRAIT : Configuration.ORIENTATION_LANDSCAPE;
                break;
        }

        int[] orientationMap = {
                ActivityInfo.SCREEN_ORIENTATION_PORTRAIT,
                ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE,
                ActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT,
                ActivityInfo.SCREEN_ORIENTATION_REVERSE_LANDSCAPE
        };
        // Since the map starts at portrait, we need to offset if this device's natural orientation
        // is landscape.
        int indexOffset = 0;
        if (naturalOrientation == Configuration.ORIENTATION_LANDSCAPE) {
            indexOffset = 1;
        }

        // The map assumes default rotation. Check for reverse rotation and correct map if required
        try {
            if (getResources().getBoolean(getResources().getSystem().getIdentifier(
                    ""config_reverseDefaultRotation"", ""bool"", ""android""))) {
                orientationMap[0] = ActivityInfo.SCREEN_ORIENTATION_REVERSE_PORTRAIT;
                orientationMap[2] = ActivityInfo.SCREEN_ORIENTATION_PORTRAIT;
            }
        } catch (Resources.NotFoundException e) {
            // If resource is not found, assume default rotation and continue
            Log.d(TAG, ""Cannot determine device rotation direction, assuming default"");
        }

        setRequestedOrientation(orientationMap[(display.getRotation() + indexOffset) % 4]);
    }

    @Override
    public void onResume() {
        super.onResume();

        // 6DoF is reset after a recreation of activity, which invalidates the tests.
        if (mHasBeenPaused) {
            Intent intent = this.getIntent();
            intent.putExtra(EXTRA_RESULT_ID, ResultCode.FAILED_PAUSE_AND_RESUME);
            this.setResult(RESULT_OK, intent);
            finish();
        }
    }

    @Override
    public void onPause() {
        super.onPause();
        mHasBeenPaused = true;
    }

    @Override
    public boolean onCreateOptionsMenu(Menu menu) {
        // Inflate the menu; this adds items to the action bar if it is present.
        getMenuInflater().inflate(R.menu.menu_cts, menu);
        return true;
    }

    @Override
    public boolean onOptionsItemSelected(MenuItem item) {
        // Handle action bar item clicks here.
        int id = item.getItemId();

        switch (id) {
            case R.id.action_save_results:
                saveResults();
                return true;
            case R.id.action_xml:
                AlertDialog.Builder builder = new AlertDialog.Builder(this);

                try {
                    builder.setMessage(mDataFragment.getTestReport().getContents())
                            .setTitle(R.string.results)
                            .setPositiveButton(R.string.got_it, null);
                } catch (IOException e) {
                    Log.e(TAG, e.toString());
                }

                AlertDialog dialog = builder.create();
                dialog.show();
                return true;
            default:
                return super.onOptionsItemSelected(item);
        }
    }

    public void saveResults() {
        try {
            new ReportExporter(this, getTestReport().getContents()).execute();
        } catch (IOException e) {
            Log.e(TAG, ""Couldn't create test report."");
        }
    }

    public TestReport getTestReport() {
        return mDataFragment.getTestReport();
    }

    public void listenFor6DofData(Fragment listener) {
        mUiListener = (BaseUiListener) listener;
        switch (mCurrentTest) {
            case ACCURACY:
                mAccuracyListener = (AccuracyListener) listener;
                mRobustnessListener = null;
                mComplexMovementListener = null;
                break;
            case ROBUSTNESS:
                mAccuracyListener = null;
                mRobustnessListener = (RobustnessListener) listener;
                mComplexMovementListener = null;
                break;
            case COMPLEX_MOVEMENT:
                mAccuracyListener = null;
                mRobustnessListener = null;
                mComplexMovementListener = (ComplexMovementListener) listener;
                break;
            default:
                throw new AssertionError(""mCurrentTest is a test that doesn't exist!"");
        }
    }

    public boolean isPoseProviderReady() {
        if (mDataFragment != null) {
            return mDataFragment.isPoseProviderReady();
        } else {
            return false;
        }

    }

    public ArrayList<Waypoint> getUserGeneratedWaypoints(Lap lap) {
        return mDataFragment.getUserGeneratedWaypoints(lap);
    }

    public Lap getLap() {
        return mDataFragment.getLap();
    }

    public ArrayList<Ring> getRings() {
        return mDataFragment.getRings();
    }

    @Override
    public void onPoseProviderReady() {
        if (mUiListener != null) {
            mUiListener.onPoseProviderReady();
        } else {
            Log.e(TAG, getString(R.string.error_null_fragment));
        }

        // Possible for this to be called while switching UI fragments, so mUiListener is null
        // but we want to start the test anyway.
        mDataFragment.testStarted();
    }

    @Override
    public void onWaypointPlaced() {
        if (mUiListener != null) {
            mUiListener.onWaypointPlaced();
        } else {
            Log.e(TAG, getString(R.string.error_null_fragment));
        }
    }

    @Override
    public void onResult(ResultObject result) {
        if (mUiListener != null) {
            mUiListener.onResult(result);
        } else {
            Log.e(TAG, getString(R.string.error_null_fragment));
        }
    }

    @Override
    public void onReset() {
        if (mAccuracyListener != null) {
            if (mCurrentTest == CTSTest.ACCURACY) {
                mAccuracyListener.onReset();
            } else {
                throw new RuntimeException(""We are in the wrong test for this listener to be called."");
            }
        } else {
            Log.e(TAG, getString(R.string.error_null_fragment));
        }
    }

    @Override
    public void lap1Complete() {
        if (mAccuracyListener != null) {
            mAccuracyListener.lap1Complete();
        } else {
            Log.e(TAG, getString(R.string.error_null_fragment));
        }
    }

    public void attemptWaypointPlacement() throws WaypointAreaCoveredException, WaypointDistanceException, WaypointStartPointException, WaypointRingNotEnteredException {
        mDataFragment.onWaypointPlacementAttempt();
    }

    public void undoWaypointPlacement() {
        if (mDataFragment != null) {
            mDataFragment.undoWaypointPlacement();
        } else {
            Log.e(TAG, getString(R.string.error_retained_fragment_null));
        }
    }

    public void readyForLap2() {
        mDataFragment.startTest(CTSTest.ACCURACY);
    }

    public float getLatestDistanceData() {
        return mDataFragment.getLatestDistanceData();
    }

    public float getTimeRemaining() {
        return mDataFragment.getTimeRemaining();
    }

    public PoseProvider getPoseProvider() {
        return mDataFragment.getPoseProvider();
    }

    @Override
    public void onNewRotationData(RotationData data) {
        if (mRobustnessListener != null) {
            mRobustnessListener.onNewRotationData(data);
        } else {
            Log.e(TAG, getString(R.string.error_null_fragment));
        }
    }

    @Override
    public void onRingEntered(Ring ring) {
        if (mComplexMovementListener != null) {
            mComplexMovementListener.onRingEntered(ring);
        } else {
            Log.e(TAG, getString(R.string.error_null_fragment));
        }
    }

    /**
     * Loads test fragment for a particular phase.
     *
     * @param phase test to be started.
     */
    public void switchToTestFragment(CTSTest phase) {
        Log.d(TAG, ""switchToTestFragment"");
        Fragment fragment;

        switch (phase) {
            case ACCURACY:
                fragment = AccuracyFragment.newInstance();
                break;
            case ROBUSTNESS:
                fragment = RobustnessFragment.newInstance();
                break;
            case COMPLEX_MOVEMENT:
                fragment = ComplexMovementFragment.newInstance(); //Complex Motion
                break;
            default:
                throw new AssertionError(""Trying to start a test that doesn't exist!"");
        }
        FragmentManager fm = getFragmentManager();
        FragmentTransaction transaction = fm.beginTransaction();
        transaction.replace(R.id.contentFragment, fragment);
        transaction.commit();
    }

    /**
     * Loads start instruction fragment for a particular test.
     *
     * @param phase test to show instruction screen for.
     */
    public void switchToStartFragment(CTSTest phase) {
        Log.e(TAG, ""switchToStartFragment"");
        mUiListener = null;
        mAccuracyListener = null;
        mRobustnessListener = null;
        mComplexMovementListener = null;

        mCurrentTest = phase;
        mDataFragment.startTest(mCurrentTest);
        Fragment fragment = PhaseStartFragment.newInstance(phase);
        FragmentManager fm = getFragmentManager();
        FragmentTransaction transaction = fm.beginTransaction();
        transaction.replace(R.id.contentFragment, fragment);
        transaction.commit();
    }

    @Override
    protected void onSaveInstanceState(Bundle outState) {
        // We are always going to be restarting if this is called.
        outState.putBoolean(EXTRA_ON_RESTART, true);
        super.onSaveInstanceState(outState);
    }

    @Override
    protected void onDestroy() {
        super.onDestroy();
        onDestroyUi();
        mUiListener = null;
        mAccuracyListener = null;
        mRobustnessListener = null;
        mComplexMovementListener = null;
        mDataFragment = null;
    }

    @Override
    public void onDestroyUi() {
        if (mUiListener != null) {
            mUiListener.onDestroyUi();
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.SensorSynchronizationTestActivity"	"SensorSynchronizationTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/SensorSynchronizationTestActivity.java"	""	"public void test
package com.android.cts.verifier.sensors;

import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;

import junit.framework.Assert;

import android.annotation.TargetApi;
import android.content.Context;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.hardware.cts.helpers.TestSensorEvent;
import android.os.Build;

import java.util.ArrayList;
import java.util.List;

/**
 * Test cross-sensor timestamp alignment by detecting major change in each
 * sensor and comparing timestamps of that change.
 */
@TargetApi(Build.VERSION_CODES.JELLY_BEAN_MR1)
public class SensorSynchronizationTestActivity
        extends SensorCtsVerifierTestActivity
        implements SensorEventListener {
    public SensorSynchronizationTestActivity() {
        super(SensorSynchronizationTestActivity.class);
    }

    private final double NANOS_PER_MILLI = 1e6;
    private final int DATA_COLLECTION_TIME_IN_MS = 5000;
    private final int RATE_100HZ_IN_US = 10000;
    private final int MAX_CROSS_SENSOR_DELAY_MILLIS = 125;
    private final double THRESH_DEGREES = 10.0;
    private final double THRESH_RPS = 1.0;

    private SensorManager mSensorManager = null;
    private List<TestSensorEvent> mSensorEvents = new ArrayList<TestSensorEvent>();

    private void startDataCollection() {
        mSensorEvents.clear();

        mSensorManager = (SensorManager) getApplicationContext()
                .getSystemService(Context.SENSOR_SERVICE);
        mSensorManager.registerListener(this,
                mSensorManager.getDefaultSensor(Sensor.TYPE_ACCELEROMETER),
                RATE_100HZ_IN_US);
        mSensorManager.registerListener(this,
                mSensorManager.getDefaultSensor(Sensor.TYPE_MAGNETIC_FIELD),
                RATE_100HZ_IN_US);
        mSensorManager.registerListener(this,
                mSensorManager.getDefaultSensor(Sensor.TYPE_GYROSCOPE),
                RATE_100HZ_IN_US);
    }

    private void stopDataCollection() {
        mSensorManager.unregisterListener(this);
    }

    private void analyzeData() {
        int numberOfCollectedEvents = mSensorEvents.size();
        Assert.assertTrue(""No sensor events collected"", numberOfCollectedEvents > 2);

        boolean accMovementDetected = false;
        boolean magMovementDetected = false;
        boolean gyrMovementDetected = false;
        long accMovementTimestamp = 0, magMovementTimestamp = 0, gyrMovementTimestamp = 0;
        float[] accInitValues = null, magInitValues = null, gyrInitValues = null;

        for (int i = 0; i < numberOfCollectedEvents; i++) {
            TestSensorEvent event = mSensorEvents.get(i);

            if (event.sensor.getType() == Sensor.TYPE_ACCELEROMETER) {
                if (accInitValues == null) {
                    accInitValues = event.values.clone();
                } else if (angleBetweenVecsDegrees(accInitValues, event.values) > THRESH_DEGREES
                        && !accMovementDetected) {
                    accMovementDetected = true;
                    accMovementTimestamp = event.timestamp;
                }
            } else if (event.sensor.getType() == Sensor.TYPE_MAGNETIC_FIELD) {
                if (magInitValues == null) {
                    magInitValues = event.values.clone();
                } else if (angleBetweenVecsDegrees(magInitValues, event.values) > THRESH_DEGREES
                        && !magMovementDetected) {
                    magMovementDetected = true;
                    magMovementTimestamp = event.timestamp;
                }
            }
            if (event.sensor.getType() == Sensor.TYPE_GYROSCOPE) {
                if (gyrInitValues == null) {
                    gyrInitValues = event.values.clone();
                } else if (normVec(event.values) > THRESH_RPS && !gyrMovementDetected) {
                    gyrMovementDetected = true;
                    gyrMovementTimestamp = event.timestamp;
                }
            }

            if (accMovementDetected && magMovementDetected && gyrMovementDetected) {
                double maxTimestamp = Math.max(accMovementTimestamp,
                        magMovementTimestamp);
                maxTimestamp = Math.max(gyrMovementTimestamp, maxTimestamp);

                double minTimestamp = Math.min(accMovementTimestamp,
                        magMovementTimestamp);
                minTimestamp = Math.min(gyrMovementTimestamp, minTimestamp);

                double timeDifferenceBetweenMovementMillis =
                        (maxTimestamp - minTimestamp) / NANOS_PER_MILLI;

                appendText(String.format(""\nSensor  |  Relative Timestamp (msec)\n""
                        + ""Accelerometer | %4.1f\nMagnetometer | %4.1f\nGyroscope | %4.1f\n"",
                        (accMovementTimestamp - minTimestamp) / NANOS_PER_MILLI,
                        (magMovementTimestamp - minTimestamp) / NANOS_PER_MILLI,
                        (gyrMovementTimestamp - minTimestamp) / NANOS_PER_MILLI));
                Assert.assertEquals(String.format(
                        ""Cross sensor timestamp alignment off by more than %d msec."",
                        MAX_CROSS_SENSOR_DELAY_MILLIS),
                        0, timeDifferenceBetweenMovementMillis, MAX_CROSS_SENSOR_DELAY_MILLIS);
                appendText(String.format(
                        ""Maximum cross sensor time between movement: %4.1f msec is within ""
                                + ""required tolerance of %4.1f msec"",
                        timeDifferenceBetweenMovementMillis,
                        (float) MAX_CROSS_SENSOR_DELAY_MILLIS));
                break;
            }
        }

        Assert.assertTrue(""Accelerometer did not detect any movement"", accMovementDetected);
        Assert.assertTrue(""Magnetometer did not detect any movement"", magMovementDetected);
        Assert.assertTrue(""Gyroscope did not detect any movement"", gyrMovementDetected);
    }

    public String testCrossSensorSynchronization() throws Throwable {
        appendText(""This test provides a rough indication of cross-sensor timestamp synchronization."");
        appendText(""Hold device still in hand and click 'Next'"");
        waitForUserToBegin();
        clearText();
        appendText(""Quickly twist device upside-down and back"");

        startDataCollection();
        Thread.sleep(DATA_COLLECTION_TIME_IN_MS);

        stopDataCollection();
        analyzeData();
        return null;
    }

    protected double angleBetweenVecsDegrees(float[] vec1, float[] vec2) {
        return Math.toDegrees(Math.acos((vec1[0] * vec2[0] + vec1[1] * vec2[1] + vec1[2] * vec2[2])
                / normVec(vec1) / normVec(vec2)));
    }

    protected double normVec(float[] vec1) {
        return Math.sqrt(vec1[0] * vec1[0] + vec1[1] * vec1[1] + vec1[2] * vec1[2]);
    }

    @Override
    public void onSensorChanged(SensorEvent sensorEvent) {
        mSensorEvents.add(new TestSensorEvent(sensorEvent));
    }

    @Override
    public void onAccuracyChanged(Sensor sensor, int accuracy) {
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.OffsetVerification"	"isEmpty"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/OffsetVerification.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers.sensorverification;

import android.hardware.Sensor;
import android.hardware.cts.helpers.SensorCtsHelper;
import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.SensorTestWarningException;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEvent;

import java.util.Arrays;
import java.util.ArrayList;
import java.util.Collections;
import junit.framework.Assert;

/**
 * A {@link ISensorVerification} which verifies that the offset for a sensor event is
 * within range.
 */
public class OffsetVerification extends AbstractSensorVerification {
    public static final String PASSED_KEY = ""offset_passed"";

    // Number of indices to print in assert message before truncating
    private static final int TRUNCATE_MESSAGE_LENGTH = 3;

    // CDD 7.3.2/C1-5: Magnetometer must have a hard iron offset value less than 700uT
    private static final float MAGNETOMETER_MAXIMUM_OFFSET_UT = 700.0f;

    // Threshold to allow for the actual offsets to vary slightly from the CDD limit in order to
    // account for rounding errors.
    private static final float ALLOWED_ERROR_PERCENT = 0.0001f;

    private ArrayList<TestSensorEvent> mInvalidSamples;
    private float mMaximumOffset;

    /**
     * Construct a {@link OffsetVerification}
     *
     * @param maximumOffset the maximum allowed magnitude for the sensor event offset
     *                      in units defined by the CDD
     */
    public OffsetVerification(float maximumOffset) {
        mInvalidSamples = new ArrayList<TestSensorEvent>();
        mMaximumOffset = maximumOffset;
    }

    /**
     * Get the default {@link OffsetVerification}.
     *
     * @param environment the test environment
     * @return the verification or null if there is no offset requirement
     */
    public static OffsetVerification getDefault(TestSensorEnvironment environment) {
        if (environment.getSensor().getType() == Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED) {
            return new OffsetVerification(MAGNETOMETER_MAXIMUM_OFFSET_UT);
        }
        return null;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public void verify(TestSensorEnvironment environment, SensorStats stats) {
        verify(stats);
    }

    /**
     * Visible for unit tests only.
     */
    protected void verify(SensorStats stats) {
        boolean pass = mInvalidSamples.isEmpty();

        stats.addValue(PASSED_KEY, pass);

        if (!pass) {
            StringBuilder sb = new StringBuilder();
            sb.append(""Magnetometer must have a hard iron offset value less than "")
                .append(mMaximumOffset).append("" example sample: "").append(mInvalidSamples.get(0));
            // TODO(b/146757096): Make this an assert once OEMs have had enough
            // time to react to seeing the new warning.
            throw new SensorTestWarningException(sb.toString());
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public OffsetVerification clone() {
        return new OffsetVerification(mMaximumOffset);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    protected void addSensorEventInternal(TestSensorEvent event) {
        // Uncalibrated SensorEvent objects contain the bias in values[3], values[4] and values[5].
        float[] offsets = Arrays.copyOfRange(event.values, 3, 6);
        float maxOffsetWithError = mMaximumOffset * (1.0f + ALLOWED_ERROR_PERCENT);
        for (float offset : offsets) {
            if (offset > maxOffsetWithError) {
                mInvalidSamples.add(event);
            }
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.directreportapi31.DirectReportAPI31Test"	"testSamplingRateMicToggleOn"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/DirectReportAPI31/src/android/sensorratepermission/cts/directreportapi31/DirectReportAPI31Test.java"	""	"public void testSamplingRateMicToggleOn() throws InterruptedException {
        mDirectReportTestHelper.flipAndAssertMicToggleOn(mUserID, mSensorPrivacyManager);
        List<SensorDirectReportTest.DirectReportSensorEvent> events =
                mDirectReportTestHelper.getSensorEvents(SensorDirectChannel.RATE_VERY_FAST);

        double obtainedRate = SensorRatePermissionDirectReportTestHelper.computeAvgRate(events,
                Long.MIN_VALUE, Long.MAX_VALUE);

        Assert.assertTrue(mDirectReportTestHelper.errorWhenExceedCappedRate(),
                obtainedRate <= SensorRatePermissionDirectReportTestHelper.CAPPED_SAMPLE_RATE_HZ);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.directreportapi31.DirectReportAPI31Test"	"testSamplingRateMicToggleOff"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/DirectReportAPI31/src/android/sensorratepermission/cts/directreportapi31/DirectReportAPI31Test.java"	""	"public void testSamplingRateMicToggleOff() throws InterruptedException {
        mDirectReportTestHelper.flipAndAssertMicToggleOff(mUserID, mSensorPrivacyManager);
        List<SensorDirectReportTest.DirectReportSensorEvent> events =
                mDirectReportTestHelper.getSensorEvents(SensorDirectChannel.RATE_VERY_FAST);

        double obtainedRate = SensorRatePermissionDirectReportTestHelper.computeAvgRate(events,
                Long.MIN_VALUE, Long.MAX_VALUE);

        Assert.assertTrue(mDirectReportTestHelper.errorWhenExceedCappedRate(),
                obtainedRate <= SensorRatePermissionDirectReportTestHelper.CAPPED_SAMPLE_RATE_HZ);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.app.cts.SystemFeaturesTest"	"testSensorFeatures"	"CtsAppTestCases"	"/home/gpoor/cts-12-source/cts/tests/app/src/android/app/cts/SystemFeaturesTest.java"	""	"public void testSensorFeatures() throws Exception {
        Set<String> featuresLeft = getFeatureConstantsNames(""FEATURE_SENSOR_"");

        assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_ACCELEROMETER,
                Sensor.TYPE_ACCELEROMETER);
        assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_BAROMETER,
                Sensor.TYPE_PRESSURE);
        assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_COMPASS,
                Sensor.TYPE_MAGNETIC_FIELD);
        assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_GYROSCOPE,
                Sensor.TYPE_GYROSCOPE);
        assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_LIGHT,
                Sensor.TYPE_LIGHT);
        assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_PROXIMITY,
                Sensor.TYPE_PROXIMITY);
        assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_STEP_COUNTER,
                Sensor.TYPE_STEP_COUNTER);
        assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_STEP_DETECTOR,
                Sensor.TYPE_STEP_DETECTOR);
        assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_AMBIENT_TEMPERATURE,
                Sensor.TYPE_AMBIENT_TEMPERATURE);
        assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_RELATIVE_HUMIDITY,
                Sensor.TYPE_RELATIVE_HUMIDITY);
        assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_HINGE_ANGLE,
                Sensor.TYPE_HINGE_ANGLE);


        /*
         * We have three cases to test for :
         * Case 1:  Device does not have an HRM
         * FEATURE_SENSOR_HEART_RATE               false
         * FEATURE_SENSOR_HEART_RATE_ECG           false
         * assertFeatureForSensor(TYPE_HEART_RATE) false
         *
         * Case 2:  Device has a PPG HRM
         * FEATURE_SENSOR_HEART_RATE               true
         * FEATURE_SENSOR_HEART_RATE_ECG           false
         * assertFeatureForSensor(TYPE_HEART_RATE) true
         *
         * Case 3:  Device has an ECG HRM
         * FEATURE_SENSOR_HEART_RATE               false
         * FEATURE_SENSOR_HEART_RATE_ECG           true
         * assertFeatureForSensor(TYPE_HEART_RATE) true
         */

        if (mPackageManager.hasSystemFeature(PackageManager.FEATURE_SENSOR_HEART_RATE_ECG)) {
                /* Case 3 for FEATURE_SENSOR_HEART_RATE_ECG true case */
                assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_HEART_RATE_ECG,
                        Sensor.TYPE_HEART_RATE);

                /* Remove HEART_RATE from featuresLeft, no way to test that one */
                assertTrue(""Features left "" + featuresLeft + "" to check did not include ""
                        + PackageManager.FEATURE_SENSOR_HEART_RATE,
                        featuresLeft.remove(PackageManager.FEATURE_SENSOR_HEART_RATE));
        } else if (!mPackageManager.hasSystemFeature(PackageManager.FEATURE_SENSOR_HEART_RATE)) {
                /* Case 1 & 2 for FEATURE_SENSOR_HEART_RATE_ECG false case */
                assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_HEART_RATE_ECG,
                        Sensor.TYPE_HEART_RATE);

                /* Case 1 & 3 for FEATURE_SENSOR_HEART_RATE false case */
                assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_HEART_RATE,
                        Sensor.TYPE_HEART_RATE);
        } else {
                /* Case 2 for FEATURE_SENSOR_HEART_RATE true case */
                assertFeatureForSensor(featuresLeft, PackageManager.FEATURE_SENSOR_HEART_RATE,
                        Sensor.TYPE_HEART_RATE);

                /* Remove HEART_RATE_ECG from featuresLeft, no way to test that one */
                assertTrue(""Features left "" + featuresLeft + "" to check did not include ""
                        + PackageManager.FEATURE_SENSOR_HEART_RATE_ECG,
                        featuresLeft.remove(PackageManager.FEATURE_SENSOR_HEART_RATE_ECG));
        }

        assertTrue(""Assertions need to be added to this test for "" + featuresLeft,
                featuresLeft.isEmpty());
    }

    /** Get a list of feature constants in PackageManager matching a prefix. */
    private static Set<String> getFeatureConstantsNames(String prefix)
            throws IllegalArgumentException, IllegalAccessException {
        Set<String> features = new HashSet<String>();
        Field[] fields = PackageManager.class.getFields();
        for (Field field : fields) {
            if (field.getName().startsWith(prefix)) {
                String feature = (String) field.get(null);
                features.add(feature);
            }
        }
        return features;
    }"	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.app.cts.SystemFeaturesTest"	"testCameraFeatures"	"CtsAppTestCases"	"/home/gpoor/cts-12-source/cts/tests/app/src/android/app/cts/SystemFeaturesTest.java"	""	"public void testCameraFeatures() throws Exception {
        int numCameras = Camera.getNumberOfCameras();
        if (numCameras == 0) {
            assertNotAvailable(PackageManager.FEATURE_CAMERA);
            assertNotAvailable(PackageManager.FEATURE_CAMERA_AUTOFOCUS);
            assertNotAvailable(PackageManager.FEATURE_CAMERA_FLASH);
            assertNotAvailable(PackageManager.FEATURE_CAMERA_FRONT);
            assertNotAvailable(PackageManager.FEATURE_CAMERA_ANY);
            assertNotAvailable(PackageManager.FEATURE_CAMERA_LEVEL_FULL);
            assertNotAvailable(PackageManager.FEATURE_CAMERA_CAPABILITY_MANUAL_SENSOR);
            assertNotAvailable(PackageManager.FEATURE_CAMERA_CAPABILITY_MANUAL_POST_PROCESSING);
            assertNotAvailable(PackageManager.FEATURE_CAMERA_CAPABILITY_RAW);
            assertNotAvailable(PackageManager.FEATURE_CAMERA_AR);

            assertFalse(""Devices supporting external cameras must have a representative camera "" +
                    ""connected for testing"",
                    mPackageManager.hasSystemFeature(PackageManager.FEATURE_CAMERA_EXTERNAL));
        } else {
            assertAvailable(PackageManager.FEATURE_CAMERA_ANY);
            checkFrontCamera();
            checkRearCamera();
            checkCamera2Features();
        }
    }

    @CddTest(requirement=""7.5.4/C-0-8"")
    private void checkCamera2Features() throws Exception {
        String[] cameraIds = mCameraManager.getCameraIdList();
        boolean fullCamera = false;
        boolean manualSensor = false;
        boolean manualPostProcessing = false;
        boolean motionTracking = false;
        boolean raw = false;
        boolean hasFlash = false;
        CameraCharacteristics[] cameraChars = new CameraCharacteristics[cameraIds.length];
        for (String cameraId : cameraIds) {
            CameraCharacteristics chars = mCameraManager.getCameraCharacteristics(cameraId);
            Integer hwLevel = chars.get(CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL);
            int[] capabilities = chars.get(CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES);
            if (hwLevel == CameraMetadata.INFO_SUPPORTED_HARDWARE_LEVEL_FULL ||
                    hwLevel == CameraMetadata.INFO_SUPPORTED_HARDWARE_LEVEL_3) {
                fullCamera = true;
            }
            for (int capability : capabilities) {
                switch (capability) {
                    case CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR:
                        manualSensor = true;
                        break;
                    case CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_POST_PROCESSING:
                        manualPostProcessing = true;
                        break;
                    case CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_RAW:
                        raw = true;
                        break;
                  case CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MOTION_TRACKING:
                        motionTracking = true;
                        break;
                    default:
                        // Capabilities don't have a matching system feature
                        break;
                }
            }

            Boolean flashAvailable = chars.get(CameraCharacteristics.FLASH_INFO_AVAILABLE);
            if (flashAvailable) {
                hasFlash = true;
            }
        }
        assertFeature(fullCamera, PackageManager.FEATURE_CAMERA_LEVEL_FULL);
        assertFeature(manualSensor, PackageManager.FEATURE_CAMERA_CAPABILITY_MANUAL_SENSOR);
        assertFeature(manualPostProcessing,
                PackageManager.FEATURE_CAMERA_CAPABILITY_MANUAL_POST_PROCESSING);
        assertFeature(raw, PackageManager.FEATURE_CAMERA_CAPABILITY_RAW);
        if (!motionTracking) {
          // FEATURE_CAMERA_AR requires the presence of
          // CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MOTION_TRACKING but
          // MOTION_TRACKING does not require the presence of FEATURE_CAMERA_AR
          //
          // Logic table:
          //    AR= F   T
          // MT=F   Y   N
          //   =T   Y   Y
          //
          // So only check the one disallowed condition: No motion tracking and FEATURE_CAMERA_AR is
          // available
          assertNotAvailable(PackageManager.FEATURE_CAMERA_AR);
        }
        assertFeature(hasFlash, PackageManager.FEATURE_CAMERA_FLASH);
    }

    private void checkFrontCamera() {
        CameraInfo info = new CameraInfo();
        int numCameras = Camera.getNumberOfCameras();
        int frontCameraId = -1;
        for (int i = 0; i < numCameras; i++) {
            Camera.getCameraInfo(i, info);
            if (info.facing == CameraInfo.CAMERA_FACING_FRONT) {
                frontCameraId = i;
            }
        }

        if (frontCameraId > -1) {
            assertTrue(""Device has front-facing camera but does not report either "" +
                    ""the FEATURE_CAMERA_FRONT or FEATURE_CAMERA_EXTERNAL feature"",
                    mPackageManager.hasSystemFeature(PackageManager.FEATURE_CAMERA_FRONT) ||
                    mPackageManager.hasSystemFeature(PackageManager.FEATURE_CAMERA_EXTERNAL));
        } else {
            assertFalse(""Device does not have front-facing camera but reports either "" +
                    ""the FEATURE_CAMERA_FRONT or FEATURE_CAMERA_EXTERNAL feature"",
                    mPackageManager.hasSystemFeature(PackageManager.FEATURE_CAMERA_FRONT) ||
                    mPackageManager.hasSystemFeature(PackageManager.FEATURE_CAMERA_EXTERNAL));
        }
    }

    private void checkRearCamera() {
        Camera camera = null;
        try {
            camera = Camera.open();
            if (camera != null) {
                assertAvailable(PackageManager.FEATURE_CAMERA);

                Camera.Parameters params = camera.getParameters();
                if (params.getSupportedFocusModes().contains(Parameters.FOCUS_MODE_AUTO)) {
                    assertAvailable(PackageManager.FEATURE_CAMERA_AUTOFOCUS);
                } else {
                    assertNotAvailable(PackageManager.FEATURE_CAMERA_AUTOFOCUS);
                }

                if (params.getFlashMode() != null) {
                    assertAvailable(PackageManager.FEATURE_CAMERA_FLASH);
                } else {
                    assertNotAvailable(PackageManager.FEATURE_CAMERA_FLASH);
                }
            } else {
                assertNotAvailable(PackageManager.FEATURE_CAMERA);
                assertNotAvailable(PackageManager.FEATURE_CAMERA_AUTOFOCUS);
                assertNotAvailable(PackageManager.FEATURE_CAMERA_FLASH);
            }
        } finally {
            if (camera != null) {
                camera.release();
            }
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.app.cts.SystemFeaturesTest"	"testScreenFeatures"	"CtsAppTestCases"	"/home/gpoor/cts-12-source/cts/tests/app/src/android/app/cts/SystemFeaturesTest.java"	""	"public void testScreenFeatures() {
        assertTrue(mPackageManager.hasSystemFeature(PackageManager.FEATURE_SCREEN_LANDSCAPE)
                || mPackageManager.hasSystemFeature(PackageManager.FEATURE_SCREEN_PORTRAIT));
    }

    /**
     * Check that the sensor features reported by the PackageManager correspond to the sensors
     * returned by {@link SensorManager#getSensorList(int)}.
     */
    @FlakyTest"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.app.cts.SystemFeaturesTest"	"testSipFeatures"	"CtsAppTestCases"	"/home/gpoor/cts-12-source/cts/tests/app/src/android/app/cts/SystemFeaturesTest.java"	""	"public void testSipFeatures() {
        if (SipManager.newInstance(mContext) != null) {
            assertAvailable(PackageManager.FEATURE_SIP);
        } else {
            assertNotAvailable(PackageManager.FEATURE_SIP);
            assertNotAvailable(PackageManager.FEATURE_SIP_VOIP);
        }

        if (SipManager.isApiSupported(mContext)) {
            assertAvailable(PackageManager.FEATURE_SIP);
        } else {
            assertNotAvailable(PackageManager.FEATURE_SIP);
            assertNotAvailable(PackageManager.FEATURE_SIP_VOIP);
        }

        if (SipManager.isVoipSupported(mContext)) {
            assertAvailable(PackageManager.FEATURE_SIP);
            assertAvailable(PackageManager.FEATURE_SIP_VOIP);
        } else {
            assertNotAvailable(PackageManager.FEATURE_SIP_VOIP);
        }
    }

    /**
     * Check that if the PackageManager declares a sensor feature that the device has at least
     * one sensor that matches that feature. Also check that if a PackageManager does not declare
     * a sensor that the device also does not have such a sensor.
     *
     * @param featuresLeft to check in order to make sure the test covers all sensor features
     * @param expectedFeature that the PackageManager may report
     * @param expectedSensorType that that {@link SensorManager#getSensorList(int)} may have
     */
    private void assertFeatureForSensor(Set<String> featuresLeft, String expectedFeature,
            int expectedSensorType) {
        assertTrue(""Features left "" + featuresLeft + "" to check did not include ""
                + expectedFeature, featuresLeft.remove(expectedFeature));

        boolean hasSensorFeature = mPackageManager.hasSystemFeature(expectedFeature);

        List<Sensor> sensors = mSensorManager.getSensorList(expectedSensorType);
        List<String> sensorNames = new ArrayList<String>(sensors.size());
        for (Sensor sensor : sensors) {
            sensorNames.add(sensor.getName());
        }
        boolean hasSensorType = !sensors.isEmpty();

        String message = ""PackageManager#hasSystemFeature("" + expectedFeature + "") returns ""
                + hasSensorFeature
                + "" but SensorManager#getSensorList("" + expectedSensorType + "") shows sensors ""
                + sensorNames;

        assertEquals(message, hasSensorFeature, hasSensorType);
    }

    /**
     * Check that the {@link TelephonyManager#getPhoneType()} matches the reported features.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.JitterVerificationTest"	"testVerify"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/JitterVerificationTest.java"	""	"public void testVerify() {
        final int SAMPLE_SIZE = 100;
        // for unit testing the verification, only the parameter 'sensorMightHaveMoreListeners' is
        // required
        TestSensorEnvironment environment = new TestSensorEnvironment(
                null /* context */,
                null /* sensor */,
                false /* sensorMightHaveMoreListeners */,
                0 /*samplingPeriodUs */,
                0 /* maxReportLatencyUs */);

        // 100 samples at 1000Hz
        long[] timestamps = new long[SAMPLE_SIZE];
        for (int i = 0; i < SAMPLE_SIZE; i++) {
            timestamps[i] = i * 100000;
        }
        SensorStats stats = new SensorStats();
        ISensorVerification verification = getVerification(1, timestamps);
        verification.verify(environment, stats);
        verifyStats(stats, true, 0.0);

        // 90 samples at 1000Hz, 10 samples at 2000Hz
        long timestamp = 0;
        for (int i = 0; i < SAMPLE_SIZE; i++) {
            timestamps[i] = timestamp;
            timestamp += (i % 10 == 0) ? 500000 : 1000000;
        }
        stats = new SensorStats();
        verification = getVerification(1, timestamps);
        try {
            verification.verify(environment, stats);
            throw new Error(""Expected an AssertionError"");
        } catch (AssertionError e) {
            // Expected;
        }
        verifyStats(stats, false, 25); // 500 us range (250 us in single-sided sense)
                                       // divide by 1ms requested sample time x 100%
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.JitterVerificationTest"	"testCalculateDelta"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/JitterVerificationTest.java"	""	"public void testCalculateDelta() {
        long[] timestamps = new long[]{0, 1, 2, 3, 4};
        JitterVerification verification = getVerification(1, timestamps);
        List<Long> deltaValues = verification.getDeltaValues();
        assertEquals(4, deltaValues.size());
        assertEquals(1, deltaValues.get(0).longValue());
        assertEquals(1, deltaValues.get(1).longValue());
        assertEquals(1, deltaValues.get(2).longValue());
        assertEquals(1, deltaValues.get(3).longValue());

        timestamps = new long[]{0, 0, 2, 4, 4};
        verification = getVerification(1, timestamps);
        deltaValues = verification.getDeltaValues();
        assertEquals(4, deltaValues.size());
        assertEquals(0, deltaValues.get(0).longValue());
        assertEquals(2, deltaValues.get(1).longValue());
        assertEquals(2, deltaValues.get(2).longValue());
        assertEquals(0, deltaValues.get(3).longValue());

        timestamps = new long[]{0, 1, 4, 9, 16};
        verification = getVerification(1, timestamps);
        deltaValues = verification.getDeltaValues();
        assertEquals(4, deltaValues.size());
        assertEquals(1, deltaValues.get(0).longValue());
        assertEquals(3, deltaValues.get(1).longValue());
        assertEquals(5, deltaValues.get(2).longValue());
        assertEquals(7, deltaValues.get(3).longValue());
    }

    private static JitterVerification getVerification(int marginPercent, long ... timestamps) {
        Collection<TestSensorEvent> events = new ArrayList<>(timestamps.length);
        for (long timestamp : timestamps) {
            events.add(new TestSensorEvent(null, timestamp, 0, null));
        }
        long samplePeriodNs = 1000*1000; //1000Hz
        long jitterThresholdNs = 20*1000; // 2% of that

        JitterVerification verification =
                new JitterVerification(marginPercent/100.0f, jitterThresholdNs, samplePeriodNs);
        verification.addSensorEvents(events);
        return verification;
    }

    private void verifyStats(SensorStats stats, boolean passed, double percentageJitter) {
        assertEquals(passed, stats.getValue(JitterVerification.PASSED_KEY));
        assertEquals(
                percentageJitter,
                (Double) stats.getValue(SensorStats.JITTER_95_PERCENTILE_PERCENT_KEY),
                0.01);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.CtsMediaTextureRender"	"glFinish"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/CtsMediaTextureRender.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.nio.FloatBuffer;

import android.graphics.Bitmap;
import android.graphics.SurfaceTexture;
import android.opengl.GLES11Ext;
import android.opengl.GLES20;
import android.opengl.Matrix;
import android.util.Log;


//
// This file is copied from android.hardware.cts.media
//

/**
 * Code for rendering a texture onto a surface using OpenGL ES 2.0.
 */
class CtsMediaTextureRender {
    private static final String TAG = ""TextureRender"";

    private static final int FLOAT_SIZE_BYTES = 4;
    private static final int TRIANGLE_VERTICES_DATA_STRIDE_BYTES = 5 * FLOAT_SIZE_BYTES;
    private static final int TRIANGLE_VERTICES_DATA_POS_OFFSET = 0;
    private static final int TRIANGLE_VERTICES_DATA_UV_OFFSET = 3;
    private final float[] mTriangleVerticesData = {
        // X, Y, Z, U, V
        -1.0f, -1.0f, 0, 0.f, 0.f,
         1.0f, -1.0f, 0, 1.f, 0.f,
        -1.0f,  1.0f, 0, 0.f, 1.f,
         1.0f,  1.0f, 0, 1.f, 1.f,
    };

    private FloatBuffer mTriangleVertices;

    private static final String VERTEX_SHADER =
            ""uniform mat4 uMVPMatrix;\n"" +
            ""uniform mat4 uSTMatrix;\n"" +
            ""attribute vec4 aPosition;\n"" +
            ""attribute vec4 aTextureCoord;\n"" +
            ""varying vec2 vTextureCoord;\n"" +
            ""void main() {\n"" +
            ""  gl_Position = uMVPMatrix * aPosition;\n"" +
            ""  vTextureCoord = (uSTMatrix * aTextureCoord).xy;\n"" +
            ""}\n"";

    private static final String FRAGMENT_SHADER =
            ""#extension GL_OES_EGL_image_external : require\n"" +
            ""precision mediump float;\n"" +      // highp here doesn't seem to matter
            ""varying vec2 vTextureCoord;\n"" +
            ""uniform samplerExternalOES sTexture;\n"" +
            ""void main() {\n"" +
            ""  gl_FragColor = texture2D(sTexture, vTextureCoord);\n"" +
            ""}\n"";

    private float[] mMVPMatrix = new float[16];
    private float[] mSTMatrix = new float[16];

    private int mProgram;
    private int mTextureID = -12345;
    private int muMVPMatrixHandle;
    private int muSTMatrixHandle;
    private int maPositionHandle;
    private int maTextureHandle;

    public CtsMediaTextureRender() {
        mTriangleVertices = ByteBuffer.allocateDirect(
            mTriangleVerticesData.length * FLOAT_SIZE_BYTES)
                .order(ByteOrder.nativeOrder()).asFloatBuffer();
        mTriangleVertices.put(mTriangleVerticesData).position(0);

        Matrix.setIdentityM(mSTMatrix, 0);
    }

    public int getTextureId() {
        return mTextureID;
    }

    public void drawFrame(SurfaceTexture st) {
        checkGlError(""onDrawFrame start"");
        st.getTransformMatrix(mSTMatrix);

        GLES20.glClearColor(0.0f, 1.0f, 0.0f, 1.0f);
        GLES20.glClear(GLES20.GL_DEPTH_BUFFER_BIT | GLES20.GL_COLOR_BUFFER_BIT);

        GLES20.glUseProgram(mProgram);
        checkGlError(""glUseProgram"");

        GLES20.glActiveTexture(GLES20.GL_TEXTURE0);
        GLES20.glBindTexture(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, mTextureID);

        mTriangleVertices.position(TRIANGLE_VERTICES_DATA_POS_OFFSET);
        GLES20.glVertexAttribPointer(maPositionHandle, 3, GLES20.GL_FLOAT, false,
            TRIANGLE_VERTICES_DATA_STRIDE_BYTES, mTriangleVertices);
        checkGlError(""glVertexAttribPointer maPosition"");
        GLES20.glEnableVertexAttribArray(maPositionHandle);
        checkGlError(""glEnableVertexAttribArray maPositionHandle"");

        mTriangleVertices.position(TRIANGLE_VERTICES_DATA_UV_OFFSET);
        GLES20.glVertexAttribPointer(maTextureHandle, 2, GLES20.GL_FLOAT, false,
            TRIANGLE_VERTICES_DATA_STRIDE_BYTES, mTriangleVertices);
        checkGlError(""glVertexAttribPointer maTextureHandle"");
        GLES20.glEnableVertexAttribArray(maTextureHandle);
        checkGlError(""glEnableVertexAttribArray maTextureHandle"");

        Matrix.setIdentityM(mMVPMatrix, 0);
        GLES20.glUniformMatrix4fv(muMVPMatrixHandle, 1, false, mMVPMatrix, 0);
        GLES20.glUniformMatrix4fv(muSTMatrixHandle, 1, false, mSTMatrix, 0);

        GLES20.glDrawArrays(GLES20.GL_TRIANGLE_STRIP, 0, 4);
        checkGlError(""glDrawArrays"");
        GLES20.glFinish();
    }

    /**
     * Initializes GL state.  Call this after the EGL surface has been created and made current.
     */
    public void surfaceCreated() {
        mProgram = createProgram(VERTEX_SHADER, FRAGMENT_SHADER);
        if (mProgram == 0) {
            throw new RuntimeException(""failed creating program"");
        }
        maPositionHandle = GLES20.glGetAttribLocation(mProgram, ""aPosition"");
        checkGlError(""glGetAttribLocation aPosition"");
        if (maPositionHandle == -1) {
            throw new RuntimeException(""Could not get attrib location for aPosition"");
        }
        maTextureHandle = GLES20.glGetAttribLocation(mProgram, ""aTextureCoord"");
        checkGlError(""glGetAttribLocation aTextureCoord"");
        if (maTextureHandle == -1) {
            throw new RuntimeException(""Could not get attrib location for aTextureCoord"");
        }

        muMVPMatrixHandle = GLES20.glGetUniformLocation(mProgram, ""uMVPMatrix"");
        checkGlError(""glGetUniformLocation uMVPMatrix"");
        if (muMVPMatrixHandle == -1) {
            throw new RuntimeException(""Could not get attrib location for uMVPMatrix"");
        }

        muSTMatrixHandle = GLES20.glGetUniformLocation(mProgram, ""uSTMatrix"");
        checkGlError(""glGetUniformLocation uSTMatrix"");
        if (muSTMatrixHandle == -1) {
            throw new RuntimeException(""Could not get attrib location for uSTMatrix"");
        }


        int[] textures = new int[1];
        GLES20.glGenTextures(1, textures, 0);

        mTextureID = textures[0];
        GLES20.glBindTexture(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, mTextureID);
        checkGlError(""glBindTexture mTextureID"");

        GLES20.glTexParameterf(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, GLES20.GL_TEXTURE_MIN_FILTER,
                GLES20.GL_NEAREST);
        GLES20.glTexParameterf(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, GLES20.GL_TEXTURE_MAG_FILTER,
                GLES20.GL_LINEAR);
        GLES20.glTexParameteri(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, GLES20.GL_TEXTURE_WRAP_S,
                GLES20.GL_CLAMP_TO_EDGE);
        GLES20.glTexParameteri(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, GLES20.GL_TEXTURE_WRAP_T,
                GLES20.GL_CLAMP_TO_EDGE);
        checkGlError(""glTexParameter"");
    }

    /**
     * Replaces the fragment shader.
     */
    public void changeFragmentShader(String fragmentShader) {
        GLES20.glDeleteProgram(mProgram);
        mProgram = createProgram(VERTEX_SHADER, fragmentShader);
        if (mProgram == 0) {
            throw new RuntimeException(""failed creating program"");
        }
    }

    private int loadShader(int shaderType, String source) {
        int shader = GLES20.glCreateShader(shaderType);
        checkGlError(""glCreateShader type="" + shaderType);
        GLES20.glShaderSource(shader, source);
        GLES20.glCompileShader(shader);
        int[] compiled = new int[1];
        GLES20.glGetShaderiv(shader, GLES20.GL_COMPILE_STATUS, compiled, 0);
        if (compiled[0] == 0) {
            Log.e(TAG, ""Could not compile shader "" + shaderType + "":"");
            Log.e(TAG, "" "" + GLES20.glGetShaderInfoLog(shader));
            GLES20.glDeleteShader(shader);
            shader = 0;
        }
        return shader;
    }

    private int createProgram(String vertexSource, String fragmentSource) {
        int vertexShader = loadShader(GLES20.GL_VERTEX_SHADER, vertexSource);
        if (vertexShader == 0) {
            return 0;
        }
        int pixelShader = loadShader(GLES20.GL_FRAGMENT_SHADER, fragmentSource);
        if (pixelShader == 0) {
            return 0;
        }

        int program = GLES20.glCreateProgram();
        checkGlError(""glCreateProgram"");
        if (program == 0) {
            Log.e(TAG, ""Could not create program"");
        }
        GLES20.glAttachShader(program, vertexShader);
        checkGlError(""glAttachShader"");
        GLES20.glAttachShader(program, pixelShader);
        checkGlError(""glAttachShader"");
        GLES20.glLinkProgram(program);
        int[] linkStatus = new int[1];
        GLES20.glGetProgramiv(program, GLES20.GL_LINK_STATUS, linkStatus, 0);
        if (linkStatus[0] != GLES20.GL_TRUE) {
            Log.e(TAG, ""Could not link program: "");
            Log.e(TAG, GLES20.glGetProgramInfoLog(program));
            GLES20.glDeleteProgram(program);
            program = 0;
        }
        return program;
    }

    public void checkGlError(String op) {
        int error;
        while ((error = GLES20.glGetError()) != GLES20.GL_NO_ERROR) {
            Log.e(TAG, op + "": glError "" + error);
            throw new RuntimeException(op + "": glError "" + error);
        }
    }

    /**
     * Saves the current frame to disk as a PNG image.  Frame starts from (0,0).
     * <p>
     * Useful for debugging.
     */
    public static void saveFrame(String filename, int width, int height) {
        // glReadPixels gives us a ByteBuffer filled with what is essentially big-endian RGBA
        // data (i.e. a byte of red, followed by a byte of green...).  We need an int[] filled
        // with native-order ARGB data to feed to Bitmap.
        //
        // If we implement this as a series of buf.get() calls, we can spend 2.5 seconds just
        // copying data around for a 720p frame.  It's better to do a bulk get() and then
        // rearrange the data in memory.  (For comparison, the PNG compress takes about 500ms
        // for a trivial frame.)
        //
        // So... we set the ByteBuffer to little-endian, which should turn the bulk IntBuffer
        // get() into a straight memcpy on most Android devices.  Our ints will hold ABGR data.
        // Swapping B and R gives us ARGB.  We need about 30ms for the bulk get(), and another
        // 270ms for the color swap.
        //
        // Making this even more interesting is the upside-down nature of GL, which means we
        // may want to flip the image vertically here.

        ByteBuffer buf = ByteBuffer.allocateDirect(width * height * 4);
        buf.order(ByteOrder.LITTLE_ENDIAN);
        GLES20.glReadPixels(0, 0, width, height, GLES20.GL_RGBA, GLES20.GL_UNSIGNED_BYTE, buf);
        buf.rewind();

        int pixelCount = width * height;
        int[] colors = new int[pixelCount];
        buf.asIntBuffer().get(colors);
        for (int i = 0; i < pixelCount; i++) {
            int c = colors[i];
            colors[i] = (c & 0xff00ff00) | ((c & 0x00ff0000) >> 16) | ((c & 0x000000ff) << 16);
        }

        FileOutputStream fos = null;
        try {
            fos = new FileOutputStream(filename);
            Bitmap bmp = Bitmap.createBitmap(colors, width, height, Bitmap.Config.ARGB_8888);
            bmp.compress(Bitmap.CompressFormat.PNG, 90, fos);
            bmp.recycle();
        } catch (IOException ioe) {
            throw new RuntimeException(""Failed to write file "" + filename, ioe);
        } finally {
            try {
                if (fos != null) fos.close();
            } catch (IOException ioe2) {
                throw new RuntimeException(""Failed to close file "" + filename, ioe2);
            }
        }
        Log.d(TAG, ""Saved "" + width + ""x"" + height + "" frame as '"" + filename + ""'"");
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Utils.TestReport"	"isEmpty"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Utils/TestReport.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Utils;

import android.content.Context;
import android.os.Build;
import android.util.Xml;

import org.xmlpull.v1.XmlSerializer;

import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.text.DateFormat;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Date;
import java.util.Locale;

/**
 * Handles all the XML to print to the user.
 */
public class TestReport {

    public enum TestStatus {
        NOT_EXECUTED,
        EXECUTED,
        PASS,
        FAIL,
    }

    private static final int REPORT_VERSION = 1;
    private static DateFormat DATE_FORMAT = new SimpleDateFormat(
            ""EEE MMM dd HH:mm:ss z yyyy"", Locale.ENGLISH);
    private static final String TEST_RESULTS_REPORT_TAG = ""test-results-report"";
    private static final String VERIFIER_INFO_TAG = ""verifier-info"";
    private static final String DEVICE_INFO_TAG = ""device-info"";
    private static final String BUILD_INFO_TAG = ""build-info"";
    private static final String TEST_RESULTS_TAG = ""test-results"";
    private static final String TEST_TAG = ""test"";
    private static final String TEST_DETAILS_TAG = ""details"";
    private String mTestStatus = ""not-executed"";
    private Context mContext;
    private ArrayList<String> mTestDetails = new ArrayList<>();

    /**
     * Sets the context of this test.
     *
     * @param context reference to the activity this test is in.
     */
    public TestReport(Context context) {
        mContext = context;
    }

    /**
     * Produces the XML for the test.
     *
     * @return the XML of the test to display.
     */
    public String getContents()
            throws IllegalArgumentException, IllegalStateException, IOException {

        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();

        XmlSerializer xml = Xml.newSerializer();

        xml.setOutput(outputStream, ""utf-8"");
        xml.setFeature(""http://xmlpull.org/v1/doc/features.html#indent-output"", true);
        xml.startDocument(""utf-8"", true);

        xml.startTag(null, TEST_RESULTS_REPORT_TAG);
        xml.attribute(null, ""report-version"", Integer.toString(REPORT_VERSION));
        xml.attribute(null, ""creation-time"", DATE_FORMAT.format(new Date()));

        xml.startTag(null, VERIFIER_INFO_TAG);
        xml.attribute(null, ""version-name"", Version.getVersionName(mContext));
        xml.attribute(null, ""version-code"", Integer.toString(Version.getVersionCode(mContext)));
        xml.endTag(null, VERIFIER_INFO_TAG);

        xml.startTag(null, DEVICE_INFO_TAG);
        xml.startTag(null, BUILD_INFO_TAG);
        xml.attribute(null, ""board"", Build.BOARD);
        xml.attribute(null, ""brand"", Build.BRAND);
        xml.attribute(null, ""device"", Build.DEVICE);
        xml.attribute(null, ""display"", Build.DISPLAY);
        xml.attribute(null, ""fingerprint"", Build.FINGERPRINT);
        xml.attribute(null, ""id"", Build.ID);
        xml.attribute(null, ""model"", Build.MODEL);
        xml.attribute(null, ""product"", Build.PRODUCT);
        xml.attribute(null, ""release"", Build.VERSION.RELEASE_OR_CODENAME);
        xml.attribute(null, ""sdk"", Integer.toString(Build.VERSION.SDK_INT));
        xml.endTag(null, BUILD_INFO_TAG);
        xml.endTag(null, DEVICE_INFO_TAG);

        xml.startTag(null, TEST_RESULTS_TAG);
        xml.startTag(null, TEST_TAG);
        xml.attribute(null, ""title"", ""6dof accuracy test"");
        xml.attribute(null, ""class-name"", ""com.android.cts.verifier.sixdof.Activities.TestActivity"");

        if (mTestDetails.isEmpty()) {
            xml.attribute(null, ""result"", mTestStatus);
        } else {
            setTestState(TestStatus.FAIL);
            xml.attribute(null, ""result"", mTestStatus);
            xml.startTag(null, TEST_DETAILS_TAG);

            for (int i = 0; i < mTestDetails.size(); i++) {
                xml.text(mTestDetails.get(i));
            }

            xml.endTag(null, TEST_DETAILS_TAG);
        }

        xml.endTag(null, TEST_TAG);
        xml.endTag(null, TEST_RESULTS_TAG);

        xml.endTag(null, TEST_RESULTS_REPORT_TAG);
        xml.endDocument();

        return outputStream.toString(""utf-8"");
    }

    /**
     * Adds the failed results to the details.
     *
     * @param failedPart the failed test result.
     */
    public void setFailDetails(String failedPart) {
        mTestDetails.add(failedPart);
    }

    /**
     * Sets the status the test is currently in.
     *
     * @param state the status the test is in.
     */
    public void setTestState(TestStatus state) {
        switch (state) {
            case EXECUTED:
                mTestStatus = ""executed"";
                break;
            case PASS:
                mTestStatus = ""passed"";
                break;
            case FAIL:
                mTestStatus = ""failed"";
                break;
            case NOT_EXECUTED:
                mTestStatus = ""not-executed"";
                break;
            default:
                throw new AssertionError(""TestExecuted default we should not be in"", null);
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.CaptureRequestTest"	"testBlackLevelLock"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/CaptureRequestTest.java"	""	"public void testBlackLevelLock() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                if (!mAllStaticInfo.get(mCameraIdsUnderTest[i]).isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                    continue;
                }

                openDevice(mCameraIdsUnderTest[i]);
                SimpleCaptureCallback listener = new SimpleCaptureCallback();
                CaptureRequest.Builder requestBuilder =
                        mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);

                // Start with default manual exposure time, with black level being locked.
                requestBuilder.set(CaptureRequest.BLACK_LEVEL_LOCK, true);
                changeExposure(requestBuilder, DEFAULT_EXP_TIME_NS, DEFAULT_SENSITIVITY);

                Size previewSz =
                        getMaxPreviewSize(mCamera.getId(), mCameraManager,
                        getPreviewSizeBound(mWindowManager, PREVIEW_SIZE_BOUND));

                startPreview(requestBuilder, previewSz, listener);
                waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
                // No lock OFF state is allowed as the exposure is not changed.
                verifyBlackLevelLockResults(listener, NUM_FRAMES_VERIFIED, /*maxLockOffCnt*/0);

                // Double the exposure time and gain, with black level still being locked.
                changeExposure(requestBuilder, DEFAULT_EXP_TIME_NS * 2, DEFAULT_SENSITIVITY * 2);
                listener = new SimpleCaptureCallback();
                startPreview(requestBuilder, previewSz, listener);
                waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
                // Allow at most one lock OFF state as the exposure is changed once.
                verifyBlackLevelLockResults(listener, NUM_FRAMES_VERIFIED, /*maxLockOffCnt*/1);

                stopPreview();
            } finally {
                closeDevice();
            }
        }
    }

    /**
     * Test dynamic black/white levels if they are supported.
     *
     * <p>
     * If the dynamic black and white levels are reported, test below:
     *   1. the dynamic black and white levels shouldn't deviate from the global value too much
     *   for different sensitivities.
     *   2. If the RAW_SENSOR and optical black regions are supported, capture RAW images and
     *   calculate the optical black level values. The reported dynamic black level should be
     *   close enough to the optical black level values.
     * </p>
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.CaptureRequestTest"	"testAntiBandingModes"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/CaptureRequestTest.java"	""	"public void testAntiBandingModes() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                // Without manual sensor control, exposure time cannot be verified
                if (!mAllStaticInfo.get(mCameraIdsUnderTest[i]).isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                    continue;
                }

                openDevice(mCameraIdsUnderTest[i]);
                int[] modes = mStaticInfo.getAeAvailableAntiBandingModesChecked();

                Size previewSz =
                        getMaxPreviewSize(mCamera.getId(), mCameraManager,
                        getPreviewSizeBound(mWindowManager, PREVIEW_SIZE_BOUND));

                for (int mode : modes) {
                    antiBandingTestByMode(previewSz, mode);
                }
            } finally {
                closeDevice();
            }
        }

    }

    /**
     * Test AE mode and lock.
     *
     * <p>
     * For AE lock, when it is locked, exposure parameters shouldn't be changed.
     * For AE modes, each mode should satisfy the per frame controls defined in
     * API specifications.
     * </p>
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.CaptureRequestTest"	"testFocusDistanceControl"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/CaptureRequestTest.java"	""	"public void testFocusDistanceControl() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                StaticMetadata staticInfo = mAllStaticInfo.get(id);
                if (!staticInfo.hasFocuser()) {
                    Log.i(TAG, ""Camera "" + id + "" has no focuser, skipping test"");
                    continue;
                }

                if (!staticInfo.isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                    Log.i(TAG, ""Camera "" + id +
                            "" does not support MANUAL_SENSOR, skipping test"");
                    continue;
                }

                openDevice(id);
                focusDistanceTestByCamera();
            } finally {
                closeDevice();
            }
        }
    }

    /**
     * Test noise reduction mode for fps ranges not exceeding 30
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.CaptureRequestTest"	"testExtendedSceneModes"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/CaptureRequestTest.java"	""	"public void testExtendedSceneModes() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                if (!mAllStaticInfo.get(id).isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + id + "" does not support color outputs, skipping"");
                    continue;
                }
                openDevice(id);
                List<Range<Integer>> fpsRanges = getTargetFpsRangesUpTo30(mStaticInfo);
                extendedSceneModeTestByCamera(fpsRanges);
            } finally {
                closeDevice();
            }
        }
    }

    // TODO: add 3A state machine test.

    /**
     * Per camera dynamic black and white level test.
     */
    private void dynamicBlackWhiteLevelTestByCamera() throws Exception {
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        SimpleImageReaderListener imageListener = null;
        CaptureRequest.Builder previewBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        CaptureRequest.Builder rawBuilder = null;
        Size previewSize =
                getMaxPreviewSize(mCamera.getId(), mCameraManager,
                getPreviewSizeBound(mWindowManager, PREVIEW_SIZE_BOUND));
        Size rawSize = null;
        boolean canCaptureBlackRaw =
                mStaticInfo.isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_RAW) &&
                mStaticInfo.isOpticalBlackRegionSupported();
        if (canCaptureBlackRaw) {
            // Capture Raw16, then calculate the optical black, and use it to check with the dynamic
            // black level.
            rawBuilder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
            rawSize = mStaticInfo.getRawDimensChecked();
            imageListener = new SimpleImageReaderListener();
            prepareRawCaptureAndStartPreview(previewBuilder, rawBuilder, previewSize, rawSize,
                    resultListener, imageListener);
        } else {
            startPreview(previewBuilder, previewSize, resultListener);
        }

        // Capture a sequence of frames with different sensitivities and validate the black/white
        // level values
        int[] sensitivities = getSensitivityTestValues();
        float[][] dynamicBlackLevels = new float[sensitivities.length][];
        int[] dynamicWhiteLevels = new int[sensitivities.length];
        float[][] opticalBlackLevels = new float[sensitivities.length][];
        for (int i = 0; i < sensitivities.length; i++) {
            CaptureResult result = null;
            if (canCaptureBlackRaw) {
                changeExposure(rawBuilder, DEFAULT_EXP_TIME_NS, sensitivities[i]);
                CaptureRequest rawRequest = rawBuilder.build();
                mSession.capture(rawRequest, resultListener, mHandler);
                result = resultListener.getCaptureResultForRequest(rawRequest,
                        NUM_RESULTS_WAIT_TIMEOUT);
                Image rawImage = imageListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);

                // Get max (area-wise) optical black region
                Rect[] opticalBlackRegions = mStaticInfo.getCharacteristics().get(
                        CameraCharacteristics.SENSOR_OPTICAL_BLACK_REGIONS);
                Rect maxRegion = opticalBlackRegions[0];
                for (Rect region : opticalBlackRegions) {
                    if (region.width() * region.height() > maxRegion.width() * maxRegion.height()) {
                        maxRegion = region;
                    }
                }

                // Get average black pixel values in the region (region is multiple of 2x2)
                Image.Plane rawPlane = rawImage.getPlanes()[0];
                ByteBuffer rawBuffer = rawPlane.getBuffer();
                float[] avgBlackLevels = {0, 0, 0, 0};
                final int rowSize = rawPlane.getRowStride();
                final int bytePerPixel = rawPlane.getPixelStride();
                if (VERBOSE) {
                    Log.v(TAG, ""maxRegion: "" + maxRegion + "", Row stride: "" +
                            rawPlane.getRowStride());
                }
                for (int row = maxRegion.top; row < maxRegion.bottom; row += 2) {
                    for (int col = maxRegion.left; col < maxRegion.right; col += 2) {
                        int startOffset = row * rowSize + col * bytePerPixel;
                        avgBlackLevels[0] += rawBuffer.getShort(startOffset);
                        avgBlackLevels[1] += rawBuffer.getShort(startOffset + bytePerPixel);
                        startOffset += rowSize;
                        avgBlackLevels[2] += rawBuffer.getShort(startOffset);
                        avgBlackLevels[3] += rawBuffer.getShort(startOffset + bytePerPixel);
                    }
                }
                int numBlackBlocks = maxRegion.width() * maxRegion.height() / (2 * 2);
                for (int m = 0; m < avgBlackLevels.length; m++) {
                    avgBlackLevels[m] /= numBlackBlocks;
                }
                opticalBlackLevels[i] = avgBlackLevels;

                if (VERBOSE) {
                    Log.v(TAG, String.format(""Optical black level results for sensitivity (%d): %s"",
                            sensitivities[i], Arrays.toString(avgBlackLevels)));
                }

                rawImage.close();
            } else {
                changeExposure(previewBuilder, DEFAULT_EXP_TIME_NS, sensitivities[i]);
                CaptureRequest previewRequest = previewBuilder.build();
                mSession.capture(previewRequest, resultListener, mHandler);
                result = resultListener.getCaptureResultForRequest(previewRequest,
                        NUM_RESULTS_WAIT_TIMEOUT);
            }

            dynamicBlackLevels[i] = getValueNotNull(result,
                    CaptureResult.SENSOR_DYNAMIC_BLACK_LEVEL);
            dynamicWhiteLevels[i] = getValueNotNull(result,
                    CaptureResult.SENSOR_DYNAMIC_WHITE_LEVEL);
        }

        if (VERBOSE) {
            Log.v(TAG, ""Different sensitivities tested: "" + Arrays.toString(sensitivities));
            Log.v(TAG, ""Dynamic black level results: "" + Arrays.deepToString(dynamicBlackLevels));
            Log.v(TAG, ""Dynamic white level results: "" + Arrays.toString(dynamicWhiteLevels));
            if (canCaptureBlackRaw) {
                Log.v(TAG, ""Optical black level results "" +
                        Arrays.deepToString(opticalBlackLevels));
            }
        }

        // check the dynamic black level against global black level.
        // Implicit guarantee: if the dynamic black level is supported, fixed black level must be
        // supported as well (tested in ExtendedCameraCharacteristicsTest#testOpticalBlackRegions).
        BlackLevelPattern blackPattern = mStaticInfo.getCharacteristics().get(
                CameraCharacteristics.SENSOR_BLACK_LEVEL_PATTERN);
        int[] fixedBlackLevels = new int[4];
        int fixedWhiteLevel = mStaticInfo.getCharacteristics().get(
                CameraCharacteristics.SENSOR_INFO_WHITE_LEVEL);
        blackPattern.copyTo(fixedBlackLevels, 0);
        float maxBlackDeviation = 0;
        int maxWhiteDeviation = 0;
        for (int i = 0; i < dynamicBlackLevels.length; i++) {
            for (int j = 0; j < dynamicBlackLevels[i].length; j++) {
                if (maxBlackDeviation < Math.abs(fixedBlackLevels[j] - dynamicBlackLevels[i][j])) {
                    maxBlackDeviation = Math.abs(fixedBlackLevels[j] - dynamicBlackLevels[i][j]);
                }
            }
            if (maxWhiteDeviation < Math.abs(dynamicWhiteLevels[i] - fixedWhiteLevel)) {
                maxWhiteDeviation = Math.abs(dynamicWhiteLevels[i] - fixedWhiteLevel);
            }
        }
        mCollector.expectLessOrEqual(""Max deviation of the dynamic black level vs fixed black level""
                + "" exceed threshold.""
                + "" Dynamic black level results: "" + Arrays.deepToString(dynamicBlackLevels),
                fixedBlackLevels[0] * DYNAMIC_VS_FIXED_BLK_WH_LVL_ERROR_MARGIN, maxBlackDeviation);
        mCollector.expectLessOrEqual(""Max deviation of the dynamic white level exceed threshold.""
                + "" Dynamic white level results: "" + Arrays.toString(dynamicWhiteLevels),
                fixedWhiteLevel * DYNAMIC_VS_FIXED_BLK_WH_LVL_ERROR_MARGIN,
                (float)maxWhiteDeviation);

        // Validate against optical black levels if it is available
        if (canCaptureBlackRaw) {
            maxBlackDeviation = 0;
            for (int i = 0; i < dynamicBlackLevels.length; i++) {
                for (int j = 0; j < dynamicBlackLevels[i].length; j++) {
                    if (maxBlackDeviation <
                            Math.abs(opticalBlackLevels[i][j] - dynamicBlackLevels[i][j])) {
                        maxBlackDeviation =
                                Math.abs(opticalBlackLevels[i][j] - dynamicBlackLevels[i][j]);
                    }
                }
            }

            mCollector.expectLessOrEqual(""Max deviation of the dynamic black level vs optical black""
                    + "" exceed threshold.""
                    + "" Dynamic black level results: "" + Arrays.deepToString(dynamicBlackLevels)
                    + "" Optical black level results: "" + Arrays.deepToString(opticalBlackLevels),
                    fixedBlackLevels[0] * DYNAMIC_VS_OPTICAL_BLK_LVL_ERROR_MARGIN,
                    maxBlackDeviation);
        }
    }

    private void noiseReductionModeTestByCamera(List<Range<Integer>> fpsRanges) throws Exception {
        Size maxPrevSize = mOrderedPreviewSizes.get(0);
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        int[] availableModes = mStaticInfo.getAvailableNoiseReductionModesChecked();

        for (int mode : availableModes) {
            requestBuilder.set(CaptureRequest.NOISE_REDUCTION_MODE, mode);

            // Test that OFF and FAST mode should not slow down the frame rate.
            if (mode == CaptureRequest.NOISE_REDUCTION_MODE_OFF ||
                    mode == CaptureRequest.NOISE_REDUCTION_MODE_FAST) {
                verifyFpsNotSlowDown(requestBuilder, NUM_FRAMES_VERIFIED, fpsRanges);
            }

            SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
            startPreview(requestBuilder, maxPrevSize, resultListener);
            mSession.setRepeatingRequest(requestBuilder.build(), resultListener, mHandler);
            waitForSettingsApplied(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

            verifyCaptureResultForKey(CaptureResult.NOISE_REDUCTION_MODE, mode,
                    resultListener, NUM_FRAMES_VERIFIED);
        }

        stopPreview();
    }

    private void focusDistanceTestByCamera() throws Exception {
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        requestBuilder.set(CaptureRequest.CONTROL_AF_MODE, CaptureRequest.CONTROL_AF_MODE_OFF);
        int calibrationStatus = mStaticInfo.getFocusDistanceCalibrationChecked();
        float errorMargin = FOCUS_DISTANCE_ERROR_PERCENT_UNCALIBRATED;
        if (calibrationStatus ==
                CameraMetadata.LENS_INFO_FOCUS_DISTANCE_CALIBRATION_CALIBRATED) {
            errorMargin = FOCUS_DISTANCE_ERROR_PERCENT_CALIBRATED;
        } else if (calibrationStatus ==
                CameraMetadata.LENS_INFO_FOCUS_DISTANCE_CALIBRATION_APPROXIMATE) {
            errorMargin = FOCUS_DISTANCE_ERROR_PERCENT_APPROXIMATE;
        }

        // Test changing focus distance with repeating request
        focusDistanceTestRepeating(requestBuilder, errorMargin);

        if (calibrationStatus ==
                CameraMetadata.LENS_INFO_FOCUS_DISTANCE_CALIBRATION_CALIBRATED)  {
            // Test changing focus distance with burst request
            focusDistanceTestBurst(requestBuilder, errorMargin);
        }
    }

    private void focusDistanceTestRepeating(CaptureRequest.Builder requestBuilder,
            float errorMargin) throws Exception {
        CaptureRequest request;
        float[] testDistances = getFocusDistanceTestValuesInOrder(0, 0);
        Size maxPrevSize = mOrderedPreviewSizes.get(0);
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        startPreview(requestBuilder, maxPrevSize, resultListener);

        float[] resultDistances = new float[testDistances.length];
        int[] resultLensStates = new int[testDistances.length];

        // Collect results
        for (int i = 0; i < testDistances.length; i++) {
            requestBuilder.set(CaptureRequest.LENS_FOCUS_DISTANCE, testDistances[i]);
            request = requestBuilder.build();
            resultListener = new SimpleCaptureCallback();
            mSession.setRepeatingRequest(request, resultListener, mHandler);
            waitForSettingsApplied(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
            waitForResultValue(resultListener, CaptureResult.LENS_STATE,
                    CaptureResult.LENS_STATE_STATIONARY, NUM_RESULTS_WAIT_TIMEOUT);
            CaptureResult result = resultListener.getCaptureResultForRequest(request,
                    NUM_RESULTS_WAIT_TIMEOUT);

            resultDistances[i] = getValueNotNull(result, CaptureResult.LENS_FOCUS_DISTANCE);
            resultLensStates[i] = getValueNotNull(result, CaptureResult.LENS_STATE);

            if (VERBOSE) {
                Log.v(TAG, ""Capture repeating request focus distance: "" + testDistances[i]
                        + "" result: "" + resultDistances[i] + "" lens state "" + resultLensStates[i]);
            }
        }

        verifyFocusDistance(testDistances, resultDistances, resultLensStates,
                /*ascendingOrder*/true, /*noOvershoot*/false, /*repeatStart*/0, /*repeatEnd*/0,
                errorMargin);

        if (mStaticInfo.areKeysAvailable(CameraCharacteristics.LENS_INFO_HYPERFOCAL_DISTANCE)) {

            // Test hyperfocal distance optionally
            float hyperFocalDistance = mStaticInfo.getHyperfocalDistanceChecked();
            if (hyperFocalDistance > 0) {
                requestBuilder.set(CaptureRequest.LENS_FOCUS_DISTANCE, hyperFocalDistance);
                request = requestBuilder.build();
                resultListener = new SimpleCaptureCallback();
                mSession.setRepeatingRequest(request, resultListener, mHandler);
                waitForSettingsApplied(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

                // Then wait for the lens.state to be stationary.
                waitForResultValue(resultListener, CaptureResult.LENS_STATE,
                        CaptureResult.LENS_STATE_STATIONARY, NUM_RESULTS_WAIT_TIMEOUT);
                CaptureResult result = resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
                Float focusDistance = getValueNotNull(result, CaptureResult.LENS_FOCUS_DISTANCE);
                mCollector.expectInRange(""Focus distance for hyper focal should be close enough to"" +
                        "" requested value"", focusDistance,
                        hyperFocalDistance * (1.0f - errorMargin),
                        hyperFocalDistance * (1.0f + errorMargin));
            }
        }
    }

    private void focusDistanceTestBurst(CaptureRequest.Builder requestBuilder,
            float errorMargin) throws Exception {

        Size maxPrevSize = mOrderedPreviewSizes.get(0);
        float[] testDistances = getFocusDistanceTestValuesInOrder(NUM_FOCUS_DISTANCES_REPEAT,
                NUM_FOCUS_DISTANCES_REPEAT);
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        startPreview(requestBuilder, maxPrevSize, resultListener);

        float[] resultDistances = new float[testDistances.length];
        int[] resultLensStates = new int[testDistances.length];

        final int maxPipelineDepth = mStaticInfo.getCharacteristics().get(
            CameraCharacteristics.REQUEST_PIPELINE_MAX_DEPTH);

        // Move lens to starting position, and wait for the lens.state to be stationary.
        CaptureRequest request;
        requestBuilder.set(CaptureRequest.LENS_FOCUS_DISTANCE, testDistances[0]);
        request = requestBuilder.build();
        mSession.setRepeatingRequest(request, resultListener, mHandler);
        waitForResultValue(resultListener, CaptureResult.LENS_STATE,
                CaptureResult.LENS_STATE_STATIONARY, NUM_RESULTS_WAIT_TIMEOUT);

        // Submit burst of requests with different focus distances
        List<CaptureRequest> burst = new ArrayList<>();
        for (int i = 0; i < testDistances.length; i ++) {
            requestBuilder.set(CaptureRequest.LENS_FOCUS_DISTANCE, testDistances[i]);
            burst.add(requestBuilder.build());
        }
        mSession.captureBurst(burst, resultListener, mHandler);

        for (int i = 0; i < testDistances.length; i++) {
            CaptureResult result = resultListener.getCaptureResultForRequest(
                    burst.get(i), maxPipelineDepth+1);

            resultDistances[i] = getValueNotNull(result, CaptureResult.LENS_FOCUS_DISTANCE);
            resultLensStates[i] = getValueNotNull(result, CaptureResult.LENS_STATE);

            if (VERBOSE) {
                Log.v(TAG, ""Capture burst request focus distance: "" + testDistances[i]
                        + "" result: "" + resultDistances[i] + "" lens state "" + resultLensStates[i]);
            }
        }

        verifyFocusDistance(testDistances, resultDistances, resultLensStates,
                /*ascendingOrder*/true, /*noOvershoot*/true,
                /*repeatStart*/NUM_FOCUS_DISTANCES_REPEAT, /*repeatEnd*/NUM_FOCUS_DISTANCES_REPEAT,
                errorMargin);

    }

    /**
     * Verify focus distance control.
     *
     * Assumption:
     * - First repeatStart+1 elements of requestedDistances share the same value
     * - Last repeatEnd+1 elements of requestedDistances share the same value
     * - All elements in between are monotonically increasing/decreasing depending on ascendingOrder.
     * - Focuser is at requestedDistances[0] at the beginning of the test.
     *
     * @param requestedDistances The requested focus distances
     * @param resultDistances The result focus distances
     * @param lensStates The result lens states
     * @param ascendingOrder The order of the expected focus distance request/output
     * @param noOvershoot Assert that focus control doesn't overshoot the requested value
     * @param repeatStart The number of times the starting focus distance is repeated
     * @param repeatEnd The number of times the ending focus distance is repeated
     * @param errorMargin The error margin between request and result
     */
    private void verifyFocusDistance(float[] requestedDistances, float[] resultDistances,
            int[] lensStates, boolean ascendingOrder, boolean noOvershoot, int repeatStart,
            int repeatEnd, float errorMargin) {

        float minValue = 0;
        float maxValue = mStaticInfo.getMinimumFocusDistanceChecked();
        float hyperfocalDistance = 0;
        if (mStaticInfo.areKeysAvailable(CameraCharacteristics.LENS_INFO_HYPERFOCAL_DISTANCE)) {
            hyperfocalDistance = mStaticInfo.getHyperfocalDistanceChecked();
        }

        // Verify lens and focus distance do not change for first repeatStart
        // results.
        for (int i = 0; i < repeatStart; i ++) {
            float marginMin = requestedDistances[i] * (1.0f - errorMargin);
            // HAL may choose to use hyperfocal distance for all distances between [0, hyperfocal].
            float marginMax =
                    Math.max(requestedDistances[i], hyperfocalDistance) * (1.0f + errorMargin);

            mCollector.expectEquals(""Lens moves even though focus_distance didn't change"",
                    lensStates[i], CaptureResult.LENS_STATE_STATIONARY);
            if (noOvershoot) {
                mCollector.expectInRange(""Focus distance in result should be close enough to "" +
                        ""requested value"", resultDistances[i], marginMin, marginMax);
            }
            mCollector.expectInRange(""Result focus distance is out of range"",
                    resultDistances[i], minValue, maxValue);
        }

        for (int i = repeatStart; i < resultDistances.length-1; i ++) {
            float marginMin = requestedDistances[i] * (1.0f - errorMargin);
            // HAL may choose to use hyperfocal distance for all distances between [0, hyperfocal].
            float marginMax =
                    Math.max(requestedDistances[i], hyperfocalDistance) * (1.0f + errorMargin);
            if (noOvershoot) {
                // Result focus distance shouldn't overshoot the request
                boolean condition;
                if (ascendingOrder) {
                    condition = resultDistances[i] <= marginMax;
               } else {
                    condition = resultDistances[i] >= marginMin;
                }
                mCollector.expectTrue(String.format(
                      ""Lens shouldn't move past request focus distance. result "" +
                      resultDistances[i] + "" vs target of "" +
                      (ascendingOrder ? marginMax : marginMin)), condition);
            }

            // Verify monotonically increased focus distance setting
            boolean condition;
            float compareDistance = resultDistances[i+1] - resultDistances[i];
            if (i < resultDistances.length-1-repeatEnd) {
                condition = (ascendingOrder ? compareDistance > 0 : compareDistance < 0);
            } else {
                condition = (ascendingOrder ? compareDistance >= 0 : compareDistance <= 0);
            }
            mCollector.expectTrue(String.format(""Adjacent [resultDistances, lens_state] results [""
                  + resultDistances[i] + "","" + lensStates[i] + ""], ["" + resultDistances[i+1] + "",""
                  + lensStates[i+1] + ""] monotonicity is broken""), condition);
        }

        mCollector.expectTrue(String.format(""All values of this array are equal: "" +
                resultDistances[0] + "" "" + resultDistances[resultDistances.length-1]),
                resultDistances[0] != resultDistances[resultDistances.length-1]);

        // Verify lens moved to destination location.
        mCollector.expectInRange(""Focus distance "" + resultDistances[resultDistances.length-1] +
                "" for minFocusDistance should be closed enough to requested value "" +
                requestedDistances[requestedDistances.length-1],
                resultDistances[resultDistances.length-1],
                requestedDistances[requestedDistances.length-1] * (1.0f - errorMargin),
                requestedDistances[requestedDistances.length-1] * (1.0f + errorMargin));
    }

    /**
     * Verify edge mode control results for fpsRanges
     */
    private void edgeModesTestByCamera(List<Range<Integer>> fpsRanges) throws Exception {
        Size maxPrevSize = mOrderedPreviewSizes.get(0);
        int[] edgeModes = mStaticInfo.getAvailableEdgeModesChecked();
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);

        for (int mode : edgeModes) {
            requestBuilder.set(CaptureRequest.EDGE_MODE, mode);

            // Test that OFF and FAST mode should not slow down the frame rate.
            if (mode == CaptureRequest.EDGE_MODE_OFF ||
                    mode == CaptureRequest.EDGE_MODE_FAST) {
                verifyFpsNotSlowDown(requestBuilder, NUM_FRAMES_VERIFIED, fpsRanges);
            }

            SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
            startPreview(requestBuilder, maxPrevSize, resultListener);
            mSession.setRepeatingRequest(requestBuilder.build(), resultListener, mHandler);
            waitForSettingsApplied(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

            verifyCaptureResultForKey(CaptureResult.EDGE_MODE, mode, resultListener,
                    NUM_FRAMES_VERIFIED);
       }

        stopPreview();
    }

    /**
     * Test color correction controls.
     *
     * <p>Test different color correction modes. For TRANSFORM_MATRIX, only test
     * the unit gain and identity transform.</p>
     */
    private void colorCorrectionTestByCamera() throws Exception {
        CaptureRequest request;
        CaptureResult result;
        Size maxPreviewSz = mOrderedPreviewSizes.get(0); // Max preview size.
        updatePreviewSurface(maxPreviewSz);
        CaptureRequest.Builder manualRequestBuilder = createRequestForPreview();
        CaptureRequest.Builder previewRequestBuilder = createRequestForPreview();
        SimpleCaptureCallback listener = new SimpleCaptureCallback();

        startPreview(previewRequestBuilder, maxPreviewSz, listener);

        // Default preview result should give valid color correction metadata.
        result = listener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
        validateColorCorrectionResult(result,
                previewRequestBuilder.get(CaptureRequest.COLOR_CORRECTION_MODE));
        int colorCorrectionMode = CaptureRequest.COLOR_CORRECTION_MODE_TRANSFORM_MATRIX;
        // TRANSFORM_MATRIX mode
        // Only test unit gain and identity transform
        List<Integer> availableControlModes = Arrays.asList(
                CameraTestUtils.toObject(mStaticInfo.getAvailableControlModesChecked()));
        List<Integer> availableAwbModes = Arrays.asList(
                CameraTestUtils.toObject(mStaticInfo.getAwbAvailableModesChecked()));
        boolean isManualCCSupported =
                availableControlModes.contains(CaptureRequest.CONTROL_MODE_OFF) ||
                availableAwbModes.contains(CaptureRequest.CONTROL_AWB_MODE_OFF);
        if (isManualCCSupported) {
            if (!availableControlModes.contains(CaptureRequest.CONTROL_MODE_OFF)) {
                // Only manual AWB mode is supported
                manualRequestBuilder.set(CaptureRequest.CONTROL_MODE,
                        CaptureRequest.CONTROL_MODE_AUTO);
                manualRequestBuilder.set(CaptureRequest.CONTROL_AWB_MODE,
                        CaptureRequest.CONTROL_AWB_MODE_OFF);
            } else {
                // All 3A manual controls are supported, it doesn't matter what we set for AWB mode.
                manualRequestBuilder.set(CaptureRequest.CONTROL_MODE,
                        CaptureRequest.CONTROL_MODE_OFF);
            }

            RggbChannelVector UNIT_GAIN = new RggbChannelVector(1.0f, 1.0f, 1.0f, 1.0f);

            ColorSpaceTransform IDENTITY_TRANSFORM = new ColorSpaceTransform(
                new Rational[] {
                    ONE_R, ZERO_R, ZERO_R,
                    ZERO_R, ONE_R, ZERO_R,
                    ZERO_R, ZERO_R, ONE_R
                });

            manualRequestBuilder.set(CaptureRequest.COLOR_CORRECTION_MODE, colorCorrectionMode);
            manualRequestBuilder.set(CaptureRequest.COLOR_CORRECTION_GAINS, UNIT_GAIN);
            manualRequestBuilder.set(CaptureRequest.COLOR_CORRECTION_TRANSFORM, IDENTITY_TRANSFORM);
            request = manualRequestBuilder.build();
            mSession.capture(request, listener, mHandler);
            result = listener.getCaptureResultForRequest(request, NUM_RESULTS_WAIT_TIMEOUT);
            RggbChannelVector gains = result.get(CaptureResult.COLOR_CORRECTION_GAINS);
            ColorSpaceTransform transform = result.get(CaptureResult.COLOR_CORRECTION_TRANSFORM);
            validateColorCorrectionResult(result, colorCorrectionMode);
            mCollector.expectEquals(""control mode result/request mismatch"",
                    CaptureResult.CONTROL_MODE_OFF, result.get(CaptureResult.CONTROL_MODE));
            mCollector.expectEquals(""Color correction gain result/request mismatch"",
                    UNIT_GAIN, gains);
            mCollector.expectEquals(""Color correction gain result/request mismatch"",
                    IDENTITY_TRANSFORM, transform);

        }

        // FAST mode
        colorCorrectionMode = CaptureRequest.COLOR_CORRECTION_MODE_FAST;
        manualRequestBuilder.set(CaptureRequest.CONTROL_MODE, CaptureRequest.CONTROL_MODE_AUTO);
        manualRequestBuilder.set(CaptureRequest.COLOR_CORRECTION_MODE, colorCorrectionMode);
        request = manualRequestBuilder.build();
        mSession.capture(request, listener, mHandler);
        result = listener.getCaptureResultForRequest(request, NUM_RESULTS_WAIT_TIMEOUT);
        validateColorCorrectionResult(result, colorCorrectionMode);
        mCollector.expectEquals(""control mode result/request mismatch"",
                CaptureResult.CONTROL_MODE_AUTO, result.get(CaptureResult.CONTROL_MODE));

        // HIGH_QUALITY mode
        colorCorrectionMode = CaptureRequest.COLOR_CORRECTION_MODE_HIGH_QUALITY;
        manualRequestBuilder.set(CaptureRequest.CONTROL_MODE, CaptureRequest.CONTROL_MODE_AUTO);
        manualRequestBuilder.set(CaptureRequest.COLOR_CORRECTION_MODE, colorCorrectionMode);
        request = manualRequestBuilder.build();
        mSession.capture(request, listener, mHandler);
        result = listener.getCaptureResultForRequest(request, NUM_RESULTS_WAIT_TIMEOUT);
        validateColorCorrectionResult(result, colorCorrectionMode);
        mCollector.expectEquals(""control mode result/request mismatch"",
                CaptureResult.CONTROL_MODE_AUTO, result.get(CaptureResult.CONTROL_MODE));
    }

    private void validateColorCorrectionResult(CaptureResult result, int colorCorrectionMode) {
        final RggbChannelVector ZERO_GAINS = new RggbChannelVector(0, 0, 0, 0);
        final int TRANSFORM_SIZE = 9;
        Rational[] zeroTransform = new Rational[TRANSFORM_SIZE];
        Arrays.fill(zeroTransform, ZERO_R);
        final ColorSpaceTransform ZERO_TRANSFORM = new ColorSpaceTransform(zeroTransform);

        RggbChannelVector resultGain;
        if ((resultGain = mCollector.expectKeyValueNotNull(result,
                CaptureResult.COLOR_CORRECTION_GAINS)) != null) {
            mCollector.expectKeyValueNotEquals(result,
                    CaptureResult.COLOR_CORRECTION_GAINS, ZERO_GAINS);
        }

        ColorSpaceTransform resultTransform;
        if ((resultTransform = mCollector.expectKeyValueNotNull(result,
                CaptureResult.COLOR_CORRECTION_TRANSFORM)) != null) {
            mCollector.expectKeyValueNotEquals(result,
                    CaptureResult.COLOR_CORRECTION_TRANSFORM, ZERO_TRANSFORM);
        }

        mCollector.expectEquals(""color correction mode result/request mismatch"",
                colorCorrectionMode, result.get(CaptureResult.COLOR_CORRECTION_MODE));
    }

    /**
     * Test that flash can be turned off successfully with a given initial and final AE_CONTROL
     * states.
     *
     * This function expects that initialAeControl and flashOffAeControl will not be either
     * CaptureRequest.CONTROL_AE_MODE_ON or CaptureRequest.CONTROL_AE_MODE_OFF
     *
     * @param listener The Capture listener that is used to wait for capture result
     * @param initialAeControl The initial AE_CONTROL mode to start repeating requests with.
     * @param flashOffAeControl The final AE_CONTROL mode which is expected to turn flash off for
     *        TEMPLATE_PREVIEW repeating requests.
     */
    private void flashTurnOffTest(SimpleCaptureCallback listener, boolean isLegacy,
            int initialAeControl, int flashOffAeControl) throws Exception {
        CaptureResult result;
        final int NUM_FLASH_REQUESTS_TESTED = 10;
        CaptureRequest.Builder requestBuilder = createRequestForPreview();
        requestBuilder.set(CaptureRequest.CONTROL_MODE, CaptureRequest.CONTROL_MODE_AUTO);
        requestBuilder.set(CaptureRequest.CONTROL_AE_MODE, initialAeControl);

        mSession.setRepeatingRequest(requestBuilder.build(), listener, mHandler);
        waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

        // Turn on torch using FLASH_MODE_TORCH
        requestBuilder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON);
        requestBuilder.set(CaptureRequest.FLASH_MODE, CaptureRequest.FLASH_MODE_TORCH);
        CaptureRequest torchOnRequest = requestBuilder.build();
        mSession.setRepeatingRequest(torchOnRequest, listener, mHandler);
        waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_TORCH);
        result = listener.getCaptureResultForRequest(torchOnRequest, NUM_RESULTS_WAIT_TIMEOUT);
        // Test that the flash actually turned on continuously.
        mCollector.expectEquals(""Flash state result must be FIRED"", CaptureResult.FLASH_STATE_FIRED,
                result.get(CaptureResult.FLASH_STATE));
        mSession.stopRepeating();
        // Turn off the torch
        requestBuilder.set(CaptureRequest.CONTROL_AE_MODE, flashOffAeControl);
        // TODO: jchowdhary@, b/130323585, this line can be removed.
        requestBuilder.set(CaptureRequest.FLASH_MODE, CaptureRequest.FLASH_MODE_OFF);
        int numAllowedTransitionStates = NUM_PARTIAL_FRAMES_NPFC;
        if (mStaticInfo.isPerFrameControlSupported()) {
           numAllowedTransitionStates = NUM_PARTIAL_FRAMES_PFC;

        }
        // We submit 2 * numAllowedTransitionStates + 1 requests since we have two torch mode
        // transitions. The additional request is to check for at least 1 expected (FIRED / READY)
        // state.
        int numTorchTestSamples =  2 * numAllowedTransitionStates  + 1;
        CaptureRequest flashOffRequest = requestBuilder.build();
        int flashModeOffRequests = captureRequestsSynchronizedBurst(flashOffRequest,
                numTorchTestSamples, listener, mHandler);
        // Turn it on again.
        requestBuilder.set(CaptureRequest.FLASH_MODE, CaptureRequest.FLASH_MODE_TORCH);
        // We need to have CONTROL_AE_MODE be either CONTROL_AE_MODE_ON or CONTROL_AE_MODE_OFF to
        // turn the torch on again.
        requestBuilder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON);
        CaptureRequest flashModeTorchRequest = requestBuilder.build();
        int flashModeTorchRequests = captureRequestsSynchronizedBurst(flashModeTorchRequest,
                numTorchTestSamples, listener, mHandler);

        CaptureResult[] torchStateResults =
                new CaptureResult[flashModeTorchRequests + flashModeOffRequests];
        Arrays.fill(torchStateResults, null);
        int i = 0;
        for (; i < flashModeOffRequests; i++) {
            torchStateResults[i] =
                    listener.getCaptureResultForRequest(flashOffRequest, NUM_RESULTS_WAIT_TIMEOUT);
            mCollector.expectNotEquals(""Result for flashModeOff request null"",
                    torchStateResults[i], null);
        }
        for (int j = i; j < torchStateResults.length; j++) {
            torchStateResults[j] =
                    listener.getCaptureResultForRequest(flashModeTorchRequest,
                            NUM_RESULTS_WAIT_TIMEOUT);
            mCollector.expectNotEquals(""Result for flashModeTorch request null"",
                    torchStateResults[j], null);
        }
        if (isLegacy) {
            // For LEGACY devices, flash state is null for all situations except:
            // android.control.aeMode == ON_ALWAYS_FLASH, where flash.state will be FIRED
            // android.flash.mode == TORCH, where flash.state will be FIRED
            testLegacyTorchStates(torchStateResults, 0, flashModeOffRequests - 1, flashOffRequest);
            testLegacyTorchStates(torchStateResults, flashModeOffRequests,
                    torchStateResults.length -1,
                    flashModeTorchRequest);
        } else {
            checkTorchStates(torchStateResults, numAllowedTransitionStates, flashModeOffRequests,
                    flashModeTorchRequests);
        }
    }

    private void testLegacyTorchStates(CaptureResult []torchStateResults, int beg, int end,
            CaptureRequest request) {
        for (int i = beg; i <= end; i++) {
            Integer requestControlAeMode = request.get(CaptureRequest.CONTROL_AE_MODE);
            Integer requestFlashMode = request.get(CaptureRequest.FLASH_MODE);
            Integer resultFlashState = torchStateResults[i].get(CaptureResult.FLASH_STATE);
            if (requestControlAeMode == CaptureRequest.CONTROL_AE_MODE_ON_ALWAYS_FLASH ||
                    requestFlashMode == CaptureRequest.FLASH_MODE_TORCH) {
                mCollector.expectEquals(""For LEGACY devices, flash state must be FIRED when"" +
                        ""CONTROL_AE_MODE == CONTROL_AE_MODE_ON_ALWAYS_FLASH or FLASH_MODE == "" +
                        ""TORCH, CONTROL_AE_MODE = "" + requestControlAeMode + "" FLASH_MODE = "" +
                        requestFlashMode, CaptureResult.FLASH_STATE_FIRED, resultFlashState);
                continue;
            }
            mCollector.expectTrue(""For LEGACY devices, flash state must be null when"" +
                        ""CONTROL_AE_MODE != CONTROL_AE_MODE_ON_ALWAYS_FLASH or FLASH_MODE != "" +
                        ""TORCH, CONTROL_AE_MODE = "" + requestControlAeMode + "" FLASH_MODE = "" +
                        requestFlashMode,  resultFlashState == null);
        }
    }
    // We check that torch states appear in the order expected. We don't necessarily know how many
    // times each state might appear, however we make sure that the states do not appear out of
    // order.
    private void checkTorchTransitionStates(CaptureResult []torchStateResults, int beg, int end,
            List<Integer> stateOrder, boolean isTurningOff) {
        Integer flashState;
        Integer curIndex = 0;
        for (int i = beg; i <= end; i++) {
            flashState = torchStateResults[i].get(CaptureResult.FLASH_STATE);
            int index = stateOrder.indexOf(flashState);
            mCollector.expectNotEquals(""Invalid state "" + flashState + "" not in expected list"" +
                    stateOrder, index, -1);
            mCollector.expectGreaterOrEqual(""state "" + flashState  + "" index "" + index +
                    "" is expected to be >= "" + curIndex,
                    curIndex, index);
            curIndex = index;
        }
    }

    private void checkTorchStates(CaptureResult []torchResults, int numAllowedTransitionStates,
            int numTorchOffSamples, int numTorchOnSamples) {
        // We test for flash states from request:
        // Request:       O(0) O(1) O(2) O(n)....O(nOFF) T(0) T(1) T(2) ....T(n) .... T(nON)
        // Valid Result : P/R  P/R  P/R  R R R...P/R P/R   P/F  P/F  P/F      F         F
        // For the FLASH_STATE_OFF requests, once FLASH_STATE READY has been seen, for the
        // transition states while switching the torch off, it must not transition to
        // FLASH_STATE_PARTIAL again till the next transition period which turns the torch on.
        // P - FLASH_STATE_PARTIAL
        // R - FLASH_STATE_READY
        // F - FLASH_STATE_FIRED
        // O(k) - kth FLASH_MODE_OFF request
        // T(k) - kth FLASH_MODE_TORCH request
        // nOFF - number of torch off samples
        // nON - number of torch on samples
        Integer flashState;
        // Check on -> off transition states
        List<Integer> onToOffStateOrderList = new ArrayList<Integer>();
        onToOffStateOrderList.add(CaptureRequest.FLASH_STATE_PARTIAL);
        onToOffStateOrderList.add(CaptureRequest.FLASH_STATE_READY);
        checkTorchTransitionStates(torchResults, 0, numAllowedTransitionStates,
                onToOffStateOrderList, true);
        // The next frames (before transition) must have its flash state as FLASH_STATE_READY
        for (int i = numAllowedTransitionStates + 1;
                i < numTorchOffSamples - numAllowedTransitionStates; i++) {
            flashState = torchResults[numAllowedTransitionStates].get(CaptureResult.FLASH_STATE);
            mCollector.expectEquals(""flash state result must be READY"",
                    CaptureResult.FLASH_STATE_READY, flashState);
        }
        // check off -> on transition states, before the FLASH_MODE_TORCH request was sent
        List<Integer> offToOnPreStateOrderList = new ArrayList<Integer>();
        offToOnPreStateOrderList.add(CaptureRequest.FLASH_STATE_READY);
        offToOnPreStateOrderList.add(CaptureRequest.FLASH_STATE_PARTIAL);
        checkTorchTransitionStates(torchResults,
                numTorchOffSamples - numAllowedTransitionStates, numTorchOffSamples - 1,
                offToOnPreStateOrderList, false);
        // check off -> on transition states
        List<Integer> offToOnPostStateOrderList = new ArrayList<Integer>();
        offToOnPostStateOrderList.add(CaptureRequest.FLASH_STATE_PARTIAL);
        offToOnPostStateOrderList.add(CaptureRequest.FLASH_STATE_FIRED);
        checkTorchTransitionStates(torchResults,
                numTorchOffSamples, numTorchOffSamples + numAllowedTransitionStates,
                offToOnPostStateOrderList, false);
        // check on states after off -> on transition
        // The next frames must have its flash state as FLASH_STATE_FIRED
        for (int i = numTorchOffSamples + numAllowedTransitionStates + 1;
                i < torchResults.length - 1; i++) {
            flashState = torchResults[i].get(CaptureResult.FLASH_STATE);
            mCollector.expectEquals(""flash state result must be FIRED for frame "" + i,
                    CaptureRequest.FLASH_STATE_FIRED, flashState);
        }
    }

    /**
     * Test flash mode control by AE mode.
     * <p>
     * Only allow AE mode ON or OFF, because other AE mode could run into conflict with
     * flash manual control. This function expects the camera to already have an active
     * repeating request and be sending results to the listener.
     * </p>
     *
     * @param listener The Capture listener that is used to wait for capture result
     * @param aeMode The AE mode for flash to test with
     */
    private void flashTestByAeMode(SimpleCaptureCallback listener, int aeMode) throws Exception {
        CaptureResult result;
        final int NUM_FLASH_REQUESTS_TESTED = 10;
        CaptureRequest.Builder requestBuilder = createRequestForPreview();

        if (aeMode == CaptureRequest.CONTROL_AE_MODE_ON) {
            requestBuilder.set(CaptureRequest.CONTROL_AE_MODE, aeMode);
        } else if (aeMode == CaptureRequest.CONTROL_AE_MODE_OFF) {
            changeExposure(requestBuilder, DEFAULT_EXP_TIME_NS, DEFAULT_SENSITIVITY);
        } else {
            throw new IllegalArgumentException(""This test only works when AE mode is ON or OFF"");
        }

        mSession.setRepeatingRequest(requestBuilder.build(), listener, mHandler);
        waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

        // For camera that doesn't have flash unit, flash state should always be UNAVAILABLE.
        if (mStaticInfo.getFlashInfoChecked() == false) {
            for (int i = 0; i < NUM_FLASH_REQUESTS_TESTED; i++) {
                result = listener.getCaptureResult(CAPTURE_RESULT_TIMEOUT_MS);
                mCollector.expectEquals(""No flash unit available, flash state must be UNAVAILABLE""
                        + ""for AE mode "" + aeMode, CaptureResult.FLASH_STATE_UNAVAILABLE,
                        result.get(CaptureResult.FLASH_STATE));
            }

            return;
        }

        // Test flash SINGLE mode control. Wait for flash state to be READY first.
        if (mStaticInfo.isHardwareLevelAtLeastLimited()) {
            waitForResultValue(listener, CaptureResult.FLASH_STATE, CaptureResult.FLASH_STATE_READY,
                    NUM_RESULTS_WAIT_TIMEOUT);
        } // else the settings were already waited on earlier

        requestBuilder.set(CaptureRequest.FLASH_MODE, CaptureRequest.FLASH_MODE_SINGLE);
        CaptureRequest flashSinglerequest = requestBuilder.build();

        int flashModeSingleRequests = captureRequestsSynchronized(
                flashSinglerequest, listener, mHandler);
        waitForNumResults(listener, flashModeSingleRequests - 1);
        result = listener.getCaptureResultForRequest(flashSinglerequest, NUM_RESULTS_WAIT_TIMEOUT);
        // Result mode must be SINGLE, state must be FIRED.
        mCollector.expectEquals(""Flash mode result must be SINGLE"",
                CaptureResult.FLASH_MODE_SINGLE, result.get(CaptureResult.FLASH_MODE));
        mCollector.expectEquals(""Flash state result must be FIRED"",
                CaptureResult.FLASH_STATE_FIRED, result.get(CaptureResult.FLASH_STATE));

        // Test flash TORCH mode control.
        requestBuilder.set(CaptureRequest.FLASH_MODE, CaptureRequest.FLASH_MODE_TORCH);
        CaptureRequest torchRequest = requestBuilder.build();

        int flashModeTorchRequests = captureRequestsSynchronized(torchRequest,
                NUM_FLASH_REQUESTS_TESTED, listener, mHandler);
        waitForNumResults(listener, flashModeTorchRequests - NUM_FLASH_REQUESTS_TESTED);

        // Verify the results
        TorchSeqState state = TorchSeqState.RAMPING_UP;
        for (int i = 0; i < NUM_FLASH_REQUESTS_TESTED; i++) {
            result = listener.getCaptureResultForRequest(torchRequest,
                    NUM_RESULTS_WAIT_TIMEOUT);
            int flashMode = result.get(CaptureResult.FLASH_MODE);
            int flashState = result.get(CaptureResult.FLASH_STATE);
            // Result mode must be TORCH
            mCollector.expectEquals(""Flash mode result "" + i + "" must be TORCH"",
                    CaptureResult.FLASH_MODE_TORCH, result.get(CaptureResult.FLASH_MODE));
            if (state == TorchSeqState.RAMPING_UP &&
                    flashState == CaptureResult.FLASH_STATE_FIRED) {
                state = TorchSeqState.FIRED;
            } else if (state == TorchSeqState.FIRED &&
                    flashState == CaptureResult.FLASH_STATE_PARTIAL) {
                state = TorchSeqState.RAMPING_DOWN;
            }

            if (i == 0 && mStaticInfo.isPerFrameControlSupported()) {
                mCollector.expectTrue(
                        ""Per frame control device must enter FIRED state on first torch request"",
                        state == TorchSeqState.FIRED);
            }

            if (state == TorchSeqState.FIRED) {
                mCollector.expectEquals(""Flash state result "" + i + "" must be FIRED"",
                        CaptureResult.FLASH_STATE_FIRED, result.get(CaptureResult.FLASH_STATE));
            } else {
                mCollector.expectEquals(""Flash state result "" + i + "" must be PARTIAL"",
                        CaptureResult.FLASH_STATE_PARTIAL, result.get(CaptureResult.FLASH_STATE));
            }
        }
        mCollector.expectTrue(""Torch state FIRED never seen"",
                state == TorchSeqState.FIRED || state == TorchSeqState.RAMPING_DOWN);

        // Test flash OFF mode control
        requestBuilder.set(CaptureRequest.FLASH_MODE, CaptureRequest.FLASH_MODE_OFF);
        CaptureRequest flashOffrequest = requestBuilder.build();

        int flashModeOffRequests = captureRequestsSynchronized(flashOffrequest, listener, mHandler);
        waitForNumResults(listener, flashModeOffRequests - 1);
        result = listener.getCaptureResultForRequest(flashOffrequest, NUM_RESULTS_WAIT_TIMEOUT);
        mCollector.expectEquals(""Flash mode result must be OFF"", CaptureResult.FLASH_MODE_OFF,
                result.get(CaptureResult.FLASH_MODE));
    }

    private void verifyAntiBandingMode(SimpleCaptureCallback listener, int numFramesVerified,
            int mode, boolean isAeManual, long requestExpTime) throws Exception {
        // Skip the first a couple of frames as antibanding may not be fully up yet.
        final int NUM_FRAMES_SKIPPED = 5;
        for (int i = 0; i < NUM_FRAMES_SKIPPED; i++) {
            listener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
        }

        for (int i = 0; i < numFramesVerified; i++) {
            CaptureResult result = listener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
            Long resultExpTime = result.get(CaptureResult.SENSOR_EXPOSURE_TIME);
            assertNotNull(""Exposure time shouldn't be null"", resultExpTime);
            Integer flicker = result.get(CaptureResult.STATISTICS_SCENE_FLICKER);
            // Scene flicker result should be always available.
            assertNotNull(""Scene flicker must not be null"", flicker);
            assertTrue(""Scene flicker is invalid"", flicker >= STATISTICS_SCENE_FLICKER_NONE &&
                    flicker <= STATISTICS_SCENE_FLICKER_60HZ);

            Integer antiBandMode = result.get(CaptureResult.CONTROL_AE_ANTIBANDING_MODE);
            assertNotNull(""antiBanding mode shouldn't be null"", antiBandMode);
            assertTrue(""antiBanding Mode invalid, should be == "" + mode + "", is: "" + antiBandMode,
                    antiBandMode == mode);
            if (isAeManual) {
                // First, round down not up, second, need close enough.
                validateExposureTime(requestExpTime, resultExpTime);
                return;
            }

            long expectedExpTime = resultExpTime; // Default, no exposure adjustment.
            if (mode == CONTROL_AE_ANTIBANDING_MODE_50HZ) {
                // result exposure time must be adjusted by 50Hz illuminant source.
                expectedExpTime =
                        getAntiFlickeringExposureTime(ANTI_FLICKERING_50HZ, resultExpTime);
            } else if (mode == CONTROL_AE_ANTIBANDING_MODE_60HZ) {
                // result exposure time must be adjusted by 60Hz illuminant source.
                expectedExpTime =
                        getAntiFlickeringExposureTime(ANTI_FLICKERING_60HZ, resultExpTime);
            } else if (mode == CONTROL_AE_ANTIBANDING_MODE_AUTO){
                /**
                 * Use STATISTICS_SCENE_FLICKER to tell the illuminant source
                 * and do the exposure adjustment.
                 */
                expectedExpTime = resultExpTime;
                if (flicker == STATISTICS_SCENE_FLICKER_60HZ) {
                    expectedExpTime =
                            getAntiFlickeringExposureTime(ANTI_FLICKERING_60HZ, resultExpTime);
                } else if (flicker == STATISTICS_SCENE_FLICKER_50HZ) {
                    expectedExpTime =
                            getAntiFlickeringExposureTime(ANTI_FLICKERING_50HZ, resultExpTime);
                }
            }

            if (Math.abs(resultExpTime - expectedExpTime) > EXPOSURE_TIME_ERROR_MARGIN_NS) {
                mCollector.addMessage(String.format(""Result exposure time %dns diverges too much""
                        + "" from expected exposure time %dns for mode %d when AE is auto"",
                        resultExpTime, expectedExpTime, mode));
            }
        }
    }

    private void antiBandingTestByMode(Size size, int mode)
            throws Exception {
        if(VERBOSE) {
            Log.v(TAG, ""Anti-banding test for mode "" + mode + "" for camera "" + mCamera.getId());
        }
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);

        requestBuilder.set(CaptureRequest.CONTROL_AE_ANTIBANDING_MODE, mode);

        // Test auto AE mode anti-banding behavior
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        startPreview(requestBuilder, size, resultListener);
        waitForSettingsApplied(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
        verifyAntiBandingMode(resultListener, NUM_FRAMES_VERIFIED, mode, /*isAeManual*/false,
                IGNORE_REQUESTED_EXPOSURE_TIME_CHECK);

        // Test manual AE mode anti-banding behavior
        // 65ms, must be supported by full capability devices.
        final long TEST_MANUAL_EXP_TIME_NS = 65000000L;
        long manualExpTime = mStaticInfo.getExposureClampToRange(TEST_MANUAL_EXP_TIME_NS);
        changeExposure(requestBuilder, manualExpTime);
        resultListener = new SimpleCaptureCallback();
        startPreview(requestBuilder, size, resultListener);
        waitForSettingsApplied(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
        verifyAntiBandingMode(resultListener, NUM_FRAMES_VERIFIED, mode, /*isAeManual*/true,
                manualExpTime);

        stopPreview();
    }

    /**
     * Test the all available AE modes and AE lock.
     * <p>
     * For manual AE mode, test iterates through different sensitivities and
     * exposure times, validate the result exposure time correctness. For
     * CONTROL_AE_MODE_ON_ALWAYS_FLASH mode, the AE lock and flash are tested.
     * For the rest of the AUTO mode, AE lock is tested.
     * </p>
     *
     * @param mode
     */
    private void aeModeAndLockTestByMode(int mode)
            throws Exception {
        switch (mode) {
            case CONTROL_AE_MODE_OFF:
                if (mStaticInfo.isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                    // Test manual exposure control.
                    aeManualControlTest();
                } else {
                    Log.w(TAG,
                            ""aeModeAndLockTestByMode - can't test AE mode OFF without "" +
                            ""manual sensor control"");
                }
                break;
            case CONTROL_AE_MODE_ON:
            case CONTROL_AE_MODE_ON_AUTO_FLASH:
            case CONTROL_AE_MODE_ON_AUTO_FLASH_REDEYE:
            case CONTROL_AE_MODE_ON_ALWAYS_FLASH:
            case CONTROL_AE_MODE_ON_EXTERNAL_FLASH:
                // Test AE lock for above AUTO modes.
                aeAutoModeTestLock(mode);
                break;
            default:
                throw new UnsupportedOperationException(""Unhandled AE mode "" + mode);
        }
    }

    /**
     * Test AE auto modes.
     * <p>
     * Use single request rather than repeating request to test AE lock per frame control.
     * </p>
     */
    private void aeAutoModeTestLock(int mode) throws Exception {
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        if (mStaticInfo.isAeLockSupported()) {
            requestBuilder.set(CaptureRequest.CONTROL_AE_LOCK, false);
        }
        requestBuilder.set(CaptureRequest.CONTROL_AE_MODE, mode);
        configurePreviewOutput(requestBuilder);

        final int MAX_NUM_CAPTURES_DURING_LOCK = 5;
        for (int i = 1; i <= MAX_NUM_CAPTURES_DURING_LOCK; i++) {
            autoAeMultipleCapturesThenTestLock(requestBuilder, mode, i);
        }
    }

    /**
     * Issue multiple auto AE captures, then lock AE, validate the AE lock vs.
     * the first capture result after the AE lock. The right AE lock behavior is:
     * When it is locked, it locks to the current exposure value, and all subsequent
     * request with lock ON will have the same exposure value locked.
     */
    private void autoAeMultipleCapturesThenTestLock(
            CaptureRequest.Builder requestBuilder, int aeMode, int numCapturesDuringLock)
            throws Exception {
        if (numCapturesDuringLock < 1) {
            throw new IllegalArgumentException(""numCapturesBeforeLock must be no less than 1"");
        }
        if (VERBOSE) {
            Log.v(TAG, ""Camera "" + mCamera.getId() + "": Testing auto AE mode and lock for mode ""
                    + aeMode + "" with "" + numCapturesDuringLock + "" captures before lock"");
        }

        final int NUM_CAPTURES_BEFORE_LOCK = 2;
        SimpleCaptureCallback listener =  new SimpleCaptureCallback();

        CaptureResult[] resultsDuringLock = new CaptureResult[numCapturesDuringLock];
        boolean canSetAeLock = mStaticInfo.isAeLockSupported();

        // Reset the AE lock to OFF, since we are reusing this builder many times
        if (canSetAeLock) {
            requestBuilder.set(CaptureRequest.CONTROL_AE_LOCK, false);
        }

        // Just send several captures with auto AE, lock off.
        CaptureRequest request = requestBuilder.build();
        for (int i = 0; i < NUM_CAPTURES_BEFORE_LOCK; i++) {
            mSession.capture(request, listener, mHandler);
        }
        waitForNumResults(listener, NUM_CAPTURES_BEFORE_LOCK);

        if (!canSetAeLock) {
            // Without AE lock, the remaining tests items won't work
            return;
        }

        // Then fire several capture to lock the AE.
        requestBuilder.set(CaptureRequest.CONTROL_AE_LOCK, true);

        int requestCount = captureRequestsSynchronized(
                requestBuilder.build(), numCapturesDuringLock, listener, mHandler);

        int[] sensitivities = new int[numCapturesDuringLock];
        long[] expTimes = new long[numCapturesDuringLock];
        Arrays.fill(sensitivities, -1);
        Arrays.fill(expTimes, -1L);

        // Get the AE lock on result and validate the exposure values.
        waitForNumResults(listener, requestCount - numCapturesDuringLock);
        for (int i = 0; i < resultsDuringLock.length; i++) {
            resultsDuringLock[i] = listener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
        }

        for (int i = 0; i < numCapturesDuringLock; i++) {
            mCollector.expectKeyValueEquals(
                    resultsDuringLock[i], CaptureResult.CONTROL_AE_LOCK, true);
        }

        // Can't read manual sensor/exposure settings without manual sensor
        if (mStaticInfo.isCapabilitySupported(
                CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_READ_SENSOR_SETTINGS)) {
            int sensitivityLocked =
                    getValueNotNull(resultsDuringLock[0], CaptureResult.SENSOR_SENSITIVITY);
            long expTimeLocked =
                    getValueNotNull(resultsDuringLock[0], CaptureResult.SENSOR_EXPOSURE_TIME);
            for (int i = 1; i < resultsDuringLock.length; i++) {
                mCollector.expectKeyValueEquals(
                        resultsDuringLock[i], CaptureResult.SENSOR_EXPOSURE_TIME, expTimeLocked);
                mCollector.expectKeyValueEquals(
                        resultsDuringLock[i], CaptureResult.SENSOR_SENSITIVITY, sensitivityLocked);
            }
        }
    }

    /**
     * Iterate through exposure times and sensitivities for manual AE control.
     * <p>
     * Use single request rather than repeating request to test manual exposure
     * value change per frame control.
     * </p>
     */
    private void aeManualControlTest()
            throws Exception {
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        configurePreviewOutput(requestBuilder);

        // Warm up pipeline for more accurate timing
        SimpleCaptureCallback warmupListener =  new SimpleCaptureCallback();
        mSession.setRepeatingRequest(requestBuilder.build(), warmupListener, mHandler);
        warmupListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);

        // Do manual captures
        requestBuilder.set(CaptureRequest.CONTROL_AE_MODE, CONTROL_AE_MODE_OFF);
        SimpleCaptureCallback listener =  new SimpleCaptureCallback();

        long[] expTimesNs = getExposureTimeTestValues();
        int[] sensitivities = getSensitivityTestValues();
        // Submit single request at a time, then verify the result.
        for (int i = 0; i < expTimesNs.length; i++) {
            for (int j = 0; j < sensitivities.length; j++) {
                if (VERBOSE) {
                    Log.v(TAG, ""Camera "" + mCamera.getId() + "": Testing sensitivity ""
                            + sensitivities[j] + "", exposure time "" + expTimesNs[i] + ""ns"");
                }

                changeExposure(requestBuilder, expTimesNs[i], sensitivities[j]);
                mSession.capture(requestBuilder.build(), listener, mHandler);

                // make sure timeout is long enough for long exposure time - add a 2x safety margin
                // to exposure time
                long timeoutMs = WAIT_FOR_RESULT_TIMEOUT_MS + 2 * expTimesNs[i] / 1000000;
                CaptureResult result = listener.getCaptureResult(timeoutMs);
                long resultExpTimeNs = getValueNotNull(result, CaptureResult.SENSOR_EXPOSURE_TIME);
                int resultSensitivity = getValueNotNull(result, CaptureResult.SENSOR_SENSITIVITY);
                validateExposureTime(expTimesNs[i], resultExpTimeNs);
                validateSensitivity(sensitivities[j], resultSensitivity);
                validateFrameDurationForCapture(result);
            }
        }
        mSession.stopRepeating();

        // TODO: Add another case to test where we can submit all requests, then wait for
        // results, which will hide the pipeline latency. this is not only faster, but also
        // test high speed per frame control and synchronization.
    }


    /**
     * Verify black level lock control.
     */
    private void verifyBlackLevelLockResults(SimpleCaptureCallback listener, int numFramesVerified,
            int maxLockOffCnt) throws Exception {
        int noLockCnt = 0;
        for (int i = 0; i < numFramesVerified; i++) {
            CaptureResult result = listener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
            Boolean blackLevelLock = result.get(CaptureResult.BLACK_LEVEL_LOCK);
            assertNotNull(""Black level lock result shouldn't be null"", blackLevelLock);

            // Count the lock == false result, which could possibly occur at most once.
            if (blackLevelLock == false) {
                noLockCnt++;
            }

            if(VERBOSE) {
                Log.v(TAG, ""Black level lock result: "" + blackLevelLock);
            }
        }
        assertTrue(""Black level lock OFF occurs "" + noLockCnt + "" times,  expect at most ""
                + maxLockOffCnt + "" for camera "" + mCamera.getId(), noLockCnt <= maxLockOffCnt);
    }

    /**
     * Verify shading map for different shading modes.
     */
    private void verifyShadingMap(SimpleCaptureCallback listener, int numFramesVerified,
            int shadingMode) throws Exception {

        for (int i = 0; i < numFramesVerified; i++) {
            CaptureResult result = listener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
            mCollector.expectEquals(""Shading mode result doesn't match request"",
                    shadingMode, result.get(CaptureResult.SHADING_MODE));
            LensShadingMap mapObj = result.get(
                    CaptureResult.STATISTICS_LENS_SHADING_CORRECTION_MAP);
            assertNotNull(""Map object must not be null"", mapObj);
            int numElementsInMap = mapObj.getGainFactorCount();
            float[] map = new float[numElementsInMap];
            mapObj.copyGainFactors(map, /*offset*/0);
            assertNotNull(""Map must not be null"", map);
            assertFalse(String.format(
                    ""Map size %d should be less than %d"", numElementsInMap, MAX_SHADING_MAP_SIZE),
                    numElementsInMap >= MAX_SHADING_MAP_SIZE);
            assertFalse(String.format(""Map size %d should be no less than %d"", numElementsInMap,
                    MIN_SHADING_MAP_SIZE), numElementsInMap < MIN_SHADING_MAP_SIZE);

            if (shadingMode == CaptureRequest.SHADING_MODE_FAST ||
                    shadingMode == CaptureRequest.SHADING_MODE_HIGH_QUALITY) {
                // shading mode is FAST or HIGH_QUALITY, expect to receive a map with all
                // elements >= 1.0f

                int badValueCnt = 0;
                // Detect the bad values of the map data.
                for (int j = 0; j < numElementsInMap; j++) {
                    if (Float.isNaN(map[j]) || map[j] < 1.0f) {
                        badValueCnt++;
                    }
                }
                assertEquals(""Number of value in the map is "" + badValueCnt + "" out of ""
                        + numElementsInMap, /*expected*/0, /*actual*/badValueCnt);
            } else if (shadingMode == CaptureRequest.SHADING_MODE_OFF) {
                float[] unityMap = new float[numElementsInMap];
                Arrays.fill(unityMap, 1.0f);
                // shading mode is OFF, expect to receive a unity map.
                assertTrue(""Result map "" + Arrays.toString(map) + "" must be an unity map"",
                        Arrays.equals(unityMap, map));
            }
        }
    }

    /**
     * Test face detection for a camera.
     */
    private void faceDetectionTestByCamera() throws Exception {
        int[] faceDetectModes = mStaticInfo.getAvailableFaceDetectModesChecked();

        SimpleCaptureCallback listener;
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);

        Size maxPreviewSz = mOrderedPreviewSizes.get(0); // Max preview size.
        for (int mode : faceDetectModes) {
            requestBuilder.set(CaptureRequest.STATISTICS_FACE_DETECT_MODE, mode);
            if (VERBOSE) {
                Log.v(TAG, ""Start testing face detection mode "" + mode);
            }

            // Create a new listener for each run to avoid the results from one run spill
            // into another run.
            listener = new SimpleCaptureCallback();
            startPreview(requestBuilder, maxPreviewSz, listener);
            waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
            verifyFaceDetectionResults(listener, NUM_FACE_DETECTION_FRAMES_VERIFIED, mode);
        }

        stopPreview();
    }

    /**
     * Verify face detection results for different face detection modes.
     *
     * @param listener The listener to get capture result
     * @param numFramesVerified Number of results to be verified
     * @param faceDetectionMode Face detection mode to be verified against
     */
    private void verifyFaceDetectionResults(SimpleCaptureCallback listener, int numFramesVerified,
            int faceDetectionMode) {
        for (int i = 0; i < numFramesVerified; i++) {
            CaptureResult result = listener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
            mCollector.expectEquals(""Result face detection mode should match the request"",
                    faceDetectionMode, result.get(CaptureResult.STATISTICS_FACE_DETECT_MODE));

            Face[] faces = result.get(CaptureResult.STATISTICS_FACES);
            List<Integer> faceIds = new ArrayList<Integer>(faces.length);
            List<Integer> faceScores = new ArrayList<Integer>(faces.length);
            if (faceDetectionMode == CaptureResult.STATISTICS_FACE_DETECT_MODE_OFF) {
                mCollector.expectEquals(""Number of detection faces should always 0 for OFF mode"",
                        0, faces.length);
            } else if (faceDetectionMode == CaptureResult.STATISTICS_FACE_DETECT_MODE_SIMPLE) {
                for (Face face : faces) {
                    mCollector.expectNotNull(""Face rectangle shouldn't be null"", face.getBounds());
                    faceScores.add(face.getScore());
                    mCollector.expectTrue(""Face id is expected to be -1 for SIMPLE mode"",
                            face.getId() == Face.ID_UNSUPPORTED);
                }
            } else if (faceDetectionMode == CaptureResult.STATISTICS_FACE_DETECT_MODE_FULL) {
                if (VERBOSE) {
                    Log.v(TAG, ""Number of faces detected: "" + faces.length);
                }

                for (Face face : faces) {
                    Rect faceBound;
                    boolean faceRectAvailable =  mCollector.expectTrue(""Face rectangle ""
                            + ""shouldn't be null"", face.getBounds() != null);
                    if (!faceRectAvailable) {
                        continue;
                    }
                    faceBound = face.getBounds();

                    faceScores.add(face.getScore());
                    faceIds.add(face.getId());

                    mCollector.expectTrue(""Face id is shouldn't be -1 for FULL mode"",
                            face.getId() != Face.ID_UNSUPPORTED);
                    boolean leftEyeAvailable =
                            mCollector.expectTrue(""Left eye position shouldn't be null"",
                                    face.getLeftEyePosition() != null);
                    boolean rightEyeAvailable =
                            mCollector.expectTrue(""Right eye position shouldn't be null"",
                                    face.getRightEyePosition() != null);
                    boolean mouthAvailable =
                            mCollector.expectTrue(""Mouth position shouldn't be null"",
                            face.getMouthPosition() != null);
                    // Eyes/mouth position should be inside of the face rect.
                    if (leftEyeAvailable) {
                        Point leftEye = face.getLeftEyePosition();
                        mCollector.expectTrue(""Left eye "" + leftEye + ""should be""
                                + ""inside of face rect "" + faceBound,
                                faceBound.contains(leftEye.x, leftEye.y));
                    }
                    if (rightEyeAvailable) {
                        Point rightEye = face.getRightEyePosition();
                        mCollector.expectTrue(""Right eye "" + rightEye + ""should be""
                                + ""inside of face rect "" + faceBound,
                                faceBound.contains(rightEye.x, rightEye.y));
                    }
                    if (mouthAvailable) {
                        Point mouth = face.getMouthPosition();
                        mCollector.expectTrue(""Mouth "" + mouth +  "" should be inside of""
                                + "" face rect "" + faceBound,
                                faceBound.contains(mouth.x, mouth.y));
                    }
                }
            }
            mCollector.expectValuesInRange(""Face scores are invalid"", faceScores,
                    Face.SCORE_MIN, Face.SCORE_MAX);
            mCollector.expectValuesUnique(""Face ids are invalid"", faceIds);
        }
    }

    /**
     * Test tone map mode and result by camera
     */
    private void toneMapTestByCamera() throws Exception {
        if (!mStaticInfo.isManualToneMapSupported()) {
            return;
        }

        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        int[] toneMapModes = mStaticInfo.getAvailableToneMapModesChecked();
        // Test AUTO modes first. Note that FAST/HQ must both present or not present
        for (int i = 0; i < toneMapModes.length; i++) {
            if (toneMapModes[i] == CaptureRequest.TONEMAP_MODE_FAST && i > 0) {
                int tmpMode = toneMapModes[0];
                toneMapModes[0] = CaptureRequest.TONEMAP_MODE_FAST;
                toneMapModes[i] = tmpMode;
            }
            if (toneMapModes[i] == CaptureRequest.TONEMAP_MODE_HIGH_QUALITY && i > 1) {
                int tmpMode = toneMapModes[1];
                toneMapModes[1] = CaptureRequest.TONEMAP_MODE_HIGH_QUALITY;
                toneMapModes[i] = tmpMode;
            }
        }
        for (int mode : toneMapModes) {
            if (VERBOSE) {
                Log.v(TAG, ""Testing tonemap mode "" + mode);
            }

            requestBuilder.set(CaptureRequest.TONEMAP_MODE, mode);
            switch (mode) {
                case CaptureRequest.TONEMAP_MODE_CONTRAST_CURVE:
                    TonemapCurve toneCurve = new TonemapCurve(TONEMAP_CURVE_LINEAR,
                            TONEMAP_CURVE_LINEAR, TONEMAP_CURVE_LINEAR);
                    requestBuilder.set(CaptureRequest.TONEMAP_CURVE, toneCurve);
                    testToneMapMode(NUM_FRAMES_VERIFIED, requestBuilder);

                    toneCurve = new TonemapCurve(TONEMAP_CURVE_SRGB,
                            TONEMAP_CURVE_SRGB, TONEMAP_CURVE_SRGB);
                    requestBuilder.set(CaptureRequest.TONEMAP_CURVE, toneCurve);
                    testToneMapMode(NUM_FRAMES_VERIFIED, requestBuilder);
                    break;
                case CaptureRequest.TONEMAP_MODE_GAMMA_VALUE:
                    requestBuilder.set(CaptureRequest.TONEMAP_GAMMA, 1.0f);
                    testToneMapMode(NUM_FRAMES_VERIFIED, requestBuilder);
                    requestBuilder.set(CaptureRequest.TONEMAP_GAMMA, 2.2f);
                    testToneMapMode(NUM_FRAMES_VERIFIED, requestBuilder);
                    requestBuilder.set(CaptureRequest.TONEMAP_GAMMA, 5.0f);
                    testToneMapMode(NUM_FRAMES_VERIFIED, requestBuilder);
                    break;
                case CaptureRequest.TONEMAP_MODE_PRESET_CURVE:
                    requestBuilder.set(CaptureRequest.TONEMAP_PRESET_CURVE,
                            CaptureRequest.TONEMAP_PRESET_CURVE_REC709);
                    testToneMapMode(NUM_FRAMES_VERIFIED, requestBuilder);
                    requestBuilder.set(CaptureRequest.TONEMAP_PRESET_CURVE,
                            CaptureRequest.TONEMAP_PRESET_CURVE_SRGB);
                    testToneMapMode(NUM_FRAMES_VERIFIED, requestBuilder);
                    break;
                default:
                    testToneMapMode(NUM_FRAMES_VERIFIED, requestBuilder);
                    break;
            }
        }


    }

    /**
     * Test tonemap mode with speficied request settings
     *
     * @param numFramesVerified Number of results to be verified
     * @param requestBuilder the request builder of settings to be tested
     */
    private void testToneMapMode (int numFramesVerified,
            CaptureRequest.Builder requestBuilder)  throws Exception  {
        final int MIN_TONEMAP_CURVE_POINTS = 2;
        final Float ZERO = new Float(0);
        final Float ONE = new Float(1.0f);

        SimpleCaptureCallback listener = new SimpleCaptureCallback();
        int tonemapMode = requestBuilder.get(CaptureRequest.TONEMAP_MODE);
        Size maxPreviewSz = mOrderedPreviewSizes.get(0); // Max preview size.
        startPreview(requestBuilder, maxPreviewSz, listener);
        waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

        int maxCurvePoints = mStaticInfo.getMaxTonemapCurvePointChecked();
        for (int i = 0; i < numFramesVerified; i++) {
            CaptureResult result = listener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
            mCollector.expectEquals(""Capture result tonemap mode should match request"", tonemapMode,
                    result.get(CaptureResult.TONEMAP_MODE));
            TonemapCurve tc = getValueNotNull(result, CaptureResult.TONEMAP_CURVE);
            int pointCount = tc.getPointCount(TonemapCurve.CHANNEL_RED);
            float[] mapRed = new float[pointCount * TonemapCurve.POINT_SIZE];
            pointCount = tc.getPointCount(TonemapCurve.CHANNEL_GREEN);
            float[] mapGreen = new float[pointCount * TonemapCurve.POINT_SIZE];
            pointCount = tc.getPointCount(TonemapCurve.CHANNEL_BLUE);
            float[] mapBlue = new float[pointCount * TonemapCurve.POINT_SIZE];
            tc.copyColorCurve(TonemapCurve.CHANNEL_RED, mapRed, 0);
            tc.copyColorCurve(TonemapCurve.CHANNEL_GREEN, mapGreen, 0);
            tc.copyColorCurve(TonemapCurve.CHANNEL_BLUE, mapBlue, 0);
            if (tonemapMode == CaptureResult.TONEMAP_MODE_CONTRAST_CURVE) {
                /**
                 * TODO: need figure out a good way to measure the difference
                 * between request and result, as they may have different array
                 * size.
                 */
            } else if (tonemapMode == CaptureResult.TONEMAP_MODE_GAMMA_VALUE) {
                mCollector.expectEquals(""Capture result gamma value should match request"",
                        requestBuilder.get(CaptureRequest.TONEMAP_GAMMA),
                        result.get(CaptureResult.TONEMAP_GAMMA));
            } else if (tonemapMode == CaptureResult.TONEMAP_MODE_PRESET_CURVE) {
                mCollector.expectEquals(""Capture result preset curve should match request"",
                        requestBuilder.get(CaptureRequest.TONEMAP_PRESET_CURVE),
                        result.get(CaptureResult.TONEMAP_PRESET_CURVE));
            }

            // Tonemap curve result availability and basic validity check for all modes.
            mCollector.expectValuesInRange(""Tonemap curve red values are out of range"",
                    CameraTestUtils.toObject(mapRed), /*min*/ZERO, /*max*/ONE);
            mCollector.expectInRange(""Tonemap curve red length is out of range"",
                    mapRed.length, MIN_TONEMAP_CURVE_POINTS, maxCurvePoints * 2);
            mCollector.expectValuesInRange(""Tonemap curve green values are out of range"",
                    CameraTestUtils.toObject(mapGreen), /*min*/ZERO, /*max*/ONE);
            mCollector.expectInRange(""Tonemap curve green length is out of range"",
                    mapGreen.length, MIN_TONEMAP_CURVE_POINTS, maxCurvePoints * 2);
            mCollector.expectValuesInRange(""Tonemap curve blue values are out of range"",
                    CameraTestUtils.toObject(mapBlue), /*min*/ZERO, /*max*/ONE);
            mCollector.expectInRange(""Tonemap curve blue length is out of range"",
                    mapBlue.length, MIN_TONEMAP_CURVE_POINTS, maxCurvePoints * 2);

            // Make sure capture result tonemap has identical channels.
            if (mStaticInfo.isMonochromeCamera()) {
                mCollector.expectEquals(""Capture result tonemap of monochrome camera should "" +
                        ""have same dimension for all channels"", mapRed.length, mapGreen.length);
                mCollector.expectEquals(""Capture result tonemap of monochrome camera should "" +
                        ""have same dimension for all channels"", mapRed.length, mapBlue.length);

                if (mapRed.length == mapGreen.length && mapRed.length == mapBlue.length) {
                    boolean isIdentical = true;
                    for (int j = 0; j < mapRed.length; j++) {
                        isIdentical = (mapRed[j] == mapGreen[j] && mapRed[j] == mapBlue[j]);
                        if (!isIdentical)
                            break;
                    }
                    mCollector.expectTrue(""Capture result tonemap of monochrome camera should "" +
                            ""be identical between all channels"", isIdentical);
                }
            }
        }
        stopPreview();
    }

    /**
     * Test awb mode control.
     * <p>
     * Test each supported AWB mode, verify the AWB mode in capture result
     * matches request. When AWB is locked, the color correction gains and
     * transform should remain unchanged.
     * </p>
     */
    private void awbModeAndLockTestByCamera() throws Exception {
        int[] awbModes = mStaticInfo.getAwbAvailableModesChecked();
        Size maxPreviewSize = mOrderedPreviewSizes.get(0);
        boolean canSetAwbLock = mStaticInfo.isAwbLockSupported();
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        startPreview(requestBuilder, maxPreviewSize, /*listener*/null);

        for (int mode : awbModes) {
            SimpleCaptureCallback listener;
            requestBuilder.set(CaptureRequest.CONTROL_AWB_MODE, mode);
            listener = new SimpleCaptureCallback();
            mSession.setRepeatingRequest(requestBuilder.build(), listener, mHandler);
            waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

            // Verify AWB mode in capture result.
            verifyCaptureResultForKey(CaptureResult.CONTROL_AWB_MODE, mode, listener,
                    NUM_FRAMES_VERIFIED);

            if (mode == CameraMetadata.CONTROL_AWB_MODE_AUTO && canSetAwbLock) {
                // Verify color correction transform and gains stay unchanged after a lock.
                requestBuilder.set(CaptureRequest.CONTROL_AWB_LOCK, true);
                listener = new SimpleCaptureCallback();
                mSession.setRepeatingRequest(requestBuilder.build(), listener, mHandler);
                waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

                if (mStaticInfo.areKeysAvailable(CaptureResult.CONTROL_AWB_STATE)) {
                    waitForResultValue(listener, CaptureResult.CONTROL_AWB_STATE,
                            CaptureResult.CONTROL_AWB_STATE_LOCKED, NUM_RESULTS_WAIT_TIMEOUT);
                }

            }
            // Don't verify auto mode result if AWB lock is not supported
            if (mode != CameraMetadata.CONTROL_AWB_MODE_AUTO || canSetAwbLock) {
                verifyAwbCaptureResultUnchanged(listener, NUM_FRAMES_VERIFIED);
            }
        }
    }

    private void verifyAwbCaptureResultUnchanged(SimpleCaptureCallback listener,
            int numFramesVerified) {
        // Skip check if cc gains/transform/mode are not available
        if (!mStaticInfo.areKeysAvailable(
                CaptureResult.COLOR_CORRECTION_GAINS,
                CaptureResult.COLOR_CORRECTION_TRANSFORM,
                CaptureResult.COLOR_CORRECTION_MODE)) {
            return;
        }

        CaptureResult result = listener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
        RggbChannelVector lockedGains =
                getValueNotNull(result, CaptureResult.COLOR_CORRECTION_GAINS);
        ColorSpaceTransform lockedTransform =
                getValueNotNull(result, CaptureResult.COLOR_CORRECTION_TRANSFORM);

        for (int i = 0; i < numFramesVerified; i++) {
            result = listener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
            // Color correction mode check is skipped here, as it is checked in colorCorrectionTest.
            validateColorCorrectionResult(result, result.get(CaptureResult.COLOR_CORRECTION_MODE));

            RggbChannelVector gains = getValueNotNull(result, CaptureResult.COLOR_CORRECTION_GAINS);
            ColorSpaceTransform transform =
                    getValueNotNull(result, CaptureResult.COLOR_CORRECTION_TRANSFORM);
            mCollector.expectEquals(""Color correction gains should remain unchanged after awb lock"",
                    lockedGains, gains);
            mCollector.expectEquals(""Color correction transform should remain unchanged after""
                    + "" awb lock"", lockedTransform, transform);
        }
    }

    /**
     * Test AF mode control.
     * <p>
     * Test all supported AF modes, verify the AF mode in capture result matches
     * request. When AF mode is one of the CONTROL_AF_MODE_CONTINUOUS_* mode,
     * verify if the AF can converge to PASSIVE_FOCUSED or PASSIVE_UNFOCUSED
     * state within certain amount of frames.
     * </p>
     */
    private void afModeTestByCamera() throws Exception {
        int[] afModes = mStaticInfo.getAfAvailableModesChecked();
        Size maxPreviewSize = mOrderedPreviewSizes.get(0);
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        startPreview(requestBuilder, maxPreviewSize, /*listener*/null);

        for (int mode : afModes) {
            SimpleCaptureCallback listener;
            requestBuilder.set(CaptureRequest.CONTROL_AF_MODE, mode);
            listener = new SimpleCaptureCallback();
            mSession.setRepeatingRequest(requestBuilder.build(), listener, mHandler);
            waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

            // Verify AF mode in capture result.
            verifyCaptureResultForKey(CaptureResult.CONTROL_AF_MODE, mode, listener,
                    NUM_FRAMES_VERIFIED);

            // Verify AF can finish a scan for CONTROL_AF_MODE_CONTINUOUS_* modes.
            // In LEGACY mode, a transition to one of the continuous AF modes does not necessarily
            // result in a passive AF call if the camera has already been focused, and the scene has
            // not changed enough to trigger an AF pass.  Skip this constraint for LEGACY.
            if (mStaticInfo.isHardwareLevelAtLeastLimited() &&
                    (mode == CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE ||
                    mode == CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_VIDEO)) {
                List<Integer> afStateList = new ArrayList<Integer>();
                afStateList.add(CaptureResult.CONTROL_AF_STATE_PASSIVE_FOCUSED);
                afStateList.add(CaptureResult.CONTROL_AF_STATE_PASSIVE_UNFOCUSED);
                waitForAnyResultValue(listener, CaptureResult.CONTROL_AF_STATE, afStateList,
                        NUM_RESULTS_WAIT_TIMEOUT);
            }
        }
    }

    /**
     * Test video and optical stabilizations if they are supported by a given camera.
     */
    private void stabilizationTestByCamera() throws Exception {
        // video stabilization test.
        List<Key<?>> keys = mStaticInfo.getCharacteristics().getKeys();

        Integer[] videoStabModes = (keys.contains(CameraCharacteristics.
                CONTROL_AVAILABLE_VIDEO_STABILIZATION_MODES)) ?
                CameraTestUtils.toObject(mStaticInfo.getAvailableVideoStabilizationModesChecked()) :
                    new Integer[0];
        int[] opticalStabModes = (keys.contains(
                CameraCharacteristics.LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION)) ?
                mStaticInfo.getAvailableOpticalStabilizationChecked() : new int[0];

        Size maxPreviewSize = mOrderedPreviewSizes.get(0);
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        SimpleCaptureCallback listener = new SimpleCaptureCallback();
        startPreview(requestBuilder, maxPreviewSize, listener);

        for (Integer mode : videoStabModes) {
            listener = new SimpleCaptureCallback();
            requestBuilder.set(CaptureRequest.CONTROL_VIDEO_STABILIZATION_MODE, mode);
            mSession.setRepeatingRequest(requestBuilder.build(), listener, mHandler);
            waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
            // Video stabilization could return any modes.
            verifyAnyCaptureResultForKey(CaptureResult.CONTROL_VIDEO_STABILIZATION_MODE,
                    videoStabModes, listener, NUM_FRAMES_VERIFIED);
        }

        for (int mode : opticalStabModes) {
            listener = new SimpleCaptureCallback();
            requestBuilder.set(CaptureRequest.LENS_OPTICAL_STABILIZATION_MODE, mode);
            mSession.setRepeatingRequest(requestBuilder.build(), listener, mHandler);
            waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);
            verifyCaptureResultForKey(CaptureResult.LENS_OPTICAL_STABILIZATION_MODE, mode,
                    listener, NUM_FRAMES_VERIFIED);
        }

        stopPreview();
    }

    private void digitalZoomTestByCamera(Size previewSize) throws Exception {
        final int ZOOM_STEPS = 15;
        final PointF[] TEST_ZOOM_CENTERS;
        final float maxZoom = mStaticInfo.getAvailableMaxDigitalZoomChecked();
        final float ZOOM_ERROR_MARGIN = 0.01f;
        if (Math.abs(maxZoom - 1.0f) < ZOOM_ERROR_MARGIN) {
            // It doesn't make much sense to test the zoom if the device effectively supports
            // no zoom.
            return;
        }

        final int croppingType = mStaticInfo.getScalerCroppingTypeChecked();
        if (croppingType == CameraCharacteristics.SCALER_CROPPING_TYPE_FREEFORM) {
            // Set the four corners in a way that the minimally allowed zoom factor is 2x.
            float normalizedLeft = 0.25f;
            float normalizedTop = 0.25f;
            float normalizedRight = 0.75f;
            float normalizedBottom = 0.75f;
            // If the max supported zoom is too small, make sure we at least test the max
            // Zoom is tested for the four corners.
            if (maxZoom < 2.0f) {
                normalizedLeft = 0.5f / maxZoom;
                normalizedTop = 0.5f / maxZoom;
                normalizedRight = 1.0f - normalizedLeft;
                normalizedBottom = 1.0f - normalizedTop;
            }
            TEST_ZOOM_CENTERS = new PointF[] {
                new PointF(0.5f, 0.5f),   // Center point
                new PointF(normalizedLeft, normalizedTop),     // top left corner zoom
                new PointF(normalizedRight, normalizedTop),    // top right corner zoom
                new PointF(normalizedLeft, normalizedBottom),  // bottom left corner zoom
                new PointF(normalizedRight, normalizedBottom), // bottom right corner zoom
            };

            if (VERBOSE) {
                Log.v(TAG, ""Testing zoom with CROPPING_TYPE = FREEFORM"");
            }
        } else {
            // CENTER_ONLY
            TEST_ZOOM_CENTERS = new PointF[] {
                    new PointF(0.5f, 0.5f),   // Center point
            };

            if (VERBOSE) {
                Log.v(TAG, ""Testing zoom with CROPPING_TYPE = CENTER_ONLY"");
            }
        }

        final Rect activeArraySize = mStaticInfo.getActiveArraySizeChecked();
        final Rect defaultCropRegion = new Rect(0, 0,
                activeArraySize.width(), activeArraySize.height());
        Rect[] cropRegions = new Rect[ZOOM_STEPS];
        MeteringRectangle[][] expectRegions = new MeteringRectangle[ZOOM_STEPS][];
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        SimpleCaptureCallback listener = new SimpleCaptureCallback();

        updatePreviewSurface(previewSize);
        configurePreviewOutput(requestBuilder);

        CaptureRequest[] requests = new CaptureRequest[ZOOM_STEPS];

        // Set algorithm regions
        final int METERING_RECT_RATIO = 10;
        final MeteringRectangle[][] defaultMeteringRects = new MeteringRectangle[][] {
                {
                    new MeteringRectangle (
                        /*x*/0, /*y*/0, activeArraySize.width(), activeArraySize.height(),
                        /*meteringWeight*/1), /* full active region */
                },
                {
                    new MeteringRectangle (
                        /*x*/0, /*y*/0, activeArraySize.width()/METERING_RECT_RATIO,
                        activeArraySize.height()/METERING_RECT_RATIO,
                        /*meteringWeight*/1),
                },
                {
                    new MeteringRectangle (
                        /*x*/(int)(activeArraySize.width() * (0.5f - 0.5f/METERING_RECT_RATIO)),
                        /*y*/(int)(activeArraySize.height() * (0.5f - 0.5f/METERING_RECT_RATIO)),
                        activeArraySize.width()/METERING_RECT_RATIO,
                        activeArraySize.height()/METERING_RECT_RATIO,
                        /*meteringWeight*/1),
                },
        };

        final int CAPTURE_SUBMIT_REPEAT;
        {
            int maxLatency = mStaticInfo.getSyncMaxLatency();
            if (maxLatency == CameraMetadata.SYNC_MAX_LATENCY_UNKNOWN) {
                CAPTURE_SUBMIT_REPEAT = NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY + 1;
            } else {
                CAPTURE_SUBMIT_REPEAT = maxLatency + 1;
            }
        }

        if (VERBOSE) {
            Log.v(TAG, ""Testing zoom with CAPTURE_SUBMIT_REPEAT = "" + CAPTURE_SUBMIT_REPEAT);
        }

        for (MeteringRectangle[] meteringRect : defaultMeteringRects) {
            for (int algo = 0; algo < NUM_ALGORITHMS; algo++) {
                update3aRegion(requestBuilder, algo,  meteringRect);
            }

            for (PointF center : TEST_ZOOM_CENTERS) {
                Rect previousCrop = null;

                for (int i = 0; i < ZOOM_STEPS; i++) {
                    /*
                     * Submit capture request
                     */
                    float zoomFactor = (float) (1.0f + (maxZoom - 1.0) * i / ZOOM_STEPS);
                    cropRegions[i] = getCropRegionForZoom(zoomFactor, center,
                            maxZoom, defaultCropRegion);
                    if (VERBOSE) {
                        Log.v(TAG, ""Testing Zoom for factor "" + zoomFactor + "" and center "" +
                                center + "" The cropRegion is "" + cropRegions[i] +
                                "" Preview size is "" + previewSize);
                    }
                    requestBuilder.set(CaptureRequest.SCALER_CROP_REGION, cropRegions[i]);
                    requests[i] = requestBuilder.build();
                    for (int j = 0; j < CAPTURE_SUBMIT_REPEAT; ++j) {
                        if (VERBOSE) {
                            Log.v(TAG, ""submit crop region "" + cropRegions[i]);
                        }
                        mSession.capture(requests[i], listener, mHandler);
                    }

                    /*
                     * Validate capture result
                     */
                    waitForNumResults(listener, CAPTURE_SUBMIT_REPEAT - 1); // Drop first few frames
                    TotalCaptureResult result = listener.getTotalCaptureResultForRequest(
                            requests[i], NUM_RESULTS_WAIT_TIMEOUT);
                    List<CaptureResult> partialResults = result.getPartialResults();

                    Rect cropRegion = getValueNotNull(result, CaptureResult.SCALER_CROP_REGION);
                    for (CaptureResult partialResult : partialResults) {
                        Rect cropRegionInPartial =
                                partialResult.get(CaptureResult.SCALER_CROP_REGION);
                        if (cropRegionInPartial != null) {
                            mCollector.expectEquals(""SCALER_CROP_REGION in partial result must ""
                                    + ""match in final result"", cropRegionInPartial, cropRegion);
                        }
                    }

                    /*
                     * Validate resulting crop regions
                     */
                    if (previousCrop != null) {
                        Rect currentCrop = cropRegion;
                        mCollector.expectTrue(String.format(
                                ""Crop region should shrink or stay the same "" +
                                        ""(previous = %s, current = %s)"",
                                        previousCrop, currentCrop),
                                previousCrop.equals(currentCrop) ||
                                    (previousCrop.width() > currentCrop.width() &&
                                     previousCrop.height() > currentCrop.height()));
                    }

                    if (mStaticInfo.isHardwareLevelAtLeastLimited()) {
                        mCollector.expectRectsAreSimilar(
                                ""Request and result crop region should be similar"",
                                cropRegions[i], cropRegion, CROP_REGION_ERROR_PERCENT_DELTA);
                    }

                    if (croppingType == SCALER_CROPPING_TYPE_CENTER_ONLY) {
                        mCollector.expectRectCentered(
                                ""Result crop region should be centered inside the active array"",
                                new Size(activeArraySize.width(), activeArraySize.height()),
                                cropRegion, CROP_REGION_ERROR_PERCENT_CENTERED);
                    }

                    /*
                     * Validate resulting metering regions
                     */

                    // Use the actual reported crop region to calculate the resulting metering region
                    expectRegions[i] = getExpectedOutputRegion(
                            /*requestRegion*/meteringRect,
                            /*cropRect*/     cropRegion);

                    // Verify Output 3A region is intersection of input 3A region and crop region
                    for (int algo = 0; algo < NUM_ALGORITHMS; algo++) {
                        validate3aRegion(result, partialResults, algo, expectRegions[i],
                                false/*scaleByZoomRatio*/);
                    }

                    previousCrop = cropRegion;
                }

                if (maxZoom > 1.0f) {
                    mCollector.expectTrue(
                            String.format(""Most zoomed-in crop region should be smaller"" +
                                            ""than active array w/h"" +
                                            ""(last crop = %s, active array = %s)"",
                                            previousCrop, activeArraySize),
                                (previousCrop.width() < activeArraySize.width() &&
                                 previousCrop.height() < activeArraySize.height()));
                }
            }
        }
    }

    private void zoomRatioTestByCamera(Size previewSize) throws Exception {
        final int ZOOM_STEPS = 15;
        final Range<Float> zoomRatioRange = mStaticInfo.getZoomRatioRangeChecked();
        // The error margin is derive from a VGA size camera zoomed all the way to 10x, in which
        // case the cropping error can be as large as 480/46 - 480/48 = 0.435.
        final float ZOOM_ERROR_MARGIN = 0.05f;

        final Rect activeArraySize = mStaticInfo.getActiveArraySizeChecked();
        final Rect defaultCropRegion =
                new Rect(0, 0, activeArraySize.width(), activeArraySize.height());
        final Rect zoom2xCropRegion =
                new Rect(activeArraySize.width()/4, activeArraySize.height()/4,
                        activeArraySize.width()*3/4, activeArraySize.height()*3/4);
        MeteringRectangle[][] expectRegions = new MeteringRectangle[ZOOM_STEPS][];
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        requestBuilder.set(CaptureRequest.SCALER_CROP_REGION, defaultCropRegion);
        SimpleCaptureCallback listener = new SimpleCaptureCallback();

        updatePreviewSurface(previewSize);
        configurePreviewOutput(requestBuilder);

        // Set algorithm regions to full active region
        final MeteringRectangle[] defaultMeteringRect = new MeteringRectangle[] {
                new MeteringRectangle (
                        /*x*/0, /*y*/0, activeArraySize.width(), activeArraySize.height(),
                        /*meteringWeight*/1)
        };

        for (int algo = 0; algo < NUM_ALGORITHMS; algo++) {
            update3aRegion(requestBuilder, algo,  defaultMeteringRect);
        }

        final int captureSubmitRepeat;
        {
            int maxLatency = mStaticInfo.getSyncMaxLatency();
            if (maxLatency == CameraMetadata.SYNC_MAX_LATENCY_UNKNOWN) {
                captureSubmitRepeat = NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY + 1;
            } else {
                captureSubmitRepeat = maxLatency + 1;
            }
        }

        float previousRatio = zoomRatioRange.getLower();
        for (int i = 0; i < ZOOM_STEPS; i++) {
            /*
             * Submit capture request
             */
            float zoomFactor = zoomRatioRange.getLower() + (zoomRatioRange.getUpper() -
                    zoomRatioRange.getLower()) * i / ZOOM_STEPS;
            if (VERBOSE) {
                Log.v(TAG, ""Testing Zoom ratio "" + zoomFactor + "" Preview size is "" + previewSize);
            }
            requestBuilder.set(CaptureRequest.CONTROL_ZOOM_RATIO, zoomFactor);
            requestBuilder.set(CaptureRequest.SCALER_CROP_REGION, defaultCropRegion);
            CaptureRequest request = requestBuilder.build();
            for (int j = 0; j < captureSubmitRepeat; ++j) {
                mSession.capture(request, listener, mHandler);
            }

            /*
             * Validate capture result
             */
            waitForNumResults(listener, captureSubmitRepeat - 1); // Drop first few frames
            TotalCaptureResult result = listener.getTotalCaptureResultForRequest(
                    request, NUM_RESULTS_WAIT_TIMEOUT);
            List<CaptureResult> partialResults = result.getPartialResults();
            float resultZoomRatio = getValueNotNull(result, CaptureResult.CONTROL_ZOOM_RATIO);
            Rect cropRegion = getValueNotNull(result, CaptureResult.SCALER_CROP_REGION);

            for (CaptureResult partialResult : partialResults) {
                Rect cropRegionInPartial =
                        partialResult.get(CaptureResult.SCALER_CROP_REGION);
                if (cropRegionInPartial != null) {
                    mCollector.expectEquals(""SCALER_CROP_REGION in partial result must ""
                            + ""match in final result"", cropRegionInPartial, cropRegion);
                }

                Float zoomRatioInPartial = partialResult.get(CaptureResult.CONTROL_ZOOM_RATIO);
                if (zoomRatioInPartial != null) {
                    mCollector.expectEquals(""CONTROL_ZOOM_RATIO in partial result must match""
                            + "" that in final result"", resultZoomRatio, zoomRatioInPartial);
                }
            }

            /*
             * Validate resulting crop regions and zoom ratio
             */
            mCollector.expectTrue(String.format(
                    ""Zoom ratio should increase or stay the same "" +
                            ""(previous = %f, current = %f)"",
                            previousRatio, resultZoomRatio),
                    Math.abs(previousRatio - resultZoomRatio) < ZOOM_ERROR_MARGIN ||
                        (previousRatio < resultZoomRatio));

            mCollector.expectTrue(String.format(
                    ""Request and result zoom ratio should be similar "" +
                    ""(requested = %f, result = %f"", zoomFactor, resultZoomRatio),
                    Math.abs(zoomFactor - resultZoomRatio)/zoomFactor <= ZOOM_ERROR_MARGIN);

            //In case zoom ratio is converted to crop region at HAL, due to error magnification
            //when converting to post-zoom crop region, scale the error threshold for crop region
            //check.
            float errorMultiplier = Math.max(1.0f, zoomFactor);
            if (mStaticInfo.isHardwareLevelAtLeastLimited()) {
                mCollector.expectRectsAreSimilar(
                        ""Request and result crop region should be similar"",
                        defaultCropRegion, cropRegion,
                        CROP_REGION_ERROR_PERCENT_DELTA * errorMultiplier);
            }

            mCollector.expectRectCentered(
                    ""Result crop region should be centered inside the active array"",
                    new Size(activeArraySize.width(), activeArraySize.height()),
                    cropRegion, CROP_REGION_ERROR_PERCENT_CENTERED * errorMultiplier);

            /*
             * Validate resulting metering regions
             */
            // Use the actual reported crop region to calculate the resulting metering region
            expectRegions[i] = getExpectedOutputRegion(
                    /*requestRegion*/defaultMeteringRect,
                    /*cropRect*/     cropRegion);

            // Verify Output 3A region is intersection of input 3A region and crop region
            boolean scaleByZoomRatio = zoomFactor > 1.0f;
            for (int algo = 0; algo < NUM_ALGORITHMS; algo++) {
                validate3aRegion(result, partialResults, algo, expectRegions[i], scaleByZoomRatio);
            }

            previousRatio = resultZoomRatio;

            /*
             * Set windowboxing cropRegion while zoomRatio is not 1.0x, and make sure the crop
             * region was overwritten.
             */
            if (zoomFactor != 1.0f) {
                requestBuilder.set(CaptureRequest.SCALER_CROP_REGION, zoom2xCropRegion);
                CaptureRequest requestWithCrop = requestBuilder.build();
                for (int j = 0; j < captureSubmitRepeat; ++j) {
                    mSession.capture(requestWithCrop, listener, mHandler);
                }

                waitForNumResults(listener, captureSubmitRepeat - 1); // Drop first few frames
                CaptureResult resultWithCrop = listener.getCaptureResultForRequest(
                        requestWithCrop, NUM_RESULTS_WAIT_TIMEOUT);
                float resultZoomRatioWithCrop = getValueNotNull(resultWithCrop,
                        CaptureResult.CONTROL_ZOOM_RATIO);
                Rect cropRegionWithCrop = getValueNotNull(resultWithCrop,
                        CaptureResult.SCALER_CROP_REGION);

                mCollector.expectTrue(String.format(
                        ""Result zoom ratio should remain the same (activeArrayCrop: %f, "" +
                        ""zoomedCrop: %f)"", resultZoomRatio, resultZoomRatioWithCrop),
                        Math.abs(resultZoomRatio - resultZoomRatioWithCrop) < ZOOM_ERROR_MARGIN);

                if (mStaticInfo.isHardwareLevelAtLeastLimited()) {
                    mCollector.expectRectsAreSimilar(
                            ""Result crop region should remain the same with or without crop"",
                            cropRegion, cropRegionWithCrop, CROP_REGION_ERROR_PERCENT_DELTA);
                }
            }
        }
    }

    private void digitalZoomPreviewCombinationTestByCamera() throws Exception {
        final double ASPECT_RATIO_THRESHOLD = 0.001;
        List<Double> aspectRatiosTested = new ArrayList<Double>();
        Size maxPreviewSize = mOrderedPreviewSizes.get(0);
        aspectRatiosTested.add((double)(maxPreviewSize.getWidth()) / maxPreviewSize.getHeight());

        for (Size size : mOrderedPreviewSizes) {
            // Max preview size was already tested in testDigitalZoom test. skip it.
            if (size.equals(maxPreviewSize)) {
                continue;
            }

            // Only test the largest size for each aspect ratio.
            double aspectRatio = (double)(size.getWidth()) / size.getHeight();
            if (isAspectRatioContained(aspectRatiosTested, aspectRatio, ASPECT_RATIO_THRESHOLD)) {
                continue;
            }

            if (VERBOSE) {
                Log.v(TAG, ""Test preview size "" + size.toString() + "" digital zoom"");
            }

            aspectRatiosTested.add(aspectRatio);
            digitalZoomTestByCamera(size);
        }
    }

    private static boolean isAspectRatioContained(List<Double> aspectRatioList,
            double aspectRatio, double delta) {
        for (Double ratio : aspectRatioList) {
            if (Math.abs(ratio - aspectRatio) < delta) {
                return true;
            }
        }

        return false;
    }

    private void sceneModeTestByCamera() throws Exception {
        int[] sceneModes = mStaticInfo.getAvailableSceneModesChecked();
        Size maxPreviewSize = mOrderedPreviewSizes.get(0);
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        SimpleCaptureCallback listener = new SimpleCaptureCallback();
        requestBuilder.set(CaptureRequest.CONTROL_MODE, CaptureRequest.CONTROL_MODE_USE_SCENE_MODE);
        startPreview(requestBuilder, maxPreviewSize, listener);

        for(int mode : sceneModes) {
            requestBuilder.set(CaptureRequest.CONTROL_SCENE_MODE, mode);
            listener = new SimpleCaptureCallback();
            mSession.setRepeatingRequest(requestBuilder.build(), listener, mHandler);
            waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

            verifyCaptureResultForKey(CaptureResult.CONTROL_SCENE_MODE,
                    mode, listener, NUM_FRAMES_VERIFIED);
            // This also serves as purpose of showing preview for NUM_FRAMES_VERIFIED
            verifyCaptureResultForKey(CaptureResult.CONTROL_MODE,
                    CaptureRequest.CONTROL_MODE_USE_SCENE_MODE, listener, NUM_FRAMES_VERIFIED);
        }
    }

    private void effectModeTestByCamera() throws Exception {
        int[] effectModes = mStaticInfo.getAvailableEffectModesChecked();
        Size maxPreviewSize = mOrderedPreviewSizes.get(0);
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        requestBuilder.set(CaptureRequest.CONTROL_MODE, CaptureRequest.CONTROL_MODE_AUTO);
        SimpleCaptureCallback listener = new SimpleCaptureCallback();
        startPreview(requestBuilder, maxPreviewSize, listener);

        for(int mode : effectModes) {
            requestBuilder.set(CaptureRequest.CONTROL_EFFECT_MODE, mode);
            listener = new SimpleCaptureCallback();
            mSession.setRepeatingRequest(requestBuilder.build(), listener, mHandler);
            waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

            verifyCaptureResultForKey(CaptureResult.CONTROL_EFFECT_MODE,
                    mode, listener, NUM_FRAMES_VERIFIED);
            // This also serves as purpose of showing preview for NUM_FRAMES_VERIFIED
            verifyCaptureResultForKey(CaptureResult.CONTROL_MODE,
                    CaptureRequest.CONTROL_MODE_AUTO, listener, NUM_FRAMES_VERIFIED);
        }
    }

    private void extendedSceneModeTestByCamera(List<Range<Integer>> fpsRanges) throws Exception {
        Capability[] extendedSceneModeCaps = mStaticInfo.getAvailableExtendedSceneModeCapsChecked();
        if (extendedSceneModeCaps.length == 0) {
            return;
        }

        Size maxPreviewSize = mOrderedPreviewSizes.get(0);
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);

        for (Capability cap : extendedSceneModeCaps) {
            int mode = cap.getMode();
            requestBuilder.set(CaptureRequest.CONTROL_EXTENDED_SCENE_MODE, mode);

            // Test that DISABLED and BOKEH_CONTINUOUS mode doesn't slow down the frame rate
            if (mode == CaptureRequest.CONTROL_EXTENDED_SCENE_MODE_DISABLED ||
                    mode == CaptureRequest.CONTROL_EXTENDED_SCENE_MODE_BOKEH_CONTINUOUS) {
                verifyFpsNotSlowDown(requestBuilder, NUM_FRAMES_VERIFIED, fpsRanges);
            }

            Range<Float> zoomRange = cap.getZoomRatioRange();
            float[] zoomRatios = new float[]{zoomRange.getLower(), zoomRange.getUpper()};
            for (float ratio : zoomRatios) {
                SimpleCaptureCallback listener = new SimpleCaptureCallback();
                requestBuilder.set(CaptureRequest.CONTROL_ZOOM_RATIO, ratio);
                startPreview(requestBuilder, maxPreviewSize, listener);
                waitForSettingsApplied(listener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY);

                verifyCaptureResultForKey(CaptureResult.CONTROL_EXTENDED_SCENE_MODE,
                        mode, listener, NUM_FRAMES_VERIFIED);
                verifyCaptureResultForKey(CaptureResult.CONTROL_ZOOM_RATIO,
                        ratio, listener, NUM_FRAMES_VERIFIED);
            }
        }
    }

    //----------------------------------------------------------------
    //---------Below are common functions for all tests.--------------
    //----------------------------------------------------------------

    /**
     * Enable exposure manual control and change exposure and sensitivity and
     * clamp the value into the supported range.
     */
    private void changeExposure(CaptureRequest.Builder requestBuilder,
            long expTime, int sensitivity) {
        // Check if the max analog sensitivity is available and no larger than max sensitivity.  The
        // max analog sensitivity is not actually used here. This is only an extra correctness
        // check.
        mStaticInfo.getMaxAnalogSensitivityChecked();

        expTime = mStaticInfo.getExposureClampToRange(expTime);
        sensitivity = mStaticInfo.getSensitivityClampToRange(sensitivity);

        requestBuilder.set(CaptureRequest.CONTROL_AE_MODE, CONTROL_AE_MODE_OFF);
        requestBuilder.set(CaptureRequest.SENSOR_EXPOSURE_TIME, expTime);
        requestBuilder.set(CaptureRequest.SENSOR_SENSITIVITY, sensitivity);
    }
    /**
     * Enable exposure manual control and change exposure time and
     * clamp the value into the supported range.
     *
     * <p>The sensitivity is set to default value.</p>
     */
    private void changeExposure(CaptureRequest.Builder requestBuilder, long expTime) {
        changeExposure(requestBuilder, expTime, DEFAULT_SENSITIVITY);
    }

    /**
     * Get the exposure time array that contains multiple exposure time steps in
     * the exposure time range, in nanoseconds.
     */
    private long[] getExposureTimeTestValues() {
        long[] testValues = new long[DEFAULT_NUM_EXPOSURE_TIME_STEPS + 1];
        long maxExpTime = mStaticInfo.getExposureMaximumOrDefault(DEFAULT_EXP_TIME_NS);
        long minExpTime = mStaticInfo.getExposureMinimumOrDefault(DEFAULT_EXP_TIME_NS);

        long range = maxExpTime - minExpTime;
        double stepSize = range / (double)DEFAULT_NUM_EXPOSURE_TIME_STEPS;
        for (int i = 0; i < testValues.length; i++) {
            testValues[i] = maxExpTime - (long)(stepSize * i);
            testValues[i] = mStaticInfo.getExposureClampToRange(testValues[i]);
        }

        return testValues;
    }

    /**
     * Generate test focus distances in range of [0, minFocusDistance] in increasing order.
     *
     * @param repeatMin number of times minValue will be repeated.
     * @param repeatMax number of times maxValue will be repeated.
     */
    private float[] getFocusDistanceTestValuesInOrder(int repeatMin, int repeatMax) {
        int totalCount = NUM_TEST_FOCUS_DISTANCES + 1 + repeatMin + repeatMax;
        float[] testValues = new float[totalCount];
        float minValue = 0;
        float maxValue = mStaticInfo.getMinimumFocusDistanceChecked();

        float range = maxValue - minValue;
        float stepSize = range / NUM_TEST_FOCUS_DISTANCES;

        for (int i = 0; i < repeatMin; i++) {
            testValues[i] = minValue;
        }
        for (int i = 0; i <= NUM_TEST_FOCUS_DISTANCES; i++) {
            testValues[repeatMin+i] = minValue + stepSize * i;
        }
        for (int i = 0; i < repeatMax; i++) {
            testValues[repeatMin+NUM_TEST_FOCUS_DISTANCES+1+i] =
                    maxValue;
        }

        return testValues;
    }

    /**
     * Get the sensitivity array that contains multiple sensitivity steps in the
     * sensitivity range.
     * <p>
     * Sensitivity number of test values is determined by
     * {@value #DEFAULT_SENSITIVITY_STEP_SIZE} and sensitivity range, and
     * bounded by {@value #DEFAULT_NUM_SENSITIVITY_STEPS}.
     * </p>
     */
    private int[] getSensitivityTestValues() {
        int maxSensitivity = mStaticInfo.getSensitivityMaximumOrDefault(
                DEFAULT_SENSITIVITY);
        int minSensitivity = mStaticInfo.getSensitivityMinimumOrDefault(
                DEFAULT_SENSITIVITY);

        int range = maxSensitivity - minSensitivity;
        int stepSize = DEFAULT_SENSITIVITY_STEP_SIZE;
        int numSteps = range / stepSize;
        // Bound the test steps to avoid supper long test.
        if (numSteps > DEFAULT_NUM_SENSITIVITY_STEPS) {
            numSteps = DEFAULT_NUM_SENSITIVITY_STEPS;
            stepSize = range / numSteps;
        }
        int[] testValues = new int[numSteps + 1];
        for (int i = 0; i < testValues.length; i++) {
            testValues[i] = maxSensitivity - stepSize * i;
            testValues[i] = mStaticInfo.getSensitivityClampToRange(testValues[i]);
        }

        return testValues;
    }

    /**
     * Validate the AE manual control exposure time.
     *
     * <p>Exposure should be close enough, and only round down if they are not equal.</p>
     *
     * @param request Request exposure time
     * @param result Result exposure time
     */
    private void validateExposureTime(long request, long result) {
        long expTimeDelta = request - result;
        long expTimeErrorMargin = (long)(Math.max(EXPOSURE_TIME_ERROR_MARGIN_NS, request
                * EXPOSURE_TIME_ERROR_MARGIN_RATE));
        // First, round down not up, second, need close enough.
        mCollector.expectTrue(""Exposture time is invalid for AE manaul control test, request: ""
                + request + "" result: "" + result,
                expTimeDelta < expTimeErrorMargin && expTimeDelta >= 0);
    }

    /**
     * Validate AE manual control sensitivity.
     *
     * @param request Request sensitivity
     * @param result Result sensitivity
     */
    private void validateSensitivity(int request, int result) {
        float sensitivityDelta = request - result;
        float sensitivityErrorMargin = request * SENSITIVITY_ERROR_MARGIN_RATE;
        // First, round down not up, second, need close enough.
        mCollector.expectTrue(""Sensitivity is invalid for AE manaul control test, request: ""
                + request + "" result: "" + result,
                sensitivityDelta < sensitivityErrorMargin && sensitivityDelta >= 0);
    }

    /**
     * Validate frame duration for a given capture.
     *
     * <p>Frame duration should be longer than exposure time.</p>
     *
     * @param result The capture result for a given capture
     */
    private void validateFrameDurationForCapture(CaptureResult result) {
        long expTime = getValueNotNull(result, CaptureResult.SENSOR_EXPOSURE_TIME);
        long frameDuration = getValueNotNull(result, CaptureResult.SENSOR_FRAME_DURATION);
        if (VERBOSE) {
            Log.v(TAG, ""frame duration: "" + frameDuration + "" Exposure time: "" + expTime);
        }

        mCollector.expectTrue(String.format(""Frame duration (%d) should be longer than exposure""
                + "" time (%d) for a given capture"", frameDuration, expTime),
                frameDuration >= expTime);

        validatePipelineDepth(result);
    }

    /**
     * Basic verification for the control mode capture result.
     *
     * @param key The capture result key to be verified against
     * @param requestMode The request mode for this result
     * @param listener The capture listener to get capture results
     * @param numFramesVerified The number of capture results to be verified
     */
    private <T> void verifyCaptureResultForKey(CaptureResult.Key<T> key, T requestMode,
            SimpleCaptureCallback listener, int numFramesVerified) {
        for (int i = 0; i < numFramesVerified; i++) {
            CaptureResult result = listener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
            validatePipelineDepth(result);
            T resultMode = getValueNotNull(result, key);
            if (VERBOSE) {
                Log.v(TAG, ""Expect value: "" + requestMode.toString() + "" result value: ""
                        + resultMode.toString());
            }
            mCollector.expectEquals(""Key "" + key.getName() + "" result should match request"",
                    requestMode, resultMode);
        }
    }

    /**
     * Basic verification that the value of a capture result key should be one of the expected
     * values.
     *
     * @param key The capture result key to be verified against
     * @param expectedModes The list of any possible expected modes for this result
     * @param listener The capture listener to get capture results
     * @param numFramesVerified The number of captur"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Fragments.DataFragment"	"stopListening"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Fragments/DataFragment.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Fragments;


import com.android.cts.verifier.sensors.sixdof.Activities.TestActivity;
import com.android.cts.verifier.sensors.sixdof.Utils.Manager;
import com.android.cts.verifier.sensors.sixdof.Utils.TestReport;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointAreaCoveredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointDistanceException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointRingNotEnteredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointStartPointException;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Ring;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Waypoint;
import com.android.cts.verifier.sensors.sixdof.Utils.PoseProvider.AndroidPoseProvider;
import com.android.cts.verifier.sensors.sixdof.Utils.PoseProvider.PoseData;
import com.android.cts.verifier.sensors.sixdof.Utils.PoseProvider.PoseProvider;

import android.app.Activity;
import android.content.Context;
import android.app.Fragment;

import java.util.ArrayList;

/**
 * This currently deals with the pose data and what to do with it.
 */
public class DataFragment extends Fragment implements PoseProvider.PoseProviderListener {
    private final static String TAG = ""DataFragment"";

    private TestReport mTestReport;
    private Manager mManager;

    private PoseProvider mPoseProvider;
    protected boolean mIsPoseProviderReady = false;

    @Override
    public void onStart() {
        super.onStart();
        mPoseProvider = new AndroidPoseProvider(getActivity(), this);
        mPoseProvider.setup();
    }

    @Override
    public void onDestroy() {
        super.onDestroy();
        mPoseProvider = null;
    }

    @Override
    public void onPause() {
        super.onPause();
        mPoseProvider.onStopPoseProviding();
        mIsPoseProviderReady = false;
    }

    /**
     * Start PoseProvider.
     */
    @Override
    public void onSetupComplete() {
        mPoseProvider.onStartPoseProviding();
    }

    @Override
    public void onNewPoseData(PoseData newPoseData) {
        if (!mIsPoseProviderReady) {
            mIsPoseProviderReady = true;
            mManager.onPoseProviderReady();
        }

        mManager.onNewPoseData(newPoseData);
    }

    /**
     * Assign the listener when this fragment is attached to an activity.
     *
     * @param activity the activity that this fragment is attached to.
     */
    @Override
    public void onAttach(Activity activity) {
        super.onAttach(activity);
        initManager(activity);
    }

    private void initManager(Context context) {
        mTestReport = new TestReport(getActivity());
        mManager = new Manager(mTestReport);
        mManager.setupListeners(context);
    }

    /**
     * Nullify the listener to avoid leaking the activity.
     */
    @Override
    public void onDetach() {
        super.onDetach();
        mManager.stopListening();
    }

    /**
     * @return PoseProvider object associated with these tests.
     */
    public PoseProvider getPoseProvider() {
        return mPoseProvider;
    }

    /**
     * @return true if we are connected to the pose provider.
     */
    public boolean isPoseProviderReady() {
        return mIsPoseProviderReady;
    }

    /**
     * Gets all the markers (user generated waypoints) for the specified phase.
     *
     * @param lap the lap of the test to get the markers from
     * @return a list of the markers
     */
    public ArrayList<Waypoint> getUserGeneratedWaypoints(Manager.Lap lap) {
        switch (lap) {
            case LAP_1:
                return mManager.getReferencePathMarkers();
            case LAP_2:
                return mManager.getTestPathMarkers();
            case LAP_3:
                return mManager.getRobustnessMarker();
            case LAP_4:
                return mManager.getComplexMovementTestMarkers();
            default:
                throw new AssertionError(""Unrecognised Lap!"", null);
        }
    }

    /**
     * Returns a reference to the mTestReport object.
     */
    public TestReport getTestReport() {
        return mTestReport;
    }

    /**
     * Initiates the adding of a waypoint and checks if the state of the current test need to be
     * changed.
     *
     * @throws WaypointDistanceException    if the location is too close to another
     * @throws WaypointAreaCoveredException if the area covered by the user is too little
     * @throws WaypointStartPointException  if the location is not close enough to the start
     */
    public void onWaypointPlacementAttempt()
            throws WaypointStartPointException, WaypointDistanceException,
            WaypointAreaCoveredException, WaypointRingNotEnteredException {
        synchronized (TestActivity.POSE_LOCK) {
            mManager.addPoseDataToPath(
                    mPoseProvider.getLatestPoseData().getTranslationAsFloats(), true);
        }
    }

    /**
     * Removes the last marker added in the current test phase.
     */
    public void undoWaypointPlacement() {
        mManager.removeLastAddedMarker();
    }

    /**
     * Returns the current phase of the test.
     */
    public Manager.Lap getLap() {
        return mManager.getLap();
    }

    /**
     * Sets the test status to executed.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.helpers.SensorFeaturesDeactivator"	"AmbientDisplaySettingContainer"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/helpers/SensorFeaturesDeactivator.java"	""	"public void test/*
 *
 */

package com.android.cts.verifier.sensors.helpers;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.base.ISensorTestStateContainer;

import android.content.ContentResolver;
import android.content.pm.PackageManager;
import android.os.Build;
import android.provider.Settings;

import java.lang.reflect.Field;

/**
 * A helper class that provides a mechanism to:
 * - prompt users to activate/deactivate features that are known to register for sensor data.
 * - turn on/off certain components of the device on behalf of the test (described as 'runtime
 *   features')
 * - keep track of the initial state for each sensor feature, so it can be restored at will
 */
public class SensorFeaturesDeactivator {

    private final ISensorTestStateContainer mStateContainer;

    private final SensorSettingContainer mAirplaneMode = new AirplaneModeSettingContainer();
    private final SensorSettingContainer mScreenBrightnessMode =
            new ScreenBrightnessModeSettingContainer();
    private final SensorSettingContainer mAmbientDisplayMode = new AmbientDisplaySettingContainer();
    private final SensorSettingContainer mAutoRotateScreenMode =
            new AutoRotateScreenModeSettingContainer();
    private final SensorSettingContainer mKeepScreenOnMode = new KeepScreenOnModeSettingContainer();
    private final SensorSettingContainer mLocationMode = new LocationModeSettingContainer();

    public SensorFeaturesDeactivator(ISensorTestStateContainer stateContainer) {
        mStateContainer = stateContainer;
    }

    public synchronized void requestDeactivationOfFeatures() throws InterruptedException {
        captureInitialState();

        mAirplaneMode.requestToSetMode(mStateContainer, true);
        mScreenBrightnessMode.requestToSetMode(mStateContainer, false);
        mAmbientDisplayMode.requestToSetMode(mStateContainer, false);
        mAutoRotateScreenMode.requestToSetMode(mStateContainer, false);
        mKeepScreenOnMode.requestToSetMode(mStateContainer, false);
        mLocationMode.requestToSetMode(mStateContainer, false);

        // TODO: find a way to find out if there are clients still registered at this time
        mStateContainer.getTestLogger()
                .logInstructions(R.string.snsr_sensor_feature_deactivation);
        mStateContainer.waitForUserToContinue();
    }

    public synchronized void requestToSetLocationMode(boolean state) throws InterruptedException {
        mLocationMode.captureInitialState();
        mLocationMode.requestToSetMode(mStateContainer, state);
    }

    public synchronized void requestToRestoreFeatures() throws InterruptedException {
        if (Thread.currentThread().isInterrupted()) {
            // TODO: in the future, if the thread is interrupted, we might need to serialize the
            //       intermediate state we acquired so we can restore when we have a chance
            return;
        }

        mAirplaneMode.requestToResetMode(mStateContainer);
        mScreenBrightnessMode.requestToResetMode(mStateContainer);
        mAmbientDisplayMode.requestToResetMode(mStateContainer);
        mAutoRotateScreenMode.requestToResetMode(mStateContainer);
        mKeepScreenOnMode.requestToResetMode(mStateContainer);
        mLocationMode.requestToResetMode(mStateContainer);
    }

    private void captureInitialState() {
        mAirplaneMode.captureInitialState();
        mScreenBrightnessMode.captureInitialState();
        mAmbientDisplayMode.captureInitialState();
        mAutoRotateScreenMode.captureInitialState();
        mLocationMode.captureInitialState();
        mKeepScreenOnMode.captureInitialState();
    }

    private class AirplaneModeSettingContainer extends SensorSettingContainer {
        public AirplaneModeSettingContainer() {
            super(Settings.ACTION_AIRPLANE_MODE_SETTINGS, R.string.snsr_setting_airplane_mode);
        }

        @Override
        protected int getSettingMode(int defaultValue) {
            ContentResolver contentResolver = mStateContainer.getContentResolver();
            // Settings.System.AIRPLANE_MODE_ON is deprecated in API 17
            if (Build.VERSION.SDK_INT < Build.VERSION_CODES.JELLY_BEAN_MR1) {
                return Settings.System
                        .getInt(contentResolver, Settings.System.AIRPLANE_MODE_ON, defaultValue);
            } else {
                return Settings.Global
                        .getInt(contentResolver, Settings.Global.AIRPLANE_MODE_ON, defaultValue);
            }
        }

        @Override
        protected boolean isSettingAvailable() {
            // call base first, lean back UI device does not have airplane mode
            return super.isSettingAvailable() &&
                    !(mStateContainer.hasSystemFeature(PackageManager.FEATURE_LEANBACK));
        }
    }

    private class ScreenBrightnessModeSettingContainer extends SensorSettingContainer {
        public ScreenBrightnessModeSettingContainer() {
            super(Settings.ACTION_DISPLAY_SETTINGS, R.string.snsr_setting_screen_brightness_mode);
        }

        @Override
        public int getSettingMode(int defaultValue) {
            return Settings.System.getInt(
                    mStateContainer.getContentResolver(),
                    Settings.System.SCREEN_BRIGHTNESS_MODE,
                    defaultValue);
        }
    }

    private class AmbientDisplaySettingContainer extends SensorSettingContainer {
        public AmbientDisplaySettingContainer() {
            super(Settings.ACTION_DISPLAY_SETTINGS, R.string.snsr_setting_ambient_display);
        }

        @Override
        protected int getSettingMode(int defaultValue) {
            return Settings.Secure.getInt(
                    mStateContainer.getContentResolver(),
                    Settings.Secure.DOZE_ENABLED,
                    defaultValue);
        }
    }

    private class AutoRotateScreenModeSettingContainer extends SensorSettingContainer {
        public AutoRotateScreenModeSettingContainer() {
            super(Settings.ACTION_ACCESSIBILITY_SETTINGS,
                    R.string.snsr_setting_auto_rotate_screen_mode);
        }

        @Override
        protected int getSettingMode(int defaultValue) {
            return Settings.System.getInt(
                    mStateContainer.getContentResolver(),
                    Settings.System.ACCELEROMETER_ROTATION,
                    defaultValue);
        }
    }

    private class KeepScreenOnModeSettingContainer extends SensorSettingContainer {
        public KeepScreenOnModeSettingContainer() {
            super(Settings.ACTION_APPLICATION_DEVELOPMENT_SETTINGS,
                    R.string.snsr_setting_keep_screen_on);
        }

        @Override
        protected int getSettingMode(int defaultValue) {
            return Settings.Global.getInt(
                    mStateContainer.getContentResolver(),
                    Settings.Global.STAY_ON_WHILE_PLUGGED_IN,
                    defaultValue);
        }
    }

    private class LocationModeSettingContainer extends SensorSettingContainer {
        public LocationModeSettingContainer() {
            super(Settings.ACTION_LOCATION_SOURCE_SETTINGS, R.string.snsr_setting_location_mode);
        }

        @Override
        protected int getSettingMode(int defaultValue) {
            return Settings.Secure.getInt(
                    mStateContainer.getContentResolver(),
                    Settings.Secure.LOCATION_MODE,
                    defaultValue);
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Renderer.Renderable.CameraPreviewRenderable"	"disconnectCamera"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Renderer/Renderable/CameraPreviewRenderable.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Renderer.Renderable;

import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.X;
import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.Y;
import static com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils.Z;

import android.content.Context;
import android.graphics.SurfaceTexture;
import android.opengl.GLES11Ext;
import android.opengl.GLES20;
import android.opengl.Matrix;
import android.util.Log;

import com.android.cts.verifier.sensors.sixdof.Renderer.RenderUtils.CameraStreamManager;
import com.android.cts.verifier.sensors.sixdof.Renderer.RenderUtils.DrawParameters;
import com.android.cts.verifier.sensors.sixdof.Renderer.RenderUtils.ShaderHelper;

import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.nio.FloatBuffer;

/**
 * Shows the camera preview as an opengl texture.
 */
public class CameraPreviewRenderable extends Renderable {
    private static final String TAG = ""CameraPreviewRenderable"";
    private final int TEXTURE_COORDINATE_DATA_SIZE = 2;
    private static final float[] CAMERA_TEXTURE_DATA = {
            0.0f, 0.0f,
            0.0f, 1.0f,
            1.0f, 0.0f,
            0.0f, 1.0f,
            1.0f, 1.0f,
            1.0f, 0.0f
    };
    private static final float[] CAMERA_PREVIEW_POSITION = {0.0f, 0.0f, -3.0f};

    private FloatBuffer mPositionBuffer;
    private FloatBuffer mTextureBuffer;

    private int mTextureUniformHandle;
    private int mTextureCoordinateHandle;

    protected int mCameraTextureId = -1;

    private SurfaceTexture mCameraSurfaceTexture;
    private Context mContext;
    private CameraStreamManager mCameraStreamManager;
    private boolean mInvertAxis;

    public CameraPreviewRenderable() {
        // Reset the model matrix to the identity and move it so the OpenGL camera is looking at it.
        Matrix.setIdentityM(getModelMatrix(), 0);
        Matrix.translateM(getModelMatrix(), 0,
                CAMERA_PREVIEW_POSITION[X], CAMERA_PREVIEW_POSITION[Y], CAMERA_PREVIEW_POSITION[Z]);
    }

    public void initialiseCameraPreview(float[] cameraPreviewPositionData, boolean invertAxis, Context context) {
        // float count / floats per vertex.
        mVertexCount = cameraPreviewPositionData.length / POSITION_DATA_SIZE;

        // Initialize the buffers.
        mPositionBuffer = ByteBuffer.allocateDirect(cameraPreviewPositionData.length * BYTES_PER_FLOAT)
                .order(ByteOrder.nativeOrder()).asFloatBuffer();

        mTextureBuffer = ByteBuffer.allocateDirect(CAMERA_TEXTURE_DATA.length * BYTES_PER_FLOAT)
                .order(ByteOrder.nativeOrder()).asFloatBuffer();

        mPositionBuffer.put(cameraPreviewPositionData).position(0);
        mTextureBuffer.put(CAMERA_TEXTURE_DATA).position(0);

        final String vertexShader = ShaderHelper.getCameraPreviewVertexShader();
        final String fragmentShader = ShaderHelper.getCameraPreviewFragmentShader();

        final int vertexShaderHandle =
                ShaderHelper.compileShader(GLES20.GL_VERTEX_SHADER, vertexShader);
        final int fragmentShaderHandle =
                ShaderHelper.compileShader(GLES20.GL_FRAGMENT_SHADER, fragmentShader);

        mProgramHandle = ShaderHelper.createAndLinkProgram(vertexShaderHandle, fragmentShaderHandle,
                new String[]{""a_Position"", ""a_TexCoordinate""});

        mContext = context;
        mInvertAxis = invertAxis;
        connectCamera();
    }

    @Override
    public void draw(DrawParameters drawParameters) {
        GLES20.glUseProgram(mProgramHandle);

        // Set program handles for camera preview drawing.
        mMVPMatrixHandle = GLES20.glGetUniformLocation(mProgramHandle, ""u_MVPMatrix"");
        mMVMatrixHandle = GLES20.glGetUniformLocation(mProgramHandle, ""u_MVMatrix"");
        mTextureUniformHandle = GLES20.glGetUniformLocation(mProgramHandle, ""u_Texture"");
        mPositionHandle = GLES20.glGetAttribLocation(mProgramHandle, ""a_Position"");
        mTextureCoordinateHandle = GLES20.glGetAttribLocation(mProgramHandle, ""a_TexCoordinate"");

        // Set the active texture unit to texture unit 0.
        GLES20.glActiveTexture(GLES20.GL_TEXTURE0);

        // Bind the texture to this unit.
        if (mCameraTextureId != -1) {
            GLES20.glBindTexture(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, mCameraTextureId);
        }

        // Tell the texture uniform sampler to use this texture in the shader by binding to texture unit 0.
        GLES20.glUniform1i(mTextureUniformHandle, 0);

        // Compose the model, view, and projection matrices into a single m-v-p matrix
        updateMvpMatrix(drawParameters.getViewMatrix(), drawParameters.getProjectionMatrix());

        drawCameraPreview();
    }

    /**
     * Draws a camera preview.
     */
    private void drawCameraPreview() {
        // Pass in the position information
        mPositionBuffer.position(0);
        GLES20.glVertexAttribPointer(mPositionHandle, POSITION_DATA_SIZE, GLES20.GL_FLOAT, false,
                0, mPositionBuffer);

        GLES20.glEnableVertexAttribArray(mPositionHandle);

        // Pass in the texture coordinate information
        mTextureBuffer.position(0);
        GLES20.glVertexAttribPointer(mTextureCoordinateHandle, TEXTURE_COORDINATE_DATA_SIZE, GLES20.GL_FLOAT, false,
                0, mTextureBuffer);

        GLES20.glEnableVertexAttribArray(mTextureCoordinateHandle);

        // Pass in the modelview matrix.
        GLES20.glUniformMatrix4fv(mMVMatrixHandle, 1, false, getMvMatrix(), 0);

        // Pass in the combined matrix.
        GLES20.glUniformMatrix4fv(mMVPMatrixHandle, 1, false, getMvpMatrix(), 0);

        // Draw the camera preview.
        GLES20.glDrawArrays(GLES20.GL_TRIANGLES, 0, mVertexCount);
    }

    /**
     * Updates the texture with the latest camera data.
     *
     * @return the timestamp of the RGB image rendered into the texture.
     */
    public synchronized double updateTexture() {
        double latestCameraFrameTimestamp = -1.0;
        if (mCameraTextureId != -1) {
            // Copy the camera frame from the camera to the OpenGL texture
            mCameraSurfaceTexture.updateTexImage();
            latestCameraFrameTimestamp = mCameraSurfaceTexture.getTimestamp();
        }
        return latestCameraFrameTimestamp;
    }

    /**
     * Connects the camera to the OpenGl context
     */
    public void connectCamera() {
        this.mCameraTextureId = connectCameraTexture();
    }

    public void disconnectCamera() {
        mCameraStreamManager.onStopCameraStream();
    }

    /**
     * Connects a texture to an Android camera
     *
     * @return textureId of texture with camera attached/
     */
    private int connectCameraTexture() {
        if (mCameraTextureId == -1) {
            mCameraTextureId = createEmptyTexture();
            mCameraSurfaceTexture = new SurfaceTexture(mCameraTextureId);
            int width = mInvertAxis ? 1080 : 1920;
            int height = mInvertAxis ? 1920 : 1080;
            mCameraStreamManager = new CameraStreamManager(mContext, mCameraSurfaceTexture, width, height);
            mCameraStreamManager.onStartCameraStream();
        }
        return mCameraTextureId;
    }

    /**
     * Creates an empty texture.
     *
     * @return textureId of empty texture.
     */
    public static int createEmptyTexture() {
        final int[] textureHandle = new int[1];

        GLES20.glGenTextures(1, textureHandle, 0);

        if (textureHandle[0] != 0) {
            return textureHandle[0];
        }

        return -1;
    }

    @Override
    public void destroy() {
        if (mCameraStreamManager != null) {
            mCameraStreamManager.onStopCameraStream();
            mCameraStreamManager = null;
        }

        mPositionBuffer = null;
        mTextureBuffer = null;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Fragments.RobustnessFragment"	"OnClickListener"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Fragments/RobustnessFragment.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Fragments;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.sixdof.BuildConfig;
import com.android.cts.verifier.sensors.sixdof.Activities.TestActivity;
import com.android.cts.verifier.sensors.sixdof.Dialogs.RobustnessResultDialog;
import com.android.cts.verifier.sensors.sixdof.Interfaces.RobustnessListener;
import com.android.cts.verifier.sensors.sixdof.Renderer.RobustnessRenderer;
import com.android.cts.verifier.sensors.sixdof.Renderer.RenderUtils.Colour;
import com.android.cts.verifier.sensors.sixdof.Utils.Manager;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointAreaCoveredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointDistanceException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointRingNotEnteredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointStartPointException;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.RotationData;
import com.android.cts.verifier.sensors.sixdof.Utils.ResultObjects.ResultObject;

import android.app.Activity;
import android.opengl.GLSurfaceView;
import android.os.Bundle;
import android.app.AlertDialog;
import android.util.Log;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.widget.ImageButton;
import android.widget.LinearLayout;
import android.widget.TextView;
import android.widget.Toast;

/**
 * UI fragment for the second test.
 */
public class RobustnessFragment extends BaseUiFragment implements RobustnessListener {
    private static final String TAG = ""RobustnessFragment"";
    private static final Object TIMER_LOCK = new Object();

    private TextView mTvTime;
    private TextView mTvPassColour;
    private TextView mTvObjective;

    private boolean mIsPassing = false;
    private boolean mResultGiven = false;

    /**
     * Standard practice to have a static newInstance constructor. Used to pass in arguments to the
     * fragment. We don't have any at the moment, but this is good structure for the future.
     *
     * @return a new Robustness test fragment.
     */
    public static RobustnessFragment newInstance() {
        RobustnessFragment fragment = new RobustnessFragment();
        return fragment;
    }

    /**
     * Called when the parent activity has been created. Adds the GLSurfaceView to the fragment
     * layout.
     */
    @Override
    public void onActivityCreated(Bundle savedInstanceState) {
        super.onActivityCreated(savedInstanceState);

        GLSurfaceView surfaceView = new GLSurfaceView(getActivity());
        surfaceView.setEGLContextClientVersion(2);
        mRenderer = new RobustnessRenderer(getActivity());
        surfaceView.setRenderer(mRenderer);
        mLLCameraLayout = (LinearLayout) getView().findViewById(R.id.llCamera);
        mLLCameraLayout.addView(surfaceView);
        Log.d(TAG, ""Camera Preview add to layout"");
    }

    /**
     * Initialises all of the UI elements.
     */
    @Override
    public View onCreateView(LayoutInflater inflater, ViewGroup container,
                             Bundle savedInstanceState) {
        View view = inflater.inflate(R.layout.fragment_robustness, container, false);
        getActivity().setTitle(getResources().getStringArray(R.array.phase)[TestActivity.CTSTest.ROBUSTNESS.ordinal()]);

        // Set up pass/info/fail buttons
        setupButtons(view, TestActivity.CTSTest.ROBUSTNESS);

        mPlaceWaypointButton = (ImageButton) view.findViewById(R.id.fabPlaceWaypoint);
        mPlaceWaypointButton.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                try {
                    mActivity.attemptWaypointPlacement();
                } catch (WaypointDistanceException e) {
                    Toast.makeText(getActivity(),
                            getString(R.string.error_distance), Toast.LENGTH_SHORT).show();
                } catch (WaypointAreaCoveredException e) {
                    Toast.makeText(getActivity(),
                            getString(R.string.error_area), Toast.LENGTH_SHORT).show();
                } catch (WaypointStartPointException e) {
                    Toast.makeText(getActivity(),
                            getString(R.string.error_start_point), Toast.LENGTH_SHORT).show();
                } catch (WaypointRingNotEnteredException e) {
                    throw new AssertionError(
                            ""WaypointRingNotEnteredException when not in 3rd test"", e);
                }
            }
        });

        mTvTime = (TextView) view.findViewById(R.id.tvTimer);
        mTvPassColour = (TextView) view.findViewById(R.id.tvPassColour);
        mTvObjective = (TextView) view.findViewById(R.id.tvObjective);

        return view;
    }

    /**
     * Called after onCreateView. Starts listening for 6DoF events.
     */
    @Override
    public void onViewCreated(View view, Bundle savedInstanceState) {
        super.onViewCreated(view, savedInstanceState);
        mActivity.listenFor6DofData(this);
    }

    @Override
    protected void setupUILoop() {
        Runnable runnable = new Runnable() {
            @Override
            public void run() {
                if (mActivity == null || getActivity() == null) {
                    return;
                }

                String stringTimeRemaining;
                String decimalTimeRemaining = (mActivity.getTimeRemaining() / 1000f) + """";
                synchronized (TIMER_LOCK) {
                    stringTimeRemaining = String.format(getString(R.string.time_remaining), decimalTimeRemaining);
                }

                synchronized (TIMER_LOCK) {
                    if (mIsPassing) {
                        mTvPassColour.setBackgroundColor(getResources().getColor(R.color.green));
                    } else {
                        mTvPassColour.setBackgroundColor(getResources().getColor(R.color.red));
                    }
                }

                int waypointCount = mActivity.getUserGeneratedWaypoints(Manager.Lap.LAP_3).size();
                mTvObjective.setText(getObjectiveText(Manager.Lap.LAP_3, waypointCount));

                if (waypointCount < Manager.MAX_MARKER_NUMBER && !mResultGiven) {
                    mPlaceWaypointButton.setVisibility(View.VISIBLE);
                    mTvTime.setText(stringTimeRemaining);
                } else {
                    mTvTime.setText("""");
                }

                //Update the UI again in x milliseconds.
                if (mHandler != null) {
                    mHandler.postDelayed(this, UI_UPDATE_DELAY);
                }
            }
        };

        super.initUIHandler(runnable);
    }

    /**
     * Shows initial instruction dialog.
     */
    @Override
    protected void showInitialDialog() {
        AlertDialog.Builder builder = new AlertDialog.Builder(getActivity());

        builder.setMessage(R.string.phase2_initial_message)
                .setTitle(getResources().getStringArray(R.array.phase)[TestActivity.CTSTest.ROBUSTNESS.ordinal()])
                .setPositiveButton(R.string.got_it, null);

        AlertDialog dialog = builder.create();
        dialog.show();
    }

    @Override
    public void onResult(final ResultObject result) {
        getActivity().runOnUiThread(new Runnable() {
            @Override
            public void run() {
                mResultGiven = true;
                RobustnessResultDialog dialog = RobustnessResultDialog.newInstance(result);
                dialog.setTargetFragment(RobustnessFragment.this, DIALOG_FRAGMENT);
                dialog.show(getActivity().getFragmentManager(), ""ResultDialogFragment"");
                mPlaceWaypointButton.setVisibility(View.INVISIBLE);

                if (result.hasPassed() || BuildConfig.DEBUG) {
                    mBtnPass.setEnabled(true);
                    mBtnPass.setOnClickListener(new View.OnClickListener() {
                        @Override
                        public void onClick(View view) {
                            onReadyForPhase3();
                        }
                    });
                }
            }
        });
    }

    private void onReadyForPhase3() {
        mActivity.switchToStartFragment(TestActivity.CTSTest.COMPLEX_MOVEMENT);
    }

    @Override
    public void onNewRotationData(RotationData data) {
        synchronized (TIMER_LOCK) {
            mIsPassing = data.getRotationTestState();
        }

        if (mRenderer != null) {
            if (data.getRotationTestState()) {
                ((RobustnessRenderer) mRenderer).setLineColor(Colour.GREEN);
            } else {
                ((RobustnessRenderer) mRenderer).setLineColor(Colour.RED);
            }

            if (mActivity.getUserGeneratedWaypoints(Manager.Lap.LAP_3).size() > 0) {
                ((RobustnessRenderer) mRenderer).updateCurrentAngle(data.getCurrentAngle());
                ((RobustnessRenderer) mRenderer).updateTargetAngle(data.getTargetAngle());
            }
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.deviceowner.SensorToggleRestrictionTest"	"testCameraToggle_RestrictionSet_CannotChangeSensorPrivacy"	""	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/app/DeviceOwner/src/com/android/cts/deviceowner/SensorToggleRestrictionTest.java"	""	"public void testCameraToggle_RestrictionSet_CannotChangeSensorPrivacy() {
        if (!mSensorPrivacyManager.supportsSensorToggle(SensorPrivacyManager.Sensors.CAMERA)) {
            return;
        }
        assertFalse(""Camera sensor privacy should be off by default"",
                ShellIdentityUtils.invokeMethodWithShellPermissions(mSensorPrivacyManager,
                        m -> m.isSensorPrivacyEnabled(SensorPrivacyManager.Sensors.CAMERA)));

        mDevicePolicyManager.addUserRestriction(getWho(), UserManager.DISALLOW_CAMERA_TOGGLE);
        ShellIdentityUtils.invokeMethodWithShellPermissionsNoReturn(mSensorPrivacyManager,
                m -> m.setSensorPrivacy(OTHER, SensorPrivacyManager.Sensors.CAMERA, true));

        assertFalse(""Camera sensor privacy should not be enabled given admin restriction"",
                ShellIdentityUtils.invokeMethodWithShellPermissions(mSensorPrivacyManager,
                        m -> m.isSensorPrivacyEnabled(SensorPrivacyManager.Sensors.CAMERA)));
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.deviceowner.SensorToggleRestrictionTest"	"testMicrophoneToggle_RestrictionSet_CannotChangeSensorPrivacy"	""	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/app/DeviceOwner/src/com/android/cts/deviceowner/SensorToggleRestrictionTest.java"	""	"public void testMicrophoneToggle_RestrictionSet_CannotChangeSensorPrivacy() {
        if (!mSensorPrivacyManager.supportsSensorToggle(SensorPrivacyManager.Sensors.MICROPHONE)) {
            return;
        }
        assertFalse(""Microphone sensor privacy should be off by default"",
                ShellIdentityUtils.invokeMethodWithShellPermissions(mSensorPrivacyManager,
                        m -> m.isSensorPrivacyEnabled(SensorPrivacyManager.Sensors.MICROPHONE)));

        mDevicePolicyManager.addUserRestriction(getWho(), UserManager.DISALLOW_MICROPHONE_TOGGLE);
        ShellIdentityUtils.invokeMethodWithShellPermissionsNoReturn(mSensorPrivacyManager,
                m -> m.setSensorPrivacy(OTHER, SensorPrivacyManager.Sensors.MICROPHONE, true));

        assertFalse(""Microphone sensor privacy should not be enabled given admin restriction"",
                ShellIdentityUtils.invokeMethodWithShellPermissions(mSensorPrivacyManager,
                        m -> m.isSensorPrivacyEnabled(SensorPrivacyManager.Sensors.MICROPHONE)));
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.deviceowner.SensorToggleRestrictionTest"	"testCameraToggle_RestrictionSet_ResetSensorPrivacy"	""	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/app/DeviceOwner/src/com/android/cts/deviceowner/SensorToggleRestrictionTest.java"	""	"public void testCameraToggle_RestrictionSet_ResetSensorPrivacy() {
        if (!mSensorPrivacyManager.supportsSensorToggle(SensorPrivacyManager.Sensors.CAMERA)) {
            return;
        }
        ShellIdentityUtils.invokeMethodWithShellPermissionsNoReturn(mSensorPrivacyManager,
                m -> m.setSensorPrivacy(OTHER, SensorPrivacyManager.Sensors.CAMERA, true));

        mDevicePolicyManager.addUserRestriction(getWho(), UserManager.DISALLOW_CAMERA_TOGGLE);

        long deadline = System.nanoTime() + RESTRICTION_WAITING_TIMEOUT_NANO;
        while (System.nanoTime() < deadline) {
            if (!ShellIdentityUtils.invokeMethodWithShellPermissions(mSensorPrivacyManager,
                    m -> m.isSensorPrivacyEnabled(SensorPrivacyManager.Sensors.CAMERA))) {
                return;
            }
        }
        fail(""Camera sensor privacy did not get reset in time"");
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.deviceowner.SensorToggleRestrictionTest"	"testMicrophoneToggle_RestrictionSet_ResetSensorPrivacy"	""	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/app/DeviceOwner/src/com/android/cts/deviceowner/SensorToggleRestrictionTest.java"	""	"public void testMicrophoneToggle_RestrictionSet_ResetSensorPrivacy() {
        if (!mSensorPrivacyManager.supportsSensorToggle(SensorPrivacyManager.Sensors.MICROPHONE)) {
            return;
        }
        ShellIdentityUtils.invokeMethodWithShellPermissionsNoReturn(mSensorPrivacyManager,
                m -> m.setSensorPrivacy(OTHER, SensorPrivacyManager.Sensors.MICROPHONE, true));

        mDevicePolicyManager.addUserRestriction(getWho(), UserManager.DISALLOW_MICROPHONE_TOGGLE);

        long deadline = System.nanoTime() + RESTRICTION_WAITING_TIMEOUT_NANO;
        while (System.nanoTime() < deadline) {
            if (!ShellIdentityUtils.invokeMethodWithShellPermissions(mSensorPrivacyManager,
                    m -> m.isSensorPrivacyEnabled(SensorPrivacyManager.Sensors.MICROPHONE))) {
                return;
            }
        }
        fail(""Microphone sensor privacy did not get reset in time"");
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsAccelerometer"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsAccelerometer() {
        checkHifiVrSensorSupport(Sensor.TYPE_ACCELEROMETER);
    }

    @CddTest(requirement=""7.3.9/C-2-2"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsAccelerometerUncalibrated"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsAccelerometerUncalibrated() {
        // Uncalibrated accelerometer was not required before Android O
        if (PropertyUtil.getFirstApiLevel() >= Build.VERSION_CODES.O) {
            checkHifiVrSensorSupport(Sensor.TYPE_ACCELEROMETER_UNCALIBRATED);
        }
    }

    @CddTest(requirement=""7.3.9/C-2-3"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsGyroscope"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsGyroscope() {
        checkHifiVrSensorSupport(Sensor.TYPE_GYROSCOPE);
    }

    @CddTest(requirement=""7.3.9/C-2-4"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsGyroscopeUncalibrated"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsGyroscopeUncalibrated() {
        checkHifiVrSensorSupport(Sensor.TYPE_GYROSCOPE_UNCALIBRATED);
    }

    @CddTest(requirement=""7.3.9/C-2-5"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsGeoMagneticField"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsGeoMagneticField() {
        checkHifiVrSensorSupport(Sensor.TYPE_MAGNETIC_FIELD);
    }

    @CddTest(requirement=""7.3.9/C-2-6"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsMagneticFieldUncalibrated"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsMagneticFieldUncalibrated() {
        checkHifiVrSensorSupport(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED);
    }

    @CddTest(requirement=""7.3.9/C-2-7"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsPressure"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsPressure() {
        checkHifiVrSensorSupport(Sensor.TYPE_PRESSURE);
    }

    @CddTest(requirement=""7.3.9/C-2-8"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsGameRotationVector"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsGameRotationVector() {
        checkHifiVrSensorSupport(Sensor.TYPE_GAME_ROTATION_VECTOR);
    }

    @CddTest(requirement=""7.3.9/C-2-9"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsSignificantMotion"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsSignificantMotion() {
        checkHifiVrSensorSupport(Sensor.TYPE_SIGNIFICANT_MOTION);
    }

    @CddTest(requirement=""7.3.9/C-2-10"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsStepDetector"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsStepDetector() {
        checkHifiVrSensorSupport(Sensor.TYPE_STEP_DETECTOR);
    }

    @CddTest(requirement=""7.3.9/C-2-11"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsStepCounter"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsStepCounter() {
        checkHifiVrSensorSupport(Sensor.TYPE_STEP_COUNTER);
    }

    @CddTest(requirement=""7.3.9/C-2-12"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsTiltDetector"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsTiltDetector() {
        final int TYPE_TILT_DETECTOR = 22;
        checkHifiVrSensorSupport(TYPE_TILT_DETECTOR);
    }

    @CddTest(requirement=""7.3.1/C-3-1"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsGravityAndLinearAccelIfHasAG"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsGravityAndLinearAccelIfHasAG() {
        if (mHasAccel && mHasGyro) {
            assertTrue(hasSensorType(Sensor.TYPE_GRAVITY));
            assertTrue(hasSensorType(Sensor.TYPE_LINEAR_ACCELERATION));
        }
    }

    @CddTest(requirement=""7.3.1/C-4-1"")"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorSupportTest"	"testSupportsRotationVectorIfHasAGM"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorSupportTest.java"	""	"public void testSupportsRotationVectorIfHasAGM() {
        if (mHasAccel && mHasGyro && mHasMag) {
            assertTrue(hasSensorType(Sensor.TYPE_ROTATION_VECTOR));
        }
    }

    private boolean sensorRequiredForVrHighPerformanceMode(int sensorType) {
        if (sensorType == Sensor.TYPE_ACCELEROMETER ||
            sensorType == Sensor.TYPE_ACCELEROMETER_UNCALIBRATED ||
            sensorType == Sensor.TYPE_GYROSCOPE ||
            sensorType == Sensor.TYPE_GYROSCOPE_UNCALIBRATED ||
            sensorType == Sensor.TYPE_MAGNETIC_FIELD ||
            sensorType == Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED) {
            return true;
        } else {
            return false;
        }
    }

    private void checkHifiVrSensorSupport(int sensorType) {
        boolean isVrSensor = mVrHighPerformanceModeSupported &&
            sensorRequiredForVrHighPerformanceMode(sensorType);
        if (mAreHifiSensorsSupported || isVrSensor) {
            Sensor sensor = mSensorManager.getDefaultSensor(sensorType);
            assertTrue(sensor != null);
            if (isVrSensor && mIsVrHeadset) {
                assertTrue(sensor.isDirectChannelTypeSupported(SensorDirectChannel.TYPE_HARDWARE_BUFFER));
            }
        }
    }

    private boolean hasSensorType(int sensorType) {
        return (mSensorManager != null && mSensorManager.getDefaultSensor(sensorType) != null);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Utils.Path.Path"	"isUserGenerated"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Utils/Path/Path.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Utils.Path;

import com.android.cts.verifier.sensors.sixdof.Utils.Manager;
import com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointAreaCoveredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointDistanceException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointRingNotEnteredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointStartPointException;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Waypoint;

import java.util.ArrayList;

/**
 * Contains all the information of the current path.
 */
public abstract class Path {
    protected ArrayList<Waypoint> mCurrentPath = new ArrayList<>();
    protected ArrayList<Waypoint> mPathMarkers = new ArrayList<>();

    /**
     * Creates a waypoint and adds it to the path.
     *
     * @param coordinates   the coordinates to use for the waypoint.
     * @param userGenerated indicates whether the data was user created or system created.
     * @param currentLap    the lap the data was created in.
     * @throws WaypointDistanceException       if the location is too close to another.
     * @throws WaypointAreaCoveredException    if the area covered by the user is too little.
     * @throws WaypointStartPointException     if the location is not close enough to the start.
     * @throws WaypointRingNotEnteredException if a ring is not entered.
     */
    public void createWaypointAndAddToPath(
            float[] coordinates, boolean userGenerated, Manager.Lap currentLap)
            throws WaypointStartPointException, WaypointDistanceException,
            WaypointAreaCoveredException, WaypointRingNotEnteredException {
        if (userGenerated) {
            additionalChecks(coordinates);
        }
        Waypoint waypoint = new Waypoint(coordinates, userGenerated, currentLap);
        mCurrentPath.add(waypoint);
        if (waypoint.isUserGenerated()) {
            mPathMarkers.add(waypoint);
        }
    }

    protected float getLengthOfCurrentPath() {
        float length = 0.0f;

        // Start at index 1.
        for (int i = 1; i < mCurrentPath.size(); i++) {
            float distance = MathsUtils.distanceCalculationOnXYPlane(
                    mCurrentPath.get(i).getCoordinates(),
                    mCurrentPath.get(i - 1).getCoordinates());
            length += Math.abs(distance);
        }

        return length;
    }

    /**
     * Abstract method used by classes that extend this one to run additional functionality.
     *
     * @param coordinates the coordinates for the waypoint.
     * @throws WaypointDistanceException       if the location is too close to another.
     * @throws WaypointAreaCoveredException    if the area covered by the user is too little.
     * @throws WaypointStartPointException     if the location is not close enough to the start.
     * @throws WaypointRingNotEnteredException if a ring is not entered.
     */
    public abstract void additionalChecks(float[] coordinates)
            throws WaypointStartPointException, WaypointDistanceException,
            WaypointAreaCoveredException, WaypointRingNotEnteredException;

    /**
     * Removes the last maker in the current path.
     *
     * @return true of the first marker false if any other marker.
     */
    public boolean removeLastMarker() {
        Waypoint markerToRemove = mPathMarkers.get(mPathMarkers.size() - 1);
        mCurrentPath.remove(markerToRemove);
        mPathMarkers.remove(markerToRemove);
        return false;
    }

    /**
     * Returns the current path.
     */
    public ArrayList<Waypoint> getCurrentPath() {
        return new ArrayList<>(mCurrentPath);
    }

    /**
     * Returns the markers for the current path.
     */
    public ArrayList<Waypoint> getPathMarkers() {
        return new ArrayList<>(mPathMarkers);
    }

    /**
     * Returns the size of the path.
     */
    public int getCurrentPathSize() {
        return mCurrentPath.size();
    }

    /**
     * Returns the number if markers.
     */
    public int getPathMarkersSize() {
        return mPathMarkers.size();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingFifoTest"	"testAccelerometerFifoLength"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingFifoTest.java"	""	"public void testAccelerometerFifoLength() throws Throwable {
        if (!mHasHifiSensors) return;
        runBatchingSensorFifoTest(
                Sensor.TYPE_ACCELEROMETER,
                getReservedFifoLength(Sensor.TYPE_ACCELEROMETER));
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingFifoTest"	"testUncalMagnetometerFifoLength"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingFifoTest.java"	""	"public void testUncalMagnetometerFifoLength() throws Throwable {
        if (!mHasHifiSensors) return;
        runBatchingSensorFifoTest(
                Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED,
                getReservedFifoLength(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED));
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingFifoTest"	"testPressureFifoLength"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingFifoTest.java"	""	"public void testPressureFifoLength() throws Throwable {
        if (!mHasHifiSensors) return;
        runBatchingSensorFifoTest(
                Sensor.TYPE_PRESSURE,
                getReservedFifoLength(Sensor.TYPE_PRESSURE));
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.SensorBatchingFifoTest"	"testGameRotationVectorFifoLength"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/SensorBatchingFifoTest.java"	""	"public void testGameRotationVectorFifoLength() throws Throwable {
        if (!mHasHifiSensors) return;
        runBatchingSensorFifoTest(
                Sensor.TYPE_GAME_ROTATION_VECTOR,
                getReservedFifoLength(Sensor.TYPE_GAME_ROTATION_VECTOR));
    }

    private int getReservedFifoLength(int sensorType) {
        Sensor sensor = mSensorManager.getDefaultSensor(sensorType);
        assertTrue(String.format(""sensor of type=%d (null)"", sensorType), sensor != null);
        return sensor.getFifoReservedEventCount();
    }

    private void runBatchingSensorFifoTest(int sensorType, int fifoLength) throws Throwable {
        if (fifoLength == 0) {
            return;
        }
        Sensor sensor = mSensorManager.getDefaultSensor(sensorType);
        TestSensorEnvironment environment =  new TestSensorEnvironment(getContext(),
                sensor,
                false, /* sensorMightHaveMoreListeners */
                sensor.getMinDelay(),
                Integer.MAX_VALUE /*maxReportLatencyUs*/);

        int preFlushMs = 2000;  // 2 sec to make sure there is sample at the time of flush
        int postFlushMs = environment.getExpectedSamplingPeriodUs() * 100 /1000;
        int testFlushMs =
                environment.getSensor().getFifoReservedEventCount() *
                environment.getExpectedSamplingPeriodUs() / (int)(1000 / 1.2); // 120%

        TestSensorOperation op = TestSensorOperation.createFlushOperation(
                environment, new int [] { preFlushMs, testFlushMs, postFlushMs }, -1);

        op.addVerification(FifoLengthVerification.getDefault(environment));
        op.execute(getCurrentTestNode());
        op.getStats().log(TAG);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.JitterVerification"	"isSensorSamplingRateOverloaded"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/JitterVerification.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers.sensorverification;

import android.content.Context;
import android.content.pm.PackageManager;

import android.util.Log;
import android.hardware.Sensor;
import android.hardware.cts.helpers.SensorCtsHelper;
import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEvent;
import android.util.SparseIntArray;

import java.util.ArrayList;
import java.util.LinkedList;
import java.util.List;
import junit.framework.Assert;

/**
 * A {@link ISensorVerification} which verifies that the sensor jitter is in an acceptable range.
 */
public class JitterVerification extends AbstractSensorVerification {
    public static final String PASSED_KEY = ""jitter_passed"";

    // sensorType: threshold (% of expected period)
    private static final SparseIntArray DEFAULTS = new SparseIntArray(12);
    // Max allowed jitter in +/- sense (in percentage).
    private static final int GRACE_FACTOR = 2;
    private static final int THRESHOLD_PERCENT_FOR_HIFI_SENSORS = 1 * GRACE_FACTOR;

    // Margin sample intervals that considered outliers, lower and higher margin is discarded
    // before verification
    private static final float OUTLIER_MARGIN = 0.025f; //2.5%

    static {
        // Use a method so that the @deprecation warning can be set for that method only
        setDefaults();
    }

    private final float     mOutlierMargin;
    private final long      mThresholdNs;
    private final long      mExpectedPeriodNs; // for error message only
    private final List<Long> mTimestamps = new LinkedList<Long>();

    /**
     * Construct a {@link JitterVerification}
     *
     * @param thresholdAsPercentage the acceptable margin of error as a percentage
     */
    public JitterVerification(float outlierMargin, long thresholdNs, long expectedPeriodNs) {
        mExpectedPeriodNs = expectedPeriodNs;
        mOutlierMargin = outlierMargin;
        mThresholdNs = thresholdNs;
    }

    /**
     * Get the default {@link JitterVerification} for a sensor.
     *
     * @param environment the test environment
     * @return the verification or null if the verification does not apply to the sensor.
     */
    public static JitterVerification getDefault(TestSensorEnvironment environment) {
        int sensorType = environment.getSensor().getType();

        int thresholdPercent = DEFAULTS.get(sensorType, -1);
        if (thresholdPercent == -1) {
            return null;
        }
        boolean hasHifiSensors = environment.getContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_HIFI_SENSORS);
        if (hasHifiSensors) {
           thresholdPercent = THRESHOLD_PERCENT_FOR_HIFI_SENSORS;
        }

        long expectedPeriodNs = (long) environment.getExpectedSamplingPeriodUs() * 1000;
        long jitterThresholdNs = expectedPeriodNs * thresholdPercent * 2 / 100; // *2 is for +/-
        return new JitterVerification(OUTLIER_MARGIN, jitterThresholdNs, expectedPeriodNs);
    }

    /**
     * Verify that the 95th percentile of the jitter is in the acceptable range. Add
     * {@value #PASSED_KEY} and {@value SensorStats#JITTER_95_PERCENTILE_PERCENT_KEY} keys to
     * {@link SensorStats}.
     *
     * @throws AssertionError if the verification failed.
     */
    @Override
    public void verify(TestSensorEnvironment environment, SensorStats stats) {
        int timestampsCount = mTimestamps.size();
        if (timestampsCount < 2 || environment.isSensorSamplingRateOverloaded()) {
            // the verification is not reliable in environments under load
            stats.addValue(PASSED_KEY, true);
            return;
        }

        List<Long> deltas = getDeltaValues();
        List<Long> percentileValues =
                SensorCtsHelper.getPercentileValue(deltas, mOutlierMargin, 1 - mOutlierMargin);

        double normalizedRange =
                (double)(percentileValues.get(1) - percentileValues.get(0)) / mThresholdNs;

        double percentageJitter =
                (double)(percentileValues.get(1) - percentileValues.get(0)) /
                        mExpectedPeriodNs / 2 * 100; //one side variation comparing to sample time

        stats.addValue(SensorStats.JITTER_95_PERCENTILE_PERCENT_KEY, percentageJitter);

        boolean success = normalizedRange <= 1.0;
        stats.addValue(PASSED_KEY, success);

        if (!success) {
            String message = String.format(
                    ""Jitter out of range: requested period = %dns, "" +
                    ""jitter min, max, range (95th percentile) = (%dns, %dns, %dns), "" +
                    ""jitter expected range <= %dns"",
                    mExpectedPeriodNs,
                    percentileValues.get(0), percentileValues.get(1),
                    percentileValues.get(1) - percentileValues.get(0),
                    mThresholdNs);
            Assert.fail(message);
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public JitterVerification clone() {
        return new JitterVerification(mOutlierMargin, mThresholdNs, mExpectedPeriodNs);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    protected void addSensorEventInternal(TestSensorEvent event) {
        mTimestamps.add(event.timestamp);
    }

    /**
     * Get the list of delta values. Exposed for unit testing.
     */
    List<Long> getDeltaValues() {
        List<Long> deltas = new ArrayList<Long>(mTimestamps.size() - 1);
        for (int i = 1; i < mTimestamps.size(); i++) {
            deltas.add(mTimestamps.get(i) - mTimestamps.get(i - 1));
        }
        return deltas;
    }

    @SuppressWarnings(""deprecation"")
    private static void setDefaults() {
        DEFAULTS.put(Sensor.TYPE_ACCELEROMETER, Integer.MAX_VALUE);
        DEFAULTS.put(Sensor.TYPE_MAGNETIC_FIELD, Integer.MAX_VALUE);
        DEFAULTS.put(Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED, Integer.MAX_VALUE);
        DEFAULTS.put(Sensor.TYPE_GYROSCOPE, Integer.MAX_VALUE);
        DEFAULTS.put(Sensor.TYPE_GYROSCOPE_UNCALIBRATED, Integer.MAX_VALUE);
        DEFAULTS.put(Sensor.TYPE_ORIENTATION, Integer.MAX_VALUE);
        DEFAULTS.put(Sensor.TYPE_PRESSURE, Integer.MAX_VALUE);
        DEFAULTS.put(Sensor.TYPE_GRAVITY, Integer.MAX_VALUE);
        DEFAULTS.put(Sensor.TYPE_LINEAR_ACCELERATION, Integer.MAX_VALUE);
        DEFAULTS.put(Sensor.TYPE_ROTATION_VECTOR, Integer.MAX_VALUE);
        DEFAULTS.put(Sensor.TYPE_GAME_ROTATION_VECTOR, Integer.MAX_VALUE);
        DEFAULTS.put(Sensor.TYPE_GEOMAGNETIC_ROTATION_VECTOR, Integer.MAX_VALUE);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.permission.cts.PermissionControllerTest"	"OnRevokeRuntimePermissionsCallback"	"CtsPermissionTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/permission/src/android/permission/cts/PermissionControllerTest.java"	""	"/*
 *.
 */

package android.permission.cts;

import static android.Manifest.permission.ACCESS_BACKGROUND_LOCATION;
import static android.Manifest.permission.ACCESS_COARSE_LOCATION;
import static android.Manifest.permission.ACCESS_FINE_LOCATION;
import static android.Manifest.permission.BODY_SENSORS;
import static android.Manifest.permission.READ_CALENDAR;
import static android.Manifest.permission.READ_CONTACTS;
import static android.Manifest.permission.WRITE_CALENDAR;
import static android.app.AppOpsManager.MODE_ALLOWED;
import static android.app.AppOpsManager.MODE_FOREGROUND;
import static android.app.AppOpsManager.permissionToOp;
import static android.content.pm.PackageManager.PERMISSION_DENIED;
import static android.permission.PermissionControllerManager.COUNT_ONLY_WHEN_GRANTED;
import static android.permission.PermissionControllerManager.REASON_INSTALLER_POLICY_VIOLATION;
import static android.permission.PermissionControllerManager.REASON_MALWARE;
import static android.permission.cts.PermissionUtils.grantPermission;
import static android.permission.cts.PermissionUtils.isGranted;
import static android.permission.cts.PermissionUtils.isPermissionGranted;

import static com.android.compatibility.common.util.SystemUtil.callWithShellPermissionIdentity;
import static com.android.compatibility.common.util.SystemUtil.eventually;
import static com.android.compatibility.common.util.SystemUtil.runShellCommand;
import static com.android.compatibility.common.util.SystemUtil.runWithShellPermissionIdentity;

import static com.google.common.truth.Truth.assertThat;

import static java.util.Collections.singletonList;

import android.app.AppOpsManager;
import android.app.UiAutomation;
import android.content.Context;
import android.content.pm.PermissionGroupInfo;
import android.permission.PermissionControllerManager;
import android.permission.RuntimePermissionPresentationInfo;
import android.platform.test.annotations.AppModeFull;

import androidx.annotation.NonNull;
import androidx.test.InstrumentationRegistry;
import androidx.test.runner.AndroidJUnit4;

import org.junit.After;
import org.junit.AfterClass;
import org.junit.Before;
import org.junit.BeforeClass;
import org.junit.Test;
import org.junit.runner.RunWith;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.Map;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.Executor;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicReference;

/**
 * Test {@link PermissionControllerManager}
 */
@RunWith(AndroidJUnit4.class)
@AppModeFull(reason = ""Instant apps cannot talk to permission controller"")
public class PermissionControllerTest {
    private static final String APK =
            ""/data/local/tmp/cts/permissions/CtsAppThatAccessesLocationOnCommand.apk"";
    private static final String APP = ""android.permission.cts.appthataccesseslocation"";
    private static final String APK2 =
            ""/data/local/tmp/cts/permissions/""
                    + ""CtsAppThatRequestsCalendarContactsBodySensorCustomPermission.apk"";
    private static final String APP2 = ""android.permission.cts.appthatrequestcustompermission"";
    private static final String CUSTOM_PERMISSION =
            ""android.permission.cts.appthatrequestcustompermission.TEST_PERMISSION"";

    private static final UiAutomation sUiAutomation =
            InstrumentationRegistry.getInstrumentation().getUiAutomation();
    private static final Context sContext = InstrumentationRegistry.getTargetContext();
    private static final PermissionControllerManager sController =
            sContext.getSystemService(PermissionControllerManager.class);

    @Before
    @After
    public void resetAppState() {
        runWithShellPermissionIdentity(() -> {
            sUiAutomation.grantRuntimePermission(APP, ACCESS_FINE_LOCATION);
            sUiAutomation.grantRuntimePermission(APP, ACCESS_BACKGROUND_LOCATION);
            setAppOp(APP, ACCESS_FINE_LOCATION, MODE_ALLOWED);
        });
    }

    @BeforeClass
    public static void installApp() {
        runShellCommand(""pm install -r -g "" + APK);
        runShellCommand(""pm install -r "" + APK2);
    }

    @AfterClass
    public static void uninstallApp() {
        runShellCommand(""pm uninstall "" + APP);
        runShellCommand(""pm uninstall "" + APP2);
    }

    private @NonNull Map<String, List<String>> revokePermissions(
            @NonNull Map<String, List<String>> request, boolean doDryRun, int reason,
            @NonNull Executor executor) throws Exception {
        AtomicReference<Map<String, List<String>>> result = new AtomicReference<>();

        sController.revokeRuntimePermissions(request, doDryRun, reason, executor,
                new PermissionControllerManager.OnRevokeRuntimePermissionsCallback() {
                    @Override
                    public void onRevokeRuntimePermissions(@NonNull Map<String, List<String>> r) {
                        synchronized (result) {
                            result.set(r);
                            result.notifyAll();
                        }
                    }
                });

        synchronized (result) {
            while (result.get() == null) {
                result.wait();
            }
        }

        return result.get();
    }

    private @NonNull Map<String, List<String>> revokePermissions(
            @NonNull Map<String, List<String>> request, boolean doDryRun, boolean adoptShell)
            throws Exception {
        if (adoptShell) {
            Map<String, List<String>> revokeRet =
                    callWithShellPermissionIdentity(() -> revokePermissions(
                            request, doDryRun, REASON_MALWARE, sContext.getMainExecutor()));
            return revokeRet;
        }
        return revokePermissions(request, doDryRun, REASON_MALWARE, sContext.getMainExecutor());
    }

    private @NonNull Map<String, List<String>> revokePermissions(
            @NonNull Map<String, List<String>> request, boolean doDryRun) throws Exception {
        return revokePermissions(request, doDryRun, true);
    }

    private void setAppOp(@NonNull String pkg, @NonNull String perm, int mode) throws Exception {
        sContext.getSystemService(AppOpsManager.class).setUidMode(permissionToOp(perm),
                sContext.getPackageManager().getPackageUid(pkg, 0), mode);
    }

    private Map<String, List<String>> buildRevokeRequest(@NonNull String app,
            @NonNull String permission) {
        return Collections.singletonMap(app, singletonList(permission));
    }

    private void assertRuntimePermissionLabelsAreValid(List<String> runtimePermissions,
            List<RuntimePermissionPresentationInfo> permissionInfos, int expectedRuntimeGranted,
            String app) throws Exception {
        int numRuntimeGranted = 0;
        for (String permission : runtimePermissions) {
            if (isPermissionGranted(app, permission)) {
                numRuntimeGranted++;
            }
        }
        assertThat(numRuntimeGranted).isEqualTo(expectedRuntimeGranted);

        ArrayList<CharSequence> maybeStandardPermissionLabels = new ArrayList<>();
        ArrayList<CharSequence> nonStandardPermissionLabels = new ArrayList<>();
        for (PermissionGroupInfo permGroup : sContext.getPackageManager().getAllPermissionGroups(
                0)) {
            CharSequence permissionGroupLabel = permGroup.loadLabel(sContext.getPackageManager());
            if (permGroup.packageName.equals(""android"")) {
                maybeStandardPermissionLabels.add(permissionGroupLabel);
            } else {
                nonStandardPermissionLabels.add(permissionGroupLabel);
            }
        }

        int numInfosGranted = 0;

        for (RuntimePermissionPresentationInfo permissionInfo : permissionInfos) {
            CharSequence permissionGroupLabel = permissionInfo.getLabel();

            // PermissionInfo should be included in exactly one of existing (possibly) standard
            // or nonstandard permission groups
            if (permissionInfo.isStandard()) {
                assertThat(maybeStandardPermissionLabels).contains(permissionGroupLabel);
            } else {
                assertThat(nonStandardPermissionLabels).contains(permissionGroupLabel);
            }
            if (permissionInfo.isGranted()) {
                numInfosGranted++;
            }
        }

        // Each permissionInfo represents one or more runtime permissions, but we don't have a
        // mapping, so we check that we have at least as many runtimePermissions as permissionInfos
        assertThat(numRuntimeGranted).isAtLeast(numInfosGranted);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.permission.cts.PermissionControllerTest"	"getAppPermissionsForCustomApp"	"CtsPermissionTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/permission/src/android/permission/cts/PermissionControllerTest.java"	""	"public void getAppPermissionsForCustomApp() throws Exception {
        CompletableFuture<List<RuntimePermissionPresentationInfo>> futurePermissionInfos =
                new CompletableFuture<>();

        // Grant all requested permissions except READ_CALENDAR
        sUiAutomation.grantRuntimePermission(APP2, CUSTOM_PERMISSION);
        PermissionUtils.grantPermission(APP2, BODY_SENSORS);
        PermissionUtils.grantPermission(APP2, READ_CONTACTS);
        PermissionUtils.grantPermission(APP2, WRITE_CALENDAR);

        List<String> runtimePermissions;
        List<RuntimePermissionPresentationInfo> permissionInfos;
        sUiAutomation.adoptShellPermissionIdentity();
        try {
            sController.getAppPermissions(APP2, futurePermissionInfos::complete, null);
            runtimePermissions = PermissionUtils.getRuntimePermissions(APP2);

            permissionInfos = futurePermissionInfos.get();
        } finally {
            sUiAutomation.dropShellPermissionIdentity();
        }

        assertThat(permissionInfos).isNotEmpty();
        assertThat(runtimePermissions.size()).isEqualTo(5);
        assertRuntimePermissionLabelsAreValid(runtimePermissions, permissionInfos, 4, APP2);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.EventSanitizationTestActivity"	"EventSanitizationTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/EventSanitizationTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.hardware.TriggerEvent;
import android.hardware.TriggerEventListener;
import android.hardware.cts.helpers.SensorNotSupportedException;
import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.base.SensorCtsVerifierTestActivity;
import junit.framework.Assert;

import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

/**
 * Tests about event policy when the observer's UID is idle.
 */
public class EventSanitizationTestActivity extends SensorCtsVerifierTestActivity {
    public EventSanitizationTestActivity() {
        super(EventSanitizationTestActivity.class);
    }

    // time for the test to wait for an event
    private static final int EVENT_TIMEOUT = 30;

    @Override
    protected void activitySetUp() throws Exception {
        getTestLogger().logInstructions(R.string.snsr_event_sanitization_test_setup);
        waitForUserToBegin();
    }

    @Override
    protected void activityCleanUp() throws Exception {
        getTestLogger().logInstructions(R.string.snsr_event_sanitization_test_cleanup);
        waitForUserToContinue();
    }

    /**
     * Test that no trigger events are triggered while the UID is idle.
     */
    public String testNoTriggerEventsWhileUidIdle() throws Exception {
        // Not significant motion sensor, nothing to do.
        final SensorManager sensorManager = getApplicationContext()
                .getSystemService(SensorManager.class);
        final Sensor sensor = sensorManager.getDefaultSensor(
                Sensor.TYPE_SIGNIFICANT_MOTION);
        if (sensor == null) {
            throw new SensorNotSupportedException(Sensor.TYPE_SIGNIFICANT_MOTION);
        }

        // Let us begin.
        final SensorTestLogger logger = getTestLogger();
        logger.logInstructions(R.string.snsr_significant_motion_test_uid_idle);
        waitForUserToBegin();

        // Watch for the trigger event.
        final CountDownLatch latch = new CountDownLatch(1);
        final TriggerEventListener listener = new TriggerEventListener() {
            @Override
            public void onTrigger(TriggerEvent event) {
                latch.countDown();
            }
        };
        sensorManager.requestTriggerSensor(listener, sensor);

        // Tell the user now when the test completes.
        logger.logWaitForSound();

        // We shouldn't be getting an event.
        try {
            Assert.assertFalse(getString(R.string
                    .snsr_significant_motion_test_uid_idle_expectation),
                    latch.await(EVENT_TIMEOUT, TimeUnit.SECONDS));
        } finally {
            sensorManager.cancelTriggerSensor(listener, sensor);
            playSound();
        }

        return null;
    }

    /**
     * Test that no on-change events are triggered while the UID is idle.
     */
    public String testNoOnChangeEventsWhileUidIdle() throws Exception {
        // Not significant motion sensor, nothing to do.
        final SensorManager sensorManager = getApplicationContext()
                .getSystemService(SensorManager.class);
        final Sensor sensor = sensorManager.getDefaultSensor(
                Sensor.TYPE_PROXIMITY);
        if (sensor == null) {
            throw new SensorNotSupportedException(Sensor.TYPE_PROXIMITY);
        }

        // Let us begin.
        final SensorTestLogger logger = getTestLogger();
        logger.logInstructions(R.string.snsr_proximity_test_uid_idle);
        waitForUserToBegin();

        // Watch for the change event.
        final CountDownLatch latch = new CountDownLatch(1);
        final SensorEventListener listener = new SensorEventListener() {
            @Override
            public void onSensorChanged(SensorEvent event) {
                latch.countDown();
            }

            @Override
            public void onAccuracyChanged(Sensor sensor, int accuracy) {
                /* do nothing */
            }
        };
        sensorManager.registerListener(listener, sensor,
                sensor.getMinDelay(), sensor.getMaxDelay());

        // Tell the user now when the test completes.
        logger.logWaitForSound();

        // We shouldn't be getting an event.
        try {
            Assert.assertFalse(getString(R.string
                    .snsr_proximity_test_uid_idle_expectation),
                    latch.await(EVENT_TIMEOUT, TimeUnit.SECONDS));
        } finally {
            sensorManager.unregisterListener(listener, sensor);
            playSound();
        }

        return null;
    }
}"	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.OfflineSessionTest"	"testInvalidOutput"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/OfflineSessionTest.java"	""	"public void testInvalidOutput() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                Log.i(TAG, ""Testing camera device "" + mCameraIdsUnderTest[i]);

                if (!mAllStaticInfo.get(mCameraIdsUnderTest[i]).isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support color outputs, skipping"");
                    continue;
                }

                if (!mAllStaticInfo.get(mCameraIdsUnderTest[i]).isOfflineProcessingSupported()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support offline processing, skipping"");
                    continue;
                }

                openDevice(mCameraIdsUnderTest[i]);

                CaptureRequest.Builder previewRequest =
                        mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
                CaptureRequest.Builder stillCaptureRequest =
                        mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
                Size previewSize = mOrderedPreviewSizes.get(0);
                Size stillSize = mOrderedStillSizes.get(0);
                SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
                SimpleImageReaderListener imageListener = new SimpleImageReaderListener();

                startPreview(previewRequest, previewSize, resultListener);

                CaptureResult result = resultListener.getCaptureResult(WAIT_FOR_FRAMES_TIMEOUT_MS);

                Long timestamp = result.get(CaptureResult.SENSOR_TIMESTAMP);
                assertNotNull(""Can't read a capture result timestamp"", timestamp);

                CaptureResult result2 = resultListener.getCaptureResult(WAIT_FOR_FRAMES_TIMEOUT_MS);

                Long timestamp2 = result2.get(CaptureResult.SENSOR_TIMESTAMP);
                assertNotNull(""Can't read a capture result 2 timestamp"", timestamp2);

                assertTrue(""Bad timestamps"", timestamp2 > timestamp);

                createImageReader(stillSize, ImageFormat.JPEG, MAX_READER_IMAGES, imageListener);

                BlockingOfflineSessionCallback offlineCb = new BlockingOfflineSessionCallback();

                try {
                    ArrayList<Surface> offlineSurfaces = new ArrayList<Surface>();
                    offlineSurfaces.add(mReaderSurface);
                    mSession.switchToOffline(offlineSurfaces, new HandlerExecutor(mHandler),
                            offlineCb);
                    fail(""Offline session switch accepts unregistered output surface"");
                } catch (IllegalArgumentException e) {
                    //Expected
                }

                if (mSession.supportsOfflineProcessing(mPreviewSurface)) {
                    ArrayList<Surface> offlineSurfaces = new ArrayList<Surface>();
                    offlineSurfaces.add(mPreviewSurface);
                    mSession.switchToOffline(offlineSurfaces, new HandlerExecutor(mHandler),
                            offlineCb);
                    // We only have a single repeating request, in this case the camera
                    // implementation should fail to find any capture requests that can
                    // be migrated to offline mode and notify the failure accordingly.
                    offlineCb.waitForState(BlockingOfflineSessionCallback.STATE_SWITCH_FAILED,
                            WAIT_FOR_STATE_TIMEOUT_MS);
                } else {
                    stopPreview();
                }

                closeImageReader();
            } finally {
                closeDevice();
            }
        }
    }

    /**
     * Test camera callback sequence during and after offline session switch.
     *
     * <p>Camera clients must receive respective capture results or failures for all
     * non-offline outputs after the offline switch call returns.
     * In case the switch was successful clients must be notified about the
     * remaining offline requests via the registered offline callback.</p>
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.OfflineSessionTest"	"testOfflineHEIC"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/OfflineSessionTest.java"	""	"public void testOfflineHEIC() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                Log.i(TAG, ""Testing camera2 API for camera device "" + mCameraIdsUnderTest[i]);

                if (!mAllStaticInfo.get(mCameraIdsUnderTest[i]).isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support color outputs, skipping"");
                    continue;
                }

                if (!mAllStaticInfo.get(mCameraIdsUnderTest[i]).isOfflineProcessingSupported()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support offline processing, skipping"");
                    continue;
                }

                if (!mAllStaticInfo.get(mCameraIdsUnderTest[i]).isHeicSupported()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support HEIC, skipping"");
                    continue;
                }

                List<Size> heicSizes = CameraTestUtils.getSupportedHeicSizes(
                        mCameraIdsUnderTest[i], mCameraManager, null /*bound*/);
                openDevice(mCameraIdsUnderTest[i]);
                camera2OfflineSessionTest(mCameraIdsUnderTest[i], heicSizes.get(0),
                        ImageFormat.HEIC, OfflineTestSequence.NoExtraSteps);
            } finally {
                closeDevice();
            }
        }
    }

    /**
     * Test camera offline session behavior after close and reopen.
     *
     * <p> Verify that closing the initial camera device and opening the same
     * sensor during offline processing does not have any unexpected side effects.</p>
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.OfflineSessionTest"	"testUnsupportedOfflineSessionOutputs"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/OfflineSessionTest.java"	""	"public void testUnsupportedOfflineSessionOutputs() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                Log.i(TAG, ""Testing camera2 API for camera device "" + mCameraIdsUnderTest[i]);

                if (!mAllStaticInfo.get(mCameraIdsUnderTest[i]).isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support color outputs, skipping"");
                    continue;
                }

                if (!mAllStaticInfo.get(mCameraIdsUnderTest[i]).isOfflineProcessingSupported()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support offline processing, skipping"");
                    continue;
                }

                openDevice(mCameraIdsUnderTest[i]);
                camera2UnsupportedOfflineOutputTest(true /*useSurfaceGroup*/);
                camera2UnsupportedOfflineOutputTest(false /*useSurfaceGroup*/);
            } finally {
                closeDevice();
            }
        }
    }

    private void checkForSequenceAbort(SimpleCaptureCallback resultListener, int sequenceId) {
        ArrayList<Integer> abortedSeq = resultListener.geAbortedSequences(
                1 /*maxNumbAborts*/);
        assertNotNull(""No aborted capture sequence ids present"", abortedSeq);
        assertTrue(""Unexpected number of aborted capture sequence ids : "" +
                abortedSeq.size() + "" expected 1"", abortedSeq.size() == 1);
        assertTrue(""Unexpected abort capture sequence id: "" +
                abortedSeq.get(0).intValue() + "" expected capture sequence id: "" +
                sequenceId, abortedSeq.get(0).intValue() == sequenceId);
    }

    private void verifyCaptureResults(SimpleCaptureCallback resultListener,
            SimpleImageReaderListener imageListener, int sequenceId, boolean offlineResults)
            throws Exception {
        long sequenceLastFrameNumber = resultListener.getCaptureSequenceLastFrameNumber(
                sequenceId, 0 /*timeoutMs*/);

        long lastFrameNumberReceived = -1;
        while (resultListener.hasMoreResults()) {
            TotalCaptureResult result = resultListener.getTotalCaptureResult(0 /*timeout*/);
            if (lastFrameNumberReceived < result.getFrameNumber()) {
                lastFrameNumberReceived = result.getFrameNumber();
            }

            if (imageListener != null) {
                long resultTimestamp = result.get(CaptureResult.SENSOR_TIMESTAMP);
                Image offlineImage = imageListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
                assertEquals(""Offline image timestamp: "" + offlineImage.getTimestamp() +
                        "" doesn't match with the result timestamp: "" + resultTimestamp,
                        offlineImage.getTimestamp(), resultTimestamp);
            }
        }

        while (resultListener.hasMoreFailures()) {
            ArrayList<CaptureFailure> failures = resultListener.getCaptureFailures(
                    /*maxNumFailures*/ 1);
            for (CaptureFailure failure : failures) {
                if (lastFrameNumberReceived < failure.getFrameNumber()) {
                    lastFrameNumberReceived = failure.getFrameNumber();
                }
            }
        }

        String assertString = offlineResults ?
                ""Last offline frame number from "" +
                ""onCaptureSequenceCompleted (%d) doesn't match the last frame number "" +
                ""received from results/failures (%d)"" :
                ""Last frame number from onCaptureSequenceCompleted "" +
                ""(%d) doesn't match the last frame number received from "" +
                ""results/failures (%d)"";
        assertEquals(String.format(assertString, sequenceLastFrameNumber, lastFrameNumberReceived),
                sequenceLastFrameNumber, lastFrameNumberReceived);
    }

    /**
     * Verify offline session behavior during common use cases
     *
     * @param cameraId      Id of the camera device under test
     * @param offlineSize   The offline surface size
     * @param offlineFormat The offline surface pixel format
     * @param testSequence  Specific scenario to be verified
     * @return true if the offline session switch is successful, false if there is any failure.
     */
    private boolean camera2OfflineSessionTest(String cameraId, Size offlineSize, int offlineFormat,
            OfflineTestSequence testSequence) throws Exception {
        boolean ret = false;
        int remoteOfflinePID = -1;
        Size previewSize = mOrderedPreviewSizes.get(0);
        for (Size sz : mOrderedPreviewSizes) {
            if (sz.getWidth() <= MANDATORY_STREAM_BOUND.getWidth() && sz.getHeight() <=
                    MANDATORY_STREAM_BOUND.getHeight()) {
                previewSize = sz;
                break;
            }
        }
        Size privateSize = previewSize;
        if (mAllStaticInfo.get(cameraId).isPrivateReprocessingSupported()) {
            privateSize = mAllStaticInfo.get(cameraId).getSortedSizesForInputFormat(
                    ImageFormat.PRIVATE, MANDATORY_STREAM_BOUND).get(0);
        }

        CaptureRequest.Builder previewRequest =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        CaptureRequest.Builder stillCaptureRequest =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        SimpleCaptureCallback regularResultListener = new SimpleCaptureCallback();
        SimpleCaptureCallback offlineResultListener = new SimpleCaptureCallback();
        SimpleImageReaderListener imageListener = new SimpleImageReaderListener();
        ImageReader privateReader = null;
        ImageReader yuvCallbackReader = null;
        ImageReader jpegReader = null;
        int repeatingSeqId = -1;

        // Update preview size.
        updatePreviewSurface(previewSize);

        // Create ImageReader.
        createImageReader(offlineSize, offlineFormat, MAX_READER_IMAGES, imageListener);

        // Configure output streams with preview and offline streams.
        ArrayList<Surface> outputSurfaces = new ArrayList<Surface>();
        outputSurfaces.add(mPreviewSurface);
        outputSurfaces.add(mReaderSurface);
        final CameraCaptureSession.StateCallback sessionCb = mock(
                CameraCaptureSession.StateCallback.class);
        mSessionListener = new BlockingSessionCallback(sessionCb);
        mSession = configureCameraSession(mCamera, outputSurfaces, mSessionListener, mHandler);

        if (!mSession.supportsOfflineProcessing(mReaderSurface)) {
            Log.i(TAG, ""Camera does not support offline processing for still capture output"");
            return false;
        }

        // Configure the requests.
        previewRequest.addTarget(mPreviewSurface);
        stillCaptureRequest.addTarget(mReaderSurface);


        ArrayList<Integer> allowedOfflineStates = new ArrayList<Integer>();
        allowedOfflineStates.add(BlockingOfflineSessionCallback.STATE_READY);
        allowedOfflineStates.add(BlockingOfflineSessionCallback.STATE_SWITCH_FAILED);
        ArrayList<Surface> offlineSurfaces = new ArrayList<Surface>();
        offlineSurfaces.add(mReaderSurface);
        final CameraOfflineSessionCallback mockOfflineCb = mock(CameraOfflineSessionCallback.class);
        BlockingOfflineSessionCallback offlineCb = new BlockingOfflineSessionCallback(
                mockOfflineCb);
        ArrayList<CaptureRequest> offlineRequestList = new ArrayList<CaptureRequest>();
        for (int i = 0; i < MAX_READER_IMAGES; i++) {
            offlineRequestList.add(stillCaptureRequest.build());
        }

        if (testSequence != OfflineTestSequence.RepeatingSequenceAbort) {
            repeatingSeqId = mSession.setRepeatingRequest(previewRequest.build(), resultListener,
                    mHandler);
            checkInitialResults(resultListener);
        }

        int offlineSeqId = mSession.captureBurst(offlineRequestList, offlineResultListener,
                mHandler);

        if (testSequence == OfflineTestSequence.RepeatingSequenceAbort) {
            // Submit the preview repeating request after the offline burst so it can be delayed
            // long enough and fail to reach the camera processing pipeline.
            repeatingSeqId = mSession.setRepeatingRequest(previewRequest.build(), resultListener,
                    mHandler);
        }

        CameraOfflineSession offlineSession = mSession.switchToOffline(offlineSurfaces,
                new HandlerExecutor(mHandler), offlineCb);
        assertNotNull(""Invalid offline session"", offlineSession);

        // The regular capture session must be closed as well
        verify(sessionCb, times(1)).onClosed(mSession);

        int offlineState = offlineCb.waitForAnyOfStates(allowedOfflineStates,
                WAIT_FOR_STATE_TIMEOUT_MS);
        if (offlineState == BlockingOfflineSessionCallback.STATE_SWITCH_FAILED) {
            // A failure during offline mode switch is only allowed in case the switch gets
            // triggered too late without pending offline requests.
            verify(mockOfflineCb, times(1)).onSwitchFailed(offlineSession);
            verify(mockOfflineCb, times(0)).onReady(offlineSession);
            verify(mockOfflineCb, times(0)).onIdle(offlineSession);
            verify(mockOfflineCb, times(0)).onError(offlineSession,
                    CameraOfflineSessionCallback.STATUS_INTERNAL_ERROR);

            try {
                verifyCaptureResults(resultListener, null /*imageListener*/, repeatingSeqId,
                        false /*offlineResults*/);
            } catch (AssertionFailedError e) {
                if (testSequence == OfflineTestSequence.RepeatingSequenceAbort) {
                    checkForSequenceAbort(resultListener, repeatingSeqId);
                } else {
                    throw e;
                }
            }
            verifyCaptureResults(offlineResultListener, null /*imageListener*/, offlineSeqId,
                    true /*offlineResults*/);
        } else {
            verify(mockOfflineCb, times(1)).onReady(offlineSession);
            verify(mockOfflineCb, times(0)).onSwitchFailed(offlineSession);

            switch (testSequence) {
                case RepeatingSequenceAbort:
                    checkForSequenceAbort(resultListener, repeatingSeqId);
                    break;
                case CloseDeviceAndOpenRemote:
                    // According to the documentation, closing the initial camera device and
                    // re-opening the same device from a different client after successful
                    // offline session switch must not have any noticeable impact on the
                    // offline processing.
                    closeDevice();
                    remoteOfflinePID = startRemoteOfflineTestProcess(cameraId);

                    break;
                case CloseOfflineSession:
                    offlineSession.close();

                    break;
                case InitializeRegularSession:
                    // According to the documentation, initializing a regular capture session
                    // along with the offline session should not have any side effects.
                    // We also don't want to re-use the same offline output surface as part
                    // of the new  regular capture session.
                    outputSurfaces.remove(mReaderSurface);

                    // According to the specification, an active offline session must allow
                    // camera devices to support at least one preview stream, one yuv stream
                    // of size up-to 1080p, one jpeg stream with any supported size and
                    // an extra input/output private pair in case reprocessing is also available.
                    yuvCallbackReader = makeImageReader(previewSize, ImageFormat.YUV_420_888,
                            1 /*maxNumImages*/, new SimpleImageReaderListener(), mHandler);
                    outputSurfaces.add(yuvCallbackReader.getSurface());

                    jpegReader = makeImageReader(offlineSize, ImageFormat.JPEG,
                            1 /*maxNumImages*/, new SimpleImageReaderListener(), mHandler);
                    outputSurfaces.add(jpegReader.getSurface());

                    if (mAllStaticInfo.get(cameraId).isPrivateReprocessingSupported()) {
                        privateReader = makeImageReader(privateSize, ImageFormat.PRIVATE,
                                1 /*maxNumImages*/, new SimpleImageReaderListener(), mHandler);
                        outputSurfaces.add(privateReader.getSurface());

                        InputConfiguration inputConfig = new InputConfiguration(
                                privateSize.getWidth(), privateSize.getHeight(),
                                ImageFormat.PRIVATE);
                        mSession = CameraTestUtils.configureReprocessableCameraSession(mCamera,
                                inputConfig, outputSurfaces, mSessionListener, mHandler);

                    } else {
                        mSession = configureCameraSession(mCamera, outputSurfaces, mSessionListener,
                                mHandler);
                    }

                    mSession.setRepeatingRequest(previewRequest.build(), regularResultListener,
                            mHandler);

                    break;
                case NoExtraSteps:
                default:
            }

            if (testSequence != OfflineTestSequence.RepeatingSequenceAbort) {
                // The repeating non-offline request should be done after the switch returns.
                verifyCaptureResults(resultListener, null /*imageListener*/, repeatingSeqId,
                        false /*offlineResults*/);
            }

            if (testSequence != OfflineTestSequence.CloseOfflineSession) {
                offlineCb.waitForState(BlockingOfflineSessionCallback.STATE_IDLE,
                        WAIT_FOR_STATE_TIMEOUT_MS);
                verify(mockOfflineCb, times(1)).onIdle(offlineSession);
                verify(mockOfflineCb, times(0)).onError(offlineSession,
                        CameraOfflineSessionCallback.STATUS_INTERNAL_ERROR);

                // The offline requests should be done after we reach idle state.
                verifyCaptureResults(offlineResultListener, imageListener, offlineSeqId,
                        true /*offlineResults*/);

                offlineSession.close();
            }

            if (testSequence == OfflineTestSequence.InitializeRegularSession) {
                checkInitialResults(regularResultListener);
                stopPreview();

                if (privateReader != null) {
                    privateReader.close();
                }

                if (yuvCallbackReader != null) {
                    yuvCallbackReader.close();
                }

                if (jpegReader != null) {
                    jpegReader.close();
                }
            }

            offlineCb.waitForState(BlockingOfflineSessionCallback.STATE_CLOSED,
                  WAIT_FOR_STATE_TIMEOUT_MS);
            verify(mockOfflineCb, times(1)).onClosed(offlineSession);

            ret = true;
        }

        closeImageReader();

        stopRemoteOfflineTestProcess(remoteOfflinePID);

        return ret;
    }

    private void checkInitialResults(SimpleCaptureCallback resultListener) {
        CaptureResult result = resultListener.getCaptureResult(WAIT_FOR_FRAMES_TIMEOUT_MS);

        Long timestamp = result.get(CaptureResult.SENSOR_TIMESTAMP);
        assertNotNull(""Can't read a capture result timestamp"", timestamp);

        CaptureResult result2 = resultListener.getCaptureResult(WAIT_FOR_FRAMES_TIMEOUT_MS);

        Long timestamp2 = result2.get(CaptureResult.SENSOR_TIMESTAMP);
        assertNotNull(""Can't read a capture result 2 timestamp"", timestamp2);

        assertTrue(""Bad timestamps"", timestamp2 > timestamp);
    }

    private void camera2UnsupportedOfflineOutputTest(boolean useSurfaceGroup) throws Exception {
        CaptureRequest.Builder previewRequest =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        Size previewSize = mOrderedPreviewSizes.get(0);
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        updatePreviewSurface(previewSize);

        OutputConfiguration outConfig;
        if (useSurfaceGroup) {
            outConfig = new OutputConfiguration(1 /*surfaceGroupId*/, mPreviewSurface);
        } else {
            outConfig = new OutputConfiguration(mPreviewSurface);
            outConfig.enableSurfaceSharing();
        }

        ArrayList<OutputConfiguration> outputList = new ArrayList<OutputConfiguration>();
        outputList.add(outConfig);
        BlockingSessionCallback sessionListener = new BlockingSessionCallback();
        mCamera.createCaptureSessionByOutputConfigurations(outputList, sessionListener, mHandler);
        CameraCaptureSession session = sessionListener.waitAndGetSession(
                SESSION_CONFIGURE_TIMEOUT_MS);

        assertFalse(useSurfaceGroup ? ""Group surface outputs cannot support offline mode"" :
                ""Shared surface outputs cannot support offline mode"",
                session.supportsOfflineProcessing(mPreviewSurface));

        ArrayList<CaptureRequest> offlineRequestList = new ArrayList<CaptureRequest>();
        previewRequest.addTarget(mPreviewSurface);
        for (int i = 0; i < MAX_READER_IMAGES; i++) {
            offlineRequestList.add(previewRequest.build());
        }

        final CameraOfflineSessionCallback offlineCb = mock(CameraOfflineSessionCallback.class);
        ArrayList<Surface> offlineSurfaces = new ArrayList<Surface>();
        offlineSurfaces.add(mPreviewSurface);
        session.captureBurst(offlineRequestList, resultListener, mHandler);
        try {
            session.switchToOffline(offlineSurfaces, new HandlerExecutor(mHandler), offlineCb);
            fail(useSurfaceGroup ? ""Group surface outputs cannot be switched to offline mode"" :
                ""Shared surface outputs cannot be switched to offline mode"");
        } catch (IllegalArgumentException e) {
            // Expected
        }

        session.close();
    }

    private int startRemoteOfflineTestProcess(String cameraId) throws InterruptedException {
        // Ensure no running activity process with same name
        String cameraActivityName = mContext.getPackageName() + "":"" + REMOTE_PROCESS_NAME;
        ActivityManager activityManager = (ActivityManager) mContext.getSystemService(
                Context.ACTIVITY_SERVICE);
        List<ActivityManager.RunningAppProcessInfo> list = activityManager.getRunningAppProcesses();
        for (ActivityManager.RunningAppProcessInfo rai : list) {
            if (cameraActivityName.equals(rai.processName)) {
                fail(""Remote offline session test activity already running"");
                return -1;
            }
        }

        Activity activity = mActivityRule.getActivity();
        Intent activityIntent = new Intent(activity, REMOTE_PROCESS_CLASS);
        Bundle b = new Bundle();
        b.putString(CameraTestUtils.OFFLINE_CAMERA_ID, cameraId);
        activityIntent.putExtras(b);
        activity.startActivity(activityIntent);
        Thread.sleep(WAIT_FOR_REMOTE_ACTIVITY_LAUNCH_MS);

        // Fail if activity isn't running
        list = activityManager.getRunningAppProcesses();
        for (ActivityManager.RunningAppProcessInfo rai : list) {
            if (cameraActivityName.equals(rai.processName))
                return rai.pid;
        }

        fail(""Remote offline session test activity failed to start"");

        return -1;
    }

    private void stopRemoteOfflineTestProcess(int remotePID) throws InterruptedException {
        if (remotePID < 0) {
            return;
        }

        android.os.Process.killProcess(remotePID);
        Thread.sleep(WAIT_FOR_REMOTE_ACTIVITY_DESTROY_MS);

        ActivityManager activityManager = (ActivityManager) mContext.getSystemService(
                Context.ACTIVITY_SERVICE);
        String cameraActivityName = mContext.getPackageName() + "":"" + REMOTE_PROCESS_NAME;
        List<ActivityManager.RunningAppProcessInfo> list = activityManager.getRunningAppProcesses();
        for (ActivityManager.RunningAppProcessInfo rai : list) {
            if (cameraActivityName.equals(rai.processName))
                fail(""Remote offline session test activity is still running"");
        }

    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.MeanVerification"	"isAutomotiveSpecificTest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/MeanVerification.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers.sensorverification;

import junit.framework.Assert;

import android.hardware.Sensor;
import android.hardware.SensorManager;
import android.hardware.cts.helpers.SensorCtsHelper;
import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.content.pm.PackageManager;

import java.util.HashMap;
import java.util.Map;

/**
 * A {@link ISensorVerification} which verifies that the means matches the expected measurement.
 */
public class MeanVerification extends AbstractMeanVerification {
    public static final String PASSED_KEY = ""mean_passed"";

    // sensorType: {expected, threshold}
    private static final Map<Integer, ExpectedValuesAndThresholds> DEFAULTS
        = new HashMap<Integer, ExpectedValuesAndThresholds>(5);
    static {
        // Use a method so that the @deprecation warning can be set for that method only
        setDefaults();
    }

    private final float[] mExpected;
    private final float[] mUpperThresholds;
    private final float[] mLowerThresholds;

    /**
     * Construct a {@link MeanVerification}
     *
     * @param expected the expected values
     * @param upperThresholds the upper thresholds
     * @param lowerThresholds the lower thresholds
     */
    public MeanVerification(float[] expected, float[] upperThresholds, float[] lowerThresholds) {
        mExpected = expected;
        mUpperThresholds = upperThresholds;
        mLowerThresholds = lowerThresholds;
    }

    /**
     * Get the default {@link MeanVerification} for a sensor.
     *
     * @param environment the test environment
     * @return the verification or null if the verification does not apply to the sensor.
     */
    public static MeanVerification getDefault(TestSensorEnvironment environment) {

        Map<Integer, ExpectedValuesAndThresholds> currentDefaults =
                new HashMap<Integer, ExpectedValuesAndThresholds>(DEFAULTS);

        // Handle automotive specific tests.
        if(environment.isAutomotiveSpecificTest()) {
            // If device is an automotive device, add car defaults.
            if (environment.getContext().getPackageManager().hasSystemFeature(
                    PackageManager.FEATURE_AUTOMOTIVE)) {
                addCarDefaultTests(currentDefaults);
            } else {
                // Skip as this is an automotive test and device is non-automotive.
                return null;
            }
        }

        int sensorType = environment.getSensor().getType();
        if (!currentDefaults.containsKey(sensorType)) {
            return null;
        }
        float[] expected = currentDefaults.get(sensorType).mExpectedValues;
        float[] upperThresholds = currentDefaults.get(sensorType).mUpperThresholds;
        float[] lowerThresholds = currentDefaults.get(sensorType).mLowerThresholds;
        return new MeanVerification(expected, upperThresholds, lowerThresholds);
    }

    /**
     * Verify that the mean is in the acceptable range. Add {@value #PASSED_KEY} and
     * {@value SensorStats#MEAN_KEY} keys to {@link SensorStats}.
     *
     * @throws AssertionError if the verification failed.
     */
    @Override
    public void verify(TestSensorEnvironment environment, SensorStats stats) {
        verify(stats);
    }

    /**
     * Visible for unit tests only.
     */
    void verify(SensorStats stats) {
        if (getCount() < 1) {
            stats.addValue(PASSED_KEY, true);
            return;
        }

        float[] means = getMeans();

        boolean failed = false;
        for (int i = 0; i < means.length; i++) {
            if (means[i]  > mExpected[i] + mUpperThresholds[i]) {
                failed = true;
            }
            if (means[i] < mExpected[i] - mLowerThresholds[i]) {
                failed = true;
            }
        }

        stats.addValue(PASSED_KEY, !failed);
        stats.addValue(SensorStats.MEAN_KEY, means);

        if (failed) {
            Assert.fail(String.format(""Mean out of range: mean=%s (expected %s)"",
                    SensorCtsHelper.formatFloatArray(means),
                    SensorCtsHelper.formatFloatArray(mExpected)));
        }
    }

    @Override
    public MeanVerification clone() {
        return new MeanVerification(mExpected, mUpperThresholds, mLowerThresholds);
    }

    @SuppressWarnings(""deprecation"")
    private static void setDefaults() {
        // Sensors that we don't want to test at this time but still want to record the values.
        // Gyroscope should be 0 for a static device
        DEFAULTS.put(Sensor.TYPE_GYROSCOPE,
            new ExpectedValuesAndThresholds(new float[]{0.0f, 0.0f, 0.0f},
                                            new float[]{Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE},
                                            new float[]{Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE}));
        // Pressure will not be exact in a controlled environment but should be relatively close to
        // sea level (400HPa and 200HPa are very lax thresholds).
        // Second values should always be 0.
        DEFAULTS.put(Sensor.TYPE_PRESSURE,
            new ExpectedValuesAndThresholds(new float[]{SensorManager.PRESSURE_STANDARD_ATMOSPHERE,
                                                        0.0f,
                                                        0.0f},
                                            new float[]{100f,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE},
                                            new float[]{400f,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE}));
        // Linear acceleration should be 0 in all directions for a static device
        DEFAULTS.put(Sensor.TYPE_LINEAR_ACCELERATION,
            new ExpectedValuesAndThresholds(new float[]{0.0f, 0.0f, 0.0f},
                                            new float[]{Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE},
                                            new float[]{Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE}));
        // Game rotation vector should be (0, 0, 0, 1, 0) for a static device
        DEFAULTS.put(Sensor.TYPE_GAME_ROTATION_VECTOR,
            new ExpectedValuesAndThresholds(new float[]{0.0f, 0.0f, 0.0f, 1.0f, 0.0f},
                                            new float[]{Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE},
                                            new float[]{Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE}));
        // Uncalibrated gyroscope should be 0 for a static device but allow a bigger threshold
        DEFAULTS.put(Sensor.TYPE_GYROSCOPE_UNCALIBRATED,
            new ExpectedValuesAndThresholds(new float[]{0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f},
                                            new float[]{Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE},
                                            new float[]{Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE,
                                                        Float.MAX_VALUE}));
    }

    @SuppressWarnings(""deprecation"")
    private static void addCarDefaultTests(Map<Integer, ExpectedValuesAndThresholds> defaults) {
        // Sensors that are being tested for mean verification for the car.
        // Accelerometer axes should be aligned to car axes: X right, Y forward, Z up.
        // Refer for car axes: https://source.android.com/devices/sensors/sensor-types
        // Verifying Z axis is Gravity, X and Y is zero as car is expected to be stationary.
        // Tolerance set to 1.95 as used in CTS Verifier tests.
        defaults.put(Sensor.TYPE_ACCELEROMETER,
                new ExpectedValuesAndThresholds(
                        new float[]{0.0f, 0.0f, SensorManager.STANDARD_GRAVITY},
                        new float[]{1.95f, 1.95f, 1.95f} /* m / s^2 */,
                        new float[]{1.95f, 1.95f, 1.95f} /* m / s^2 */));
    }

    private static final class ExpectedValuesAndThresholds {
        private float[] mExpectedValues;
        private float[] mUpperThresholds;
        private float[] mLowerThresholds;
        private ExpectedValuesAndThresholds(float[] expectedValues,
                                            float[] upperThresholds,
                                            float[] lowerThresholds) {
            mExpectedValues = expectedValues;
            mUpperThresholds = upperThresholds;
            mLowerThresholds = lowerThresholds;
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.camera.its.ItsTestActivity"	"ItsTestActivity"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/camera/its/ItsTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.camera.its;

import android.content.BroadcastReceiver;
import android.content.Context;
import android.content.Intent;
import android.content.IntentFilter;
import android.content.res.Configuration;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.CameraManager;
import android.os.Bundle;
import android.text.method.ScrollingMovementMethod;
import android.util.Log;
import android.view.WindowManager;
import android.widget.TextView;
import android.widget.Toast;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Comparator;
import java.util.HashSet;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Locale;
import java.util.Map;
import java.util.Set;
import java.util.TreeSet;
import java.io.BufferedReader;
import java.io.FileReader;
import java.io.FileNotFoundException;
import java.io.IOException;

import com.android.compatibility.common.util.ResultType;
import com.android.compatibility.common.util.ResultUnit;
import com.android.cts.verifier.ArrayTestListAdapter;
import com.android.cts.verifier.DialogTestListActivity;
import com.android.cts.verifier.R;
import com.android.cts.verifier.TestResult;

import org.json.JSONArray;
import org.json.JSONObject;

/**
 * Test for Camera features that require that the camera be aimed at a specific test scene.
 * This test activity requires a USB connection to a computer, and a corresponding host-side run of
 * the python scripts found in the CameraITS directory.
 */
public class ItsTestActivity extends DialogTestListActivity {
    private static final String TAG = ""ItsTestActivity"";
    private static final String EXTRA_CAMERA_ID = ""camera.its.extra.CAMERA_ID"";
    private static final String EXTRA_RESULTS = ""camera.its.extra.RESULTS"";
    private static final String EXTRA_VERSION = ""camera.its.extra.VERSION"";
    private static final String CURRENT_VERSION = ""1.0"";
    private static final String ACTION_ITS_RESULT =
            ""com.android.cts.verifier.camera.its.ACTION_ITS_RESULT"";

    private static final String RESULT_PASS = ""PASS"";
    private static final String RESULT_FAIL = ""FAIL"";
    private static final String RESULT_NOT_EXECUTED = ""NOT_EXECUTED"";
    private static final Set<String> RESULT_VALUES = new HashSet<String>(
            Arrays.asList(new String[] {RESULT_PASS, RESULT_FAIL, RESULT_NOT_EXECUTED}));
    private static final int MAX_SUMMARY_LEN = 200;

    private final ResultReceiver mResultsReceiver = new ResultReceiver();
    private boolean mReceiverRegistered = false;

    // Initialized in onCreate
    List<String> mToBeTestedCameraIds = null;

    // Scenes
    private static final ArrayList<String> mSceneIds = new ArrayList<String> () {{
            add(""scene0"");
            add(""scene1_1"");
            add(""scene1_2"");
            add(""scene2_a"");
            add(""scene2_b"");
            add(""scene2_c"");
            add(""scene2_d"");
            add(""scene2_e"");
            add(""scene3"");
            add(""scene4"");
            add(""scene5"");
            add(""scene6"");
            add(""scene_change"");
            add(""sensor_fusion"");
        }};
    // This must match scenes of SUB_CAMERA_TESTS in tools/run_all_tests.py
    private static final ArrayList<String> mHiddenPhysicalCameraSceneIds =
            new ArrayList<String> () {{
                    add(""scene0"");
                    add(""scene1_1"");
                    add(""scene1_2"");
                    add(""scene2_a"");
                    add(""scene4"");
                    add(""sensor_fusion"");
            }};
    // TODO: cache the following in saved bundle
    private Set<ResultKey> mAllScenes = null;
    // (camera, scene) -> (pass, fail)
    private final HashMap<ResultKey, Boolean> mExecutedScenes = new HashMap<>();
    // map camera id to ITS summary report path
    private final HashMap<ResultKey, String> mSummaryMap = new HashMap<>();

    final class ResultKey {
        public final String cameraId;
        public final String sceneId;

        public ResultKey(String cameraId, String sceneId) {
            this.cameraId = cameraId;
            this.sceneId = sceneId;
        }

        @Override
        public boolean equals(final Object o) {
            if (o == null) return false;
            if (this == o) return true;
            if (o instanceof ResultKey) {
                final ResultKey other = (ResultKey) o;
                return cameraId.equals(other.cameraId) && sceneId.equals(other.sceneId);
            }
            return false;
        }

        @Override
        public int hashCode() {
            int h = cameraId.hashCode();
            h = ((h << 5) - h) ^ sceneId.hashCode();
            return h;
        }
    }

    public ItsTestActivity() {
        super(R.layout.its_main,
                R.string.camera_its_test,
                R.string.camera_its_test_info,
                R.string.camera_its_test);
    }

    private final Comparator<ResultKey> mComparator = new Comparator<ResultKey>() {
        @Override
        public int compare(ResultKey k1, ResultKey k2) {
            if (k1.cameraId.equals(k2.cameraId))
                return k1.sceneId.compareTo(k2.sceneId);
            return k1.cameraId.compareTo(k2.cameraId);
        }
    };

    class ResultReceiver extends BroadcastReceiver {
        @Override
        public void onReceive(Context context, Intent intent) {
            Log.i(TAG, ""Received result for Camera ITS tests"");
            if (ACTION_ITS_RESULT.equals(intent.getAction())) {
                String version = intent.getStringExtra(EXTRA_VERSION);
                if (version == null || !version.equals(CURRENT_VERSION)) {
                    Log.e(TAG, ""Its result version mismatch: expect "" + CURRENT_VERSION +
                            "", got "" + ((version == null) ? ""null"" : version));
                    ItsTestActivity.this.showToast(R.string.its_version_mismatch);
                    return;
                }

                String cameraId = intent.getStringExtra(EXTRA_CAMERA_ID);
                String results = intent.getStringExtra(EXTRA_RESULTS);
                if (cameraId == null || results == null) {
                    Log.e(TAG, ""cameraId = "" + ((cameraId == null) ? ""null"" : cameraId) +
                            "", results = "" + ((results == null) ? ""null"" : results));
                    return;
                }

                if (!mToBeTestedCameraIds.contains(cameraId)) {
                    Log.e(TAG, ""Unknown camera id "" + cameraId + "" reported to ITS"");
                    return;
                }

                try {
                    /* Sample JSON results string
                    {
                       ""scene0"":{
                          ""result"":""PASS"",
                          ""summary"":""/sdcard/cam0_scene0.txt""
                       },
                       ""scene1"":{
                          ""result"":""NOT_EXECUTED""
                       },
                       ""scene2"":{
                          ""result"":""FAIL"",
                          ""summary"":""/sdcard/cam0_scene2.txt""
                       }
                    }
                    */
                    JSONObject jsonResults = new JSONObject(results);
                    Log.d(TAG,""Results received:"" + jsonResults.toString());
                    Set<String> scenes = new HashSet<>();
                    Iterator<String> keys = jsonResults.keys();
                    while (keys.hasNext()) {
                        scenes.add(keys.next());
                    }

                    // Update test execution results
                    for (String scene : scenes) {
                        HashMap<String, String> executedTests = new HashMap<>();
                        JSONObject sceneResult = jsonResults.getJSONObject(scene);
                        Log.v(TAG, sceneResult.toString());
                        String result = sceneResult.getString(""result"");
                        if (result == null) {
                            Log.e(TAG, ""Result for "" + scene + "" is null"");
                            return;
                        }
                        Log.i(TAG, ""ITS camera"" + cameraId + "" "" + scene + "": result:"" + result);
                        if (!RESULT_VALUES.contains(result)) {
                            Log.e(TAG, ""Unknown result for "" + scene + "": "" + result);
                            return;
                        }
                        ResultKey key = new ResultKey(cameraId, scene);
                        if (result.equals(RESULT_PASS) || result.equals(RESULT_FAIL)) {
                            boolean pass = result.equals(RESULT_PASS);
                            mExecutedScenes.put(key, pass);
                            // Get start/end time per camera/scene for result history collection.
                            mStartTime = sceneResult.getLong(""start"");
                            mEndTime = sceneResult.getLong(""end"");
                            setTestResult(testId(cameraId, scene), pass ?
                                    TestResult.TEST_RESULT_PASSED : TestResult.TEST_RESULT_FAILED);
                            Log.e(TAG, ""setTestResult for "" + testId(cameraId, scene) + "": "" + result);
                            String summary = sceneResult.optString(""summary"");
                            if (!summary.equals("""")) {
                                mSummaryMap.put(key, summary);
                            }
                        } // do nothing for NOT_EXECUTED scenes
                    }
                } catch (org.json.JSONException e) {
                    Log.e(TAG, ""Error reading json result string:"" + results , e);
                    return;
                }

                // Set summary if all scenes reported
                if (mSummaryMap.keySet().containsAll(mAllScenes)) {
                    StringBuilder summary = new StringBuilder();
                    for (String path : mSummaryMap.values()) {
                        appendFileContentToSummary(summary, path);
                    }
                    if (summary.length() > MAX_SUMMARY_LEN) {
                        Log.w(TAG, ""ITS summary report too long: len: "" + summary.length());
                    }
                    ItsTestActivity.this.getReportLog().setSummary(
                            summary.toString(), 1.0, ResultType.NEUTRAL, ResultUnit.NONE);
                }

                // Display current progress
                StringBuilder progress = new StringBuilder();
                for (ResultKey k : mAllScenes) {
                    String status = RESULT_NOT_EXECUTED;
                    if (mExecutedScenes.containsKey(k)) {
                        status = mExecutedScenes.get(k) ? RESULT_PASS : RESULT_FAIL;
                    }
                    progress.append(String.format(""Cam %s, %s: %s\n"",
                            k.cameraId, k.sceneId, status));
                }
                TextView progressView = (TextView) findViewById(R.id.its_progress);
                progressView.setMovementMethod(new ScrollingMovementMethod());
                progressView.setText(progress.toString());


                // Enable pass button if all scenes pass
                boolean allScenesPassed = true;
                for (ResultKey k : mAllScenes) {
                    Boolean pass = mExecutedScenes.get(k);
                    if (pass == null || pass == false) {
                        allScenesPassed = false;
                        break;
                    }
                }
                if (allScenesPassed) {
                    Log.i(TAG, ""All scenes passed."");
                    // Enable pass button
                    ItsTestActivity.this.getPassButton().setEnabled(true);
                    ItsTestActivity.this.setTestResultAndFinish(true);
                } else {
                    ItsTestActivity.this.getPassButton().setEnabled(false);
                }
            }
        }

        private void appendFileContentToSummary(StringBuilder summary, String path) {
            BufferedReader reader = null;
            try {
                reader = new BufferedReader(new FileReader(path));
                String line = null;
                do {
                    line = reader.readLine();
                    if (line != null) {
                        summary.append(line);
                    }
                } while (line != null);
            } catch (FileNotFoundException e) {
                Log.e(TAG, ""Cannot find ITS summary file at "" + path);
                summary.append(""Cannot find ITS summary file at "" + path);
            } catch (IOException e) {
                Log.e(TAG, ""IO exception when trying to read "" + path);
                summary.append(""IO exception when trying to read "" + path);
            } finally {
                if (reader != null) {
                    try {
                        reader.close();
                    } catch (IOException e) {
                    }
                }
            }
        }
    }

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        // Hide the test if all camera devices are legacy
        CameraManager manager = (CameraManager) this.getSystemService(Context.CAMERA_SERVICE);
        try {
            ItsUtils.ItsCameraIdList cameraIdList = ItsUtils.getItsCompatibleCameraIds(manager);
            mToBeTestedCameraIds = cameraIdList.mCameraIdCombos;
        } catch (ItsException e) {
            Toast.makeText(ItsTestActivity.this,
                    ""Received error from camera service while checking device capabilities: ""
                            + e, Toast.LENGTH_SHORT).show();
        }

        super.onCreate(savedInstanceState);
        if (mToBeTestedCameraIds.size() == 0) {
            showToast(R.string.all_exempted_devices);
            ItsTestActivity.this.getReportLog().setSummary(
                    ""PASS: all cameras on this device are exempted from ITS""
                    , 1.0, ResultType.NEUTRAL, ResultUnit.NONE);
            setTestResultAndFinish(true);
        }
        // Default locale must be set to ""en-us""
        Locale locale = Locale.getDefault();
        if (!Locale.US.equals(locale)) {
            String toastMessage = ""Unsupported default language "" + locale + ""! "" +
                    ""Please switch the default language to English (United States) in "" +
                    ""Settings > Language & input > Languages"";
            Toast.makeText(ItsTestActivity.this, toastMessage, Toast.LENGTH_LONG).show();
            ItsTestActivity.this.getReportLog().setSummary(
                    ""FAIL: Default language is not set to "" + Locale.US,
                    1.0, ResultType.NEUTRAL, ResultUnit.NONE);
            setTestResultAndFinish(false);
        }
        getWindow().addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);
    }

    @Override
    public void showManualTestDialog(final DialogTestListItem test,
            final DialogTestListItem.TestCallback callback) {
        //Nothing todo for ITS
    }

    protected String testTitle(String cam, String scene) {
        return ""Camera: "" + cam + "", "" + scene;
    }

    protected String testId(String cam, String scene) {
        return ""Camera_ITS_"" + cam + ""_"" + scene;
    }

    protected void setupItsTests(ArrayTestListAdapter adapter) {
        for (String cam : mToBeTestedCameraIds) {
            List<String> scenes = cam.contains(ItsUtils.CAMERA_ID_TOKENIZER) ?
                    mHiddenPhysicalCameraSceneIds : mSceneIds;
            for (String scene : scenes) {
                // Add camera and scene combinations in mAllScenes to avoid adding n/a scenes for
                // devices with sub-cameras.
                if(mAllScenes == null){
                    mAllScenes = new TreeSet<>(mComparator);
                }
                mAllScenes.add(new ResultKey(cam, scene));
                adapter.add(new DialogTestListItem(this,
                testTitle(cam, scene),
                testId(cam, scene)));
            }
            Log.d(TAG,""Total combinations to test on this device:"" + mAllScenes.size());
        }
    }

    @Override
    protected void setupTests(ArrayTestListAdapter adapter) {
        setupItsTests(adapter);
    }

    @Override
    protected void onResume() {
        super.onResume();
        CameraManager manager = (CameraManager) this.getSystemService(Context.CAMERA_SERVICE);
        if (manager == null) {
            showToast(R.string.no_camera_manager);
        } else {
            Log.d(TAG, ""register ITS result receiver"");
            IntentFilter filter = new IntentFilter(ACTION_ITS_RESULT);
            registerReceiver(mResultsReceiver, filter);
            mReceiverRegistered = true;
        }
    }

    @Override
    public void onDestroy() {
        Log.d(TAG, ""unregister ITS result receiver"");
        if (mReceiverRegistered) {
            unregisterReceiver(mResultsReceiver);
        }
        super.onDestroy();
    }

    @Override
    public void onConfigurationChanged(Configuration newConfig) {
        super.onConfigurationChanged(newConfig);
        setContentView(R.layout.its_main);
        setInfoResources(R.string.camera_its_test, R.string.camera_its_test_info, -1);
        setPassFailButtonClickListeners();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.EventOrderingVerificationTest"	"testNoEvents"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/EventOrderingVerificationTest.java"	""	"public void testNoEvents() {
        SensorStats stats = new SensorStats();
        EventOrderingVerification verification = getVerification();
        verification.verify(stats);
        verifyStats(stats, true, 0);
    }

    /**
     * Test that the verification passes when the timestamps are increasing.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.EventOrderingVerificationTest"	"testSequentialTimestamp"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/EventOrderingVerificationTest.java"	""	"public void testSequentialTimestamp() {
        SensorStats stats = new SensorStats();
        EventOrderingVerification verification = getVerification(0, 1, 2, 3, 4);
        verification.verify(stats);
        verifyStats(stats, true, 0);
    }

    /**
     * Test that the verification fails when there is one event out of order.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.EventOrderingVerificationTest"	"testSingleOutofOrder"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/EventOrderingVerificationTest.java"	""	"public void testSingleOutofOrder() {
        SensorStats stats = new SensorStats();
        EventOrderingVerification verification = getVerification(0, 2, 1, 3, 4);
        try {
            verification.verify(stats);
            throw new Error(""Expected an AssertionError"");
        } catch (AssertionError e) {
            // Expected;
        }
        verifyStats(stats, false, 1);
        List<Integer> indices = getIndices(stats);
        assertTrue(indices.contains(2));
    }

    /**
     * Test that the verification fails when there are multiple events out of order.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.EventOrderingVerificationTest"	"testMultipleOutOfOrder"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/EventOrderingVerificationTest.java"	""	"public void testMultipleOutOfOrder() {
        SensorStats stats = new SensorStats();
        EventOrderingVerification verification = getVerification(4, 0, 1, 2, 3);
        try {
            verification.verify(stats);
            throw new Error(""Expected an AssertionError"");
        } catch (AssertionError e) {
            // Expected;
        }
        verifyStats(stats, false, 4);
        List<Integer> indices = getIndices(stats);
        assertTrue(indices.contains(1));
        assertTrue(indices.contains(2));
        assertTrue(indices.contains(3));
        assertTrue(indices.contains(4));
    }

    private static EventOrderingVerification getVerification(long ... timestamps) {
        Collection<TestSensorEvent> events = new ArrayList<>(timestamps.length);
        for (long timestamp : timestamps) {
            events.add(new TestSensorEvent(null, timestamp, 0, null));
        }
        EventOrderingVerification verification = new EventOrderingVerification();
        verification.addSensorEvents(events);
        return verification;
    }

    private void verifyStats(SensorStats stats, boolean passed, int count) {
        assertEquals(passed, stats.getValue(EventOrderingVerification.PASSED_KEY));
        assertEquals(count, stats.getValue(SensorStats.EVENT_OUT_OF_ORDER_COUNT_KEY));
        assertNotNull(stats.getValue(SensorStats.EVENT_OUT_OF_ORDER_POSITIONS_KEY));
    }

    private List<Integer> getIndices(SensorStats stats) {
        int[] primitiveIndices = (int[]) stats.getValue(
                SensorStats.EVENT_OUT_OF_ORDER_POSITIONS_KEY);
        List<Integer> indices = new ArrayList<Integer>(primitiveIndices.length);
        for (int index : primitiveIndices) {
            indices.add(index);
        }
        return indices;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ZoomCaptureTest"	"testRawZoomCapture"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ZoomCaptureTest.java"	""	"public void testRawZoomCapture() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.v(TAG, ""Testing raw zoom capture for camera "" + id);
                openDevice(id);

                bufferFormatZoomTestByCamera(ImageFormat.RAW_SENSOR);
            } finally {
                closeDevice(id);
            }
        }
    }

    private void bufferFormatZoomTestByCamera(int format) throws Exception {
        Size[] availableSizes = mStaticInfo.getAvailableSizesForFormatChecked(format,
                StaticMetadata.StreamDirection.Output);
        if (availableSizes.length == 0) {
            return;
        }

        List<Float> candidateZoomRatios = CameraTestUtils.getCandidateZoomRatios(mStaticInfo);
        Set<String> physicalCameraIds = null;
        if (mStaticInfo.isLogicalMultiCamera()) {
            physicalCameraIds = mStaticInfo.getCharacteristics().getPhysicalCameraIds();
        }
        try {
            mListener  = new SimpleImageListener();
            // Pick the largest image size:
            Size maxSize = CameraTestUtils.getMaxSize(availableSizes);
            createDefaultImageReader(maxSize, format, 1, mListener);

            checkImageReaderSessionConfiguration(
                    ""Camera capture session validation for format: "" + format + ""failed"");

            ArrayList<OutputConfiguration> outputConfigs = new ArrayList<>();
            OutputConfiguration config = new OutputConfiguration(mReader.getSurface());
            outputConfigs.add(config);

            CaptureRequest.Builder requestBuilder = prepareCaptureRequestForConfigs(
                    outputConfigs, CameraDevice.TEMPLATE_PREVIEW);

            Set<String> activePhysicalIdsSeen = new HashSet<String>();
            boolean checkActivePhysicalIdConsistency =
                    PropertyUtil.getFirstApiLevel() >= Build.VERSION_CODES.S;
            for (Float zoomRatio : candidateZoomRatios) {
                if (VERBOSE) {
                    Log.v(TAG, ""Testing format "" + format + "" zoomRatio "" + zoomRatio +
                            "" for camera "" + mCamera.getId());
                }

                requestBuilder.set(CaptureRequest.CONTROL_ZOOM_RATIO, zoomRatio);
                CaptureRequest request = requestBuilder.build();

                SimpleCaptureCallback listener = new SimpleCaptureCallback();
                startCapture(request, false /*repeating*/, listener, mHandler);

                // Validate images.
                mListener.waitForAnyImageAvailable(CAPTURE_WAIT_TIMEOUT_MS);
                Image img = mReader.acquireNextImage();
                assertNotNull(""Unable to acquire the latest image"", img);
                CameraTestUtils.validateImage(img, maxSize.getWidth(), maxSize.getHeight(), format,
                        mDebugFileNameBase);
                img.close();

                // Validate capture result.
                if (mStaticInfo.isActivePhysicalCameraIdSupported()) {
                    CaptureResult result = listener.getCaptureResult(CAPTURE_RESULT_TIMEOUT_MS);
                    String activePhysicalId = result.get(
                            CaptureResult.LOGICAL_MULTI_CAMERA_ACTIVE_PHYSICAL_ID);
                    if (checkActivePhysicalIdConsistency) {
                        assertNotNull(""Camera "" + mCamera.getId() +
                                "" result metadata must contain ACTIVE_PHYSICAL_ID"",
                                activePhysicalId);
                        assertTrue(""Camera "" + mCamera.getId() + "" must be logical "" +
                                ""camera if activePhysicalId exists in capture result"",
                                physicalCameraIds != null && physicalCameraIds.size() != 0);
                        mCollector.expectTrue(""Camera "" + mCamera.getId() + ""  activePhysicalId "" +
                                activePhysicalId + ""must be among valid physical Ids ""  +
                                physicalCameraIds.toString(),
                                physicalCameraIds.contains(activePhysicalId));

                        activePhysicalIdsSeen.add(activePhysicalId);
                    }
                }
            }
            // stop capture.
            stopCapture(/*fast*/false);

            if (activePhysicalIdsSeen.size() > 0 && format == ImageFormat.RAW_SENSOR) {
                mCollector.expectTrue(""Logical camera's activePhysicalCamera should not "" +
                        "" change at different zoom levels."", activePhysicalIdsSeen.size() == 1);
            }
        } finally {
            closeDefaultImageReader();
        }
    }

    private final class SimpleImageListener implements ImageReader.OnImageAvailableListener {
        private final ConditionVariable imageAvailable = new ConditionVariable();
        @Override
        public void onImageAvailable(ImageReader reader) {
            imageAvailable.open();
        }

        public void waitForAnyImageAvailable(long timeout) {
            if (imageAvailable.block(timeout)) {
                imageAvailable.close();
            } else {
                fail(""wait for image available timed out after "" + timeout + ""ms"");
            }
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.testcases.Camera2SurfaceViewTestCase"	"isInstantApp"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/testcases/Camera2SurfaceViewTestCase.java"	""	"public void test/*
 *.
 */

package android.hardware.camera2.cts.testcases;

import static android.hardware.camera2.cts.CameraTestUtils.*;

import static com.android.ex.camera2.blocking.BlockingStateCallback.STATE_CLOSED;
import androidx.test.InstrumentationRegistry;
import android.app.UiAutomation;

import android.content.Context;
import android.graphics.ImageFormat;
import android.hardware.camera2.CameraAccessException;
import android.hardware.camera2.CameraCaptureSession;
import android.hardware.camera2.CameraCaptureSession.CaptureCallback;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.CameraDevice;
import android.hardware.camera2.CameraManager;
import android.hardware.camera2.CameraMetadata;
import android.hardware.camera2.CaptureRequest;
import android.hardware.camera2.CaptureResult;
import android.hardware.camera2.cts.Camera2SurfaceViewCtsActivity;
import android.hardware.camera2.cts.Camera2ParameterizedTestCase;
import android.hardware.camera2.cts.CameraTestUtils;
import android.hardware.camera2.cts.CameraTestUtils.SimpleCaptureCallback;
import android.hardware.camera2.cts.helpers.CameraErrorCollector;
import android.hardware.camera2.cts.helpers.StaticMetadata;
import android.hardware.camera2.cts.helpers.StaticMetadata.CheckLevel;
import android.media.ImageReader;
import android.os.Handler;
import android.os.HandlerThread;
import android.os.Looper;
import android.util.Log;
import android.util.Range;
import android.util.Size;
import android.view.Surface;
import android.view.SurfaceHolder;
import android.view.View;
import android.view.WindowManager;

import androidx.test.rule.ActivityTestRule;

import com.android.ex.camera2.blocking.BlockingSessionCallback;
import com.android.ex.camera2.blocking.BlockingStateCallback;
import com.android.ex.camera2.exceptions.TimeoutRuntimeException;

import org.junit.After;
import org.junit.Before;
import org.junit.Ignore;
import org.junit.Rule;

import java.io.File;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.junit.runners.Parameterized;
import org.junit.runners.Parameterized.Parameter;
import org.junit.runners.Parameterized.Parameters;


/**
 * Camera2 Preview test case base class by using SurfaceView as rendering target.
 *
 * <p>This class encapsulates the SurfaceView based preview common functionalities.
 * The setup and teardown of CameraManager, test HandlerThread, Activity, Camera IDs
 * and CameraStateCallback are handled in this class. Some basic preview related utility
 * functions are provided to facilitate the derived preview-based test classes.
 * </p>
 */

public class Camera2SurfaceViewTestCase extends Camera2ParameterizedTestCase {
    private static final String TAG = ""SurfaceViewTestCase"";
    private static final boolean VERBOSE = Log.isLoggable(TAG, Log.VERBOSE);
    private static final int WAIT_FOR_SURFACE_CHANGE_TIMEOUT_MS = 1000;

    protected static final int WAIT_FOR_RESULT_TIMEOUT_MS = 3000;
    protected static final float FRAME_DURATION_ERROR_MARGIN = 0.01f; // 1 percent error margin.
    protected static final int NUM_RESULTS_WAIT_TIMEOUT = 100;
    protected static final int NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY = 8;
    protected static final int MIN_FRAME_DURATION_ERROR_MARGIN = 100; // ns

    protected HandlerThread mHandlerThread;
    protected Handler mHandler;
    protected BlockingStateCallback mCameraListener;
    protected BlockingSessionCallback mSessionListener;
    protected CameraErrorCollector mCollector;
    protected HashMap<String, StaticMetadata> mAllStaticInfo;
    // Per device fields:
    protected StaticMetadata mStaticInfo;
    protected CameraDevice mCamera;
    protected CameraCaptureSession mSession;
    protected ImageReader mReader;
    protected Surface mReaderSurface;
    protected Surface mPreviewSurface;
    protected SurfaceHolder mPreviewHolder;
    protected Size mPreviewSize;
    protected List<Size> mOrderedPreviewSizes; // In descending order.
    protected List<Size> m1080pBoundedOrderedPreviewSizes; // In descending order.
    protected List<Size> mOrderedVideoSizes; // In descending order.
    protected List<Size> mOrderedStillSizes; // In descending order.
    protected HashMap<Size, Long> mMinPreviewFrameDurationMap;
    protected String mDebugFileNameBase;

    protected WindowManager mWindowManager;

    @Rule
    public ActivityTestRule<Camera2SurfaceViewCtsActivity> mActivityRule =
            new ActivityTestRule<>(Camera2SurfaceViewCtsActivity.class);

    @Before
    public void setUp() throws Exception {
        super.setUp();
        mHandlerThread = new HandlerThread(TAG);
        mHandlerThread.start();
        mHandler = new Handler(mHandlerThread.getLooper());
        mCameraListener = new BlockingStateCallback();
        mCollector = new CameraErrorCollector();

        File filesDir = mContext.getPackageManager().isInstantApp()
                ? mContext.getFilesDir()
                : mContext.getExternalFilesDir(null);

        mDebugFileNameBase = filesDir.getPath();

        mAllStaticInfo = new HashMap<String, StaticMetadata>();
        List<String> hiddenPhysicalIds = new ArrayList<>();
        for (String cameraId : mCameraIdsUnderTest) {
            CameraCharacteristics props = mCameraManager.getCameraCharacteristics(cameraId);
            StaticMetadata staticMetadata = new StaticMetadata(props,
                    CheckLevel.ASSERT, /*collector*/null);
            mAllStaticInfo.put(cameraId, staticMetadata);

            for (String physicalId : props.getPhysicalCameraIds()) {
                if (!Arrays.asList(mCameraIdsUnderTest).contains(physicalId) &&
                        !hiddenPhysicalIds.contains(physicalId)) {
                    hiddenPhysicalIds.add(physicalId);
                    props = mCameraManager.getCameraCharacteristics(physicalId);
                    staticMetadata = new StaticMetadata(
                            mCameraManager.getCameraCharacteristics(physicalId),
                            CheckLevel.ASSERT, /*collector*/null);
                    mAllStaticInfo.put(physicalId, staticMetadata);
                }
            }
        }

        mWindowManager = (WindowManager) mContext.getSystemService(Context.WINDOW_SERVICE);
    }

    @After
    public void tearDown() throws Exception {
        mHandlerThread.quitSafely();
        mHandler = null;
        mCameraListener = null;

        try {
            mCollector.verify();
        } catch (Throwable e) {
            // When new Exception(e) is used, exception info will be printed twice.
            throw new Exception(e.getMessage());
        }
        super.tearDown();
    }

    /**
     * Start camera preview by using the given request, preview size and capture
     * listener.
     * <p>
     * If preview is already started, calling this function will stop the
     * current preview stream and start a new preview stream with given
     * parameters. No need to call stopPreview between two startPreview calls.
     * </p>
     *
     * @param request The request builder used to start the preview.
     * @param previewSz The size of the camera device output preview stream.
     * @param listener The callbacks the camera device will notify when preview
     *            capture is available.
     */
    protected void startPreview(CaptureRequest.Builder request, Size previewSz,
            CaptureCallback listener) throws Exception {
        // Update preview size.
        updatePreviewSurface(previewSz);
        if (VERBOSE) {
            Log.v(TAG, ""start preview with size "" + mPreviewSize.toString());
        }

        configurePreviewOutput(request);

        mSession.setRepeatingRequest(request.build(), listener, mHandler);
    }

    /**
     * Configure the preview output stream.
     *
     * @param request The request to be configured with preview surface
     */
    protected void configurePreviewOutput(CaptureRequest.Builder request)
            throws CameraAccessException {
        List<Surface> outputSurfaces = new ArrayList<Surface>(/*capacity*/1);
        outputSurfaces.add(mPreviewSurface);
        mSessionListener = new BlockingSessionCallback();
        mSession = configureCameraSession(mCamera, outputSurfaces, mSessionListener, mHandler);

        request.addTarget(mPreviewSurface);
    }

    /**
     * Create a {@link CaptureRequest#Builder} and add the default preview surface.
     *
     * @return The {@link CaptureRequest#Builder} to be created
     * @throws CameraAccessException When create capture request from camera fails
     */
    protected CaptureRequest.Builder createRequestForPreview() throws CameraAccessException {
        if (mPreviewSurface == null) {
            throw new IllegalStateException(
                    ""Preview surface is not set yet, call updatePreviewSurface or startPreview""
                    + ""first to set the preview surface properly."");
        }
        CaptureRequest.Builder requestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        requestBuilder.addTarget(mPreviewSurface);
        return requestBuilder;
    }

    /**
     * Stop preview for current camera device by closing the session.
     * Does _not_ wait for the device to go idle
     */
    protected void stopPreview() throws Exception {
        // Stop repeat, wait for captures to complete, and disconnect from surfaces
        if (mSession != null) {
            if (VERBOSE) Log.v(TAG, ""Stopping preview"");
            mSession.close();
        }
    }

    /**
     * Stop preview for current camera device by closing the session and waiting for it to close,
     * resulting in an idle device.
     */
    protected void stopPreviewAndDrain() throws Exception {
        // Stop repeat, wait for captures to complete, and disconnect from surfaces
        if (mSession != null) {
            if (VERBOSE) Log.v(TAG, ""Stopping preview and waiting for idle"");
            mSession.close();
            mSessionListener.getStateWaiter().waitForState(BlockingSessionCallback.SESSION_CLOSED,
                    /*timeoutMs*/WAIT_FOR_RESULT_TIMEOUT_MS);
        }
    }

    /**
     * Setup still (JPEG) capture configuration and start preview.
     * <p>
     * The default max number of image is set to image reader.
     * </p>
     *
     * @param previewRequest The capture request to be used for preview
     * @param stillRequest The capture request to be used for still capture
     * @param previewSz Preview size
     * @param stillSz The still capture size
     * @param resultListener Capture result listener
     * @param imageListener The still capture image listener
     */
    protected void prepareStillCaptureAndStartPreview(CaptureRequest.Builder previewRequest,
            CaptureRequest.Builder stillRequest, Size previewSz, Size stillSz,
            CaptureCallback resultListener,
            ImageReader.OnImageAvailableListener imageListener, boolean isHeic) throws Exception {
        prepareCaptureAndStartPreview(previewRequest, stillRequest, previewSz, stillSz,
                isHeic ? ImageFormat.HEIC : ImageFormat.JPEG, resultListener, MAX_READER_IMAGES,
                imageListener);
    }

    /**
     * Setup still (JPEG) capture configuration and start preview.
     *
     * @param previewRequest The capture request to be used for preview
     * @param stillRequest The capture request to be used for still capture
     * @param previewSz Preview size
     * @param stillSz The still capture size
     * @param resultListener Capture result listener
     * @param maxNumImages The max number of images set to the image reader
     * @param imageListener The still capture image listener
     */
    protected void prepareStillCaptureAndStartPreview(CaptureRequest.Builder previewRequest,
            CaptureRequest.Builder stillRequest, Size previewSz, Size stillSz,
            CaptureCallback resultListener, int maxNumImages,
            ImageReader.OnImageAvailableListener imageListener, boolean isHeic) throws Exception {
        prepareCaptureAndStartPreview(previewRequest, stillRequest, previewSz, stillSz,
                isHeic ? ImageFormat.HEIC : ImageFormat.JPEG, resultListener, maxNumImages, imageListener);
    }

    /**
     * Setup raw capture configuration and start preview.
     *
     * <p>
     * The default max number of image is set to image reader.
     * </p>
     *
     * @param previewRequest The capture request to be used for preview
     * @param rawRequest The capture request to be used for raw capture
     * @param previewSz Preview size
     * @param rawSz The raw capture size
     * @param resultListener Capture result listener
     * @param imageListener The raw capture image listener
     */
    protected void prepareRawCaptureAndStartPreview(CaptureRequest.Builder previewRequest,
            CaptureRequest.Builder rawRequest, Size previewSz, Size rawSz,
            CaptureCallback resultListener,
            ImageReader.OnImageAvailableListener imageListener) throws Exception {
        prepareCaptureAndStartPreview(previewRequest, rawRequest, previewSz, rawSz,
                ImageFormat.RAW_SENSOR, resultListener, MAX_READER_IMAGES, imageListener);
    }

    /**
     * Wait for expected result key value available in a certain number of results.
     *
     * <p>
     * Check the result immediately if numFramesWait is 0.
     * </p>
     *
     * @param listener The capture listener to get capture result
     * @param resultKey The capture result key associated with the result value
     * @param expectedValue The result value need to be waited for
     * @param numResultsWait Number of frame to wait before times out
     * @throws TimeoutRuntimeException If more than numResultsWait results are
     * seen before the result matching myRequest arrives, or each individual wait
     * for result times out after {@value #WAIT_FOR_RESULT_TIMEOUT_MS}ms.
     */
    protected static <T> void waitForResultValue(SimpleCaptureCallback listener,
            CaptureResult.Key<T> resultKey,
            T expectedValue, int numResultsWait) {
        CameraTestUtils.waitForResultValue(listener, resultKey, expectedValue,
                numResultsWait, WAIT_FOR_RESULT_TIMEOUT_MS);
    }

    /**
     * Wait for any expected result key values available in a certain number of results.
     *
     * <p>
     * Check the result immediately if numFramesWait is 0.
     * </p>
     *
     * @param listener The capture listener to get capture result.
     * @param resultKey The capture result key associated with the result value.
     * @param expectedValues The list of result value need to be waited for,
     * return immediately if the list is empty.
     * @param numResultsWait Number of frame to wait before times out.
     * @throws TimeoutRuntimeException If more than numResultsWait results are.
     * seen before the result matching myRequest arrives, or each individual wait
     * for result times out after {@value #WAIT_FOR_RESULT_TIMEOUT_MS}ms.
     */
    protected static <T> void waitForAnyResultValue(SimpleCaptureCallback listener,
            CaptureResult.Key<T> resultKey,
            List<T> expectedValues, int numResultsWait) {
        CameraTestUtils.waitForAnyResultValue(listener, resultKey, expectedValues, numResultsWait,
                WAIT_FOR_RESULT_TIMEOUT_MS);
    }

    /**
     * Submit a burst of the same capture request, then submit additional captures in order to
     * ensure that the camera will be synchronized.
     *
     * <p>
     * The additional capture count is determined by android.sync.maxLatency (or
     * a fixed {@value #NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY}) captures if maxLatency is unknown).
     * </p>
     *
     * <p>Returns the number of captures that were submitted (at least 1), which is useful
     * with {@link #waitForNumResults}.</p>
     *
     * @param request capture request to forward to {@link CameraDevice#capture}
     * @param listener request listener to forward to {@link CameraDevice#capture}
     * @param handler handler to forward to {@link CameraDevice#capture}
     *
     * @return the number of captures that were submitted
     *
     * @throws CameraAccessException if capturing failed
     */
    protected int captureRequestsSynchronizedBurst(
            CaptureRequest request, int count, CaptureCallback listener, Handler handler)
                    throws CameraAccessException {
        return captureRequestsSynchronizedImpl(request, count, listener, handler, true);
    }
    /**
     * Submit a capture once, then submit additional captures in order to ensure that
     * the camera will be synchronized.
     *
     * <p>
     * The additional capture count is determined by android.sync.maxLatency (or
     * a fixed {@value #NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY}) captures if maxLatency is unknown).
     * </p>
     *
     * <p>Returns the number of captures that were submitted (at least 1), which is useful
     * with {@link #waitForNumResults}.</p>
     *
     * @param request capture request to forward to {@link CameraDevice#capture}
     * @param listener request listener to forward to {@link CameraDevice#capture}
     * @param handler handler to forward to {@link CameraDevice#capture}
     *
     * @return the number of captures that were submitted
     *
     * @throws CameraAccessException if capturing failed
     */
    protected int captureRequestsSynchronized(
            CaptureRequest request, CaptureCallback listener, Handler handler)
                    throws CameraAccessException {
        return captureRequestsSynchronizedImpl(request, /*count*/1, listener, handler, false);
    }

    /**
     * Submit a capture {@code count} times, then submit additional captures in order to ensure that
     * the camera will be synchronized.
     *
     * <p>
     * The additional capture count is determined by android.sync.maxLatency (or
     * a fixed {@value #NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY}) captures if maxLatency is unknown).
     * </p>
     *
     * <p>Returns the number of captures that were submitted (at least 1), which is useful
     * with {@link #waitForNumResults}.</p>
     *
     * @param request capture request to forward to {@link CameraDevice#capture}
     * @param count the number of times to submit the request (minimally), must be at least 1
     * @param listener request listener to forward to {@link CameraDevice#capture}
     * @param handler handler to forward to {@link CameraDevice#capture}
     *
     * @return the number of captures that were submitted
     *
     * @throws IllegalArgumentException if {@code count} was not at least 1
     * @throws CameraAccessException if capturing failed
     */
    protected int captureRequestsSynchronized(
            CaptureRequest request, int count, CaptureCallback listener, Handler handler)
                    throws CameraAccessException {
        return captureRequestsSynchronizedImpl(request, count, listener, handler, false);
    }

    /**
     * Wait for numResultWait frames
     *
     * @param resultListener The capture listener to get capture result back.
     * @param numResultsWait Number of frame to wait
     *
     * @return the last result, or {@code null} if there was none
     */
    protected static CaptureResult waitForNumResults(SimpleCaptureCallback resultListener,
            int numResultsWait) {
        return CameraTestUtils.waitForNumResults(resultListener, numResultsWait,
                WAIT_FOR_RESULT_TIMEOUT_MS);
    }

    /**
     * Wait for enough results for settings to be applied
     *
     * @param resultListener The capture listener to get capture result back.
     * @param numResultWaitForUnknownLatency Number of frame to wait if camera device latency is
     *                                       unknown.
     */
    protected void waitForSettingsApplied(SimpleCaptureCallback resultListener,
            int numResultWaitForUnknownLatency) {
        int maxLatency = mStaticInfo.getSyncMaxLatency();
        if (maxLatency == CameraMetadata.SYNC_MAX_LATENCY_UNKNOWN) {
            maxLatency = numResultWaitForUnknownLatency;
        }
        // Wait for settings to take effect
        waitForNumResults(resultListener, maxLatency);
    }

    /**
     * Wait for AE to be stabilized before capture: CONVERGED or FLASH_REQUIRED.
     *
     * <p>Waits for {@code android.sync.maxLatency} number of results first, to make sure
     * that the result is synchronized (or {@code numResultWaitForUnknownLatency} if the latency
     * is unknown.</p>
     *
     * <p>This is a no-op for {@code LEGACY} devices since they don't report
     * the {@code aeState} result.</p>
     *
     * @param resultListener The capture listener to get capture result back.
     * @param numResultWaitForUnknownLatency Number of frame to wait if camera device latency is
     *                                       unknown.
     */
    protected void waitForAeStable(SimpleCaptureCallback resultListener,
            int numResultWaitForUnknownLatency) {
        CameraTestUtils.waitForAeStable(resultListener, NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY,
                mStaticInfo, WAIT_FOR_RESULT_TIMEOUT_MS, NUM_RESULTS_WAIT_TIMEOUT);
    }

    /**
     * Wait for AE to be: LOCKED
     *
     * <p>Waits for {@code android.sync.maxLatency} number of results first, to make sure
     * that the result is synchronized (or {@code numResultWaitForUnknownLatency} if the latency
     * is unknown.</p>
     *
     * <p>This is a no-op for {@code LEGACY} devices since they don't report
     * the {@code aeState} result.</p>
     *
     * @param resultListener The capture listener to get capture result back.
     * @param numResultWaitForUnknownLatency Number of frame to wait if camera device latency is
     *                                       unknown.
     */
    protected void waitForAeLocked(SimpleCaptureCallback resultListener,
            int numResultWaitForUnknownLatency) {

        waitForSettingsApplied(resultListener, numResultWaitForUnknownLatency);

        if (!mStaticInfo.isHardwareLevelAtLeastLimited()) {
            // No-op for legacy devices
            return;
        }

        List<Integer> expectedAeStates = new ArrayList<Integer>();
        expectedAeStates.add(new Integer(CaptureResult.CONTROL_AE_STATE_LOCKED));
        CameraTestUtils.waitForAnyResultValue(resultListener, CaptureResult.CONTROL_AE_STATE,
                expectedAeStates, NUM_RESULTS_WAIT_TIMEOUT, WAIT_FOR_RESULT_TIMEOUT_MS);
    }

    /**
     * Create an {@link ImageReader} object and get the surface.
     *
     * @param size The size of this ImageReader to be created.
     * @param format The format of this ImageReader to be created
     * @param maxNumImages The max number of images that can be acquired simultaneously.
     * @param listener The listener used by this ImageReader to notify callbacks.
     */
    protected void createImageReader(Size size, int format, int maxNumImages,
            ImageReader.OnImageAvailableListener listener) throws Exception {
        closeImageReader();

        ImageReader r = makeImageReader(size, format, maxNumImages, listener,
                mHandler);
        mReader = r;
        mReaderSurface = r.getSurface();
    }

    /**
     * Close the pending images then close current active {@link ImageReader} object.
     */
    protected void closeImageReader() {
        CameraTestUtils.closeImageReader(mReader);
        mReader = null;
        mReaderSurface = null;
    }

    /**
     * Close the pending images then close current active {@link ImageReader} objects.
     */
    protected void closeImageReaders(ImageReader[] readers) {
        CameraTestUtils.closeImageReaders(readers);
    }

    /**
     * Setup still capture configuration and start preview.
     *
     * @param previewRequest The capture request to be used for preview
     * @param stillRequest The capture request to be used for still capture
     * @param previewSz Preview size
     * @param captureSizes Still capture sizes
     * @param formats The single capture image formats
     * @param resultListener Capture result listener
     * @param maxNumImages The max number of images set to the image reader
     * @param imageListeners The single capture capture image listeners
     * @param isHeic HEIC still capture if true, JPEG still capture if false
     */
    protected ImageReader[] prepareStillCaptureAndStartPreview(
            CaptureRequest.Builder previewRequest, CaptureRequest.Builder stillRequest,
            Size previewSz, Size[] captureSizes, int[] formats, CaptureCallback resultListener,
            int maxNumImages, ImageReader.OnImageAvailableListener[] imageListeners,
            boolean isHeic)
            throws Exception {

        if ((captureSizes == null) || (formats == null) || (imageListeners == null) &&
                (captureSizes.length != formats.length) ||
                (formats.length != imageListeners.length)) {
            throw new IllegalArgumentException(""Invalid capture sizes/formats or image listeners!"");
        }

        if (VERBOSE) {
            Log.v(TAG, String.format(""Prepare still capture and preview (%s)"",
                    previewSz.toString()));
        }

        // Update preview size.
        updatePreviewSurface(previewSz);

        ImageReader[] readers = new ImageReader[captureSizes.length];
        List<Surface> outputSurfaces = new ArrayList<Surface>();
        outputSurfaces.add(mPreviewSurface);
        for (int i = 0; i < captureSizes.length; i++) {
            readers[i] = makeImageReader(captureSizes[i], formats[i], maxNumImages,
                    imageListeners[i], mHandler);
            outputSurfaces.add(readers[i].getSurface());
        }

        mSessionListener = new BlockingSessionCallback();
        mSession = configureCameraSession(mCamera, outputSurfaces, mSessionListener, mHandler);

        // Configure the requests.
        previewRequest.addTarget(mPreviewSurface);
        stillRequest.addTarget(mPreviewSurface);
        for (int i = 0; i < readers.length; i++) {
            stillRequest.addTarget(readers[i].getSurface());
        }

        // Start preview.
        mSession.setRepeatingRequest(previewRequest.build(), resultListener, mHandler);

        return readers;
    }

    /**
     * Open a camera device and get the StaticMetadata for a given camera id.
     *
     * @param cameraId The id of the camera device to be opened.
     */
    protected void openDevice(String cameraId) throws Exception {
        mCamera = CameraTestUtils.openCamera(
                mCameraManager, cameraId, mCameraListener, mHandler);
        mCollector.setCameraId(cameraId);
        mStaticInfo = new StaticMetadata(mCameraManager.getCameraCharacteristics(cameraId),
                CheckLevel.ASSERT, /*collector*/null);
        if (mStaticInfo.isColorOutputSupported()) {
            mOrderedPreviewSizes = getSupportedPreviewSizes(cameraId, mCameraManager,
                    getPreviewSizeBound(mWindowManager, PREVIEW_SIZE_BOUND));
            m1080pBoundedOrderedPreviewSizes = getSupportedPreviewSizes(cameraId, mCameraManager,
                    PREVIEW_SIZE_BOUND);
            mOrderedVideoSizes = getSupportedVideoSizes(cameraId, mCameraManager, PREVIEW_SIZE_BOUND);
            mOrderedStillSizes = getSupportedStillSizes(cameraId, mCameraManager, null);
            // Use ImageFormat.YUV_420_888 for now. TODO: need figure out what's format for preview
            // in public API side.
            mMinPreviewFrameDurationMap =
                mStaticInfo.getAvailableMinFrameDurationsForFormatChecked(ImageFormat.YUV_420_888);
        }
    }

    /**
     * Close the current actively used camera device.
     */
    protected void closeDevice() {
        if (mCamera != null) {
            mCamera.close();
            mCameraListener.waitForState(STATE_CLOSED, CAMERA_CLOSE_TIMEOUT_MS);
            mCamera = null;
            mSession = null;
            mSessionListener = null;
            mStaticInfo = null;
            mOrderedPreviewSizes = null;
            mOrderedVideoSizes = null;
            mOrderedStillSizes = null;
        }
    }

    /**
     * Update the preview surface size.
     *
     * @param size The preview size to be updated.
     */
    protected void updatePreviewSurface(Size size) {
        if (size.equals(mPreviewSize) && mPreviewSurface != null) {
            Log.w(TAG, ""Skipping update preview surface size..."");
            return;
        }

        mPreviewSize = size;
        Camera2SurfaceViewCtsActivity ctsActivity = mActivityRule.getActivity();
        final SurfaceHolder holder = ctsActivity.getSurfaceView().getHolder();
        Handler handler = new Handler(Looper.getMainLooper());
        handler.post(new Runnable() {
            @Override
            public void run() {
                holder.setFixedSize(mPreviewSize.getWidth(), mPreviewSize.getHeight());
            }
        });

        boolean res = ctsActivity.waitForSurfaceSizeChanged(
                WAIT_FOR_SURFACE_CHANGE_TIMEOUT_MS, mPreviewSize.getWidth(),
                mPreviewSize.getHeight());
        assertTrue(""wait for surface change to "" + mPreviewSize.toString() + "" timed out"", res);
        mPreviewHolder = holder;
        mPreviewSurface = holder.getSurface();
        assertNotNull(""Preview surface is null"", mPreviewSurface);
        assertTrue(""Preview surface is invalid"", mPreviewSurface.isValid());
    }

    /**
     * Recreate the SurfaceView's Surface
     *
     * Hide and unhide the activity's preview SurfaceView, so that its backing Surface is
     * recreated
     */
    protected void recreatePreviewSurface() {
        Camera2SurfaceViewCtsActivity ctsActivity = mActivityRule.getActivity();
        setPreviewVisibility(View.GONE);
        boolean res = ctsActivity.waitForSurfaceState(
            WAIT_FOR_SURFACE_CHANGE_TIMEOUT_MS, /*valid*/ false);
        assertTrue(""wait for surface destroyed timed out"", res);
        setPreviewVisibility(View.VISIBLE);
        res = ctsActivity.waitForSurfaceState(
            WAIT_FOR_SURFACE_CHANGE_TIMEOUT_MS, /*valid*/ true);
        assertTrue(""wait for surface created timed out"", res);
    }

    /**
     * Show/hide the preview SurfaceView.
     *
     * If set to View.GONE, the surfaceDestroyed callback will fire
     * @param visibility the new new visibility to set, one of View.VISIBLE / INVISIBLE / GONE
     */
    protected void setPreviewVisibility(int visibility) {
        final Camera2SurfaceViewCtsActivity ctsActivity = mActivityRule.getActivity();
        Handler handler = new Handler(Looper.getMainLooper());
        handler.post(new Runnable() {
            @Override
            public void run() {
                ctsActivity.getSurfaceView().setVisibility(visibility);
            }
        });
    }

    /**
     * Setup single capture configuration and start preview.
     *
     * @param previewRequest The capture request to be used for preview
     * @param stillRequest The capture request to be used for still capture
     * @param previewSz Preview size
     * @param captureSz Still capture size
     * @param format The single capture image format
     * @param resultListener Capture result listener
     * @param maxNumImages The max number of images set to the image reader
     * @param imageListener The single capture capture image listener
     */
    protected void prepareCaptureAndStartPreview(CaptureRequest.Builder previewRequest,
            CaptureRequest.Builder stillRequest, Size previewSz, Size captureSz, int format,
            CaptureCallback resultListener, int maxNumImages,
            ImageReader.OnImageAvailableListener imageListener) throws Exception {
        prepareCaptureAndStartPreview(previewRequest, stillRequest, previewSz, captureSz,
            format, resultListener, null, maxNumImages, imageListener);
    }

    /**
     * Setup single capture configuration and start preview.
     *
     * @param previewRequest The capture request to be used for preview
     * @param stillRequest The capture request to be used for still capture
     * @param previewSz Preview size
     * @param captureSz Still capture size
     * @param format The single capture image format
     * @param resultListener Capture result listener
     * @param sessionListener Session listener
     * @param maxNumImages The max number of images set to the image reader
     * @param imageListener The single capture capture image listener
     */
    protected void prepareCaptureAndStartPreview(CaptureRequest.Builder previewRequest,
            CaptureRequest.Builder stillRequest, Size previewSz, Size captureSz, int format,
            CaptureCallback resultListener, CameraCaptureSession.StateCallback sessionListener,
            int maxNumImages, ImageReader.OnImageAvailableListener imageListener) throws Exception {
        if (VERBOSE) {
            Log.v(TAG, String.format(""Prepare single capture (%s) and preview (%s)"",
                    captureSz.toString(), previewSz.toString()));
        }

        // Update preview size.
        updatePreviewSurface(previewSz);

        // Create ImageReader.
        createImageReader(captureSz, format, maxNumImages, imageListener);

        // Configure output streams with preview and jpeg streams.
        List<Surface> outputSurfaces = new ArrayList<Surface>();
        outputSurfaces.add(mPreviewSurface);
        outputSurfaces.add(mReaderSurface);
        if (sessionListener == null) {
            mSessionListener = new BlockingSessionCallback();
        } else {
            mSessionListener = new BlockingSessionCallback(sessionListener);
        }
        mSession = configureCameraSession(mCamera, outputSurfaces, mSessionListener, mHandler);

        // Configure the requests.
        previewRequest.addTarget(mPreviewSurface);
        stillRequest.addTarget(mPreviewSurface);
        stillRequest.addTarget(mReaderSurface);

        // Start preview.
        mSession.setRepeatingRequest(previewRequest.build(), resultListener, mHandler);
    }

    /**
     * Get the max preview size that supports the given fpsRange.
     *
     * @param fpsRange The fps range the returned size must support.
     * @return max size that support the given fps range.
     */
    protected Size getMaxPreviewSizeForFpsRange(Range<Integer> fpsRange) {
        if (fpsRange == null || fpsRange.getLower() <= 0 || fpsRange.getUpper() <= 0) {
            throw new IllegalArgumentException(""Invalid fps range argument"");
        }
        if (mOrderedPreviewSizes == null || mMinPreviewFrameDurationMap == null) {
            throw new IllegalStateException(""mOrderedPreviewSizes and mMinPreviewFrameDurationMap""
                    + "" must be initialized"");
        }

        long[] frameDurationRange =
                new long[]{(long) (1e9 / fpsRange.getUpper()), (long) (1e9 / fpsRange.getLower())};
        for (Size size : mOrderedPreviewSizes) {
            Long minDuration = mMinPreviewFrameDurationMap.get(size);
            if (minDuration == null ||
                    minDuration == 0) {
                if (mStaticInfo.isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                    throw new IllegalArgumentException(
                            ""No min frame duration available for the size "" + size);
                }
                continue;
            }
            if (minDuration <= (frameDurationRange[0] + MIN_FRAME_DURATION_ERROR_MARGIN)) {
                return size;
            }
        }

        // Search again for sizes not bounded by display size
        for (Size size : m1080pBoundedOrderedPreviewSizes) {
            Long minDuration = mMinPreviewFrameDurationMap.get(size);
            if (minDuration == null ||
                    minDuration == 0) {
                if (mStaticInfo.isCapabilitySupported(
                        CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR)) {
                    throw new IllegalArgumentException(
                            ""No min frame duration available for the size "" + size);
                }
                continue;
            }
            if (minDuration <= (frameDurationRange[0] + MIN_FRAME_DURATION_ERROR_MARGIN)) {
                return size;
            }
        }
        return null;
    }

    protected boolean isReprocessSupported(String cameraId, int format)
            throws CameraAccessException {
        if (format != ImageFormat.YUV_420_888 && format != ImageFormat.PRIVATE) {
            throw new IllegalArgumentException(
                    ""format "" + format + "" is not supported for reprocessing"");
        }

        StaticMetadata info =
                new StaticMetadata(mCameraManager.getCameraCharacteristics(cameraId),
                                   CheckLevel.ASSERT, /*collector*/ null);
        int cap = CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_YUV_REPROCESSING;
        if (format == ImageFormat.PRIVATE) {
            cap = CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING;
        }
        return info.isCapabilitySupported(cap);
    }

    protected Range<Integer> getSuitableFpsRangeForDuration(String cameraId, long frameDuration) {
        return CameraTestUtils.getSuitableFpsRangeForDuration(cameraId, frameDuration, mStaticInfo);
    }

    private int captureRequestsSynchronizedImpl(
            CaptureRequest request, int count, CaptureCallback listener, Handler handler,
            boolean isBurst) throws CameraAccessException {
        if (count < 1) {
            throw new IllegalArgumentException(""count must be positive"");
        }

        int maxLatency = mStaticInfo.getSyncMaxLatency();
        if (maxLatency == CameraMetadata.SYNC_MAX_LATENCY_UNKNOWN) {
            maxLatency = NUM_FRAMES_WAITED_FOR_UNKNOWN_LATENCY;
        }

        assertTrue(""maxLatency is non-negative"", maxLatency >= 0);

        int numCaptures = maxLatency + count;
        ArrayList<CaptureRequest> burstCaptureRequests = new ArrayList<>();
        for (int i = 0; i < numCaptures; ++i) {
            if (isBurst) {
                burstCaptureRequests.add(request);
            } else {
                mSession.capture(request, listener, handler);
            }
        }
        if (isBurst) {
            mSession.captureBurst(burstCaptureRequests, listener, handler);
        }

        return numCaptures;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.returnedrateinfo.ReturnedRateInfoTest"	"getSensorList"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/ReturnedRateInfo/src/android/sensorratepermission/cts/returnedrateinfo/ReturnedRateInfoTest.java"	""	"/*
 *.
 */

package android.sensorratepermission.cts.returnedrateinfo;

import android.content.Context;
import android.hardware.Sensor;
import android.hardware.SensorManager;
import android.hardware.cts.helpers.SensorRatePermissionDirectReportTestHelper;
import android.hardware.cts.helpers.SensorRatePermissionEventConnectionTestHelper;

import androidx.test.platform.app.InstrumentationRegistry;

import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.junit.runners.Parameterized;

import java.util.Collection;
import java.util.List;

/**
 * Test output of the following methods when the app targets API level >= S.
 * - getMinDelay()
 * - getSensorList()
 * - getHighestDirectReportRateLevel()
 */
@RunWith(Parameterized.class)
public class ReturnedRateInfoTest {
    private static SensorManager mSensorManager;

    private final int sensorType;

    public ReturnedRateInfoTest(int sensorType) {
        this.sensorType = sensorType;
    }

    @Parameterized.Parameters
    public static Collection cappedSensorTypeSet() {
        return SensorRatePermissionEventConnectionTestHelper.CAPPED_SENSOR_TYPE_SET;
    }

    @Before
    public void setUp() {
        Context context = InstrumentationRegistry.getInstrumentation().getContext();
        mSensorManager = context.getSystemService(SensorManager.class);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.returnedrateinfo.ReturnedRateInfoTest"	"testGetMinDelayMethod"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/ReturnedRateInfo/src/android/sensorratepermission/cts/returnedrateinfo/ReturnedRateInfoTest.java"	""	"public void testGetMinDelayMethod() {
        int cappedMinDelayUs = 1 * 1000 * 1000
                / SensorRatePermissionEventConnectionTestHelper.CAPPED_SAMPLE_RATE_HZ;

        Sensor s = mSensorManager.getDefaultSensor(sensorType);
        if (s == null) {
            return;
        }
        int minDelay = s.getMinDelay();

        Assert.assertTrue(""Min delay cannot be smaller than "" + cappedMinDelayUs + "" (Us)!"",
                minDelay >= cappedMinDelayUs);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.returnedrateinfo.ReturnedRateInfoTest"	"testGetSensorListMethod"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/ReturnedRateInfo/src/android/sensorratepermission/cts/returnedrateinfo/ReturnedRateInfoTest.java"	""	"public void testGetSensorListMethod() {
        int cappedMinDelayUs = 1 * 1000 * 1000
                / SensorRatePermissionEventConnectionTestHelper.CAPPED_SAMPLE_RATE_HZ;

        List<Sensor> allSensorList = mSensorManager.getSensorList(sensorType);
        if (allSensorList == null) {
            return;
        }
        for (Sensor s : allSensorList) {
            Assert.assertTrue(""Min delay cannot be smaller than "" + cappedMinDelayUs + "" (Us)!"",
                    s.getMinDelay() >= cappedMinDelayUs);
        }
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.sensorratepermission.cts.returnedrateinfo.ReturnedRateInfoTest"	"testGetHighestDirectReportRateLevelMethod"	""	"/home/gpoor/cts-12-source/cts/tests/sensor/sensorratepermission/ReturnedRateInfo/src/android/sensorratepermission/cts/returnedrateinfo/ReturnedRateInfoTest.java"	""	"public void testGetHighestDirectReportRateLevelMethod() {
        Sensor s = mSensorManager.getDefaultSensor(sensorType);
        if (s == null) {
            return;
        }
        int obtainedHighestRateLevel = s.getHighestDirectReportRateLevel();

        Assert.assertTrue(""Highest direct report rate level cannot be larger than ""
                        + SensorRatePermissionDirectReportTestHelper.CAPPED_DIRECT_REPORT_RATE_LEVEL,
                obtainedHighestRateLevel
                        <= SensorRatePermissionDirectReportTestHelper.CAPPED_DIRECT_REPORT_RATE_LEVEL);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.location.cts.fine.GeofencingTest"	"currentTimeMillis"	"CtsLocationFineTestCases"	"/home/gpoor/cts-12-source/cts/tests/location/location_fine/src/android/location/cts/fine/GeofencingTest.java"	""	"/*
 *.
 */

package android.location.cts.fine;

import static android.location.LocationManager.FUSED_PROVIDER;

import static com.android.compatibility.common.util.LocationUtils.createLocation;

import static com.google.common.truth.Truth.assertThat;

import static org.junit.Assert.fail;

import android.app.PendingIntent;
import android.content.Context;
import android.content.Intent;
import android.location.Criteria;
import android.location.LocationManager;
import android.location.cts.common.ProximityPendingIntentCapture;
import android.util.Log;

import androidx.test.core.app.ApplicationProvider;
import androidx.test.ext.junit.runners.AndroidJUnit4;
import androidx.test.platform.app.InstrumentationRegistry;

import com.android.compatibility.common.util.LocationUtils;

import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import org.junit.runner.RunWith;

import java.util.Objects;

@RunWith(AndroidJUnit4.class)
public class GeofencingTest {

    private static final String TAG = ""GeofenceManagerTest"";

    private static final long TIMEOUT_MS = 5000;
    private static final long FAILURE_TIMEOUT_MS = 200;

    private static final String TEST_PROVIDER = ""test_provider"";

    private Context mContext;
    private LocationManager mManager;

    @Before
    public void setUp() throws Exception {
        LocationUtils.registerMockLocationProvider(InstrumentationRegistry.getInstrumentation(),
                true);

        long seed = System.currentTimeMillis();
        Log.i(TAG, ""location random seed: "" + seed);

        mContext = ApplicationProvider.getApplicationContext();
        mManager = Objects.requireNonNull(mContext.getSystemService(LocationManager.class));

        for (String provider : mManager.getAllProviders()) {
            mManager.removeTestProvider(provider);
        }

        mManager.addTestProvider(TEST_PROVIDER,
                true,
                false,
                true,
                false,
                false,
                false,
                false,
                Criteria.POWER_MEDIUM,
                Criteria.ACCURACY_FINE);
        mManager.setTestProviderEnabled(TEST_PROVIDER, true);
    }

    @After
    public void tearDown() throws Exception {
        if (mManager != null) {
            for (String provider : mManager.getAllProviders()) {
                mManager.removeTestProvider(provider);
            }
        }

        LocationUtils.registerMockLocationProvider(InstrumentationRegistry.getInstrumentation(),
                false);
    }"	""	""	"proximity"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.location.cts.fine.GeofencingTest"	"testAddProximityAlert"	"CtsLocationFineTestCases"	"/home/gpoor/cts-12-source/cts/tests/location/location_fine/src/android/location/cts/fine/GeofencingTest.java"	""	"public void testAddProximityAlert() throws Exception {
        mManager.addTestProvider(FUSED_PROVIDER,
                true,
                false,
                true,
                false,
                false,
                false,
                false,
                Criteria.POWER_MEDIUM,
                Criteria.ACCURACY_FINE);
        mManager.setTestProviderEnabled(FUSED_PROVIDER, true);
        mManager.setTestProviderLocation(FUSED_PROVIDER,
                createLocation(FUSED_PROVIDER, 30, 30, 10));

        try (ProximityPendingIntentCapture capture = new ProximityPendingIntentCapture(mContext)) {
            mManager.addProximityAlert(0, 0, 1000, -1, capture.getPendingIntent());

            mManager.setTestProviderLocation(FUSED_PROVIDER,
                    createLocation(FUSED_PROVIDER, 0, 0, 10));
            assertThat(capture.getNextProximityChange(TIMEOUT_MS)).isEqualTo(Boolean.TRUE);

            mManager.setTestProviderLocation(FUSED_PROVIDER,
                    createLocation(FUSED_PROVIDER, 30, 30, 10));
            assertThat(capture.getNextProximityChange(TIMEOUT_MS)).isEqualTo(Boolean.FALSE);
        }

        try {
            mManager.addProximityAlert(0, 0, 1000, -1, null);
            fail(""Should throw IllegalArgumentException if pending intent is null!"");
        } catch (IllegalArgumentException e) {
            // expected
        }

        PendingIntent immutablePI = PendingIntent.getBroadcast(mContext, 0,
                new Intent(""IMMUTABLE_TEST_ACTION"")
                        .setPackage(mContext.getPackageName())
                        .addFlags(Intent.FLAG_RECEIVER_FOREGROUND),
                PendingIntent.FLAG_CANCEL_CURRENT | PendingIntent.FLAG_IMMUTABLE);
        try {
            mManager.addProximityAlert(0, 0, 1000, -1, immutablePI);
            fail(""Should throw IllegalArgumentException if pending intent is immutable!"");
        } catch (IllegalArgumentException e) {
            // expected
        } finally {
            immutablePI.cancel();
        }

        try (ProximityPendingIntentCapture capture = new ProximityPendingIntentCapture(mContext)) {
            try {
                mManager.addProximityAlert(0, 0, 0, -1, capture.getPendingIntent());
                fail(""Should throw IllegalArgumentException if radius == 0!"");
            } catch (IllegalArgumentException e) {
                // expected
            }

            try {
                mManager.addProximityAlert(0, 0, -1, -1, capture.getPendingIntent());
                fail(""Should throw IllegalArgumentException if radius < 0!"");
            } catch (IllegalArgumentException e) {
                // expected
            }

            try {
                mManager.addProximityAlert(1000, 1000, 1000, -1, capture.getPendingIntent());
                fail(""Should throw IllegalArgumentException if lat/lon are illegal!"");
            } catch (IllegalArgumentException e) {
                // expected
            }
        }
    }"	""	""	"proximity"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.location.cts.fine.GeofencingTest"	"testRemoveProximityAlert"	"CtsLocationFineTestCases"	"/home/gpoor/cts-12-source/cts/tests/location/location_fine/src/android/location/cts/fine/GeofencingTest.java"	""	"public void testRemoveProximityAlert() throws Exception {
        mManager.addTestProvider(FUSED_PROVIDER,
                true,
                false,
                true,
                false,
                false,
                false,
                false,
                Criteria.POWER_MEDIUM,
                Criteria.ACCURACY_FINE);
        mManager.setTestProviderEnabled(FUSED_PROVIDER, true);
        mManager.setTestProviderLocation(FUSED_PROVIDER,
                createLocation(FUSED_PROVIDER, 30, 30, 10));

        try (ProximityPendingIntentCapture capture = new ProximityPendingIntentCapture(mContext)) {
            mManager.addProximityAlert(0, 0, 1000, -1, capture.getPendingIntent());
            mManager.removeProximityAlert(capture.getPendingIntent());

            mManager.setTestProviderLocation(FUSED_PROVIDER,
                    createLocation(FUSED_PROVIDER, 0, 0, 10));
            assertThat(capture.getNextProximityChange(FAILURE_TIMEOUT_MS)).isNull();
        }

        try {
            mManager.removeProximityAlert(null);
            fail(""Should throw IllegalArgumentException if pending intent is null!"");
        } catch (IllegalArgumentException e) {
            // expected
        }
    }"	""	""	"proximity"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.location.cts.fine.GeofencingTest"	"testAddProximityAlert_StartProximate"	"CtsLocationFineTestCases"	"/home/gpoor/cts-12-source/cts/tests/location/location_fine/src/android/location/cts/fine/GeofencingTest.java"	""	"public void testAddProximityAlert_StartProximate() throws Exception {
        mManager.addTestProvider(FUSED_PROVIDER,
                true,
                false,
                true,
                false,
                false,
                false,
                false,
                Criteria.POWER_MEDIUM,
                Criteria.ACCURACY_FINE);
        mManager.setTestProviderEnabled(FUSED_PROVIDER, true);
        mManager.setTestProviderLocation(FUSED_PROVIDER, createLocation(FUSED_PROVIDER, 0, 0, 10));

        try (ProximityPendingIntentCapture capture = new ProximityPendingIntentCapture(mContext)) {
            mManager.addProximityAlert(0, 0, 1000, -1, capture.getPendingIntent());
            assertThat(capture.getNextProximityChange(TIMEOUT_MS)).isEqualTo(Boolean.TRUE);
        }
    }"	""	""	"proximity"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.location.cts.fine.GeofencingTest"	"testAddProximityAlert_Multiple"	"CtsLocationFineTestCases"	"/home/gpoor/cts-12-source/cts/tests/location/location_fine/src/android/location/cts/fine/GeofencingTest.java"	""	"public void testAddProximityAlert_Multiple() throws Exception {
        mManager.addTestProvider(FUSED_PROVIDER,
                true,
                false,
                true,
                false,
                false,
                false,
                false,
                Criteria.POWER_MEDIUM,
                Criteria.ACCURACY_FINE);
        mManager.setTestProviderEnabled(FUSED_PROVIDER, true);
        mManager.setTestProviderLocation(FUSED_PROVIDER,
                createLocation(FUSED_PROVIDER, 30, 30, 10));

        ProximityPendingIntentCapture capture = new ProximityPendingIntentCapture(mContext);
        try {
            mManager.addProximityAlert(0, 0, 1000, -1, capture.getPendingIntent());
            mManager.addProximityAlert(30, 30, 1000, -1, capture.getPendingIntent());

            assertThat(capture.getNextProximityChange(TIMEOUT_MS)).isEqualTo(Boolean.TRUE);

            mManager.setTestProviderLocation(FUSED_PROVIDER,
                    createLocation(FUSED_PROVIDER, 0, 0, 10));
            Boolean first = capture.getNextProximityChange(TIMEOUT_MS);
            assertThat(first).isNotNull();
            Boolean second = capture.getNextProximityChange(TIMEOUT_MS);
            assertThat(second).isNotNull();
            assertThat(first).isNotEqualTo(second);
        } finally {
            capture.close();
        }

        mManager.setTestProviderLocation(FUSED_PROVIDER,
                createLocation(FUSED_PROVIDER, 30, 30, 10));
        assertThat(capture.getNextProximityChange(FAILURE_TIMEOUT_MS)).isNull();
    }"	""	""	"proximity"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.location.cts.fine.GeofencingTest"	"testAddProximityAlert_Expires"	"CtsLocationFineTestCases"	"/home/gpoor/cts-12-source/cts/tests/location/location_fine/src/android/location/cts/fine/GeofencingTest.java"	""	"public void testAddProximityAlert_Expires() throws Exception {
        mManager.addTestProvider(FUSED_PROVIDER,
                true,
                false,
                true,
                false,
                false,
                false,
                false,
                Criteria.POWER_MEDIUM,
                Criteria.ACCURACY_FINE);
        mManager.setTestProviderEnabled(FUSED_PROVIDER, true);
        mManager.setTestProviderLocation(FUSED_PROVIDER,
                createLocation(FUSED_PROVIDER, 30, 30, 10));

        try (ProximityPendingIntentCapture capture = new ProximityPendingIntentCapture(mContext)) {
            mManager.addProximityAlert(0, 0, 1000, 1, capture.getPendingIntent());

            mManager.setTestProviderLocation(FUSED_PROVIDER,
                    createLocation(FUSED_PROVIDER, 0, 0, 10));
            assertThat(capture.getNextProximityChange(FAILURE_TIMEOUT_MS)).isNull();
        }
    }
}"	""	""	"proximity"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.OffsetVerificationTest"	"testSingleEventVerify"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/OffsetVerificationTest.java"	""	"public void testSingleEventVerify() {
        float[][] values = null;

        // Verify that the norm is calculated correctly
        values = new float[][]{ {10, 10, 10, 2, 2, 2} };
        runStats(2.0f /* threshold */, values, true /* pass */);
        runStats(1.9f /* threshold */, values, false /* pass */);

        // Verify that the first value from the offsets is used
        values = new float[][]{ {10, 10, 10, 2, 0, 0} };
        runStats(2.0f /* threshold */, values, true /* pass */);
        runStats(1.9f /* threshold */, values, false /* pass */);

        // Verify that the last value from the offsets is used
        values = new float[][]{ {10, 10, 10, 0, 0, 2} };
        runStats(2.0f /* threshold */, values, true /* pass */);
        runStats(1.9f /* threshold */, values, false /* pass */);

        // Verify that no values outside the offsets is used
        values = new float[][]{ {10, 10, 10, 0, 0, 0, 1} };
        runStats(0.1f /* threshold */, values, true /* pass */);
    }

    /**
     * Test {@link OffsetVerification#verify(TestSensorEnvironment, SensorStats)}.
     * This test verifies that multiple sensor events are correctly recorded and
     * verified.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.OffsetVerificationTest"	"testMultipleEventVerify"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/OffsetVerificationTest.java"	""	"public void testMultipleEventVerify() {
        float[][] values = null;

        values = new float[][] {
                {10, 10, 10, 2, 2, 2},
                {10, 10, 10, 2, 2, 2}
        };
        runStats(2.0f /* threshold */, values, true /* pass */);
        runStats(1.9f /* threshold */, values, false /* pass */);

        // Verify when the first event exceeds the threshold and the second does not
        values = new float[][] {
                {0, 0, 0, 2, 2, 2},
                {0, 0, 0, 0, 0, 0}
        };
        runStats(1.9f /* threshold */, values, false /* pass */);

        // Verify when the second event exceeds the threshold and the first does not
        values = new float[][] {
                {0, 0, 0, 0, 0, 0},
                {0, 0, 0, 10, 10, 10}
        };
        runStats(3.0f /* threshold */, values, false /* pass */);
    }

    private void runStats(float threshold, float[][] values, boolean pass) {
        SensorStats stats = new SensorStats();
        OffsetVerification verification = getVerification(threshold, values);
        if (pass) {
            verification.verify(stats);
        } else {
            try {
                verification.verify(stats);
                throw new Error(""Expected a SensorTestWarningException"");
            } catch (SensorTestWarningException e) {
                // Expected;
            }
        }
        assertEquals(pass, stats.getValue(OffsetVerification.PASSED_KEY));
    }

    private static OffsetVerification getVerification(
            float threshold, float[] ... values) {
        Collection<TestSensorEvent> events = new ArrayList<>(values.length);
        for (float[] value : values) {
            events.add(new TestSensorEvent(null /* sensor */, 0 /* timestamp */,
                    0 /* receivedTimestamp */, value));
        }
        OffsetVerification verification = new OffsetVerification(threshold);
        verification.addSensorEvents(events);
        return verification;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.EventTimestampSynchronizationVerification"	"isDeviceSuspendTest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/EventTimestampSynchronizationVerification.java"	""	"public void test/*
 *
 */

package android.hardware.cts.helpers.sensorverification;

import junit.framework.Assert;

import android.hardware.SensorEvent;
import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEvent;
import android.os.SystemClock;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;

/**
 * A {@link ISensorVerification} which verifies that the timestamp of the {@link SensorEvent} is
 * synchronized with {@link SystemClock#elapsedRealtimeNanos()}, based on a given threshold.
 */
public class EventTimestampSynchronizationVerification extends AbstractSensorVerification {
    public static final String PASSED_KEY = ""timestamp_synchronization_passed"";

    // number of indices to print in assertion message before truncating
    private static final int TRUNCATE_MESSAGE_LENGTH = 3;

    private static final long DEFAULT_THRESHOLD_NS = TimeUnit.MILLISECONDS.toNanos(1000);
    private static final float ALLOWED_LATENCY_ERROR = 0.1f; //10%

    private final ArrayList<TestSensorEvent> mCollectedEvents = new ArrayList<TestSensorEvent>();

    private final long mMaximumSynchronizationErrorNs;
    private final long mExpectedSyncLatencyNs;

    /**
     * Constructs an instance of {@link EventTimestampSynchronizationVerification}.
     *
     * @param maximumSynchronizationErrorNs The valid threshold for timestamp synchronization.
     * @param reportLatencyNs The latency on which batching events are received
     */
    public EventTimestampSynchronizationVerification(
            long maximumSynchronizationErrorNs,
            long expectedSyncLatencyNs) {
        mMaximumSynchronizationErrorNs = maximumSynchronizationErrorNs;
        mExpectedSyncLatencyNs = expectedSyncLatencyNs;
    }

    /**
     * Gets a default {@link EventTimestampSynchronizationVerification}.
     *
     * @param environment The test environment
     * @return The verification or null if the verification is not supported in the given
     *         environment.
     */
    public static EventTimestampSynchronizationVerification getDefault(
            TestSensorEnvironment environment) {
        long reportLatencyUs = environment.getMaxReportLatencyUs();
        long fifoMaxEventCount = environment.getSensor().getFifoMaxEventCount();
        int maximumExpectedSamplingPeriodUs = environment.getMaximumExpectedSamplingPeriodUs();
        if (fifoMaxEventCount > 0 && maximumExpectedSamplingPeriodUs != Integer.MAX_VALUE) {
            long fifoBasedReportLatencyUs = fifoMaxEventCount * maximumExpectedSamplingPeriodUs;
            // If the device goes into suspend mode and the sensor is a non wake-up sensor, the
            // FIFO will keep overwriting itself and the reportLatency will be equal to the time
            // it takes to fill up the FIFO.
            if (environment.isDeviceSuspendTest() && !environment.getSensor().isWakeUpSensor()) {
                reportLatencyUs = fifoBasedReportLatencyUs;
            } else {
                // In this case the sensor under test is either a wake-up sensor OR it
                // is a non wake-up sensor but the device does not go into suspend.
                // So the expected delay of a sensor_event is the minimum of the
                // fifoBasedReportLatencyUs and the requested latency by the application.
                reportLatencyUs = Math.min(reportLatencyUs, fifoBasedReportLatencyUs);
            }
        }
        // Add an additional filter delay which is a function of the samplingPeriod.
        long filterDelayUs = (long)(2.5 * maximumExpectedSamplingPeriodUs);

        long expectedSyncLatencyNs = TimeUnit.MICROSECONDS.toNanos(reportLatencyUs + filterDelayUs);
        return new EventTimestampSynchronizationVerification(
                (long) (DEFAULT_THRESHOLD_NS + ALLOWED_LATENCY_ERROR * reportLatencyUs * 1000),
                expectedSyncLatencyNs);
    }

    @Override
    public void verify(TestSensorEnvironment environment, SensorStats stats) {
        StringBuilder errorMessageBuilder =
                new StringBuilder("" event timestamp synchronization failures: "");
        List<IndexedEvent> failures = verifyTimestampSynchronization(errorMessageBuilder);
        int failuresCount = failures.size();
        stats.addValue(SensorStats.EVENT_TIME_SYNCHRONIZATION_COUNT_KEY, failuresCount);
        stats.addValue(
                SensorStats.EVENT_TIME_SYNCHRONIZATION_POSITIONS_KEY,
                getIndexArray(failures));

        boolean success = failures.isEmpty();
        stats.addValue(PASSED_KEY, success);
        errorMessageBuilder.insert(0, failuresCount);
        Assert.assertTrue(errorMessageBuilder.toString(), success);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public EventTimestampSynchronizationVerification clone() {
        return new EventTimestampSynchronizationVerification(
                mMaximumSynchronizationErrorNs,
                mExpectedSyncLatencyNs);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    protected void addSensorEventInternal(TestSensorEvent event) {
        mCollectedEvents.add(event);
    }

    /**
     * Verifies timestamp synchronization for all sensor events.
     * The verification accounts for a lower and upper threshold, such thresholds are adjusted for
     * batching cases.
     *
     * @param builder A string builder to store error messaged found in the collected sensor events.
     * @return A list of events tha failed the verification.
     */
    private List<IndexedEvent> verifyTimestampSynchronization(StringBuilder builder) {
        int collectedEventsCount = mCollectedEvents.size();
        ArrayList<IndexedEvent> failures = new ArrayList<IndexedEvent>();

        for (int i = 0; i < collectedEventsCount; ++i) {
            TestSensorEvent event = mCollectedEvents.get(i);
            long eventTimestampNs = event.timestamp;
            long receivedTimestampNs = event.receivedTimestamp;
            long upperThresholdNs = receivedTimestampNs;
            long lowerThresholdNs = receivedTimestampNs - mMaximumSynchronizationErrorNs
                    - mExpectedSyncLatencyNs;

            if (eventTimestampNs < lowerThresholdNs || eventTimestampNs > upperThresholdNs) {
                if (failures.size() < TRUNCATE_MESSAGE_LENGTH) {
                    builder.append(""position="").append(i);
                    builder.append("", timestamp="").append(String.format(""%.2fms"",
                                nanosToMillis(eventTimestampNs)));
                    builder.append("", expected=["").append(String.format(""%.2fms"",
                                nanosToMillis(lowerThresholdNs)));
                    builder.append("", "").append(String.format(""%.2f]ms; "",
                                nanosToMillis(upperThresholdNs)));
                }
                failures.add(new IndexedEvent(i, event));
            }
        }
        if (failures.size() >= TRUNCATE_MESSAGE_LENGTH) {
            builder.append(""more; "");
        }
        return failures;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.EventBasicVerificationTest"	"testVerify"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/EventBasicVerificationTest.java"	""	"public void testVerify() {

        /* Sensor contents is not used in this verification, use Object as mock */
        SensorManager mgr = (SensorManager) mContext.getSystemService(Context.SENSOR_SERVICE);

        Sensor sensor1 = null;

        // accelerometer is the most likely sensor to exist
        Sensor sensor2 = mgr.getDefaultSensor(Sensor.TYPE_ACCELEROMETER);

        SensorStats stats;

        EventBasicVerification verification;

        // case 1
        verification = getVerification(10, sensor1, sensor1, new float[20][3]);
        stats = new SensorStats();

        verification.verify(stats);
        assertEquals(true, stats.getValue(EventBasicVerification.PASSED_KEY));
        assertEquals(20, (long) stats.getValue(SensorStats.EVENT_COUNT_KEY));
        assertEquals(false, stats.getValue(SensorStats.WRONG_SENSOR_KEY));

        // case 2
        verification = getVerification(10, sensor1, sensor1, new float[5][3]);
        stats = new SensorStats();

        try {
            verification.verify(stats);
            throw new Error(""Expect an AssertionError due to insufficient samples"");
        } catch (AssertionError e) {
            //Expected
        }
        assertEquals(false, stats.getValue(EventBasicVerification.PASSED_KEY));
        assertEquals(5, (long) stats.getValue(SensorStats.EVENT_COUNT_KEY));
        assertEquals(false, stats.getValue(SensorStats.WRONG_SENSOR_KEY));

        // case 3
        if (sensor1 != sensor2) {
            // if we cannot even get a second sensor then do not bother this test.
            verification = getVerification(10, sensor1, sensor2, new float[15][3]);
            stats = new SensorStats();

            try {
                verification.verify(stats);
                throw new Error(""Expect an AssertionError due to wrong sensor event"");
            } catch (AssertionError e) {
                //Expected
            }
            assertEquals(false, stats.getValue(EventBasicVerification.PASSED_KEY));
            // zero here because wrong sensor is used.
            assertEquals(0, (long) stats.getValue(SensorStats.EVENT_COUNT_KEY));
            assertEquals(true, stats.getValue(SensorStats.WRONG_SENSOR_KEY));
        }
    }

    private static EventBasicVerification getVerification(
            int expectedMinNumEvent, Sensor sensor, Sensor eventSensor, float[] ... values) {

        Collection<TestSensorEvent> events = new ArrayList<>(values.length);
        for (float[] value : values) {
            events.add(new TestSensorEvent(eventSensor, 0, 0, value));
        }
        EventBasicVerification verification =
                new EventBasicVerification(expectedMinNumEvent, sensor);
        verification.addSensorEvents(events);
        return verification;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.BurstCaptureRawTest"	"testRawSensorSize"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/BurstCaptureRawTest.java"	""	"public void testRawSensorSize() throws Exception {
        Log.i(TAG, ""Begin testRawSensorSize"");
        for (String id : mCameraIdsUnderTest) {
            try {
                ArrayList<Integer> supportedRawList = new ArrayList<Integer>(RAW_FORMATS.length);
                if (!checkCapability(id, supportedRawList, RAW_FORMATS)) {
                    Log.i(TAG, ""Capability is not supported on camera "" + id
                            + "". Skip the test."");
                    continue;
                }

                openDevice(id);
                Size[] rawSizes = mStaticInfo.getRawOutputSizesChecked();
                assertTrue(""No capture sizes available for RAW format!"", rawSizes.length != 0);

                // Check happens in getRawDimensChecked.
                Size rawSize = mStaticInfo.getRawDimensChecked();
            } finally {
                closeDevice();
            }
        }
        Log.i(TAG, ""End testRawSensorSize"");
    }

    /**
     * Round [exposure, gain] down, rather than to the nearest, in RAW 10/16
     * <p>
     * Verify the value of metadata (exposure and sensitivity) is rounded down if the request cannot
     * be honored.
     * </p>
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.BurstCaptureRawTest"	"testTimestamp"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/BurstCaptureRawTest.java"	""	"public void testTimestamp() throws Exception {
        Log.i(TAG, ""Begin testTimestamp"");

        performTestRoutine(new TestTimestamp(), NONSTALL_RAW_FORMATS);

        Log.i(TAG, ""End testTimestamp"");
    }

    /*
     * Below are private infrastructure for all tests
     */

    /**
     * A structure encapsulates all the parameters for setting up preview, and RAW capture.
     */
    class CaptureSetup
    {
        public CaptureSetup(Size previewCaptureSize, Size rawCaptureSize,
                CaptureRequest.Builder previewRequestBuilder,
                CaptureRequest.Builder rawRequestBuilder,
                SimpleCaptureCallback previewCaptureCallback,
                SimpleCaptureCallback rawCaptureCallback,
                SimpleImageReaderListener rawReaderListener)
        {
            mPreviewCaptureSize = previewCaptureSize;
            mRawCaptureSize = rawCaptureSize;
            mPreviewRequestBuilder = previewRequestBuilder;
            mRawRequestBuilder = rawRequestBuilder;
            mPreviewCaptureCallback = previewCaptureCallback;
            mRawCaptureCallback = rawCaptureCallback;
            mRawReaderListener = rawReaderListener;
        }

        public Size getPreviewCaptureSize()
        {
            return mPreviewCaptureSize;
        }

        public Size getRawCaptureSize()
        {
            return mRawCaptureSize;
        }

        public CaptureRequest.Builder getPreviewRequestBuilder()
        {
            return mPreviewRequestBuilder;
        }

        public CaptureRequest.Builder getRawRequestBuilder() {
            return mRawRequestBuilder;
        }

        public SimpleCaptureCallback getPreviewCaptureCallback() {
            return mPreviewCaptureCallback;
        }

        public SimpleCaptureCallback getRawCaptureCallback() {
            return mRawCaptureCallback;
        }

        public SimpleImageReaderListener getRawReaderListener() {
            return mRawReaderListener;
        }

        private Size mPreviewCaptureSize;
        private Size mRawCaptureSize;
        private CaptureRequest.Builder mPreviewRequestBuilder;
        private CaptureRequest.Builder mRawRequestBuilder;

        /** all the non-testing requests are sent to here */
        private SimpleCaptureCallback mPreviewCaptureCallback;
        /** all the testing requests are sent to here */
        private SimpleCaptureCallback mRawCaptureCallback;
        /** all the testing framebuffers are sent to here */
        private SimpleImageReaderListener mRawReaderListener;
    }

    /**
     * Interface for the test routines that are being called by performTestRoutines(). Implement
     * different test cases in execute().
     */
    interface TestRoutine {
        public void execute(CaptureRequest.Builder rawBurstBuilder,
                SimpleCaptureCallback rawCaptureCallback,
                SimpleImageReaderListener rawReaderListener, int rawFormat) throws Exception;
    }

    /**
     * Implementation of metadata round down test.
     */
    class TestMetaDataRoundDownRoutine implements TestRoutine
    {
        @Override
        public void execute(CaptureRequest.Builder rawBurstBuilder,
                SimpleCaptureCallback rawCaptureCallback,
                SimpleImageReaderListener rawReaderListener, int rawFormat) throws Exception
        {
            // build burst capture
            ArrayList<CaptureRequest> rawRequestList = createBurstRequest(rawBurstBuilder);

            // submit captrue
            Log.i(TAG, ""Submitting Burst Request."");
            mSession.captureBurst(rawRequestList, rawCaptureCallback, mHandler);

            // verify metadata
            for (int i = 0; i < MAX_FRAMES_BURST; i++) {
                CaptureResult result = rawCaptureCallback.getCaptureResult(
                        CAPTURE_IMAGE_TIMEOUT_MS);

                long resultExposure = result.get(CaptureResult.SENSOR_EXPOSURE_TIME);
                int resultSensitivity = result.get(CaptureResult.SENSOR_SENSITIVITY);
                long desiredExposure = rawRequestList.get(i).get(
                        CaptureRequest.SENSOR_EXPOSURE_TIME);
                int desiredSensitivity = rawRequestList.get(i).get(
                        CaptureRequest.SENSOR_SENSITIVITY);

                Log.i(TAG, String.format(
                        ""Received capture result, exposure = %d, sensitivity = %d. ""
                                + ""Requested exposure = %d, sensitivity = %d."",
                        resultExposure,
                        resultSensitivity, desiredExposure, desiredSensitivity));

                mCollector.expectTrue(
                        String.format(""Exposure value is greater than requested: ""
                                + ""requested = %d, result = %d."",
                                desiredExposure, resultExposure),
                                resultExposure <= desiredExposure);

                mCollector.expectTrue(
                        String.format(""Sensitivity value is greater than requested: ""
                                + ""requested = %d, result = %d."",
                                desiredSensitivity, resultSensitivity),
                                resultSensitivity <= desiredSensitivity);
            }
        }
    }

    /**
     * Implementation of manual-auto switching test.
     */
    class TestManualAutoSwitch implements TestRoutine
    {
        @Override
        public void execute(CaptureRequest.Builder rawBurstBuilder,
                SimpleCaptureCallback rawCaptureCallback,
                SimpleImageReaderListener rawReaderListener, int rawFormat) throws Exception
        {
            // create a capture request builder to preserve all the original values
            CaptureRequest.Builder originBuilder = mCamera.createCaptureRequest(
                    CameraDevice.TEMPLATE_STILL_CAPTURE);
            copyBurstRequetBuilder(originBuilder, rawBurstBuilder);

            // build burst capture
            ArrayList<CaptureRequest> rawRequestList = createBurstRequest(rawBurstBuilder);

            // submit captrue but ignore
            mSession.captureBurst(rawRequestList, rawCaptureCallback, mHandler);

            // drain the capture result
            drainQueues(rawReaderListener, rawCaptureCallback);

            // reset and build capture with 3A
            copyBurstRequetBuilder(rawBurstBuilder, originBuilder);
            rawRequestList = createBurstRequestWith3A(rawBurstBuilder);

            // submit captrue but ignore
            mSession.captureBurst(rawRequestList, rawCaptureCallback, mHandler);

            // drain the capture result
            drainQueues(rawReaderListener, rawCaptureCallback);

            // reset and rebuild manual raw burst capture
            copyBurstRequetBuilder(rawBurstBuilder, originBuilder);
            rawRequestList = createBurstRequest(rawBurstBuilder);

            // submit capture
            Log.i(TAG, ""Submitting Burst Request."");
            mSession.captureBurst(rawRequestList, rawCaptureCallback, mHandler);

            // verify metadata
            for (int i = 0; i < MAX_FRAMES_BURST; i++) {
                CaptureResult result = rawCaptureCallback.getCaptureResult(
                        CAPTURE_IMAGE_TIMEOUT_MS);

                long resultExposure = result.get(CaptureResult.SENSOR_EXPOSURE_TIME);
                int resultSensitivity = result.get(CaptureResult.SENSOR_SENSITIVITY);
                int resultEdgeMode = result.get(CaptureResult.EDGE_MODE);
                int resultNoiseReductionMode = result.get(
                        CaptureResult.NOISE_REDUCTION_MODE);
                long desiredExposure = rawRequestList.get(i).get(
                        CaptureRequest.SENSOR_EXPOSURE_TIME);
                int desiredSensitivity = rawRequestList.get(i).get(
                        CaptureRequest.SENSOR_SENSITIVITY);

                Log.i(TAG, String.format(
                        ""Received capture result, exposure = %d, sensitivity = %d. ""
                                + ""Requested exposure = %d, sensitivity = %d."",
                        resultExposure,
                        resultSensitivity, desiredExposure, desiredSensitivity));

                mCollector.expectTrue(String.format(""Edge mode is not turned off.""),
                        resultEdgeMode == CaptureRequest.EDGE_MODE_OFF);

                mCollector.expectTrue(String.format(""Noise reduction is not turned off.""),
                        resultNoiseReductionMode
                        == CaptureRequest.NOISE_REDUCTION_MODE_OFF);

                mCollector.expectTrue(
                        String.format(""Exposure value is greater than requested: ""
                                + ""requested = %d, result = %d."",
                                desiredExposure, resultExposure),
                                resultExposure <= desiredExposure);

                mCollector.expectTrue(
                        String.format(""Sensitivity value is greater than requested: ""
                                + ""requested = %d, result = %d."",
                                desiredSensitivity, resultSensitivity),
                                resultSensitivity <= desiredSensitivity);
            }

        }
    }

    /**
     * Implementation of timestamp test
     */
    class TestTimestamp implements TestRoutine
    {
        private final double THRESHOLD = 5000000.0; // 5ms
        private final long EXPOSURE_MULTIPLIERS_PRIVATE[] = {
                1, 1, 1 };
        private final int SENSITIVITY_MLTIPLIERS_PRIVATE[] = {
                1, 1, 1 };
        private final int MAX_FRAMES_BURST_PRIVATE =
                EXPOSURE_MULTIPLIERS_PRIVATE.length * SENSITIVITY_MLTIPLIERS_PRIVATE.length;

        @Override
        public void execute(Builder rawBurstBuilder, SimpleCaptureCallback rawCaptureCallback,
                SimpleImageReaderListener rawReaderListener, int rawFormat) throws Exception {
            // prepare some local variables
            ArrayList<Long> sensorTime = new ArrayList<Long>(MAX_FRAMES_BURST_PRIVATE);

            // build burst capture
            ArrayList<CaptureRequest> rawRequestList = createBurstRequest(rawBurstBuilder,
                    EXPOSURE_MULTIPLIERS_PRIVATE, SENSITIVITY_MLTIPLIERS_PRIVATE);

            // submit capture while recording timestamp
            Log.i(TAG, ""Submitting Burst Request."");
            mSession.captureBurst(rawRequestList, rawCaptureCallback, mHandler);

            // receive frames while recording timestamp
            for (int i = 0; i < MAX_FRAMES_BURST_PRIVATE; i++) {
                CaptureResult result = rawCaptureCallback.getCaptureResult(
                        CAPTURE_IMAGE_TIMEOUT_MS);
                long resultExposure = result.get(CaptureResult.SENSOR_EXPOSURE_TIME);
                int resultSensitivity = result.get(CaptureResult.SENSOR_SENSITIVITY);
                long resultTimestamp = result.get(CaptureResult.SENSOR_TIMESTAMP);
                Log.i(TAG, String.format(
                        ""Received capture result, exposure = %d, sensitivity = %d, timestamp = %d"",
                        resultExposure, resultSensitivity, resultTimestamp));

                sensorTime.add(resultTimestamp);
            }

            // compare sensor time and compute the difference
            ArrayList<Long> deltaList = new ArrayList<Long>();
            for (int i = 1; i < MAX_FRAMES_BURST_PRIVATE; i++)
            {
                deltaList.add(sensorTime.get(i) - sensorTime.get(i - 1));
            }

            // compute the average and standard deviation of the differences
            double average = 0.0;
            for (int i = 0; i < deltaList.size(); i++)
            {
                average += deltaList.get(i);
            }
            average /= deltaList.size();

            double stddev = 0.0;
            for (int i = 0; i < deltaList.size(); i++)
            {
                double diff = deltaList.get(i) - average;
                stddev += diff * diff;
            }
            stddev = Math.sqrt(stddev / deltaList.size());

            Log.i(TAG, String.format(""average = %.2f, stddev = %.2f"", average, stddev));

            StringBuilder sensorTimestampMessage = new StringBuilder();
            for (int i = 0; i < sensorTime.size(); i++)
            {
                sensorTimestampMessage.append(""frame ["");
                sensorTimestampMessage.append(i);
                sensorTimestampMessage.append(""] SENSOR_TIMESTAMP = "");
                sensorTimestampMessage.append(sensorTime.get(i));
                sensorTimestampMessage.append(""\n"");
            }

            mCollector.expectLessOrEqual(
                    ""The standard deviation of frame interval is larger then threshold: "" +
                    String.format(""stddev = %.2f, threshold = %.2f.\n"", stddev, THRESHOLD) +
                    sensorTimestampMessage.toString(),
                    THRESHOLD, stddev);
        }
    }

    /**
     * Check sensor capability prior to the test.
     *
     * @return true if the it is has the capability to execute the test.
     */
    private boolean checkCapability(String id, ArrayList<Integer> supportedRawList,
            int[] testedFormats) {
        StaticMetadata staticInfo = mAllStaticInfo.get(id);
        // make sure the sensor has manual support
        if (!staticInfo.isHardwareLevelAtLeastFull()) {
            Log.w(TAG, ""Full hardware level is not supported"");
            return false;
        }

        // get the list of supported RAW format
        StreamConfigurationMap config = staticInfo.getValueFromKeyNonNull(
                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);

        // check for the RAW support
        supportedRawList.clear();
        for (int rawFormat : testedFormats) {
            if (!config.isOutputSupportedFor(rawFormat)) {
                continue;
            }
            supportedRawList.add(rawFormat);
        }

        if (supportedRawList.size() == 0)
        {
            Log.w(TAG, ""RAW output is not supported!"");
            return false;
        }

        return true;
    }

    /**
     * Return the sensor format to human readable string.
     *
     * @param format Sensor image format.
     * @return Human readable string.
     */
    private String imageFormatToString(int format) {
        switch (format) {
            case ImageFormat.RAW10:
                return ""RAW10"";
            case ImageFormat.RAW12:
                return ""RAW12"";
            case ImageFormat.RAW_SENSOR:
                return ""RAW_SENSOR"";
        }

        return ""Unknown"";
    }

    /**
     * Setting up various classes prior to the request, e.g.: capture size, builder, callback and
     * listener
     *
     * @return initialized variables that can be directly fed into prepareCaptureAndStartPreview().
     */
    private CaptureSetup initCaptureSetupForPreviewAndRaw() throws Exception
    {
        // capture size
        Size previewSize = mOrderedPreviewSizes.get(0);
        Size rawSize = mStaticInfo.getRawDimensChecked();

        // builder
        CaptureRequest.Builder previewCaptureBuilder = mCamera.createCaptureRequest(
                CameraDevice.TEMPLATE_PREVIEW);
        CaptureRequest.Builder rawCaptureBuilder = mCamera.createCaptureRequest(
                CameraDevice.TEMPLATE_STILL_CAPTURE);

        // callback
        SimpleCaptureCallback previewCaptureCallback = new SimpleCaptureCallback();
        SimpleCaptureCallback rawCaptureCallback = new SimpleCaptureCallback();
        SimpleImageReaderListener rawReaderListener = new SimpleImageReaderListener();

        CaptureSetup setup = new CaptureSetup(previewSize, rawSize, previewCaptureBuilder,
                rawCaptureBuilder, previewCaptureCallback, rawCaptureCallback, rawReaderListener);

        return setup;
    }

    /**
     * Construct an array of burst request with manual exposure and sensitivity.
     * <p>
     * For each capture request, 3A and post processing (noise reduction, sharpening, etc) will be
     * turned off. Then exposure and sensitivity value will be configured, which are determined by
     * EXPOSURE_MULIPLIERS and SENSITIVITY_MULTIPLIERS.
     * </p>
     *
     * @param rawBurstBuilder The builder needs to have targets setup.
     * @return An array list capture request for burst.
     */
    private ArrayList<CaptureRequest> createBurstRequest(CaptureRequest.Builder rawBurstBuilder)
    {
        return createBurstRequest(rawBurstBuilder, EXPOSURE_MULTIPLIERS, SENSITIVITY_MLTIPLIERS);
    }

    private ArrayList<CaptureRequest> createBurstRequest(CaptureRequest.Builder rawBurstBuilder,
            long[] exposureMultipliers, int[] sensitivityMultipliers) {
        // set manual mode
        rawBurstBuilder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_OFF);
        rawBurstBuilder.set(CaptureRequest.CONTROL_AWB_MODE, CaptureRequest.CONTROL_AWB_MODE_OFF);
        rawBurstBuilder.set(CaptureRequest.NOISE_REDUCTION_MODE,
                CaptureRequest.NOISE_REDUCTION_MODE_OFF);
        rawBurstBuilder.set(CaptureRequest.EDGE_MODE, CaptureRequest.EDGE_MODE_OFF);
        // exposure has higher priority over frame duration; therefore the frame readout time:
        // exposure time + overhead
        rawBurstBuilder.set(CaptureRequest.SENSOR_FRAME_DURATION, 0L);

        // get the exposure and sensitivity range
        Range<Long> exposureRangeNs = new Range<Long>(mStaticInfo.getExposureMinimumOrDefault(),
                mStaticInfo.getExposureMaximumOrDefault());

        Range<Integer> isoRange = new Range<Integer>(mStaticInfo.getSensitivityMinimumOrDefault(),
                mStaticInfo.getSensitivityMaximumOrDefault());

        Log.i(TAG, String.format(""Exposure time - max: %d, min: %d."", exposureRangeNs.getUpper(),
                exposureRangeNs.getLower()));
        Log.i(TAG, String.format(""Sensitivity - max: %d, min: %d."", isoRange.getUpper(),
                isoRange.getLower()));

        // building burst request
        int maxFramesBurst = exposureMultipliers.length * sensitivityMultipliers.length;
        Log.i(TAG, String.format(""Setting up burst = %d frames."", maxFramesBurst));
        ArrayList<CaptureRequest> rawRequestList = new ArrayList<CaptureRequest>(maxFramesBurst);

        for (int i = 0; i < exposureMultipliers.length; i++) {
            for (int j = 0; j < sensitivityMultipliers.length; j++) {
                long desiredExposure = Math.min(
                        exposureRangeNs.getLower() * exposureMultipliers[i],
                        exposureRangeNs.getUpper());

                int desiredSensitivity =
                        Math.min(isoRange.getLower() * sensitivityMultipliers[j],
                                isoRange.getUpper());

                rawBurstBuilder.set(CaptureRequest.SENSOR_EXPOSURE_TIME, desiredExposure);
                rawBurstBuilder.set(CaptureRequest.SENSOR_SENSITIVITY, desiredSensitivity);

                rawRequestList.add(rawBurstBuilder.build());
            }
        }
        return rawRequestList;
    }

    /**
     * Construct an array of burst request with 3A
     * <p>
     * For each capture request, 3A and post processing (noise reduction, sharpening, etc) will be
     * turned on.
     * </p>
     *
     * @param rawBurstBuilder The builder needs to have targets setup.
     * @return An array list capture request for burst.
     */
    private ArrayList<CaptureRequest> createBurstRequestWith3A(
            CaptureRequest.Builder rawBurstBuilder)
    {
        // set 3A mode to simulate regular still capture
        rawBurstBuilder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON);
        rawBurstBuilder.set(CaptureRequest.CONTROL_AWB_MODE, CaptureRequest.CONTROL_AWB_MODE_AUTO);
        rawBurstBuilder.set(CaptureRequest.NOISE_REDUCTION_MODE,
                CaptureRequest.NOISE_REDUCTION_MODE_HIGH_QUALITY);
        rawBurstBuilder.set(CaptureRequest.EDGE_MODE, CaptureRequest.EDGE_MODE_HIGH_QUALITY);

        // building burst request
        Log.i(TAG, String.format(""Setting up burst = %d frames."", MAX_FRAMES_BURST));
        ArrayList<CaptureRequest> rawRequestList = new ArrayList<CaptureRequest>(MAX_FRAMES_BURST);

        for (int i = 0; i < MAX_FRAMES_BURST; i++) {
            rawRequestList.add(rawBurstBuilder.build());
        }

        return rawRequestList;
    }

    /**
     * An utility method to copy capture request builders. This is used for recovery purpose to
     * reverse the changes we made to the builder.
     *
     * @param dst the builder to write into.
     * @param src the builder that needs to be copied.
     */
    private void copyBurstRequetBuilder(CaptureRequest.Builder dst, CaptureRequest.Builder src)
    {
        dst.set(CaptureRequest.CONTROL_AE_MODE, src.get(CaptureRequest.CONTROL_AE_MODE));
        dst.set(CaptureRequest.CONTROL_AWB_MODE, src.get(CaptureRequest.CONTROL_AWB_MODE));
        dst.set(CaptureRequest.NOISE_REDUCTION_MODE, src.get(CaptureRequest.NOISE_REDUCTION_MODE));
        dst.set(CaptureRequest.EDGE_MODE, src.get(CaptureRequest.EDGE_MODE));
        dst.set(CaptureRequest.SENSOR_FRAME_DURATION,
                src.get(CaptureRequest.SENSOR_FRAME_DURATION));
        dst.set(CaptureRequest.SENSOR_EXPOSURE_TIME, src.get(CaptureRequest.SENSOR_EXPOSURE_TIME));
        dst.set(CaptureRequest.SENSOR_SENSITIVITY, src.get(CaptureRequest.SENSOR_SENSITIVITY));
    }

    /**
     * Draining the image reader and capture callback queue
     *
     * @param readerListener Image reader listener needs to be drained.
     * @param captureCallback Capture callback needs to be drained.
     * @throws Exception Exception from the queue.
     */
    private void drainQueues(SimpleImageReaderListener readerListener,
            SimpleCaptureCallback captureCallback) throws Exception
    {
        for (int i = 0; i < MAX_FRAMES_BURST; i++) {
            Image image = readerListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
            image.close();

            CaptureResult result = captureCallback.getCaptureResult(
                    CAPTURE_IMAGE_TIMEOUT_MS);
            long timestamp = result.get(CaptureResult.SENSOR_TIMESTAMP);
            Log.d(TAG, String.format(""timestamp = %d"", timestamp));
        }
    }

    /**
     * Stop preview and remove the target surfaces inside the CaptureRequest.Builder.
     *
     * @param previewBuilder Configured builder for preview.
     * @param rawBurstBuilder Configured builder for RAW.
     * @throws Exception Exceptions from stopPreview.
     */
    private void stopPreviewAndClearSurface(CaptureRequest.Builder previewBuilder,
            CaptureRequest.Builder rawBurstBuilder) throws Exception
    {
        previewBuilder.removeTarget(mPreviewSurface);
        rawBurstBuilder.removeTarget(mPreviewSurface);
        rawBurstBuilder.removeTarget(mReaderSurface);

        stopPreview();
    }

    private void performTestRoutine(TestRoutine routine, int[] testedFormats) throws Exception
    {
        final int PREPARE_TIMEOUT_MS = 10000;
        for (String id : mCameraIdsUnderTest) {
            try {
                ArrayList<Integer> supportedRawList = new ArrayList<Integer>(RAW_FORMATS.length);
                if (!checkCapability(id, supportedRawList, testedFormats)) {
                    Log.i(TAG, ""Capability is not supported on camera "" + id
                            + "". Skip the test."");
                    continue;
                }

                openDevice(id);
                // test each supported RAW format
                for (int rawFormat : supportedRawList) {
                    Log.i(TAG, ""Testing format "" + imageFormatToString(rawFormat) + ""."");

                    // prepare preview and still RAW capture
                    CaptureSetup captureSetup = initCaptureSetupForPreviewAndRaw();

                    Size previewCaptureSize = captureSetup.getPreviewCaptureSize();
                    Size rawCaptureSize = captureSetup.getRawCaptureSize();

                    CaptureRequest.Builder previewBuilder = captureSetup.getPreviewRequestBuilder();
                    CaptureRequest.Builder rawBurstBuilder = captureSetup.getRawRequestBuilder();

                    SimpleCaptureCallback previewCaptureCallback =
                            captureSetup.getPreviewCaptureCallback();
                    SimpleCaptureCallback rawCaptureCallback = captureSetup.getRawCaptureCallback();
                    SimpleImageReaderListener rawReaderListener = captureSetup
                            .getRawReaderListener();

                    // start preview and prepare RAW capture
                    prepareCaptureAndStartPreview(previewBuilder, rawBurstBuilder,
                            previewCaptureSize, rawCaptureSize, rawFormat, previewCaptureCallback,
                            MAX_FRAMES_BURST, rawReaderListener);

                    // Prepare still surface to prevent large allocations slow down capture
                    mSession.prepare(mReaderSurface);
                    mSessionListener.waitForSurfacePrepared(
                            mSession, mReaderSurface, PREPARE_TIMEOUT_MS);

                    // execute test routine
                    routine.execute(rawBurstBuilder, rawCaptureCallback, rawReaderListener,
                            rawFormat);

                    // clear out the surface and camera session
                    stopPreviewAndClearSurface(previewBuilder, rawBurstBuilder);
                    rawReaderListener.drain();
                    closeImageReader();
                }
            } finally {
                closeDevice();
            }
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.AccelerometerTestActivity"	"setPassFailButtonClickListeners"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/AccelerometerTestActivity.java"	""	"public void test/*
 *.
 */

package com.android.cts.verifier.sensors;

import com.android.cts.verifier.PassFailButtons;
import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.renderers.GLArrowSensorTestRenderer;

import android.content.Context;
import android.hardware.Sensor;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;
import android.opengl.GLSurfaceView;
import android.os.Bundle;

/**
 * CTS Verifier case for verifying correct integration of accelerometer.
 * Displays a wedge using OpenGL that, on a correctly-integrated device, always
 * points down.
 *
 * @deprecated It has been replaced by {@link AccelerometerMeasurementTestActivity}
 */
@Deprecated
public class AccelerometerTestActivity extends PassFailButtons.Activity {
    private GLSurfaceView mGLSurfaceView;

    private SensorManager mSensorManager;

    private SensorEventListener mListener;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);

        mSensorManager = (SensorManager) getApplicationContext().getSystemService(
                Context.SENSOR_SERVICE);
        GLArrowSensorTestRenderer renderer =
                new GLArrowSensorTestRenderer(this, Sensor.TYPE_ACCELEROMETER);
        mListener = renderer;

        setContentView(R.layout.pass_fail_gl);
        setPassFailButtonClickListeners();
        setInfoResources(R.string.snsr_accel_test, R.string.snsr_accel_test_info, -1);
        mGLSurfaceView = (GLSurfaceView) findViewById(R.id.gl_surface_view);
        mGLSurfaceView.setRenderer(renderer);
    }

    @Override
    protected void onPause() {
        super.onPause();
        mSensorManager.unregisterListener(mListener);
        mGLSurfaceView.onPause();
    }

    @Override
    protected void onResume() {
        super.onResume();
        mGLSurfaceView.onResume();
        mSensorManager.registerListener(mListener, mSensorManager.getSensorList(
                Sensor.TYPE_ACCELEROMETER).get(0), SensorManager.SENSOR_DELAY_UI);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.testcases.Camera2MultiViewTestCase"	"isOpened"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/testcases/Camera2MultiViewTestCase.java"	""	"public void test/*
 *.
 */

package android.hardware.camera2.cts.testcases;

import static android.hardware.camera2.cts.CameraTestUtils.*;

import static com.android.ex.camera2.blocking.BlockingSessionCallback.*;
import static com.android.ex.camera2.blocking.BlockingStateCallback.*;

import android.app.Activity;
import android.content.Context;
import android.content.res.Configuration;
import android.graphics.Matrix;
import android.graphics.RectF;
import android.graphics.SurfaceTexture;
import android.hardware.camera2.CameraCaptureSession;
import android.hardware.camera2.cts.Camera2ParameterizedTestCase;
import android.hardware.camera2.cts.CameraTestUtils;
import android.hardware.camera2.CameraCaptureSession.CaptureCallback;
import android.hardware.camera2.CameraDevice;
import android.hardware.camera2.CameraManager;
import android.hardware.camera2.CaptureRequest;
import android.hardware.camera2.cts.Camera2MultiViewCtsActivity;
import android.hardware.camera2.cts.helpers.StaticMetadata;
import android.hardware.camera2.cts.helpers.StaticMetadata.CheckLevel;
import android.hardware.camera2.params.OutputConfiguration;
import android.hardware.camera2.params.SessionConfiguration;
import android.os.ConditionVariable;
import android.os.Handler;
import android.os.HandlerThread;
import android.os.Looper;
import android.os.SystemClock;
import android.util.Log;
import android.util.Size;
import android.view.Surface;
import android.view.TextureView;
import android.view.WindowManager;

import androidx.test.rule.ActivityTestRule;

import com.android.ex.camera2.blocking.BlockingCameraManager;
import com.android.ex.camera2.blocking.BlockingSessionCallback;
import com.android.ex.camera2.blocking.BlockingStateCallback;

import junit.framework.Assert;

import org.junit.After;
import org.junit.Before;
import org.junit.Ignore;
import org.junit.Rule;

import java.util.Arrays;
import java.util.HashMap;
import java.util.List;

/**
 * Camera2 test case base class by using mixed SurfaceView and TextureView as rendering target.
 */

public class Camera2MultiViewTestCase extends Camera2ParameterizedTestCase {
    private static final String TAG = ""MultiViewTestCase"";
    private static final boolean VERBOSE = Log.isLoggable(TAG, Log.VERBOSE);

    protected TextureView[] mTextureView =
            new TextureView[Camera2MultiViewCtsActivity.MAX_TEXTURE_VIEWS];
    protected Handler mHandler;

    private HandlerThread mHandlerThread;
    private Activity mActivity;

    private CameraHolder[] mCameraHolders;
    private HashMap<String, Integer> mCameraIdMap;

    protected WindowManager mWindowManager;

    @Rule
    public ActivityTestRule<Camera2MultiViewCtsActivity> mActivityRule =
            new ActivityTestRule<>(Camera2MultiViewCtsActivity.class);

    @Override
    public void setUp() throws Exception {
        super.setUp();
        mActivity = mActivityRule.getActivity();
        mHandlerThread = new HandlerThread(TAG);
        mHandlerThread.start();
        mHandler = new Handler(mHandlerThread.getLooper());
        Camera2MultiViewCtsActivity activity = (Camera2MultiViewCtsActivity) mActivity;
        for (int i = 0; i < Camera2MultiViewCtsActivity.MAX_TEXTURE_VIEWS; i++) {
            mTextureView[i] = activity.getTextureView(i);
        }
        assertNotNull(""Unable to get texture view"", mTextureView);
        mCameraIdMap = new HashMap<String, Integer>();
        int numCameras = mCameraIdsUnderTest.length;
        mCameraHolders = new CameraHolder[numCameras];
        for (int i = 0; i < numCameras; i++) {
            mCameraHolders[i] = new CameraHolder(mCameraIdsUnderTest[i]);
            mCameraIdMap.put(mCameraIdsUnderTest[i], i);
        }
        mWindowManager = (WindowManager) mContext.getSystemService(Context.WINDOW_SERVICE);
    }

    @Override
    public void tearDown() throws Exception {
        mHandlerThread.quitSafely();
        mHandler = null;
        for (CameraHolder camera : mCameraHolders) {
            if (camera.isOpened()) {
                camera.close();
                camera = null;
            }
        }
        super.tearDown();
    }

    /**
     * Update preview TextureView rotation to accommodate discrepancy between preview
     * buffer and the view window orientation.
     *
     * Assumptions:
     * - Aspect ratio for the sensor buffers is in landscape orientation,
     * - Dimensions of buffers received are rotated to the natural device orientation.
     * - The contents of each buffer are rotated by the inverse of the display rotation.
     * - Surface scales the buffer to fit the current view bounds.
     * TODO: Make this method works for all orientations
     *
     */
    protected void updatePreviewDisplayRotation(Size previewSize, TextureView textureView) {
        int rotationDegrees = 0;
        Camera2MultiViewCtsActivity activity = (Camera2MultiViewCtsActivity) mActivity;
        int displayRotation = activity.getWindowManager().getDefaultDisplay().getRotation();
        Configuration config = activity.getResources().getConfiguration();

        // Get UI display rotation
        switch (displayRotation) {
            case Surface.ROTATION_0:
                rotationDegrees = 0;
                break;
            case Surface.ROTATION_90:
                rotationDegrees = 90;
            break;
            case Surface.ROTATION_180:
                rotationDegrees = 180;
            break;
            case Surface.ROTATION_270:
                rotationDegrees = 270;
            break;
        }

        // Get device natural orientation
        int deviceOrientation = Configuration.ORIENTATION_PORTRAIT;
        if ((rotationDegrees % 180 == 0 &&
                config.orientation == Configuration.ORIENTATION_LANDSCAPE) ||
                ((rotationDegrees % 180 != 0 &&
                config.orientation == Configuration.ORIENTATION_PORTRAIT))) {
            deviceOrientation = Configuration.ORIENTATION_LANDSCAPE;
        }

        // Rotate the buffer dimensions if device orientation is portrait.
        int effectiveWidth = previewSize.getWidth();
        int effectiveHeight = previewSize.getHeight();
        if (deviceOrientation == Configuration.ORIENTATION_PORTRAIT) {
            effectiveWidth = previewSize.getHeight();
            effectiveHeight = previewSize.getWidth();
        }

        // Find and center view rect and buffer rect
        Matrix transformMatrix =  textureView.getTransform(null);
        int viewWidth = textureView.getWidth();
        int viewHeight = textureView.getHeight();
        RectF viewRect = new RectF(0, 0, viewWidth, viewHeight);
        RectF bufRect = new RectF(0, 0, effectiveWidth, effectiveHeight);
        float centerX = viewRect.centerX();
        float centerY = viewRect.centerY();
        bufRect.offset(centerX - bufRect.centerX(), centerY - bufRect.centerY());

        // Undo ScaleToFit.FILL done by the surface
        transformMatrix.setRectToRect(viewRect, bufRect, Matrix.ScaleToFit.FILL);

        // Rotate buffer contents to proper orientation
        transformMatrix.postRotate((360 - rotationDegrees) % 360, centerX, centerY);
        if ((rotationDegrees % 180) == 90) {
            int temp = effectiveWidth;
            effectiveWidth = effectiveHeight;
            effectiveHeight = temp;
        }

        // Scale to fit view, cropping the longest dimension
        float scale =
                Math.max(viewWidth / (float) effectiveWidth, viewHeight / (float) effectiveHeight);
        transformMatrix.postScale(scale, scale, centerX, centerY);

        Handler handler = new Handler(Looper.getMainLooper());
        class TransformUpdater implements Runnable {
            TextureView mView;
            Matrix mTransformMatrix;
            TransformUpdater(TextureView view, Matrix matrix) {
                mView = view;
                mTransformMatrix = matrix;
            }

            @Override
            public void run() {
                mView.setTransform(mTransformMatrix);
            }
        }
        handler.post(new TransformUpdater(textureView, transformMatrix));
    }

    protected void openCamera(String cameraId) throws Exception {
        CameraHolder camera = getCameraHolder(cameraId);
        assertFalse(""Camera has already opened"", camera.isOpened());
        camera.open();
        return;
    }

    protected void closeCamera(String cameraId) throws Exception {
        CameraHolder camera = getCameraHolder(cameraId);
        camera.close();
    }

    protected void createSessionWithConfigs(String cameraId, List<OutputConfiguration> configs)
            throws Exception {
        CameraHolder camera = getCameraHolder(cameraId);
        camera.createSessionWithConfigs(configs);
    }

    protected void startPreview(
            String cameraId, List<Surface> outputSurfaces, CaptureCallback listener)
            throws Exception {
        CameraHolder camera = getCameraHolder(cameraId);
        assertTrue(""Camera "" + cameraId + "" is not openned"", camera.isOpened());
        camera.startPreview(outputSurfaces, listener);
    }

    protected int startPreviewWithConfigs(String cameraId,
            List<OutputConfiguration> outputConfigs,
            CaptureCallback listener)
            throws Exception {
        CameraHolder camera = getCameraHolder(cameraId);
        assertTrue(""Camera "" + cameraId + "" is not openned"", camera.isOpened());
        return camera.startPreviewWithConfigs(outputConfigs, listener);
    }

    protected void stopPreview(String cameraId) throws Exception {
        CameraHolder camera = getCameraHolder(cameraId);
        assertTrue(""Camera "" + cameraId + "" preview is not running"", camera.isPreviewStarted());
        camera.stopPreview();
    }

    protected void stopRepeating(String cameraId) throws Exception {
        CameraHolder camera = getCameraHolder(cameraId);
        assertTrue(""Camera "" + cameraId + "" preview is not running"", camera.isPreviewStarted());
        camera.stopRepeating();
    }

    protected void finalizeOutputConfigs(String cameraId, List<OutputConfiguration> configs,
            CaptureCallback listener) throws Exception {
        CameraHolder camera = getCameraHolder(cameraId);
        assertTrue(""Camera "" + cameraId + "" is not opened"", camera.isOpened());
        camera.finalizeOutputConfigs(configs, listener);
    }

    protected int updateRepeatingRequest(String cameraId, List<OutputConfiguration> configs,
            CaptureCallback listener) throws Exception {
        CameraHolder camera = getCameraHolder(cameraId);
        assertTrue(""Camera "" + cameraId + "" is not opened"", camera.isOpened());
        return camera.updateRepeatingRequest(configs, listener);
    }

    protected void updateOutputConfiguration(String cameraId, OutputConfiguration config)
            throws Exception {
        CameraHolder camera = getCameraHolder(cameraId);
        assertTrue(""Camera "" + cameraId + "" is not opened"", camera.isOpened());
        camera.updateOutputConfiguration(config);
    }

    protected boolean isSessionConfigurationSupported(String cameraId,
            List<OutputConfiguration> configs) {
        CameraHolder camera = getCameraHolder(cameraId);
        assertTrue(""Camera "" + cameraId + "" is not opened"", camera.isOpened());
        return camera.isSessionConfigurationSupported(configs);
    }

    protected void capture(String cameraId, CaptureRequest request, CaptureCallback listener)
            throws Exception {
        CameraHolder camera = getCameraHolder(cameraId);
        assertTrue(""Camera "" + cameraId + "" is not opened"", camera.isOpened());
        camera.capture(request, listener);
    }

    protected CaptureRequest.Builder getCaptureBuilder(String cameraId, int templateId)
            throws Exception {
        CameraHolder camera = getCameraHolder(cameraId);
        assertTrue(""Camera "" + cameraId + "" is not opened"", camera.isOpened());
        return camera.getCaptureBuilder(templateId);
    }

    protected StaticMetadata getStaticInfo(String cameraId) {
        CameraHolder camera = getCameraHolder(cameraId);
        StaticMetadata staticInfo = camera.getStaticInfo();
        assertNotNull(""Camera "" + cameraId + "" static info is null"", staticInfo);
        return staticInfo;
    }

    protected List<Size> getOrderedPreviewSizes(String cameraId) {
        CameraHolder camera = getCameraHolder(cameraId);
        assertTrue(""Camera is not openned"", camera.isOpened());
        return camera.getOrderedPreviewSizes();
    }

    protected void verifyCreateSessionWithConfigsFailure(String cameraId,
            List<OutputConfiguration> configs) throws Exception {
        CameraHolder camera = getCameraHolder(cameraId);
        camera.verifyCreateSessionWithConfigsFailure(configs);
    }

    public static class CameraPreviewListener implements TextureView.SurfaceTextureListener {
        private boolean mFirstPreviewAvailable = false;
        private final ConditionVariable mPreviewDone = new ConditionVariable();

        @Override
        public void onSurfaceTextureAvailable(SurfaceTexture surface, int width, int height) {
            // Ignored. The SurfaceTexture is polled by getAvailableSurfaceTexture.
        }

        @Override
        public void onSurfaceTextureSizeChanged(SurfaceTexture surface, int width, int height) {
            // Ignored. The CameraDevice should already know the changed size.
        }

        @Override
        public boolean onSurfaceTextureDestroyed(SurfaceTexture surface) {
            /**
             * Return true, assume that client detaches the surface before it is
             * destroyed. For example, CameraDevice should detach this surface when
             * stopping preview. No need to release the SurfaceTexture here as it
             * is released by TextureView after onSurfaceTextureDestroyed is called.
             */
            Log.i(TAG, ""onSurfaceTextureDestroyed called."");
            return true;
        }

        @Override
        public void onSurfaceTextureUpdated(SurfaceTexture surface) {
            // Invoked every time there's a new Camera preview frame
            if (!mFirstPreviewAvailable) {
                mFirstPreviewAvailable = true;
                mPreviewDone.open();
            }
        }

        /** Waits until the camera preview is up running */
        public boolean waitForPreviewDone(long timeOutMs) {
            if (!mPreviewDone.block(timeOutMs)) {
                // timeout could be expected or unexpected. The caller will decide.
                Log.w(TAG, ""waitForPreviewDone timed out after "" + timeOutMs + ""ms"");
                return false;
            }
            mPreviewDone.close();
            return true;
        }

        /** Reset the Listener */
        public void reset() {
            mFirstPreviewAvailable = false;
            mPreviewDone.close();
        }
    }

    private CameraHolder getCameraHolder(String cameraId) {
        Integer cameraIdx = mCameraIdMap.get(cameraId);
        if (cameraIdx == null) {
            Assert.fail(""Unknown camera Id"");
        }
        return mCameraHolders[cameraIdx];
    }

    // Per device fields
    private class CameraHolder {
        private String mCameraId;
        private CameraStateListener mCameraStateListener;
        private BlockingStateCallback mBlockingStateListener;
        private CameraCaptureSession mSession;
        private CameraDevice mCamera;
        private StaticMetadata mStaticInfo;
        private List<Size> mOrderedPreviewSizes;
        private BlockingSessionCallback mSessionListener;

        public CameraHolder(String id){
            mCameraId = id;
            mCameraStateListener = new CameraStateListener();
        }

        public StaticMetadata getStaticInfo() {
            return mStaticInfo;
        }

        public List<Size> getOrderedPreviewSizes() {
            return mOrderedPreviewSizes;
        }

        class CameraStateListener extends CameraDevice.StateCallback {
            boolean mDisconnected = false;

            @Override
            public void onOpened(CameraDevice camera) {
            }

            @Override
            public void onDisconnected(CameraDevice camera) {
                synchronized(this) {
                    mDisconnected = true;
                }
            }

            @Override
            public void onError(CameraDevice camera, int error) {
            }

            public synchronized boolean isDisconnected() {
                return mDisconnected;
            }
        }

        public void open() throws Exception {
            assertNull(""Camera is already opened"", mCamera);
            mBlockingStateListener = new BlockingStateCallback(mCameraStateListener);
            mCamera = (new BlockingCameraManager(mCameraManager)).openCamera(
                    mCameraId, mBlockingStateListener, mHandler);
            mStaticInfo = new StaticMetadata(mCameraManager.getCameraCharacteristics(mCameraId),
                    CheckLevel.ASSERT, /*collector*/null);
            if (mStaticInfo.isColorOutputSupported()) {
                mOrderedPreviewSizes = getSupportedPreviewSizes(
                        mCameraId, mCameraManager,
                        getPreviewSizeBound(mWindowManager, PREVIEW_SIZE_BOUND));
            }
            assertNotNull(String.format(""Failed to open camera device ID: %s"", mCameraId), mCamera);
        }

        public boolean isOpened() {
            return (mCamera != null && !mCameraStateListener.isDisconnected());
        }

        public void close() throws Exception {
            if (!isOpened()) {
                return;
            }
            mCamera.close();
            mBlockingStateListener.waitForState(STATE_CLOSED, CAMERA_CLOSE_TIMEOUT_MS);
            mCamera = null;
            mSession = null;
            mStaticInfo = null;
            mOrderedPreviewSizes = null;
            mBlockingStateListener = null;
        }

        public void startPreview(List<Surface> outputSurfaces, CaptureCallback listener)
                throws Exception {
            mSessionListener = new BlockingSessionCallback();
            mSession = configureCameraSession(mCamera, outputSurfaces, mSessionListener, mHandler);
            if (outputSurfaces.isEmpty()) {
                return;
            }

            // TODO: vary the different settings like crop region to cover more cases.
            CaptureRequest.Builder captureBuilder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);

            for (Surface surface : outputSurfaces) {
                captureBuilder.addTarget(surface);
            }
            mSession.setRepeatingRequest(captureBuilder.build(), listener, mHandler);
        }

        public void createSessionWithConfigs(List<OutputConfiguration> outputConfigs)
                throws Exception {
            mSessionListener = new BlockingSessionCallback();
            mSession = configureCameraSessionWithConfig(mCamera, outputConfigs, mSessionListener, mHandler);
        }

        public void verifyCreateSessionWithConfigsFailure(List<OutputConfiguration> configs)
                throws Exception {
            BlockingSessionCallback sessionListener = new BlockingSessionCallback();
            CameraCaptureSession session = configureCameraSessionWithConfig(
                    mCamera, configs, sessionListener, mHandler);

            Integer[] sessionStates = {BlockingSessionCallback.SESSION_READY,
                    BlockingSessionCallback.SESSION_CONFIGURE_FAILED};
            int state = sessionListener.getStateWaiter().waitForAnyOfStates(
                    Arrays.asList(sessionStates), SESSION_CONFIGURE_TIMEOUT_MS);
            assertTrue(""Expecting a createSessionWithConfig failure."",
                    state == BlockingSessionCallback.SESSION_CONFIGURE_FAILED);
        }

        public int startPreviewWithConfigs(List<OutputConfiguration> outputConfigs,
                CaptureCallback listener)
                throws Exception {
            checkSessionConfigurationSupported(mCamera, mHandler, outputConfigs,
                    /*inputConfig*/ null, SessionConfiguration.SESSION_REGULAR,
                    /*defaultSupport*/ true, ""Session configuration query should not fail"");
            createSessionWithConfigs(outputConfigs);

            CaptureRequest.Builder captureBuilder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);

            for (OutputConfiguration config : outputConfigs) {
                for (Surface surface : config.getSurfaces()) {
                    captureBuilder.addTarget(surface);
                }
            }
            return mSession.setRepeatingRequest(captureBuilder.build(), listener, mHandler);
        }

        public int updateRepeatingRequest(List<OutputConfiguration> configs,
                CaptureCallback listener) throws Exception {
            CaptureRequest.Builder captureBuilder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);

            for (OutputConfiguration config : configs) {
                for (Surface surface : config.getSurfaces()) {
                    captureBuilder.addTarget(surface);
                }
            }
            return mSession.setRepeatingRequest(captureBuilder.build(), listener, mHandler);
        }

        public void updateOutputConfiguration(OutputConfiguration config) throws Exception {
            mSession.updateOutputConfiguration(config);
        }

        public boolean isSessionConfigurationSupported(List<OutputConfiguration> configs) {
            return isSessionConfigSupported(mCamera, mHandler, configs,
                    /*inputConig*/ null, SessionConfiguration.SESSION_REGULAR,
                    /*expectedResult*/ true).configSupported;
        }

        public void capture(CaptureRequest request, CaptureCallback listener)
                throws Exception {
            mSession.capture(request, listener, mHandler);
        }

        public CaptureRequest.Builder getCaptureBuilder(int templateId) throws Exception {
            return mCamera.createCaptureRequest(templateId);
        }

        public void finalizeOutputConfigs(List<OutputConfiguration> configs,
                CaptureCallback listener) throws Exception {
            mSession.finalizeOutputConfigurations(configs);
            updateRepeatingRequest(configs, listener);
        }

        public boolean isPreviewStarted() {
            return (mSession != null);
        }

        public void stopPreview() throws Exception {
            if (VERBOSE) Log.v(TAG,
                    ""Stopping camera "" + mCameraId +"" preview and waiting for idle"");
            if (!isOpened()) {
                return;
            }
            // Stop repeat, wait for captures to complete, and disconnect from surfaces
            mSession.close();
            mSessionListener.getStateWaiter().waitForState(
                    SESSION_CLOSED, SESSION_CLOSE_TIMEOUT_MS);
            mSessionListener = null;
        }

        public void stopRepeating() throws Exception {
            if (VERBOSE) Log.v(TAG,
                    ""Stopping camera "" + mCameraId +"" repeating request"");
            if (!isOpened()) {
                return;
            }
            mSession.stopRepeating();
            mSessionListener.getStateWaiter().waitForState(
                    SESSION_READY, SESSION_READY_TIMEOUT_MS);
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.FifoLengthVerification"	"isDeviceSuspendTest"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/FifoLengthVerification.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers.sensorverification;

import junit.framework.Assert;

import android.hardware.Sensor;
import android.hardware.cts.helpers.SensorCtsHelper;
import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEvent;
import android.util.Log;

import java.util.LinkedList;

/**
 * A {@link ISensorVerification} which verifies that each batch of events has the FIFO
 *  length within the 5% of the expected value.
 */
public class FifoLengthVerification extends AbstractSensorVerification {
    public static final String PASSED_KEY = ""fifo_length_passed"";

    private static double FIFO_LENGTH_TOLERANCE = 0.8;

    private final int mExpectedFifoLength;

    private int mIndex = 0;
    private LinkedList<Long> mRecvdTimeStampDiffs = new LinkedList<>();
    private long mPrevRecvdTimeStampMs = -1,  mExpectedReportLatencyUs;

    /**
     * Construct a {@link FifoLengthVerification}
     *
     * @param expectedLength the expected FIFO length for the batch.
     */
    public FifoLengthVerification(int expectedLength, long expectedReportLatencyUs) {
        mExpectedFifoLength = expectedLength;
        mExpectedReportLatencyUs = expectedReportLatencyUs;
    }

    /**
     * Get the default {@link FifoLengthVerification}.
     *
     * @param environment the test environment
     * @return the verification or null if the verification is not a continuous mode sensor.
     */
    public static FifoLengthVerification getDefault(
            TestSensorEnvironment environment) {
        if (environment.getSensor().getReportingMode() != Sensor.REPORTING_MODE_CONTINUOUS) {
            return null;
        }
        long expectedReportLatencyUs = environment.getMaxReportLatencyUs();
        long fifoReservedEventCount = environment.getSensor().getFifoReservedEventCount();
        int maximumExpectedSamplingPeriodUs = environment.getMaximumExpectedSamplingPeriodUs();
        if (fifoReservedEventCount > 0 && maximumExpectedSamplingPeriodUs != Integer.MAX_VALUE) {
            long fifoBasedReportLatencyUs = fifoReservedEventCount * maximumExpectedSamplingPeriodUs;
            // If the device goes into suspend mode and the sensor is a non wake-up sensor, the
            // FIFO will keep overwriting itself and the reportLatency will be equal to the time
            // it takes to fill up the FIFO.
            if (environment.isDeviceSuspendTest() && !environment.getSensor().isWakeUpSensor()) {
                expectedReportLatencyUs = fifoBasedReportLatencyUs;
            } else {
                // In this case the sensor under test is either a wake-up sensor OR it
                // is a non wake-up sensor but the device does not go into suspend.
                // So the expected delay of a sensor_event is the minimum of the
                // fifoBasedReportLatencyUs and the requested latency by the application.
                expectedReportLatencyUs = Math.min(expectedReportLatencyUs,
                        fifoBasedReportLatencyUs);
            }
        }

        return new FifoLengthVerification((int) fifoReservedEventCount, expectedReportLatencyUs);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public void verify(TestSensorEnvironment environment, SensorStats stats) {
        if (mExpectedFifoLength <= 0) {
            // the expected length isn't defined.
            stats.addValue(PASSED_KEY, ""skipped (no fifo length requirements)"");
            return;
        }
        int batchCount = 0;
        int maxBatchCount = 0;
        boolean success, endofbatch = false;
        long maxTsDiff = -1;
        for (long timestampDiff : mRecvdTimeStampDiffs) {
            if (maxTsDiff < timestampDiff) maxTsDiff = timestampDiff;
            // Any event that arrives within before 0.5*expectedReportLatency is considered
            // to be in the same batch of events, else it is considered as the beginning of a new
            // batch.
            if (timestampDiff < mExpectedReportLatencyUs/1000/2) {
                batchCount++;
            } else {
                endofbatch = true;
                maxBatchCount = (maxBatchCount >= batchCount) ? maxBatchCount : batchCount;
                batchCount = 0;
            }
        }
        Log.v(""SensorFifoLengthVerification"", ""batchCount ="" +batchCount + "" mExpected="" +
                mExpectedFifoLength + "" maxTsDiff="" + maxTsDiff + "" expectedReportLatency="" +
                mExpectedReportLatencyUs/1000 + "" recvdEventCount="" + mRecvdTimeStampDiffs.size());
        // Fifo length must be at least 80% of the advertized FIFO length.
        success = endofbatch && (batchCount >= mExpectedFifoLength * FIFO_LENGTH_TOLERANCE);

        stats.addValue(PASSED_KEY, success);
        stats.addValue(SensorStats.EVENT_FIFO_LENGTH, batchCount);

        if (!success) {
            StringBuilder sb = new StringBuilder();
            if (endofbatch) {
                sb.append(String.format(""Fifo length verification error: Fifo length found=%d,"" +
                            ""expected fifo length ~%d, maxReportLatencyObserved=%dms, "" +
                            ""expectedMaxReportLantency=%dms"",
                            batchCount, mExpectedFifoLength, maxTsDiff,
                            mExpectedReportLatencyUs/1000));
            } else {
               sb.append(String.format(""End of batch NOT observed maxReportLatencyObserved=%dms,""
                            + "" expectedMaxReportLantency=%dms"", maxTsDiff,
                            mExpectedReportLatencyUs/1000));
            }
            Assert.fail(sb.toString());
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public FifoLengthVerification clone() {
        return new FifoLengthVerification(mExpectedFifoLength, mExpectedReportLatencyUs);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    protected void addSensorEventInternal(TestSensorEvent event) {
        if (mPrevRecvdTimeStampMs == -1) {
            mPrevRecvdTimeStampMs = (long)event.receivedTimestamp/(1000 * 1000);
        } else {
            long currRecvdTimeStampMs = (long) event.receivedTimestamp/(1000 * 1000);
            mRecvdTimeStampDiffs.add(currRecvdTimeStampMs - mPrevRecvdTimeStampMs);
            mPrevRecvdTimeStampMs = currRecvdTimeStampMs;
        }
        mIndex++;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.ReprocessCaptureTest"	"testReprocessRequestKeys"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/ReprocessCaptureTest.java"	""	"public void testReprocessRequestKeys() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            if (!isYuvReprocessSupported(id) && !isOpaqueReprocessSupported(id)) {
                continue;
            }

            try {
                // open Camera device
                openDevice(id);

                int[] supportedInputFormats =
                    mStaticInfo.getAvailableFormats(StaticMetadata.StreamDirection.Input);
                for (int inputFormat : supportedInputFormats) {
                    int[] supportedReprocessOutputFormats =
                            mStaticInfo.getValidOutputFormatsForInput(inputFormat);
                    for (int reprocessOutputFormat : supportedReprocessOutputFormats) {
                        testReprocessingMaxSizes(id, inputFormat, reprocessOutputFormat,
                                /*previewSize*/null, CaptureTestCase.REQUEST_KEYS);
                    }
                }
            } finally {
                closeDevice();
            }
        }
    }

    /**
     * Test the input format and output format with the largest input and output sizes.
     */
    private void testBasicReprocessing(String cameraId, int inputFormat,
            int reprocessOutputFormat) throws Exception {
        try {
            openDevice(cameraId);

            testReprocessingMaxSizes(cameraId, inputFormat, reprocessOutputFormat,
                    /* previewSize */null, CaptureTestCase.SINGLE_SHOT);
        } finally {
            closeDevice();
        }
    }

    /**
     * Test the input format and output format with the largest input and output sizes for a
     * certain test case.
     */
    private void testReprocessingMaxSizes(String cameraId, int inputFormat,
            int reprocessOutputFormat, Size previewSize, CaptureTestCase captureTestCase)
            throws Exception {
        Size maxInputSize = getMaxSize(inputFormat, StaticMetadata.StreamDirection.Input);
        Size maxReprocessOutputSize =
                getMaxSize(reprocessOutputFormat, StaticMetadata.StreamDirection.Output);

        switch (captureTestCase) {
            case SINGLE_SHOT:
                testReprocess(cameraId, maxInputSize, inputFormat, maxReprocessOutputSize,
                        reprocessOutputFormat, previewSize, NUM_REPROCESS_CAPTURES);
                break;
            case ABORT_CAPTURE:
                testReprocessAbort(cameraId, maxInputSize, inputFormat, maxReprocessOutputSize,
                        reprocessOutputFormat);
                break;
            case TIMESTAMPS:
                testReprocessTimestamps(cameraId, maxInputSize, inputFormat, maxReprocessOutputSize,
                        reprocessOutputFormat);
                break;
            case JPEG_EXIF:
                testReprocessJpegExif(cameraId, maxInputSize, inputFormat, maxReprocessOutputSize);
                break;
            case REQUEST_KEYS:
                testReprocessRequestKeys(cameraId, maxInputSize, inputFormat,
                        maxReprocessOutputSize, reprocessOutputFormat);
                break;
            default:
                throw new IllegalArgumentException(""Invalid test case"");
        }
    }

    /**
     * Test all input format, input size, output format, and output size combinations.
     */
    private void testReprocessingAllCombinations(String cameraId, Size previewSize,
            CaptureTestCase captureTestCase) throws Exception {

        Size QCIF = new Size(176, 144);
        Size VGA = new Size(640, 480);
        Size FULL_HD = new Size(1920, 1080);
        int[] supportedInputFormats =
                mStaticInfo.getAvailableFormats(StaticMetadata.StreamDirection.Input);
        for (int inputFormat : supportedInputFormats) {
            Size[] supportedInputSizes =
                    mStaticInfo.getAvailableSizesForFormatChecked(inputFormat,
                    StaticMetadata.StreamDirection.Input);

            for (Size inputSize : supportedInputSizes) {
                int[] supportedReprocessOutputFormats =
                        mStaticInfo.getValidOutputFormatsForInput(inputFormat);

                for (int reprocessOutputFormat : supportedReprocessOutputFormats) {
                    Size[] supportedReprocessOutputSizes =
                            mStaticInfo.getAvailableSizesForFormatChecked(reprocessOutputFormat,
                            StaticMetadata.StreamDirection.Output);

                    for (Size reprocessOutputSize : supportedReprocessOutputSizes) {
                        // Handle QCIF exceptions
                        if (reprocessOutputSize.equals(QCIF) &&
                                ((inputSize.getWidth() > FULL_HD.getWidth()) ||
                                 (inputSize.getHeight() > FULL_HD.getHeight()))) {
                            continue;
                        }
                        if (inputSize.equals(QCIF) &&
                                ((reprocessOutputSize.getWidth() > FULL_HD.getWidth()) ||
                                 (reprocessOutputSize.getHeight() > FULL_HD.getHeight()))) {
                            continue;
                        }
                        if ((previewSize != null) &&
                                ((previewSize.getWidth() > FULL_HD.getWidth()) || (
                                  previewSize.getHeight() > FULL_HD.getHeight())) &&
                                (inputSize.equals(QCIF) || reprocessOutputSize.equals(QCIF))) {
                            previewSize = VGA;
                        }

                        switch (captureTestCase) {
                            case SINGLE_SHOT:
                                testReprocess(cameraId, inputSize, inputFormat,
                                        reprocessOutputSize, reprocessOutputFormat, previewSize,
                                        NUM_REPROCESS_CAPTURES);
                                break;
                            case BURST:
                                testReprocessBurst(cameraId, inputSize, inputFormat,
                                        reprocessOutputSize, reprocessOutputFormat, previewSize,
                                        NUM_REPROCESS_BURST);
                                break;
                            case MIXED_BURST:
                                testReprocessMixedBurst(cameraId, inputSize, inputFormat,
                                        reprocessOutputSize, reprocessOutputFormat, previewSize,
                                        NUM_REPROCESS_BURST);
                                break;
                            default:
                                throw new IllegalArgumentException(""Invalid test case"");
                        }
                    }
                }
            }
        }
    }

    /**
     * Test burst that is mixed with regular and reprocess capture requests.
     */
    private void testReprocessMixedBurst(String cameraId, Size inputSize, int inputFormat,
            Size reprocessOutputSize, int reprocessOutputFormat, Size previewSize,
            int numBurst) throws Exception {
        if (VERBOSE) {
            Log.v(TAG, ""testReprocessMixedBurst: cameraId: "" + cameraId + "" inputSize: "" +
                    inputSize + "" inputFormat: "" + inputFormat + "" reprocessOutputSize: "" +
                    reprocessOutputSize + "" reprocessOutputFormat: "" + reprocessOutputFormat +
                    "" previewSize: "" + previewSize + "" numBurst: "" + numBurst);
        }

        boolean enablePreview = (previewSize != null);
        ImageResultHolder[] imageResultHolders = new ImageResultHolder[0];

        try {
            // totalNumBurst = number of regular burst + number of reprocess burst.
            int totalNumBurst = numBurst * 2;

            if (enablePreview) {
                updatePreviewSurface(previewSize);
            } else {
                mPreviewSurface = null;
            }

            setupImageReaders(inputSize, inputFormat, reprocessOutputSize, reprocessOutputFormat,
                totalNumBurst);
            setupReprocessableSession(mPreviewSurface, /*numImageWriterImages*/numBurst);

            if (enablePreview) {
                startPreview(mPreviewSurface);
            }

            // Prepare an array of booleans indicating each capture's type (regular or reprocess)
            boolean[] isReprocessCaptures = new boolean[totalNumBurst];
            for (int i = 0; i < totalNumBurst; i++) {
                if ((i & 1) == 0) {
                    isReprocessCaptures[i] = true;
                } else {
                    isReprocessCaptures[i] = false;
                }
            }

            imageResultHolders = doMixedReprocessBurstCapture(isReprocessCaptures);
            for (ImageResultHolder holder : imageResultHolders) {
                Image reprocessedImage = holder.getImage();
                TotalCaptureResult result = holder.getTotalCaptureResult();

                mCollector.expectImageProperties(""testReprocessMixedBurst"", reprocessedImage,
                            reprocessOutputFormat, reprocessOutputSize,
                            result.get(CaptureResult.SENSOR_TIMESTAMP));

                if (DEBUG) {
                    Log.d(TAG, String.format(""camera %s in %dx%d %d out %dx%d %d"",
                            cameraId, inputSize.getWidth(), inputSize.getHeight(), inputFormat,
                            reprocessOutputSize.getWidth(), reprocessOutputSize.getHeight(),
                            reprocessOutputFormat));
                    dumpImage(reprocessedImage,
                            ""/testReprocessMixedBurst_camera"" + cameraId + ""_"" + mDumpFrameCount);
                    mDumpFrameCount++;
                }
            }
        } finally {
            for (ImageResultHolder holder : imageResultHolders) {
                holder.getImage().close();
            }
            closeReprossibleSession();
            closeImageReaders();
        }
    }

    /**
     * Test burst of reprocess capture requests.
     */
    private void testReprocessBurst(String cameraId, Size inputSize, int inputFormat,
            Size reprocessOutputSize, int reprocessOutputFormat, Size previewSize,
            int numBurst) throws Exception {
        if (VERBOSE) {
            Log.v(TAG, ""testReprocessBurst: cameraId: "" + cameraId + "" inputSize: "" +
                    inputSize + "" inputFormat: "" + inputFormat + "" reprocessOutputSize: "" +
                    reprocessOutputSize + "" reprocessOutputFormat: "" + reprocessOutputFormat +
                    "" previewSize: "" + previewSize + "" numBurst: "" + numBurst);
        }

        boolean enablePreview = (previewSize != null);
        ImageResultHolder[] imageResultHolders = new ImageResultHolder[0];

        try {
            if (enablePreview) {
                updatePreviewSurface(previewSize);
            } else {
                mPreviewSurface = null;
            }

            setupImageReaders(inputSize, inputFormat, reprocessOutputSize, reprocessOutputFormat,
                numBurst);
            setupReprocessableSession(mPreviewSurface, numBurst);

            if (enablePreview) {
                startPreview(mPreviewSurface);
            }

            imageResultHolders = doReprocessBurstCapture(numBurst);
            for (ImageResultHolder holder : imageResultHolders) {
                Image reprocessedImage = holder.getImage();
                TotalCaptureResult result = holder.getTotalCaptureResult();

                mCollector.expectImageProperties(""testReprocessBurst"", reprocessedImage,
                            reprocessOutputFormat, reprocessOutputSize,
                            result.get(CaptureResult.SENSOR_TIMESTAMP));

                if (DEBUG) {
                    Log.d(TAG, String.format(""camera %s in %dx%d %d out %dx%d %d"",
                            cameraId, inputSize.getWidth(), inputSize.getHeight(), inputFormat,
                            reprocessOutputSize.getWidth(), reprocessOutputSize.getHeight(),
                            reprocessOutputFormat));
                    dumpImage(reprocessedImage,
                            ""/testReprocessBurst_camera"" + cameraId + ""_"" + mDumpFrameCount);
                    mDumpFrameCount++;
                }
            }
        } finally {
            for (ImageResultHolder holder : imageResultHolders) {
                holder.getImage().close();
            }
            closeReprossibleSession();
            closeImageReaders();
        }
    }

    /**
     * Test a sequences of reprocess capture requests.
     */
    private void testReprocess(String cameraId, Size inputSize, int inputFormat,
            Size reprocessOutputSize, int reprocessOutputFormat, Size previewSize,
            int numReprocessCaptures) throws Exception {
        if (VERBOSE) {
            Log.v(TAG, ""testReprocess: cameraId: "" + cameraId + "" inputSize: "" +
                    inputSize + "" inputFormat: "" + inputFormat + "" reprocessOutputSize: "" +
                    reprocessOutputSize + "" reprocessOutputFormat: "" + reprocessOutputFormat +
                    "" previewSize: "" + previewSize);
        }

        boolean enablePreview = (previewSize != null);

        try {
            if (enablePreview) {
                updatePreviewSurface(previewSize);
            } else {
                mPreviewSurface = null;
            }

            setupImageReaders(inputSize, inputFormat, reprocessOutputSize, reprocessOutputFormat,
                    /*maxImages*/1);
            setupReprocessableSession(mPreviewSurface, /*numImageWriterImages*/1);

            if (enablePreview) {
                startPreview(mPreviewSurface);
            }

            for (int i = 0; i < numReprocessCaptures; i++) {
                ImageResultHolder imageResultHolder = null;

                try {
                    imageResultHolder = doReprocessCapture();
                    Image reprocessedImage = imageResultHolder.getImage();
                    TotalCaptureResult result = imageResultHolder.getTotalCaptureResult();

                    mCollector.expectImageProperties(""testReprocess"", reprocessedImage,
                            reprocessOutputFormat, reprocessOutputSize,
                            result.get(CaptureResult.SENSOR_TIMESTAMP));

                    if (DEBUG) {
                        Log.d(TAG, String.format(""camera %s in %dx%d %d out %dx%d %d"",
                                cameraId, inputSize.getWidth(), inputSize.getHeight(), inputFormat,
                                reprocessOutputSize.getWidth(), reprocessOutputSize.getHeight(),
                                reprocessOutputFormat));

                        dumpImage(reprocessedImage,
                                ""/testReprocess_camera"" + cameraId + ""_"" + mDumpFrameCount);
                        mDumpFrameCount++;
                    }
                } finally {
                    if (imageResultHolder != null) {
                        imageResultHolder.getImage().close();
                    }
                }
            }
        } finally {
            closeReprossibleSession();
            closeImageReaders();
        }
    }

    /**
     * Test aborting a burst reprocess capture and multiple single reprocess captures.
     */
    private void testReprocessAbort(String cameraId, Size inputSize, int inputFormat,
            Size reprocessOutputSize, int reprocessOutputFormat) throws Exception {
        if (VERBOSE) {
            Log.v(TAG, ""testReprocessAbort: cameraId: "" + cameraId + "" inputSize: "" +
                    inputSize + "" inputFormat: "" + inputFormat + "" reprocessOutputSize: "" +
                    reprocessOutputSize + "" reprocessOutputFormat: "" + reprocessOutputFormat);
        }

        try {
            setupImageReaders(inputSize, inputFormat, reprocessOutputSize, reprocessOutputFormat,
                    NUM_REPROCESS_CAPTURES);
            setupReprocessableSession(/*previewSurface*/null, NUM_REPROCESS_CAPTURES);

            // Wait for session READY state after session creation
            mSessionListener.getStateWaiter().waitForState(
                    BlockingSessionCallback.SESSION_READY, SESSION_CLOSE_TIMEOUT_MS);

            // Test two cases: submitting reprocess requests one by one and in a burst.
            boolean submitInBursts[] = {false, true};
            for (boolean submitInBurst : submitInBursts) {
                // Prepare reprocess capture requests.
                ArrayList<CaptureRequest> reprocessRequests =
                        new ArrayList<>(NUM_REPROCESS_CAPTURES);

                for (int i = 0; i < NUM_REPROCESS_CAPTURES; i++) {
                    TotalCaptureResult result = submitCaptureRequest(mFirstImageReader.getSurface(),
                            /*inputResult*/null);

                    // Wait and drain the READY state for each reprocessing input output.
                    mSessionListener.getStateWaiter().waitForState(
                            BlockingSessionCallback.SESSION_READY, SESSION_CLOSE_TIMEOUT_MS);

                    mImageWriter.queueInputImage(
                            mFirstImageReaderListener.getImage(CAPTURE_TIMEOUT_MS));
                    CaptureRequest.Builder builder = mCamera.createReprocessCaptureRequest(result);
                    builder.addTarget(getReprocessOutputImageReader().getSurface());
                    reprocessRequests.add(builder.build());
                }

                SimpleCaptureCallback captureCallback = new SimpleCaptureCallback();

                // Submit reprocess capture requests.
                if (submitInBurst) {
                    mSession.captureBurst(reprocessRequests, captureCallback, mHandler);
                } else {
                    for (CaptureRequest request : reprocessRequests) {
                        mSession.capture(request, captureCallback, mHandler);
                    }
                }

                // Abort after getting the first result
                TotalCaptureResult reprocessResult =
                        captureCallback.getTotalCaptureResultForRequest(reprocessRequests.get(0),
                        CAPTURE_TIMEOUT_FRAMES);
                mSession.abortCaptures();

                // Wait until the session is ready again.
                mSessionListener.getStateWaiter().waitForState(
                        BlockingSessionCallback.SESSION_READY, SESSION_CLOSE_TIMEOUT_MS);

                // Gather all failed requests.
                ArrayList<CaptureFailure> failures =
                        captureCallback.getCaptureFailures(NUM_REPROCESS_CAPTURES - 1);
                ArrayList<CaptureRequest> failedRequests = new ArrayList<>();
                for (CaptureFailure failure : failures) {
                    failedRequests.add(failure.getRequest());
                }

                // For each request that didn't fail must have a valid result.
                for (int i = 1; i < reprocessRequests.size(); i++) {
                    CaptureRequest request = reprocessRequests.get(i);
                    if (!failedRequests.contains(request)) {
                        captureCallback.getTotalCaptureResultForRequest(request,
                                CAPTURE_TIMEOUT_FRAMES);
                    }
                }

                // Drain the image reader listeners.
                mFirstImageReaderListener.drain();
                if (!mShareOneImageReader) {
                    mSecondImageReaderListener.drain();
                }

                // Make sure all input surfaces are released.
                for (int i = 0; i < NUM_REPROCESS_CAPTURES; i++) {
                    mImageWriterListener.waitForImageReleased(CAPTURE_TIMEOUT_MS);
                }
            }
        } finally {
            closeReprossibleSession();
            closeImageReaders();
        }
    }

    /**
     * Test timestamps for reprocess requests. Reprocess request's shutter timestamp, result's
     * sensor timestamp, and output image's timestamp should match the reprocess input's timestamp.
     */
    private void testReprocessTimestamps(String cameraId, Size inputSize, int inputFormat,
            Size reprocessOutputSize, int reprocessOutputFormat) throws Exception {
        if (VERBOSE) {
            Log.v(TAG, ""testReprocessTimestamps: cameraId: "" + cameraId + "" inputSize: "" +
                    inputSize + "" inputFormat: "" + inputFormat + "" reprocessOutputSize: "" +
                    reprocessOutputSize + "" reprocessOutputFormat: "" + reprocessOutputFormat);
        }

        try {
            setupImageReaders(inputSize, inputFormat, reprocessOutputSize, reprocessOutputFormat,
                    NUM_REPROCESS_CAPTURES);
            setupReprocessableSession(/*previewSurface*/null, NUM_REPROCESS_CAPTURES);

            // Prepare reprocess capture requests.
            ArrayList<CaptureRequest> reprocessRequests = new ArrayList<>(NUM_REPROCESS_CAPTURES);
            ArrayList<Long> expectedTimestamps = new ArrayList<>(NUM_REPROCESS_CAPTURES);

            for (int i = 0; i < NUM_REPROCESS_CAPTURES; i++) {
                TotalCaptureResult result = submitCaptureRequest(mFirstImageReader.getSurface(),
                        /*inputResult*/null);

                mImageWriter.queueInputImage(
                        mFirstImageReaderListener.getImage(CAPTURE_TIMEOUT_MS));
                CaptureRequest.Builder builder = mCamera.createReprocessCaptureRequest(result);
                builder.addTarget(getReprocessOutputImageReader().getSurface());
                reprocessRequests.add(builder.build());
                // Reprocess result's timestamp should match input image's timestamp.
                expectedTimestamps.add(result.get(CaptureResult.SENSOR_TIMESTAMP));
            }

            // Submit reprocess requests.
            SimpleCaptureCallback captureCallback = new SimpleCaptureCallback();
            mSession.captureBurst(reprocessRequests, captureCallback, mHandler);

            // Verify we get the expected timestamps.
            for (int i = 0; i < reprocessRequests.size(); i++) {
                captureCallback.waitForCaptureStart(reprocessRequests.get(i),
                        expectedTimestamps.get(i), CAPTURE_TIMEOUT_FRAMES);
            }

            TotalCaptureResult[] reprocessResults =
                    captureCallback.getTotalCaptureResultsForRequests(reprocessRequests,
                    CAPTURE_TIMEOUT_FRAMES);

            for (int i = 0; i < expectedTimestamps.size(); i++) {
                // Verify the result timestamps match the input image's timestamps.
                long expected = expectedTimestamps.get(i);
                long timestamp = reprocessResults[i].get(CaptureResult.SENSOR_TIMESTAMP);
                assertEquals(""Reprocess result timestamp ("" + timestamp + "") doesn't match input "" +
                        ""image's timestamp ("" + expected + "")"", expected, timestamp);

                // Verify the reprocess output image timestamps match the input image's timestamps.
                Image image = getReprocessOutputImageReaderListener().getImage(CAPTURE_TIMEOUT_MS);
                timestamp = image.getTimestamp();
                image.close();

                assertEquals(""Reprocess output timestamp ("" + timestamp + "") doesn't match input "" +
                        ""image's timestamp ("" + expected + "")"", expected, timestamp);
            }

            // Make sure all input surfaces are released.
            for (int i = 0; i < NUM_REPROCESS_CAPTURES; i++) {
                mImageWriterListener.waitForImageReleased(CAPTURE_TIMEOUT_MS);
            }
        } finally {
            closeReprossibleSession();
            closeImageReaders();
        }
    }

    /**
     * Test JPEG tags for reprocess requests. Reprocess result's JPEG tags and JPEG image's tags
     * match reprocess request's JPEG tags.
     */
    private void testReprocessJpegExif(String cameraId, Size inputSize, int inputFormat,
            Size reprocessOutputSize) throws Exception {
        if (VERBOSE) {
            Log.v(TAG, ""testReprocessJpegExif: cameraId: "" + cameraId + "" inputSize: "" +
                    inputSize + "" inputFormat: "" + inputFormat + "" reprocessOutputSize: "" +
                    reprocessOutputSize);
        }

        Size[] thumbnailSizes = mStaticInfo.getAvailableThumbnailSizesChecked();
        Size[] testThumbnailSizes = new Size[EXIF_TEST_DATA.length];
        Arrays.fill(testThumbnailSizes, thumbnailSizes[thumbnailSizes.length - 1]);
        // Make sure thumbnail size (0, 0) is covered.
        testThumbnailSizes[0] = new Size(0, 0);

        try {
            setupImageReaders(inputSize, inputFormat, reprocessOutputSize, ImageFormat.JPEG,
                    EXIF_TEST_DATA.length);
            setupReprocessableSession(/*previewSurface*/null, EXIF_TEST_DATA.length);

            // Prepare reprocess capture requests.
            ArrayList<CaptureRequest> reprocessRequests = new ArrayList<>(EXIF_TEST_DATA.length);

            for (int i = 0; i < EXIF_TEST_DATA.length; i++) {
                TotalCaptureResult result = submitCaptureRequest(mFirstImageReader.getSurface(),
                        /*inputResult*/null);
                mImageWriter.queueInputImage(
                        mFirstImageReaderListener.getImage(CAPTURE_TIMEOUT_MS));

                CaptureRequest.Builder builder = mCamera.createReprocessCaptureRequest(result);
                builder.addTarget(getReprocessOutputImageReader().getSurface());

                // set jpeg keys
                setJpegKeys(builder, EXIF_TEST_DATA[i], testThumbnailSizes[i], mCollector);
                reprocessRequests.add(builder.build());
            }

            // Submit reprocess requests.
            SimpleCaptureCallback captureCallback = new SimpleCaptureCallback();
            mSession.captureBurst(reprocessRequests, captureCallback, mHandler);

            TotalCaptureResult[] reprocessResults =
                    captureCallback.getTotalCaptureResultsForRequests(reprocessRequests,
                    CAPTURE_TIMEOUT_FRAMES);

            for (int i = 0; i < EXIF_TEST_DATA.length; i++) {
                // Verify output image's and result's JPEG EXIF data.
                Image image = getReprocessOutputImageReaderListener().getImage(CAPTURE_TIMEOUT_MS);
                verifyJpegKeys(image, reprocessResults[i], reprocessOutputSize,
                        testThumbnailSizes[i], EXIF_TEST_DATA[i], mStaticInfo, mCollector,
                        mDebugFileNameBase, ImageFormat.JPEG);
                image.close();

            }
        } finally {
            closeReprossibleSession();
            closeImageReaders();
        }
    }



    /**
     * Test the following keys in reprocess results match the keys in reprocess requests:
     *   1. EDGE_MODE
     *   2. NOISE_REDUCTION_MODE
     *   3. REPROCESS_EFFECTIVE_EXPOSURE_FACTOR (only for YUV reprocess)
     */
    private void testReprocessRequestKeys(String cameraId, Size inputSize, int inputFormat,
            Size reprocessOutputSize, int reprocessOutputFormat) throws Exception {
        if (VERBOSE) {
            Log.v(TAG, ""testReprocessRequestKeys: cameraId: "" + cameraId + "" inputSize: "" +
                    inputSize + "" inputFormat: "" + inputFormat + "" reprocessOutputSize: "" +
                    reprocessOutputSize + "" reprocessOutputFormat: "" + reprocessOutputFormat);
        }

        final Integer[] EDGE_MODES = {CaptureRequest.EDGE_MODE_FAST,
                CaptureRequest.EDGE_MODE_HIGH_QUALITY, CaptureRequest.EDGE_MODE_OFF,
                CaptureRequest.EDGE_MODE_ZERO_SHUTTER_LAG};
        final Integer[] NR_MODES = {CaptureRequest.NOISE_REDUCTION_MODE_HIGH_QUALITY,
                CaptureRequest.NOISE_REDUCTION_MODE_OFF,
                CaptureRequest.NOISE_REDUCTION_MODE_ZERO_SHUTTER_LAG,
                CaptureRequest.NOISE_REDUCTION_MODE_FAST};
        final Float[] EFFECTIVE_EXP_FACTORS = {null, 1.0f, 2.5f, 4.0f};
        int numFrames = EDGE_MODES.length;

        try {
            setupImageReaders(inputSize, inputFormat, reprocessOutputSize, reprocessOutputFormat,
                    numFrames);
            setupReprocessableSession(/*previewSurface*/null, numFrames);

            // Prepare reprocess capture requests.
            ArrayList<CaptureRequest> reprocessRequests = new ArrayList<>(numFrames);

            for (int i = 0; i < numFrames; i++) {
                TotalCaptureResult result = submitCaptureRequest(mFirstImageReader.getSurface(),
                        /*inputResult*/null);
                mImageWriter.queueInputImage(
                        mFirstImageReaderListener.getImage(CAPTURE_TIMEOUT_MS));

                CaptureRequest.Builder builder = mCamera.createReprocessCaptureRequest(result);
                builder.addTarget(getReprocessOutputImageReader().getSurface());

                // Set reprocess request keys
                builder.set(CaptureRequest.EDGE_MODE, EDGE_MODES[i]);
                builder.set(CaptureRequest.NOISE_REDUCTION_MODE, NR_MODES[i]);
                if (inputFormat == ImageFormat.YUV_420_888) {
                    builder.set(CaptureRequest.REPROCESS_EFFECTIVE_EXPOSURE_FACTOR,
                            EFFECTIVE_EXP_FACTORS[i]);
                }
                reprocessRequests.add(builder.build());
            }

            // Submit reprocess requests.
            SimpleCaptureCallback captureCallback = new SimpleCaptureCallback();
            mSession.captureBurst(reprocessRequests, captureCallback, mHandler);

            TotalCaptureResult[] reprocessResults =
                    captureCallback.getTotalCaptureResultsForRequests(reprocessRequests,
                    CAPTURE_TIMEOUT_FRAMES);

            for (int i = 0; i < numFrames; i++) {
                // Verify result's keys
                Integer resultEdgeMode = reprocessResults[i].get(CaptureResult.EDGE_MODE);
                Integer resultNoiseReductionMode =
                        reprocessResults[i].get(CaptureResult.NOISE_REDUCTION_MODE);

                assertEquals(""Reprocess result edge mode ("" + resultEdgeMode +
                        "") doesn't match requested edge mode ("" + EDGE_MODES[i] + "")"",
                        resultEdgeMode, EDGE_MODES[i]);
                assertEquals(""Reprocess result noise reduction mode ("" + resultNoiseReductionMode +
                        "") doesn't match requested noise reduction mode ("" +
                        NR_MODES[i] + "")"", resultNoiseReductionMode,
                        NR_MODES[i]);

                if (inputFormat == ImageFormat.YUV_420_888) {
                    Float resultEffectiveExposureFactor = reprocessResults[i].get(
                            CaptureResult.REPROCESS_EFFECTIVE_EXPOSURE_FACTOR);
                    assertEquals(""Reprocess effective exposure factor ("" +
                            resultEffectiveExposureFactor + "") doesn't match requested "" +
                            ""effective exposure factor ("" + EFFECTIVE_EXP_FACTORS[i] + "")"",
                            resultEffectiveExposureFactor, EFFECTIVE_EXP_FACTORS[i]);
                }
            }
        } finally {
            closeReprossibleSession();
            closeImageReaders();
        }
    }

    /**
     * Set up two image readers: one for regular capture (used for reprocess input) and one for
     * reprocess capture.
     */
    private void setupImageReaders(Size inputSize, int inputFormat, Size reprocessOutputSize,
            int reprocessOutputFormat, int maxImages) {

        mShareOneImageReader = false;
        // If the regular output and reprocess output have the same size and format,
        // they can share one image reader.
        if (inputFormat == reprocessOutputFormat &&
                inputSize.equals(reprocessOutputSize)) {
            maxImages *= 2;
            mShareOneImageReader = true;
        }
        // create an ImageReader for the regular capture
        mFirstImageReaderListener = new SimpleImageReaderListener();
        mFirstImageReader = makeImageReader(inputSize, inputFormat, maxImages,
                mFirstImageReaderListener, mHandler);

        if (!mShareOneImageReader) {
            // create an ImageReader for the reprocess capture
            mSecondImageReaderListener = new SimpleImageReaderListener();
            mSecondImageReader = makeImageReader(reprocessOutputSize, reprocessOutputFormat,
                    maxImages, mSecondImageReaderListener, mHandler);
        }
    }

    /**
     * Close two image readers.
     */
    private void closeImageReaders() {
        CameraTestUtils.closeImageReader(mFirstImageReader);
        mFirstImageReader = null;
        CameraTestUtils.closeImageReader(mSecondImageReader);
        mSecondImageReader = null;
    }

    /**
     * Get the ImageReader for reprocess output.
     */
    private ImageReader getReprocessOutputImageReader() {
        if (mShareOneImageReader) {
            return mFirstImageReader;
        } else {
            return mSecondImageReader;
        }
    }

    private SimpleImageReaderListener getReprocessOutputImageReaderListener() {
        if (mShareOneImageReader) {
            return mFirstImageReaderListener;
        } else {
            return mSecondImageReaderListener;
        }
    }

    /**
     * Set up a reprocessable session and create an ImageWriter with the sessoin's input surface.
     */
    private void setupReprocessableSession(Surface previewSurface, int numImageWriterImages)
            throws Exception {
        // create a reprocessable capture session
        List<Surface> outSurfaces = new ArrayList<Surface>();
        outSurfaces.add(mFirstImageReader.getSurface());
        if (!mShareOneImageReader) {
            outSurfaces.add(mSecondImageReader.getSurface());
        }
        if (previewSurface != null) {
            outSurfaces.add(previewSurface);
        }

        InputConfiguration inputConfig = new InputConfiguration(mFirstImageReader.getWidth(),
                mFirstImageReader.getHeight(), mFirstImageReader.getImageFormat());
        String inputConfigString = inputConfig.toString();
        if (VERBOSE) {
            Log.v(TAG, ""InputConfiguration: "" + inputConfigString);
        }
        assertTrue(String.format(""inputConfig is wrong: %dx%d format %d. Expect %dx%d format %d"",
                inputConfig.getWidth(), inputConfig.getHeight(), inputConfig.getFormat(),
                mFirstImageReader.getWidth(), mFirstImageReader.getHeight(),
                mFirstImageReader.getImageFormat()),
                inputConfig.getWidth() == mFirstImageReader.getWidth() &&
                inputConfig.getHeight() == mFirstImageReader.getHeight() &&
                inputConfig.getFormat() == mFirstImageReader.getImageFormat());

        mSessionListener = new BlockingSessionCallback();
        mSession = configureReprocessableCameraSession(mCamera, inputConfig, outSurfaces,
                mSessionListener, mHandler);

        // create an ImageWriter
        mInputSurface = mSession.getInputSurface();
        mImageWriter = ImageWriter.newInstance(mInputSurface,
                numImageWriterImages);

        mImageWriterListener = new SimpleImageWriterListener(mImageWriter);
        mImageWriter.setOnImageReleasedListener(mImageWriterListener, mHandler);
    }

    /**
     * Close the reprocessable session and ImageWriter.
     */
    private void closeReprossibleSession() {
        mInputSurface = null;

        if (mSession != null) {
            mSession.close();
            mSession = null;
        }

        if (mImageWriter != null) {
            mImageWriter.close();
            mImageWriter = null;
        }
    }

    /**
     * Do one reprocess capture.
     */
    private ImageResultHolder doReprocessCapture() throws Exception {
        return doReprocessBurstCapture(/*numBurst*/1)[0];
    }

    /**
     * Do a burst of reprocess captures.
     */
    private ImageResultHolder[] doReprocessBurstCapture(int numBurst) throws Exception {
        boolean[] isReprocessCaptures = new boolean[numBurst];
        for (int i = 0; i < numBurst; i++) {
            isReprocessCaptures[i] = true;
        }

        return doMixedReprocessBurstCapture(isReprocessCaptures);
    }

    /**
     * Do a burst of captures that are mixed with regular and reprocess captures.
     *
     * @param isReprocessCaptures An array whose elements indicate whether it's a reprocess capture
     *                            request. If the element is true, it represents a reprocess capture
     *                            request. If the element is false, it represents a regular capture
     *                            request. The size of the array is the number of capture requests
     *                            in the burst.
     */
    private ImageResultHolder[] doMixedReprocessBurstCapture(boolean[] isReprocessCaptures)
            throws Exception {
        if (isReprocessCaptures == null || isReprocessCaptures.length <= 0) {
            throw new IllegalArgumentException(""isReprocessCaptures must have at least 1 capture."");
        }

        boolean hasReprocessRequest = false;
        boolean hasRegularRequest = false;

        TotalCaptureResult[] results = new TotalCaptureResult[isReprocessCaptures.length];
        for (int i = 0; i < isReprocessCaptures.length; i++) {
            // submit a capture and get the result if this entry is a reprocess capture.
            if (isReprocessCaptures[i]) {
                results[i] = submitCaptureRequest(mFirstImageReader.getSurface(),
                        /*inputResult*/null);
                mImageWriter.queueInputImage(
                        mFirstImageReaderListener.getImage(CAPTURE_TIMEOUT_MS));
                hasReprocessRequest = true;
            } else {
                hasRegularRequest = true;
            }
        }

        Surface[] outputSurfaces = new Surface[isReprocessCaptures.length];
        for (int i = 0; i < isReprocessCaptures.length; i++) {
            outputSurfaces[i] = getReprocessOutputImageReader().getSurface();
        }

        TotalCaptureResult[] finalResults = submitMixedCaptureBurstRequest(outputSurfaces, results);

        ImageResultHolder[] holders = new ImageResultHolder[isReprocessCaptures.length];
        for (int i = 0; i < isReprocessCaptures.length; i++) {
            Image image = getReprocessOutputImageReaderListener().getImage(CAPTURE_TIMEOUT_MS);
            if (hasReprocessRequest && hasRegularRequest) {
                // If there are mixed requests, images and results may not be in the same order.
                for (int j = 0; j < finalResults.length; j++) {
                    if (finalResults[j] != null &&
                            finalResults[j].get(CaptureResult.SENSOR_TIMESTAMP) ==
                            image.getTimestamp()) {
                        holders[i] = new ImageResultHolder(image, finalResults[j]);
                        finalResults[j] = null;
                        break;
                    }
                }

                assertNotNull(""Cannot find a result matching output image's timestamp: "" +
                        image.getTimestamp(), holders[i]);
            } else {
                // If no mixed requests, images and results should be in the same order.
                holders[i] = new ImageResultHolder(image, finalResults[i]);
            }
        }

        return holders;
    }

    /**
     * Start preview without a listener.
     */
    private void startPreview(Surface previewSurface) throws Exception {
        CaptureRequest.Builder builder = mCamera.createCaptureRequest(ZSL_TEMPLATE);
        builder.addTarget(previewSurface);
        mSession.setRepeatingRequest(builder.build(), null, mHandler);
    }

    /**
     * Issue a capture request and return the result. If inputResult is null, it's a regular
     * request. Otherwise, it's a reprocess request.
     */
    private TotalCaptureResult submitCaptureRequest(Surface output,
            TotalCaptureResult inputResult) throws Exception {
        Surface[] outputs = new Surface[1];
        outputs[0] = output;
        TotalCaptureResult[] inputResults = new TotalCaptureResult[1];
        inputResults[0] = inputResult;

        return submitMixedCaptureBurstRequest(outputs, inputResults)[0];
    }

    /**
     * Submit a burst request mixed with regular and reprocess requests.
     *
     * @param outputs An array of output surfaces. One output surface will be used in one request
     *                so the length of the array is the number of requests in a burst request.
     * @param inputResults An array of input results. If it's null, all requests are regular
     *                     requests. If an element is null, that element represents a regular
     *                     request. If an element if not null, that element represents a reprocess
     *                     request.
     *
     */
    private TotalCaptureResult[] submitMixedCaptureBurstRequest(Surface[] outputs,
            TotalCaptureResult[] inputResults) throws Exception {
        if (outputs == null || outputs.length <= 0) {
            throw new IllegalArgumentException(""outputs must have at least 1 surface"");
        } else if (inputResults != null && inputResults.length != outputs.length) {
            throw new IllegalArgumentException(""The lengths of outputs and inputResults "" +
                    ""don't match"");
        }

        int numReprocessCaptures = 0;
        SimpleCaptureCallback captureCallback = new SimpleCaptureCallback();
        ArrayList<CaptureRequest> captureRequests = new ArrayList<>(outputs.length);

        // Prepare a list of capture requests. Whether it's a regular or reprocess capture request
        // is based on inputResults array.
        for (int i = 0; i < outputs.length; i++) {
            CaptureRequest.Builder builder;
            boolean isReprocess = (inputResults != null && inputResults[i] != null);
            if (isReprocess) {
                builder = mCamera.createReprocessCaptureRequest(inputResults[i]);
                numReprocessCaptures++;
            } else {
                builder = mCamera.createCaptureRequest(CAPTURE_TEMPLATE);
            }
            builder.addTarget(outputs[i]);
            CaptureRequest request = builder.build();
            assertTrue(""Capture request reprocess type "" + request.isReprocess() + "" is wrong."",
                request.isReprocess() == isReprocess);

            captureRequests.add(request);
        }

        if (captureRequests.size() == 1) {
            mSession.capture(captureRequests.get(0), captureCallback, mHandler);
        } else {
            mSession.captureBurst(captureRequests, captureCallback, mHandler);
        }

        TotalCaptureResult[] results;
        if (numReprocessCaptures == 0 || numReprocessCaptures == outputs.length) {
            results = new TotalCaptureResult[outputs.length];
            // If the requests are not mixed, they should come in order.
            for (int i = 0; i < results.length; i++){
                results[i] = captureCallback.getTotalCaptureResultForRequest(
                        captureRequests.get(i), CAPTURE_TIMEOUT_FRAMES);
            }
        } else {
            // If the requests are mixed, they may not come in order.
            results = captureCallback.getTotalCaptureResultsForRequests(
                    captureRequests, CAPTURE_TIMEOUT_FRAMES * captureRequests.size());
        }

        // make sure all input surfaces are released.
        for (int i = 0; i < numReprocessCaptures; i++) {
            mImageWriterListener.waitForImageReleased(CAPTURE_TIMEOUT_MS);
        }

        return results;
    }

    private Size getMaxSize(int format, StaticMetadata.StreamDirection direction) {
        Size[] sizes = mStaticInfo.getAvailableSizesForFormatChecked(format, direction);
        return getAscendingOrderSizes(Arrays.asList(sizes), /*ascending*/false).get(0);
    }

    private boolean isYuvReprocessSupported(String cameraId) throws Exception {
        return isReprocessSupported(cameraId, ImageFormat.YUV_420_888);
    }

    private boolean isOpaqueReprocessSupported(String cameraId) throws Exception {
        return isReprocessSupported(cameraId, ImageFormat.PRIVATE);
    }

    private void dumpImage(Image image, String name) {
        String filename = mDebugFileNameBase + name;
        switch(image.getFormat()) {
            case ImageFormat.JPEG:
                filename += "".jpg"";
                break;
            case ImageFormat.HEIC:
                filename += "".heic"";
                break;
            case ImageFormat.NV16:
            case ImageFormat.NV21:
            case ImageFormat.YUV_420_888:
                filename += "".yuv"";
                break;
            default:
                filename += ""."" + image.getFormat();
                break;
        }

        Log.d(TAG, ""dumping an image to "" + filename);
        dumpFile(filename , getDataFromImage(image));
    }

    /**
     * A class that holds an Image and a TotalCaptureResult.
     */
    private static class ImageResultHolder {
        private final Image mImage;
        private final TotalCaptureResult mResult;

        public ImageResultHolder(Image image, TotalCaptureResult result) {
            mImage = image;
            mResult = result;
        }

        public Image getImage() {
            return mImage;
        }

        public TotalCaptureResult getTotalCaptureResult() {
            return mResult;
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Fragments.AccuracyFragment"	"OnClickListener"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Fragments/AccuracyFragment.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Fragments;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.sixdof.BuildConfig;
import com.android.cts.verifier.sensors.sixdof.Activities.TestActivity;
import com.android.cts.verifier.sensors.sixdof.Dialogs.AccuracyResultDialog;
import com.android.cts.verifier.sensors.sixdof.Dialogs.Lap2Dialog;
import com.android.cts.verifier.sensors.sixdof.Interfaces.AccuracyListener;
import com.android.cts.verifier.sensors.sixdof.Renderer.AccuracyRenderer;
import com.android.cts.verifier.sensors.sixdof.Utils.Manager;
import com.android.cts.verifier.sensors.sixdof.Utils.MathsUtils;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointAreaCoveredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointDistanceException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointRingNotEnteredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointStartPointException;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Waypoint;
import com.android.cts.verifier.sensors.sixdof.Utils.ResultObjects.ResultObject;

import android.app.Activity;
import android.opengl.GLSurfaceView;
import android.os.Bundle;
import android.app.DialogFragment;
import android.app.AlertDialog;
import android.util.Log;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.widget.ImageButton;
import android.widget.LinearLayout;
import android.widget.TextView;
import android.widget.Toast;

import java.text.DecimalFormat;
import java.util.ArrayList;

/**
 * UI fragment for the first test.
 */
public class AccuracyFragment extends BaseUiFragment implements AccuracyListener,
        Lap2Dialog.Lap2DialogListener {
    private static final String TAG = ""AccuracyFragment"";

    private String mCurrentObjective = """";

    private TextView mTvDistanceRemaining;
    private TextView mTvMarkers;
    private TextView mTvObjective;

    /**
     * Necessary empty constructor.
     */
    public AccuracyFragment() {
    }

    /**
     * Standard practice to have a static newInstance constructor. Used to pass in arguments to the
     * fragment. We don't have any at the moment, but this is good structure for the future.
     *
     * @return a new Accuracy test fragment.
     */
    public static AccuracyFragment newInstance() {
        AccuracyFragment fragment = new AccuracyFragment();
        return fragment;
    }

    /**
     * Called when the parent activity has been created. Adds the GLSurfaceView to the fragment
     * layout.
     */
    @Override
    public void onActivityCreated(Bundle savedInstanceState) {
        super.onActivityCreated(savedInstanceState);

        GLSurfaceView surfaceView = new GLSurfaceView(getActivity());
        surfaceView.setEGLContextClientVersion(2);
        mRenderer = new AccuracyRenderer(getActivity());
        surfaceView.setRenderer(mRenderer);
        mLLCameraLayout = (LinearLayout) getView().findViewById(R.id.llCamera);
        mLLCameraLayout.addView(surfaceView);
        Log.d(TAG, ""Camera Preview add to layout"");
    }

    /**
     * Initialises all of the UI elements
     */
    @Override
    public View onCreateView(LayoutInflater inflater, ViewGroup container,
                             Bundle savedInstanceState) {
        View view = inflater.inflate(R.layout.fragment_accuracy, container, false);
        getActivity().setTitle(getResources().getStringArray(R.array.phase)[TestActivity.CTSTest.ACCURACY.ordinal()]);
        mTvDistanceRemaining = (TextView) view.findViewById(R.id.tvTranslations);
        mTvMarkers = (TextView) view.findViewById(R.id.tvMarkers);
        mTvObjective = (TextView) view.findViewById(R.id.tvObjective);
        mPlaceWaypointButton = (ImageButton) view.findViewById(R.id.fabPlaceWaypoint);
        mPlaceWaypointButton.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                try {
                    mActivity.attemptWaypointPlacement();
                } catch (WaypointDistanceException e) {
                    Toast.makeText(getActivity(),
                            getString(R.string.error_distance), Toast.LENGTH_SHORT).show();
                } catch (WaypointAreaCoveredException e) {
                    Toast.makeText(getActivity(),
                            getString(R.string.error_area), Toast.LENGTH_SHORT).show();
                } catch (WaypointStartPointException e) {
                    Toast.makeText(getActivity(),
                            getString(R.string.error_start_point), Toast.LENGTH_SHORT).show();
                } catch (WaypointRingNotEnteredException e) {
                    throw new AssertionError(
                            ""WaypointRingNotEnteredException when not in 3rd test"", e);
                }
            }
        });

        // Setup buttons for pass/info/fail
        setupButtons(view, TestActivity.CTSTest.ACCURACY);

        return view;
    }

    /**
     * Called after onCreateView. Starts listening for 6DoF events.
     */
    @Override
    public void onViewCreated(View view, Bundle savedInstanceState) {
        super.onViewCreated(view, savedInstanceState);
        mActivity.listenFor6DofData(this);
    }

    @Override
    protected void setupUILoop() {
        Runnable runnable = new Runnable() {

            @Override
            public void run() {
                DecimalFormat oneDecimalFormat = new DecimalFormat(""0.0"");

                if (mActivity == null || getActivity() == null) {
                    return;
                }

                String distanceString = """";
                String markerString = """";
                ArrayList<Waypoint> referenceWaypoints;

                switch (mActivity.getLap()) {
                    case LAP_1:
                        referenceWaypoints = mActivity.getUserGeneratedWaypoints(Manager.Lap.LAP_1);

                        float distanceRemaining = 0f;

                        if (referenceWaypoints.size() > 0) {
                            distanceRemaining = mActivity.getLatestDistanceData();
                            float adjustedDistanceRemaining = Math.max(distanceRemaining, 0);
                            distanceString = getResources().getString(R.string.distance_remaining) +
                                    oneDecimalFormat.format(adjustedDistanceRemaining);

                            markerString = getResources().getString(R.string.markers);
                            for (Waypoint waypoint : referenceWaypoints) {
                                markerString +=
                                        MathsUtils.coordinatesToString(waypoint.getCoordinates()) + ""\n"";
                            }
                        }

                        if (distanceRemaining <= 0 || referenceWaypoints.size() == 0) {
                            mPlaceWaypointButton.setVisibility(View.VISIBLE);
                        } else {
                            mPlaceWaypointButton.setVisibility(View.INVISIBLE);
                        }
                        break;
                    case LAP_2:
                        referenceWaypoints = mActivity.getUserGeneratedWaypoints(Manager.Lap.LAP_2);

                        if (referenceWaypoints.size() == Manager.MAX_MARKER_NUMBER) {
                            mPlaceWaypointButton.setVisibility(View.INVISIBLE);
                        } else {
                            mPlaceWaypointButton.setVisibility(View.VISIBLE);
                        }
                        break;
                    default:
                        //Possible for this state to be entered when switching fragments
                        Log.e(TAG, ""Trying to run UI on Accuracy Test on a lap greater than 2"");

                        //Use an empty list as not interested in this state
                        referenceWaypoints = new ArrayList<Waypoint>();
                }

                mCurrentObjective = getObjectiveText(mActivity.getLap(), referenceWaypoints.size());

                mTvDistanceRemaining.setText(distanceString);
                mTvMarkers.setText(markerString);
                mTvObjective.setText(mCurrentObjective);

                //Update the UI again in x milliseconds.
                if (mHandler != null) {
                    mHandler.postDelayed(this, UI_UPDATE_DELAY);
                }
            }
        };

        super.initUIHandler(runnable);
    }

    /**
     * Called when this phase is done and a result is ready. Shows the results dialog and enables
     * pass button if test has been passed.
     */
    @Override
    public void onResult(ResultObject result) {
        AccuracyResultDialog dialog = AccuracyResultDialog.newInstance(result);
        dialog.setTargetFragment(AccuracyFragment.this, DIALOG_FRAGMENT);
        dialog.show(getActivity().getFragmentManager(), ""ResultDialogFragment"");
        mPlaceWaypointButton.setVisibility(View.INVISIBLE);

        if (result.hasPassed() || BuildConfig.DEBUG) {
            mBtnPass.setEnabled(true);
            mBtnPass.setOnClickListener(new View.OnClickListener() {
                @Override
                public void onClick(View view) {
                    onReadyForPhase2();
                }
            });
        }
    }

    /**
     * Resets UI to how it is at the start of test. Currently called when first waypoint is undone.
     */
    @Override
    public void onReset() {
        mActivity.runOnUiThread(new Runnable() {
            @Override
            public void run() {
                mPlaceWaypointButton.setVisibility(View.VISIBLE);
                mTvDistanceRemaining.setText("""");
                mTvMarkers.setText("""");
                mCurrentObjective = getResources().getStringArray(R.array.initial_waypoint)[0];
                mTvObjective.setText(mCurrentObjective);
            }
        });
    }

    @Override
    public void lap1Complete() {
        onBackToFirstWaypoint();
        mActivity.readyForLap2();
    }

    /**
     * Shows initial instruction dialog
     */
    @Override
    protected void showInitialDialog() {
        AlertDialog.Builder builder = new AlertDialog.Builder(getActivity());

        builder.setMessage(R.string.phase1_initial_message)
                .setTitle(R.string.initial)
                .setPositiveButton(R.string.got_it, null);

        AlertDialog dialog = builder.create();
        dialog.show();
    }

    /**
     * Called when user finishes the first lap
     */
    public void onBackToFirstWaypoint() {
        DialogFragment dialog = Lap2Dialog.newInstance();
        dialog.setTargetFragment(AccuracyFragment.this, DIALOG_FRAGMENT);
        dialog.show(getActivity().getFragmentManager(), ""Lap2DialogFragment"");
    }

    /**
     * Move to next test
     */
    public void onReadyForPhase2() {
        mActivity.switchToStartFragment(TestActivity.CTSTest.ROBUSTNESS);
    }

    /**
     * Called when lap 2 starts.
     */
    @Override
    public void onLap2Start() {
        mPlaceWaypointButton.setVisibility(View.VISIBLE);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.server.biometrics.BiometricTestBase"	"anyEnrollmentsExist"	"CtsBiometricsTestCases"	"/home/gpoor/cts-12-source/cts/tests/framework/base/biometrics/src/android/server/biometrics/BiometricTestBase.java"	""	"public void test/*
 *.
 */

package android.server.biometrics;

import static android.os.PowerManager.FULL_WAKE_LOCK;
import static android.server.biometrics.SensorStates.SensorState;
import static android.server.biometrics.SensorStates.UserState;

import static androidx.test.platform.app.InstrumentationRegistry.getInstrumentation;

import static com.android.server.biometrics.nano.BiometricServiceStateProto.STATE_AUTH_IDLE;
import static com.android.server.biometrics.nano.BiometricServiceStateProto.STATE_AUTH_PENDING_CONFIRM;
import static com.android.server.biometrics.nano.BiometricServiceStateProto.STATE_AUTH_STARTED_UI_SHOWING;
import static com.android.server.biometrics.nano.BiometricServiceStateProto.STATE_SHOWING_DEVICE_CREDENTIAL;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import static org.junit.Assume.assumeTrue;
import static org.mockito.Mockito.mock;

import android.app.Instrumentation;
import android.content.ComponentName;
import android.content.pm.PackageManager;
import android.hardware.biometrics.BiometricManager;
import android.hardware.biometrics.BiometricManager.Authenticators;
import android.hardware.biometrics.BiometricPrompt;
import android.hardware.biometrics.BiometricTestSession;
import android.hardware.biometrics.SensorProperties;
import android.os.Bundle;
import android.os.CancellationSignal;
import android.os.Handler;
import android.os.Looper;
import android.os.PowerManager;
import android.server.wm.ActivityManagerTestBase;
import android.server.wm.TestJournalProvider.TestJournal;
import android.server.wm.UiDeviceUtils;
import android.server.wm.WindowManagerState;
import android.support.test.uiautomator.By;
import android.support.test.uiautomator.UiDevice;
import android.support.test.uiautomator.UiObject2;
import android.util.Log;

import androidx.annotation.NonNull;
import androidx.annotation.Nullable;

import com.android.server.biometrics.nano.BiometricServiceStateProto;

import org.junit.After;
import org.junit.Before;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.Map;
import java.util.concurrent.Executor;

/**
 * Base class containing useful functionality. Actual tests should be done in subclasses.
 */
abstract class BiometricTestBase extends ActivityManagerTestBase {

    private static final String TAG = ""BiometricTestBase"";
    private static final String DUMPSYS_BIOMETRIC = Utils.DUMPSYS_BIOMETRIC;
    private static final String FLAG_CLEAR_SCHEDULER_LOG = "" --clear-scheduler-buffer"";

    // Negative-side (left) buttons
    protected static final String BUTTON_ID_NEGATIVE = ""button_negative"";
    protected static final String BUTTON_ID_USE_CREDENTIAL = ""button_use_credential"";

    // Positive-side (right) buttons
    protected static final String BUTTON_ID_CONFIRM = ""button_confirm"";
    protected static final String BUTTON_ID_TRY_AGAIN = ""button_try_again"";

    // Biometric text contents
    protected static final String TITLE_VIEW = ""title"";
    protected static final String SUBTITLE_VIEW = ""subtitle"";
    protected static final String DESCRIPTION_VIEW = ""description"";

    protected static final String VIEW_ID_PASSWORD_FIELD = ""lockPassword"";

    @NonNull protected Instrumentation mInstrumentation;
    @NonNull protected BiometricManager mBiometricManager;
    @NonNull protected List<SensorProperties> mSensorProperties;
    @Nullable private PowerManager.WakeLock mWakeLock;
    @NonNull protected UiDevice mDevice;
    protected boolean mHasStrongBox;

    /**
     * Expose this functionality to our package, since ActivityManagerTestBase's is `protected`.
     * @param componentName
     */
    void launchActivity(@NonNull ComponentName componentName) {
        super.launchActivity(componentName);
    }

    /** @see Utils#getBiometricServiceCurrentState() */
    @NonNull
    protected BiometricServiceState getCurrentState() throws Exception {
        return Utils.getBiometricServiceCurrentState();
    }

    @NonNull
    protected BiometricServiceState getCurrentStateAndClearSchedulerLog() throws Exception {
        final byte[] dump = Utils.executeShellCommand(DUMPSYS_BIOMETRIC
                + FLAG_CLEAR_SCHEDULER_LOG);
        final BiometricServiceStateProto proto = BiometricServiceStateProto.parseFrom(dump);
        return BiometricServiceState.parseFrom(proto);
    }

    @Nullable
    protected UiObject2 findView(String id) {
        Log.d(TAG, ""Finding view: "" + id);
        return mDevice.findObject(By.res(mBiometricManager.getUiPackage(), id));
    }

    protected void findAndPressButton(String id) {
        final UiObject2 button = findView(id);
        assertNotNull(button);
        Log.d(TAG, ""Clicking button: "" + id);
        button.click();
    }

    protected SensorStates getSensorStates() throws Exception {
        return getCurrentState().mSensorStates;
    }

    protected void waitForState(@BiometricServiceState.AuthSessionState int state)
            throws Exception {
        for (int i = 0; i < 20; i++) {
            final BiometricServiceState serviceState = getCurrentState();
            if (serviceState.mState != state) {
                Log.d(TAG, ""Not in state "" + state + "" yet, current: "" + serviceState.mState);
                Thread.sleep(300);
            } else {
                return;
            }
        }
        Log.d(TAG, ""Timed out waiting for state to become: "" + state);
    }

    private void waitForStateNotEqual(@BiometricServiceState.AuthSessionState int state)
            throws Exception {
        for (int i = 0; i < 20; i++) {
            final BiometricServiceState serviceState = getCurrentState();
            if (serviceState.mState == state) {
                Log.d(TAG, ""Not out of state yet, current: "" + serviceState.mState);
                Thread.sleep(300);
            } else {
                return;
            }
        }
        Log.d(TAG, ""Timed out waiting for state to not equal: "" + state);
    }

    private boolean anyEnrollmentsExist() throws Exception {
        final BiometricServiceState serviceState = getCurrentState();

        for (SensorState sensorState : serviceState.mSensorStates.sensorStates.values()) {
            for (UserState userState : sensorState.getUserStates().values()) {
                if (userState.numEnrolled != 0) {
                    Log.d(TAG, ""Enrollments still exist: "" + serviceState);
                    return true;
                }
            }
        }
        return false;
    }

    protected void successfullyAuthenticate(@NonNull BiometricTestSession session, int userId)
            throws Exception {
        session.acceptAuthentication(userId);
        mInstrumentation.waitForIdleSync();
        waitForStateNotEqual(STATE_AUTH_STARTED_UI_SHOWING);
        BiometricServiceState state = getCurrentState();
        Log.d(TAG, ""State after acceptAuthentication: "" + state);
        if (state.mState == STATE_AUTH_PENDING_CONFIRM) {
            findAndPressButton(BUTTON_ID_CONFIRM);
            mInstrumentation.waitForIdleSync();
            waitForState(STATE_AUTH_IDLE);
        } else {
            waitForState(STATE_AUTH_IDLE);
        }

        assertEquals(""Failed to become idle after authenticating"",
                STATE_AUTH_IDLE, getCurrentState().mState);
    }

    protected void successfullyEnterCredential() throws Exception {
        waitForState(STATE_SHOWING_DEVICE_CREDENTIAL);
        BiometricServiceState state = getCurrentState();
        assertTrue(state.toString(), state.mSensorStates.areAllSensorsIdle());
        assertEquals(state.toString(), STATE_SHOWING_DEVICE_CREDENTIAL, state.mState);

        // Wait for any animations to complete. Ideally, this should be reflected in
        // STATE_SHOWING_DEVICE_CREDENTIAL, but SysUI and BiometricService are different processes
        // so we'd need to add some additional plumbing. We can improve this in the future.
        // TODO(b/152240892)
        Thread.sleep(1000);

        // Enter credential. AuthSession done, authentication callback received
        final UiObject2 passwordField = findView(VIEW_ID_PASSWORD_FIELD);
        Log.d(TAG, ""Focusing, entering, submitting credential"");
        passwordField.click();
        passwordField.setText(LOCK_CREDENTIAL);
        mDevice.pressEnter();
        waitForState(STATE_AUTH_IDLE);

        state = getCurrentState();
        assertEquals(state.toString(), STATE_AUTH_IDLE, state.mState);
    }

    protected void cancelAuthentication(@NonNull CancellationSignal cancel) throws Exception {
        cancel.cancel();
        mInstrumentation.waitForIdleSync();
        waitForState(STATE_AUTH_IDLE);

        //TODO(b/152240892): Currently BiometricService does not get a signal from SystemUI
        //  when the dialog finishes animating away.
        Thread.sleep(1000);

        BiometricServiceState state = getCurrentState();
        assertEquals(""Not idle after requesting cancellation"", state.mState, STATE_AUTH_IDLE);
    }

    protected void waitForAllUnenrolled() throws Exception {
        for (int i = 0; i < 20; i++) {
            if (anyEnrollmentsExist()) {
                Log.d(TAG, ""Enrollments still exist.."");
                Thread.sleep(300);
            } else {
                return;
            }
        }
        fail(""Some sensors still have enrollments. State: "" + getCurrentState());
    }

    /**
     * Shows a BiometricPrompt that specifies {@link Authenticators#DEVICE_CREDENTIAL}.
     */
    protected void showCredentialOnlyBiometricPrompt(
            @NonNull BiometricPrompt.AuthenticationCallback callback,
            @NonNull CancellationSignal cancellationSignal,
            boolean shouldShow) throws Exception {
        showCredentialOnlyBiometricPromptWithContents(callback, cancellationSignal, shouldShow,
                ""Title"", ""Subtitle"", ""Description"");
    }

    /**
     * Shows a BiometricPrompt that specifies {@link Authenticators#DEVICE_CREDENTIAL}
     * and the specified contents.
     */
    protected void showCredentialOnlyBiometricPromptWithContents(
            @NonNull BiometricPrompt.AuthenticationCallback callback,
            @NonNull CancellationSignal cancellationSignal, boolean shouldShow,
            @NonNull String title, @NonNull String subtitle,
            @NonNull String description) throws Exception {
        final Handler handler = new Handler(Looper.getMainLooper());
        final Executor executor = handler::post;
        final BiometricPrompt prompt = new BiometricPrompt.Builder(mContext)
                .setTitle(title)
                .setSubtitle(subtitle)
                .setDescription(description)
                .setAllowedAuthenticators(Authenticators.DEVICE_CREDENTIAL)
                .setAllowBackgroundAuthentication(true)
                .build();

        prompt.authenticate(cancellationSignal, executor, callback);
        mInstrumentation.waitForIdleSync();

        // Wait for any animations to complete. Ideally, this should be reflected in
        // STATE_SHOWING_DEVICE_CREDENTIAL, but SysUI and BiometricService are different processes
        // so we'd need to add some additional plumbing. We can improve this in the future.
        // TODO(b/152240892)
        Thread.sleep(1000);

        if (shouldShow) {
            waitForState(STATE_SHOWING_DEVICE_CREDENTIAL);
            BiometricServiceState state = getCurrentState();
            assertEquals(state.toString(), STATE_SHOWING_DEVICE_CREDENTIAL, state.mState);
        } else {
            Utils.waitForIdleService(this::getSensorStates);
        }
    }

    /**
     * SHows a BiometricPrompt that sets
     * {@link BiometricPrompt.Builder#setDeviceCredentialAllowed(boolean)} to true.
     */
    protected void showDeviceCredentialAllowedBiometricPrompt(
            @NonNull BiometricPrompt.AuthenticationCallback callback,
            @NonNull CancellationSignal cancellationSignal,
            boolean shouldShow) throws Exception {
        final Handler handler = new Handler(Looper.getMainLooper());
        final Executor executor = handler::post;
        final BiometricPrompt prompt = new BiometricPrompt.Builder(mContext)
                .setTitle(""Title"")
                .setSubtitle(""Subtitle"")
                .setDescription(""Description"")
                .setDeviceCredentialAllowed(true)
                .setAllowBackgroundAuthentication(true)
                .build();

        prompt.authenticate(cancellationSignal, executor, callback);
        mInstrumentation.waitForIdleSync();

        // Wait for any animations to complete. Ideally, this should be reflected in
        // STATE_SHOWING_DEVICE_CREDENTIAL, but SysUI and BiometricService are different processes
        // so we'd need to add some additional plumbing. We can improve this in the future.
        // TODO(b/152240892)
        Thread.sleep(1000);

        if (shouldShow) {
            waitForState(STATE_SHOWING_DEVICE_CREDENTIAL);
            BiometricServiceState state = getCurrentState();
            assertEquals(state.toString(), STATE_SHOWING_DEVICE_CREDENTIAL, state.mState);
        } else {
            Utils.waitForIdleService(this::getSensorStates);
        }
    }

    protected void showDefaultBiometricPrompt(int sensorId, int userId,
            boolean requireConfirmation, @NonNull BiometricPrompt.AuthenticationCallback callback,
            @NonNull CancellationSignal cancellationSignal) throws Exception {
        final Handler handler = new Handler(Looper.getMainLooper());
        final Executor executor = handler::post;
        final BiometricPrompt prompt = new BiometricPrompt.Builder(mContext)
                .setTitle(""Title"")
                .setSubtitle(""Subtitle"")
                .setDescription(""Description"")
                .setConfirmationRequired(requireConfirmation)
                .setNegativeButton(""Negative Button"", executor, (dialog, which) -> {
                    Log.d(TAG, ""Negative button pressed"");
                })
                .setAllowBackgroundAuthentication(true)
                .setAllowedSensorIds(new ArrayList<>(Collections.singletonList(sensorId)))
                .build();
        prompt.authenticate(cancellationSignal, executor, callback);

        waitForState(STATE_AUTH_STARTED_UI_SHOWING);
    }

    /**
     * Shows the default BiometricPrompt (sensors meeting BIOMETRIC_WEAK) with a negative button,
     * but does not complete authentication. In other words, the dialog will stay on the screen.
     */
    protected void showDefaultBiometricPromptWithContents(int sensorId, int userId,
            boolean requireConfirmation, @NonNull BiometricPrompt.AuthenticationCallback callback,
            @NonNull String title, @NonNull String subtitle, @NonNull String description,
            @NonNull String negativeButtonText) throws Exception {
        final Handler handler = new Handler(Looper.getMainLooper());
        final Executor executor = handler::post;
        final BiometricPrompt prompt = new BiometricPrompt.Builder(mContext)
                .setTitle(title)
                .setSubtitle(subtitle)
                .setDescription(description)
                .setConfirmationRequired(requireConfirmation)
                .setNegativeButton(negativeButtonText, executor, (dialog, which) -> {
                    Log.d(TAG, ""Negative button pressed"");
                })
                .setAllowBackgroundAuthentication(true)
                .setAllowedSensorIds(new ArrayList<>(Collections.singletonList(sensorId)))
                .build();
        prompt.authenticate(new CancellationSignal(), executor,
                new BiometricPrompt.AuthenticationCallback() {
                    @Override
                    public void onAuthenticationError(int errorCode, CharSequence errString) {
                        Log.d(TAG, ""onAuthenticationError: "" + errorCode);
                    }

                    @Override
                    public void onAuthenticationSucceeded(
                            BiometricPrompt.AuthenticationResult result) {
                        Log.d(TAG, ""onAuthenticationSucceeded"");
                    }
                });

        waitForState(STATE_AUTH_STARTED_UI_SHOWING);
    }

    /**
     * Shows the default BiometricPrompt (sensors meeting BIOMETRIC_WEAK) with a negative button,
     * and fakes successful authentication via TestApis.
     */
    protected void showDefaultBiometricPromptAndAuth(@NonNull BiometricTestSession session,
            int sensorId, int userId) throws Exception {
        BiometricPrompt.AuthenticationCallback callback = mock(
                BiometricPrompt.AuthenticationCallback.class);
        showDefaultBiometricPromptWithContents(sensorId, userId, false /* requireConfirmation */,
                callback, ""Title"", ""Subtitle"", ""Description"", ""Negative Button"");
        successfullyAuthenticate(session, userId);
    }

    protected void showBiometricPromptWithAuthenticators(int authenticators) {
        final Handler handler = new Handler(Looper.getMainLooper());
        final Executor executor = handler::post;
        final BiometricPrompt prompt = new BiometricPrompt.Builder(mContext)
                .setTitle(""Title"")
                .setSubtitle(""Subtitle"")
                .setDescription(""Description"")
                .setNegativeButton(""Negative Button"", executor, (dialog, which) -> {
                    Log.d(TAG, ""Negative button pressed"");
                })
                .setAllowBackgroundAuthentication(true)
                .setAllowedAuthenticators(authenticators)
                .build();
        prompt.authenticate(new CancellationSignal(), executor,
                new BiometricPrompt.AuthenticationCallback() {
                    @Override
                    public void onAuthenticationError(int errorCode, CharSequence errString) {
                        Log.d(TAG, ""onAuthenticationError: "" + errorCode);
                    }

                    @Override
                    public void onAuthenticationSucceeded(
                            BiometricPrompt.AuthenticationResult result) {
                        Log.d(TAG, ""onAuthenticationSucceeded"");
                    }
                });
    }

    protected void launchActivityAndWaitForResumed(@NonNull ActivitySession activitySession) {
        activitySession.start();
        mWmState.waitForActivityState(activitySession.getComponentName(),
                WindowManagerState.STATE_RESUMED);
        mInstrumentation.waitForIdleSync();
    }

    protected void closeActivity(@NonNull ActivitySession activitySession) throws Exception {
        activitySession.close();
        mInstrumentation.waitForIdleSync();
    }

    protected int getCurrentStrength(int sensorId) throws Exception {
        final BiometricServiceState serviceState = getCurrentState();
        return serviceState.mSensorStates.sensorStates.get(sensorId).getCurrentStrength();
    }

    protected List<Integer> getSensorsOfTargetStrength(int targetStrength) {
        final List<Integer> sensors = new ArrayList<>();
        for (SensorProperties prop : mSensorProperties) {
            if (prop.getSensorStrength() == targetStrength) {
                sensors.add(prop.getSensorId());
            }
        }
        Log.d(TAG, ""getSensorsOfTargetStrength: num of target sensors="" + sensors.size());
        return sensors;
    }

    @NonNull
    protected static BiometricCallbackHelper.State getCallbackState(@NonNull TestJournal journal) {
        Utils.waitFor(""Waiting for authentication callback"",
                () -> journal.extras.containsKey(BiometricCallbackHelper.KEY),
                (lastResult) -> fail(""authentication callback never received - died waiting""));

        final Bundle bundle = journal.extras.getBundle(BiometricCallbackHelper.KEY);
        final BiometricCallbackHelper.State state =
                BiometricCallbackHelper.State.fromBundle(bundle);

        // Clear the extras since we want to wait for the journal to sync any new info the next
        // time it's read
        journal.extras.clear();

        return state;
    }

    @Before
    public void setUp() throws Exception {
        mInstrumentation = getInstrumentation();
        mBiometricManager = mInstrumentation.getContext().getSystemService(BiometricManager.class);

        mInstrumentation.getUiAutomation().adoptShellPermissionIdentity();
        mDevice = UiDevice.getInstance(mInstrumentation);
        mSensorProperties = mBiometricManager.getSensorProperties();

        assumeTrue(mInstrumentation.getContext().getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_SECURE_LOCK_SCREEN));

        mHasStrongBox = mContext.getPackageManager().hasSystemFeature(
                PackageManager.FEATURE_STRONGBOX_KEYSTORE);

        // Keep the screen on for the duration of each test, since BiometricPrompt goes away
        // when screen turns off.
        final PowerManager pm = mInstrumentation.getContext().getSystemService(PowerManager.class);
        mWakeLock = pm.newWakeLock(FULL_WAKE_LOCK, TAG);
        mWakeLock.acquire();

        // Turn screen on and dismiss keyguard
        UiDeviceUtils.pressWakeupButton();
        UiDeviceUtils.pressUnlockButton();
    }

    @After
    public void cleanup() {
        mInstrumentation.waitForIdleSync();

        try {
            Utils.waitForIdleService(this::getSensorStates);
        } catch (Exception e) {
            Log.e(TAG, ""Exception when waiting for idle"", e);
        }

        try {
            final BiometricServiceState state = getCurrentState();

            for (Map.Entry<Integer, SensorState> sensorEntry
                    : state.mSensorStates.sensorStates.entrySet()) {
                for (Map.Entry<Integer, UserState> userEntry
                        : sensorEntry.getValue().getUserStates().entrySet()) {
                    if (userEntry.getValue().numEnrolled != 0) {
                        Log.w(TAG, ""Cleaning up for sensor: "" + sensorEntry.getKey()
                                + "", user: "" + userEntry.getKey());
                        BiometricTestSession session = mBiometricManager.createTestSession(
                                sensorEntry.getKey());
                        session.cleanupInternalState(userEntry.getKey());
                        session.close();
                    }
                }
            }
        } catch (Exception e) {
            Log.e(TAG, ""Unable to get current state in cleanup()"");
        }

        // Authentication lifecycle is done
        try {
            Utils.waitForIdleService(this::getSensorStates);
        } catch (Exception e) {
            Log.e(TAG, ""Exception when waiting for idle"", e);
        }

        if (mWakeLock != null) {
            mWakeLock.release();
        }
        mInstrumentation.getUiAutomation().dropShellPermissionIdentity();
    }

    protected void enrollForSensor(@NonNull BiometricTestSession session, int sensorId)
            throws Exception {
        Log.d(TAG, ""Enrolling for sensor: "" + sensorId);
        final int userId = 0;

        session.startEnroll(userId);
        mInstrumentation.waitForIdleSync();
        Utils.waitForBusySensor(sensorId, this::getSensorStates);

        session.finishEnroll(userId);
        mInstrumentation.waitForIdleSync();
        Utils.waitForIdleService(this::getSensorStates);

        final BiometricServiceState state = getCurrentState();
        assertEquals(""Sensor: "" + sensorId + "" should have exactly one enrollment"",
                1, state.mSensorStates.sensorStates
                .get(sensorId).getUserStates().get(userId).numEnrolled);
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.deviceandprofileowner.SensorPermissionGrantTest"	"testAdminCanGrantSensorsPermissions"	""	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/app/DeviceAndProfileOwner/src/com/android/cts/deviceandprofileowner/SensorPermissionGrantTest.java"	""	"public void testAdminCanGrantSensorsPermissions() {
        assertThat(mDevicePolicyManager.canAdminGrantSensorsPermissions()).isTrue();
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.deviceandprofileowner.SensorPermissionGrantTest"	"testAdminCannotGrantSensorsPermission"	""	"/home/gpoor/cts-12-source/cts/hostsidetests/devicepolicy/app/DeviceAndProfileOwner/src/com/android/cts/deviceandprofileowner/SensorPermissionGrantTest.java"	""	"public void testAdminCannotGrantSensorsPermission() {
        assertThat(mDevicePolicyManager.canAdminGrantSensorsPermissions()).isFalse();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.HeifWriterTest"	"testHeif"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/HeifWriterTest.java"	""	"public void testHeif() throws Exception {
        final int NUM_SINGLE_CAPTURE_TESTED = 3;
        final int NUM_HEIC_CAPTURE_TESTED = 2;
        final int SESSION_WARMUP_MS = 1000;
        final int HEIF_STOP_TIMEOUT = 3000 * NUM_SINGLE_CAPTURE_TESTED;

        if (!canEncodeHeic()) {
            MediaUtils.skipTest(""heic encoding is not supported on this device"");
            return;
        }

        boolean sessionFailure = false;
        Integer[] sessionStates = {BlockingSessionCallback.SESSION_READY,
                BlockingSessionCallback.SESSION_CONFIGURE_FAILED};
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.v(TAG, ""Testing HEIF capture for Camera "" + id);
                openDevice(id);

                Size[] availableSizes = mStaticInfo.getAvailableSizesForFormatChecked(
                        ImageFormat.PRIVATE,
                        StaticMetadata.StreamDirection.Output);

                // for each resolution, test imageReader:
                for (Size sz : availableSizes) {
                    HeifWriter heifWriter = null;
                    OutputConfiguration outConfig = null;
                    Surface latestSurface = null;
                    CaptureRequest.Builder reqStill = null;
                    int width = sz.getWidth();
                    int height = sz.getHeight();
                    for (int cap = 0; cap < NUM_HEIC_CAPTURE_TESTED; cap++) {
                        if (VERBOSE) {
                            Log.v(TAG, ""Testing size "" + sz.toString() + "" format PRIVATE""
                                    + "" for camera "" + mCamera.getId() + "". Iteration:"" + cap);
                        }

                        try {
                            TestConfig.Builder builder = new TestConfig.Builder(/*useGrid*/false);
                            builder.setNumImages(NUM_SINGLE_CAPTURE_TESTED);
                            builder.setSize(sz);
                            String filename = ""Cam"" + id + ""_"" + width + ""x"" + height +
                                    ""_"" + cap + "".heic"";
                            builder.setOutputPath(
                                    new File(mFilePath, filename).getAbsolutePath());
                            TestConfig config = builder.build();

                            try {
                                heifWriter = new HeifWriter.Builder(
                                        config.mOutputPath,
                                        width, height, INPUT_MODE_SURFACE)
                                    .setGridEnabled(config.mUseGrid)
                                    .setMaxImages(config.mMaxNumImages)
                                    .setQuality(config.mQuality)
                                    .setPrimaryIndex(config.mNumImages - 1)
                                    .setHandler(mHandler)
                                    .build();
                            } catch (IOException e) {
                                // Continue in case the size is not supported
                                sessionFailure = true;
                                Log.i(TAG, ""Skip due to heifWriter creation failure: ""
                                        + e.getMessage());
                                continue;
                            }

                            // First capture. Start capture session
                            latestSurface = heifWriter.getInputSurface();
                            outConfig = new OutputConfiguration(latestSurface);
                            List<OutputConfiguration> configs =
                                new ArrayList<OutputConfiguration>();
                            configs.add(outConfig);

                            SurfaceTexture preview = new SurfaceTexture(/*random int*/ 1);
                            Surface previewSurface = new Surface(preview);
                            preview.setDefaultBufferSize(640, 480);
                            configs.add(new OutputConfiguration(previewSurface));

                            CaptureRequest.Builder reqPreview = mCamera.createCaptureRequest(
                                    CameraDevice.TEMPLATE_PREVIEW);
                            reqPreview.addTarget(previewSurface);

                            reqStill = mCamera.createCaptureRequest(
                                    CameraDevice.TEMPLATE_STILL_CAPTURE);
                            reqStill.addTarget(previewSurface);
                            reqStill.addTarget(latestSurface);

                            // Start capture session and preview
                            createSessionByConfigs(configs);
                            int state = mCameraSessionListener.getStateWaiter().waitForAnyOfStates(
                                    Arrays.asList(sessionStates), SESSION_CONFIGURE_TIMEOUT_MS);
                            if (state == BlockingSessionCallback.SESSION_CONFIGURE_FAILED) {
                                // session configuration failure. Bail out due to known issue of
                                // HeifWriter INPUT_SURFACE mode support for camera. b/79699819
                                sessionFailure = true;
                                break;
                            }
                            startCapture(reqPreview.build(), /*repeating*/true, null, null);

                            SystemClock.sleep(SESSION_WARMUP_MS);

                            heifWriter.start();

                            // Start capture.
                            CaptureRequest request = reqStill.build();
                            SimpleCaptureCallback listener = new SimpleCaptureCallback();

                            int numImages = config.mNumImages;

                            for (int i = 0; i < numImages; i++) {
                                startCapture(request, /*repeating*/false, listener, mHandler);
                            }

                            // Validate capture result.
                            CaptureResult result = validateCaptureResult(
                                    ImageFormat.PRIVATE, sz, listener, numImages);

                            // TODO: convert capture results into EXIF and send to heifwriter

                            heifWriter.stop(HEIF_STOP_TIMEOUT);

                            verifyResult(config.mOutputPath, width, height,
                                    config.mRotation, config.mUseGrid,
                                    Math.min(numImages, config.mMaxNumImages));
                        } finally {
                            if (heifWriter != null) {
                                heifWriter.close();
                                heifWriter = null;
                            }
                            if (!sessionFailure) {
                                stopCapture(/*fast*/false);
                            }
                        }
                    }

                    if (sessionFailure) {
                        break;
                    }
                }
            } finally {
                closeDevice(id);
            }
        }
    }

    private static boolean canEncodeHeic() {
        return MediaUtils.hasEncoder(MediaFormat.MIMETYPE_VIDEO_HEVC)
            || MediaUtils.hasEncoder(MediaFormat.MIMETYPE_IMAGE_ANDROID_HEIC);
    }

    private static class TestConfig {
        final boolean mUseGrid;
        final int mMaxNumImages;
        final int mNumImages;
        final int mWidth;
        final int mHeight;
        final int mRotation;
        final int mQuality;
        final String mOutputPath;

        TestConfig(boolean useGrid, int maxNumImages, int numImages,
                   int width, int height, int rotation, int quality,
                   String outputPath) {
            mUseGrid = useGrid;
            mMaxNumImages = maxNumImages;
            mNumImages = numImages;
            mWidth = width;
            mHeight = height;
            mRotation = rotation;
            mQuality = quality;
            mOutputPath = outputPath;
        }

        static class Builder {
            final boolean mUseGrid;
            int mMaxNumImages;
            int mNumImages;
            int mWidth;
            int mHeight;
            int mRotation;
            final int mQuality;
            String mOutputPath;

            Builder(boolean useGrids) {
                mUseGrid = useGrids;
                mMaxNumImages = mNumImages = 4;
                mWidth = 1920;
                mHeight = 1080;
                mRotation = 0;
                mQuality = 100;
                mOutputPath = new File(Environment.getExternalStorageDirectory(),
                        OUTPUT_FILENAME).getAbsolutePath();
            }

            Builder setNumImages(int numImages) {
                mMaxNumImages = mNumImages = numImages;
                return this;
            }

            Builder setRotation(int rotation) {
                mRotation = rotation;
                return this;
            }

            Builder setSize(Size sz) {
                mWidth = sz.getWidth();
                mHeight = sz.getHeight();
                return this;
            }

            Builder setOutputPath(String path) {
                mOutputPath = path;
                return this;
            }

            private void cleanupStaleOutputs() {
                File outputFile = new File(mOutputPath);
                if (outputFile.exists()) {
                    outputFile.delete();
                }
            }

            TestConfig build() {
                cleanupStaleOutputs();
                return new TestConfig(mUseGrid, mMaxNumImages, mNumImages,
                        mWidth, mHeight, mRotation, mQuality, mOutputPath);
            }
        }

        @Override
        public String toString() {
            return ""TestConfig""
                    + "": mUseGrid "" + mUseGrid
                    + "", mMaxNumImages "" + mMaxNumImages
                    + "", mNumImages "" + mNumImages
                    + "", mWidth "" + mWidth
                    + "", mHeight "" + mHeight
                    + "", mRotation "" + mRotation
                    + "", mQuality "" + mQuality
                    + "", mOutputPath "" + mOutputPath;
        }
    }

    private void verifyResult(
            String filename, int width, int height, int rotation, boolean useGrid, int numImages)
            throws Exception {
        MediaMetadataRetriever retriever = new MediaMetadataRetriever();
        retriever.setDataSource(filename);
        String hasImage = retriever.extractMetadata(MediaMetadataRetriever.METADATA_KEY_HAS_IMAGE);
        if (!""yes"".equals(hasImage)) {
            throw new Exception(""No images found in file "" + filename);
        }
        assertEquals(""Wrong image count"", numImages,
                Integer.parseInt(retriever.extractMetadata(
                    MediaMetadataRetriever.METADATA_KEY_IMAGE_COUNT)));
        assertEquals(""Wrong width"", width,
                Integer.parseInt(retriever.extractMetadata(
                    MediaMetadataRetriever.METADATA_KEY_IMAGE_WIDTH)));
        assertEquals(""Wrong height"", height,
                Integer.parseInt(retriever.extractMetadata(
                    MediaMetadataRetriever.METADATA_KEY_IMAGE_HEIGHT)));
        assertEquals(""Wrong rotation"", rotation,
                Integer.parseInt(retriever.extractMetadata(
                    MediaMetadataRetriever.METADATA_KEY_IMAGE_ROTATION)));
        retriever.release();

        if (useGrid) {
            MediaExtractor extractor = new MediaExtractor();
            extractor.setDataSource(filename);
            MediaFormat format = extractor.getTrackFormat(0);
            int tileWidth = format.getInteger(MediaFormat.KEY_TILE_WIDTH);
            int tileHeight = format.getInteger(MediaFormat.KEY_TILE_HEIGHT);
            int gridRows = format.getInteger(MediaFormat.KEY_GRID_ROWS);
            int gridCols = format.getInteger(MediaFormat.KEY_GRID_COLUMNS);
            assertTrue(""Wrong tile width or grid cols"",
                    ((width + tileWidth - 1) / tileWidth) == gridCols);
            assertTrue(""Wrong tile height or grid rows"",
                    ((height + tileHeight - 1) / tileHeight) == gridRows);
            extractor.release();
        }
    }

    /**
     * Validate capture results.
     *
     * @param format The format of this capture.
     * @param size The capture size.
     * @param listener The capture listener to get capture result callbacks.
     * @return the last verified CaptureResult
     */
    private CaptureResult validateCaptureResult(
            int format, Size size, SimpleCaptureCallback listener, int numFrameVerified) {
        CaptureResult result = null;
        for (int i = 0; i < numFrameVerified; i++) {
            result = listener.getCaptureResult(CAPTURE_RESULT_TIMEOUT_MS);
            if (mStaticInfo.isCapabilitySupported(
                    CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_READ_SENSOR_SETTINGS)) {
                Long exposureTime = getValueNotNull(result, CaptureResult.SENSOR_EXPOSURE_TIME);
                Integer sensitivity = getValueNotNull(result, CaptureResult.SENSOR_SENSITIVITY);
                mCollector.expectInRange(
                        String.format(
                                ""Capture for format %d, size %s exposure time is invalid."",
                                format, size.toString()),
                        exposureTime,
                        mStaticInfo.getExposureMinimumOrDefault(),
                        mStaticInfo.getExposureMaximumOrDefault()
                );
                mCollector.expectInRange(
                        String.format(""Capture for format %d, size %s sensitivity is invalid."",
                                format, size.toString()),
                        sensitivity,
                        mStaticInfo.getSensitivityMinimumOrDefault(),
                        mStaticInfo.getSensitivityMaximumOrDefault()
                );
            }
            // TODO: add more key validations.
        }
        return result;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.SensorCtsHelper"	"getSensorTestDataDirectory"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/SensorCtsHelper.java"	""	"public void test/*
 *.
 */
package android.hardware.cts.helpers;

import android.hardware.Sensor;
import android.os.Environment;
import android.os.Process;
import android.util.Log;

import androidx.test.InstrumentationRegistry;

import com.android.compatibility.common.util.SystemUtil;

import java.io.File;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.TimeUnit;

/**
 * Set of static helper methods for CTS tests.
 */
//TODO: Refactor this class into several more well defined helper classes, look at StatisticsUtils
public class SensorCtsHelper {

    private static final long NANOS_PER_MILLI = 1000000;

    /**
     * Private constructor for static class.
     */
    private SensorCtsHelper() {}

    /**
     * Get low and high percentiles values of an array
     *
     * @param lowPercentile Lower boundary percentile, range [0, 1]
     * @param highPercentile Higher boundary percentile, range [0, 1]
     *
     * @throws IllegalArgumentException if the collection or percentiles is null or empty.
     */
    public static <TValue extends Comparable<? super TValue>> List<TValue> getPercentileValue(
            Collection<TValue> collection, float lowPecentile, float highPercentile) {
        validateCollection(collection);
        if (lowPecentile > highPercentile || lowPecentile < 0 || highPercentile > 1) {
            throw new IllegalStateException(""percentile has to be in range [0, 1], and "" +
                    ""lowPecentile has to be less than or equal to highPercentile"");
        }

        List<TValue> arrayCopy = new ArrayList<TValue>(collection);
        Collections.sort(arrayCopy);

        List<TValue> percentileValues = new ArrayList<TValue>();
        // lower percentile: rounding upwards, index range 1 .. size - 1 for percentile > 0
        // for percentile == 0, index will be 0.
        int lowArrayIndex = Math.min(arrayCopy.size() - 1,
                arrayCopy.size() - (int)(arrayCopy.size() * (1 - lowPecentile)));
        percentileValues.add(arrayCopy.get(lowArrayIndex));

        // upper percentile: rounding downwards, index range 0 .. size - 2 for percentile < 1
        // for percentile == 1, index will be size - 1.
        // Also, lower bound by lowerArrayIndex to avoid low percentile value being higher than
        // high percentile value.
        int highArrayIndex = Math.max(lowArrayIndex, (int)(arrayCopy.size() * highPercentile - 1));
        percentileValues.add(arrayCopy.get(highArrayIndex));
        return percentileValues;
    }

    /**
     * Calculate the mean of a collection.
     *
     * @throws IllegalArgumentException if the collection is null or empty
     */
    public static <TValue extends Number> double getMean(Collection<TValue> collection) {
        validateCollection(collection);

        double sum = 0.0;
        for(TValue value : collection) {
            sum += value.doubleValue();
        }
        return sum / collection.size();
    }

    /**
     * Calculate the bias-corrected sample variance of a collection.
     *
     * @throws IllegalArgumentException if the collection is null or empty
     */
    public static <TValue extends Number> double getVariance(Collection<TValue> collection) {
        validateCollection(collection);

        double mean = getMean(collection);
        ArrayList<Double> squaredDiffs = new ArrayList<Double>();
        for(TValue value : collection) {
            double difference = mean - value.doubleValue();
            squaredDiffs.add(Math.pow(difference, 2));
        }

        double sum = 0.0;
        for (Double value : squaredDiffs) {
            sum += value;
        }
        return sum / (squaredDiffs.size() - 1);
    }

    /**
     * @return The (measured) sampling rate of a collection of {@link TestSensorEvent}.
     */
    public static long getSamplingPeriodNs(List<TestSensorEvent> collection) {
        int collectionSize = collection.size();
        if (collectionSize < 2) {
            return 0;
        }
        TestSensorEvent firstEvent = collection.get(0);
        TestSensorEvent lastEvent = collection.get(collectionSize - 1);
        return (lastEvent.timestamp - firstEvent.timestamp) / (collectionSize - 1);
    }

    /**
     * Calculate the bias-corrected standard deviation of a collection.
     *
     * @throws IllegalArgumentException if the collection is null or empty
     */
    public static <TValue extends Number> double getStandardDeviation(
            Collection<TValue> collection) {
        return Math.sqrt(getVariance(collection));
    }

    /**
     * Convert a period to frequency in Hz.
     */
    public static <TValue extends Number> double getFrequency(TValue period, TimeUnit unit) {
        return 1000000000 / (TimeUnit.NANOSECONDS.convert(1, unit) * period.doubleValue());
    }

    /**
     * Convert a frequency in Hz into a period.
     */
    public static <TValue extends Number> double getPeriod(TValue frequency, TimeUnit unit) {
        return 1000000000 / (TimeUnit.NANOSECONDS.convert(1, unit) * frequency.doubleValue());
    }

    /**
     * If value lies outside the boundary limit, then return the nearer bound value.
     * Otherwise, return the value unchanged.
     */
    public static <TValue extends Number> double clamp(TValue val, TValue min, TValue max) {
        return Math.min(max.doubleValue(), Math.max(min.doubleValue(), val.doubleValue()));
    }

    /**
     * @return The magnitude (norm) represented by the given array of values.
     */
    public static double getMagnitude(float[] values) {
        float sumOfSquares = 0.0f;
        for (float value : values) {
            sumOfSquares += value * value;
        }
        double magnitude = Math.sqrt(sumOfSquares);
        return magnitude;
    }

    /**
     * Helper method to sleep for a given duration.
     */
    public static void sleep(long duration, TimeUnit timeUnit) throws InterruptedException {
        long durationNs = TimeUnit.NANOSECONDS.convert(duration, timeUnit);
        Thread.sleep(durationNs / NANOS_PER_MILLI, (int) (durationNs % NANOS_PER_MILLI));
    }

    /**
     * Format an assertion message.
     *
     * @param label the verification name
     * @param environment the environment of the test
     *
     * @return The formatted string
     */
    public static String formatAssertionMessage(String label, TestSensorEnvironment environment) {
        return formatAssertionMessage(label, environment, ""Failed"");
    }

    /**
     * Format an assertion message with a custom message.
     *
     * @param label the verification name
     * @param environment the environment of the test
     * @param format the additional format string
     * @param params the additional format params
     *
     * @return The formatted string
     */
    public static String formatAssertionMessage(
            String label,
            TestSensorEnvironment environment,
            String format,
            Object ... params) {
        return formatAssertionMessage(label, environment, String.format(format, params));
    }

    /**
     * Format an assertion message.
     *
     * @param label the verification name
     * @param environment the environment of the test
     * @param extras the additional information for the assertion
     *
     * @return The formatted string
     */
    public static String formatAssertionMessage(
            String label,
            TestSensorEnvironment environment,
            String extras) {
        return String.format(
                ""%s | sensor='%s', samplingPeriod=%dus, maxReportLatency=%dus | %s"",
                label,
                environment.getSensor().getName(),
                environment.getRequestedSamplingPeriodUs(),
                environment.getMaxReportLatencyUs(),
                extras);
    }

    /**
     * Format an array of floats.
     *
     * @param array the array of floats
     *
     * @return The formatted string
     */
    public static String formatFloatArray(float[] array) {
        StringBuilder sb = new StringBuilder();
        if (array.length > 1) {
            sb.append(""("");
        }
        for (int i = 0; i < array.length; i++) {
            sb.append(String.format(""%.2f"", array[i]));
            if (i != array.length - 1) {
                sb.append("", "");
            }
        }
        if (array.length > 1) {
            sb.append("")"");
        }
        return sb.toString();
    }

    /**
     * @return A {@link File} representing a root directory to store sensor tests data.
     */
    public static File getSensorTestDataDirectory() throws IOException {
        File dataDirectory = new File(Environment.getExternalStorageDirectory(), ""sensorTests/"");
        return createDirectoryStructure(dataDirectory);
    }

    /**
     * Creates the directory structure for the given sensor test data sub-directory.
     *
     * @param subdirectory The sub-directory's name.
     */
    public static File getSensorTestDataDirectory(String subdirectory) throws IOException {
        File subdirectoryFile = new File(getSensorTestDataDirectory(), subdirectory);
        return createDirectoryStructure(subdirectoryFile);
    }

    /**
     * Sanitizes a string so it can be used in file names.
     *
     * @param value The string to sanitize.
     * @return The sanitized string.
     *
     * @throws SensorTestPlatformException If the string cannot be sanitized.
     */
    public static String sanitizeStringForFileName(String value)
            throws SensorTestPlatformException {
        String sanitizedValue = value.replaceAll(""[^a-zA-Z0-9_\\-]"", ""_"");
        if (sanitizedValue.matches(""_*"")) {
            throw new SensorTestPlatformException(
                    ""Unable to sanitize string '%s' for file name."",
                    value);
        }
        return sanitizedValue;
    }

    /**
     * Ensures that the directory structure represented by the given {@link File} is created.
     */
    private static File createDirectoryStructure(File directoryStructure) throws IOException {
        directoryStructure.mkdirs();
        if (!directoryStructure.isDirectory()) {
            throw new IOException(""Unable to create directory structure for ""
                    + directoryStructure.getAbsolutePath());
        }
        return directoryStructure;
    }

    /**
     * Validate that a collection is not null or empty.
     *
     * @throws IllegalStateException if collection is null or empty.
     */
    private static <T> void validateCollection(Collection<T> collection) {
        if(collection == null || collection.size() == 0) {
            throw new IllegalStateException(""Collection cannot be null or empty"");
        }
    }

    public static String getUnitsForSensor(Sensor sensor) {
        switch(sensor.getType()) {
            case Sensor.TYPE_ACCELEROMETER:
                return ""m/s^2"";
            case Sensor.TYPE_MAGNETIC_FIELD:
            case Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED:
                return ""uT"";
            case Sensor.TYPE_GYROSCOPE:
            case Sensor.TYPE_GYROSCOPE_UNCALIBRATED:
                return ""radians/sec"";
            case Sensor.TYPE_PRESSURE:
                return ""hPa"";
        };
        return """";
    }

    public static boolean hasMaxResolutionRequirement(Sensor sensor, boolean hasHifiSensors) {
        switch (sensor.getType()) {
            case Sensor.TYPE_ACCELEROMETER:
            case Sensor.TYPE_ACCELEROMETER_UNCALIBRATED:
            case Sensor.TYPE_GYROSCOPE:
            case Sensor.TYPE_GYROSCOPE_UNCALIBRATED:
            case Sensor.TYPE_MAGNETIC_FIELD:
            case Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED:
            case Sensor.TYPE_HINGE_ANGLE:
            case Sensor.TYPE_PROXIMITY:
            case Sensor.TYPE_SIGNIFICANT_MOTION:
            case Sensor.TYPE_STEP_DETECTOR:
            case Sensor.TYPE_STEP_COUNTER:
            case Sensor.TYPE_HEART_RATE:
            case Sensor.TYPE_STATIONARY_DETECT:
            case Sensor.TYPE_MOTION_DETECT:
            case Sensor.TYPE_LOW_LATENCY_OFFBODY_DETECT:
                return true;

            case Sensor.TYPE_PRESSURE:
                // Pressure sensor only has a resolution requirement when there are HiFi sensors
                return hasHifiSensors;
        }
        return false;
    }

    public static float getRequiredMaxResolutionForSensor(Sensor sensor) {
        switch (sensor.getType()) {
            case Sensor.TYPE_ACCELEROMETER:
            case Sensor.TYPE_ACCELEROMETER_UNCALIBRATED:
            case Sensor.TYPE_GYROSCOPE:
            case Sensor.TYPE_GYROSCOPE_UNCALIBRATED:
                // Accelerometer and gyroscope must have at least 12 bits
                // of resolution. The maximum resolution calculation uses
                // slightly more than twice the maximum range because
                //   1) the sensor must be able to report values from
                //      [-maxRange, maxRange] without saturating
                //   2) to allow for slight rounding errors
                return (float)(2.001f * sensor.getMaximumRange() / Math.pow(2, 12));
            case Sensor.TYPE_MAGNETIC_FIELD:
            case Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED:
                // Magnetometer must have a resolution equal to or denser
                // than 0.6 uT
                return 0.6f;
            case Sensor.TYPE_PRESSURE:
                // Pressure sensor must have at least 80 LSB / hPa which is
                // equivalent to 0.0125 hPa / LSB. Allow for a small margin of
                // error due to rounding errors.
                return 1.01f * (1.0f / 80.0f);
            case Sensor.TYPE_HINGE_ANGLE:
                // Hinge angle sensor must have a resolution the same or smaller
                // than 360 degrees.
                return 360f;
            case Sensor.TYPE_PROXIMITY:
                // Binary prox sensors must have a resolution of 5, but it's not
                // expected / recommended that prox sensors use higher than
                // this.
                return 5f;
        }

        // Any sensor not specified above must use a resolution of 1.
        return 1.0f;
    }

    public static boolean hasMinResolutionRequirement(Sensor sensor) {
        switch (sensor.getType()) {
            case Sensor.TYPE_ACCELEROMETER:
            case Sensor.TYPE_ACCELEROMETER_UNCALIBRATED:
            case Sensor.TYPE_GYROSCOPE:
            case Sensor.TYPE_GYROSCOPE_UNCALIBRATED:
            case Sensor.TYPE_MAGNETIC_FIELD:
            case Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED:
            case Sensor.TYPE_SIGNIFICANT_MOTION:
            case Sensor.TYPE_STEP_DETECTOR:
            case Sensor.TYPE_STEP_COUNTER:
            case Sensor.TYPE_HEART_RATE:
            case Sensor.TYPE_STATIONARY_DETECT:
            case Sensor.TYPE_MOTION_DETECT:
            case Sensor.TYPE_LOW_LATENCY_OFFBODY_DETECT:
                return true;
        }
        return false;
    }

    public static float getRequiredMinResolutionForSensor(Sensor sensor) {
        switch (sensor.getType()) {
            case Sensor.TYPE_ACCELEROMETER:
            case Sensor.TYPE_ACCELEROMETER_UNCALIBRATED:
            case Sensor.TYPE_GYROSCOPE:
            case Sensor.TYPE_GYROSCOPE_UNCALIBRATED:
            case Sensor.TYPE_MAGNETIC_FIELD:
            case Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED:
                // Accelerometer, gyroscope, and mag are expected to have at most 24 bits of
                // resolution. The minimum resolution calculation uses slightly more than twice
                // the maximum range because:
                //   1) the sensor must be able to report values from [-maxRange, maxRange] without
                //      saturating
                //   2) to allow for slight rounding errors
                return (float)(2.001f * sensor.getMaximumRange() / Math.pow(2, 24));
        }

        // Any sensor not specified above must use a resolution of 1.
        return 1.0f;
    }

    public static String sensorTypeShortString(int type) {
        switch (type) {
            case Sensor.TYPE_ACCELEROMETER:
                return ""Accel"";
            case Sensor.TYPE_GYROSCOPE:
                return ""Gyro"";
            case Sensor.TYPE_MAGNETIC_FIELD:
                return ""Mag"";
            case Sensor.TYPE_ACCELEROMETER_UNCALIBRATED:
                return ""UncalAccel"";
            case Sensor.TYPE_GYROSCOPE_UNCALIBRATED:
                return ""UncalGyro"";
            case Sensor.TYPE_MAGNETIC_FIELD_UNCALIBRATED:
                return ""UncalMag"";
            default:
                return ""Type_"" + type;
        }
    }

    public static class TestResultCollector {
        private List<AssertionError> mErrorList = new ArrayList<>();
        private List<String> mErrorStringList = new ArrayList<>();
        private String mTestName;
        private String mTag;

        public TestResultCollector() {
            this(""Test"");
        }

        public TestResultCollector(String test) {
            this(test, ""SensorCtsTest"");
        }

        public TestResultCollector(String test, String tag) {
            mTestName = test;
            mTag = tag;
        }

        public void perform(Runnable r) {
            perform(r, """");
        }

        public void perform(Runnable r, String s) {
            try {
                Log.d(mTag, mTestName + "" running "" + (s.isEmpty() ? ""..."" : s));
                r.run();
            } catch (AssertionError e) {
                mErrorList.add(e);
                mErrorStringList.add(s);
                Log.e(mTag, mTestName + "" error: "" + e.getMessage());
            }
        }

        public void judge() throws AssertionError {
            if (mErrorList.isEmpty() && mErrorStringList.isEmpty()) {
                return;
            }

            if (mErrorList.size() != mErrorStringList.size()) {
                throw new IllegalStateException(""Mismatch error and error message"");
            }

            StringBuffer buf = new StringBuffer();
            for (int i = 0; i < mErrorList.size(); ++i) {
                buf.append(""Test ("").append(mErrorStringList.get(i)).append("") - Error: "")
                    .append(mErrorList.get(i).getMessage()).append(""; "");
            }
            throw new AssertionError(buf.toString());
        }
    }

    public static String bytesToHex(byte[] bytes, int offset, int length) {
        if (offset == -1) {
            offset = 0;
        }

        if (length == -1) {
            length = bytes.length;
        }

        final char[] hexArray = {'0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F'};
        char[] hexChars = new char[length * 3];
        int v;
        for (int i = 0; i < length; i++) {
            v = bytes[offset + i] & 0xFF;
            hexChars[i * 3] = hexArray[v >>> 4];
            hexChars[i * 3 + 1] = hexArray[v & 0x0F];
            hexChars[i * 3 + 2] = ' ';
        }
        return new String(hexChars);
    }

    public static void makeMyPackageActive() throws IOException {
        final String command = ""cmd sensorservice reset-uid-state ""
                +  InstrumentationRegistry.getTargetContext().getPackageName()
                + "" --user "" + Process.myUserHandle().getIdentifier();
        SystemUtil.runShellCommand(InstrumentationRegistry.getInstrumentation(), command);
    }

    public static void makeMyPackageIdle() throws IOException {
        final String command = ""cmd sensorservice set-uid-state ""
                + InstrumentationRegistry.getTargetContext().getPackageName() + "" idle""
                + "" --user "" + Process.myUserHandle().getIdentifier();
        SystemUtil.runShellCommand(InstrumentationRegistry.getInstrumentation(), command);
    }
}"	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.permission.cts.PermissionUpdateListenerTest"	"LatchWithPermissionsChangedListener"	"CtsPermissionTestCases"	"/home/gpoor/cts-12-source/cts/tests/tests/permission/src/android/permission/cts/PermissionUpdateListenerTest.java"	""	"/*
 *.
 */

package android.permission.cts;

import static com.android.compatibility.common.util.ShellUtils.runShellCommand;
import static com.android.compatibility.common.util.SystemUtil.runWithShellPermissionIdentity;

import static com.google.common.truth.Truth.assertThat;

import android.content.Context;
import android.content.pm.PackageManager;
import android.content.pm.PackageManager.OnPermissionsChangedListener;
import android.platform.test.annotations.AppModeFull;

import androidx.annotation.NonNull;
import androidx.test.internal.runner.junit4.AndroidJUnit4ClassRunner;
import androidx.test.platform.app.InstrumentationRegistry;

import org.junit.AfterClass;
import org.junit.BeforeClass;
import org.junit.Test;
import org.junit.runner.RunWith;

import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

@AppModeFull(reason = ""Instant apps cannot access properties of other apps"")
@RunWith(AndroidJUnit4ClassRunner.class)
public class PermissionUpdateListenerTest {
    private static final String APK =
            ""/data/local/tmp/cts/permissions/""
                    + ""CtsAppThatRequestsCalendarContactsBodySensorCustomPermission.apk"";
    private static final String PACKAGE_NAME =
            ""android.permission.cts.appthatrequestcustompermission"";
    private static final String PERMISSION_NAME = ""android.permission.READ_CONTACTS"";
    private static final int TIMEOUT = 30000;

    private static final Context sContext =
            InstrumentationRegistry.getInstrumentation().getContext();
    private static final PackageManager sPm = sContext.getPackageManager();
    private static int sUid;

    @BeforeClass
    public static void installApp() throws PackageManager.NameNotFoundException {
        runShellCommand(""pm install -r "" + APK);
        sUid = sPm.getPackageUid(PACKAGE_NAME, 0);
    }

    @AfterClass
    public static void unInstallApp() {
        runShellCommand(""pm uninstall "" + PACKAGE_NAME);
    }

    private class LatchWithPermissionsChangedListener extends CountDownLatch
            implements OnPermissionsChangedListener {

        LatchWithPermissionsChangedListener() {
            super(1);
        }

        public void onPermissionsChanged(int uid) {
            if (uid == sUid) {
                countDown();
            }
        }
    }

    private void waitForLatchAndRemoveListener(@NonNull LatchWithPermissionsChangedListener latch)
            throws Exception {
        latch.await(TIMEOUT, TimeUnit.MILLISECONDS);
        runWithShellPermissionIdentity(() -> sPm.removeOnPermissionsChangeListener(latch));
        assertThat(latch.getCount()).isEqualTo((long) 0);
    }"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensoroperations.SensorOperationTest"	"ISensorTestNode"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensoroperations/SensorOperationTest.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers.sensoroperations;

import junit.framework.TestCase;

import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.SensorTestPlatformException;
import android.hardware.cts.helpers.reporting.ISensorTestNode;

import java.util.Set;
import java.util.concurrent.TimeUnit;

/**
 * Tests for the primitive {@link SensorOperation}s including {@link DelaySensorOperation},
 * {@link ParallelSensorOperation}, {@link RepeatingSensorOperation} and
 * {@link SequentialSensorOperation}.
 */
public class SensorOperationTest extends TestCase {
    private static final long TEST_DURATION_THRESHOLD_MS = TimeUnit.SECONDS.toMillis(5);

    private final ISensorTestNode mTestNode = new ISensorTestNode() {
        @Override
        public String getName() throws SensorTestPlatformException {
            return ""SensorOperationUnitTest"";
        }
    };

    /**
     * Test that the {@link FakeSensorOperation} functions correctly. Other tests in this class
     * rely on this operation.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensoroperations.SensorOperationTest"	"testFakeSensorOperation"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensoroperations/SensorOperationTest.java"	""	"public void testFakeSensorOperation() throws Exception {
        final int opDurationMs = 100;

        SensorOperation op = new FakeSensorOperation(opDurationMs, TimeUnit.MILLISECONDS);

        assertFalse(op.getStats().flatten().containsKey(""executed""));
        long start = System.currentTimeMillis();
        op.execute(mTestNode);
        long duration = System.currentTimeMillis() - start;
        assertTrue(Math.abs(opDurationMs - duration) < TEST_DURATION_THRESHOLD_MS);
        assertTrue(op.getStats().flatten().containsKey(""executed""));

        op = new FakeSensorOperation(true, 0, TimeUnit.MILLISECONDS);
        try {
            op.execute(mTestNode);
            throw new Error(""AssertionError expected"");
        } catch (AssertionError e) {
            // Expected
        }
        assertTrue(op.getStats().flatten().keySet().contains(SensorStats.ERROR));
    }

    /**
     * Test that the {@link DelaySensorOperation} functions correctly.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensoroperations.SensorOperationTest"	"testDelaySensorOperation"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensoroperations/SensorOperationTest.java"	""	"public void testDelaySensorOperation() throws Exception {
        final int opDurationMs = 500;
        final int subOpDurationMs = 100;

        FakeSensorOperation subOp = new FakeSensorOperation(subOpDurationMs, TimeUnit.MILLISECONDS);
        SensorOperation op = new DelaySensorOperation(subOp, opDurationMs, TimeUnit.MILLISECONDS);

        long startMs = System.currentTimeMillis();
        op.execute(mTestNode);
        long durationMs = System.currentTimeMillis() - startMs;
        long durationDeltaMs = Math.abs(opDurationMs + subOpDurationMs - durationMs);
        assertTrue(durationDeltaMs < TEST_DURATION_THRESHOLD_MS);
    }

    /**
     * Test that the {@link ParallelSensorOperation} functions correctly.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensoroperations.SensorOperationTest"	"testParallelSensorOperation"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensoroperations/SensorOperationTest.java"	""	"public void testParallelSensorOperation() throws Exception {
        final int subOpCount = 100;
        final int subOpDurationMs = 500;

        ParallelSensorOperation op = new ParallelSensorOperation();
        for (int i = 0; i < subOpCount; i++) {
            SensorOperation subOp = new FakeSensorOperation(subOpDurationMs,
                    TimeUnit.MILLISECONDS);
            op.add(subOp);
        }

        Set<String> statsKeys = op.getStats().flatten().keySet();
        assertEquals(0, statsKeys.size());

        long start = System.currentTimeMillis();
        op.execute(mTestNode);
        long durationMs = System.currentTimeMillis() - start;
        long durationDeltaMs = Math.abs(subOpDurationMs - durationMs);
        String message = String.format(
                ""Expected duration=%sms, observed=%sms, delta=%sms, thresold=%sms"",
                subOpDurationMs,
                durationMs,
                durationDeltaMs,
                TEST_DURATION_THRESHOLD_MS);
        // starting threads might have an impact in the order of 100s ms, depending on the load of
        // the system, so we relax the benchmark part of the test, and we just expect all operations
        // to complete
        assertTrue(message, durationDeltaMs < TEST_DURATION_THRESHOLD_MS);

        statsKeys = op.getStats().flatten().keySet();
        assertEquals(subOpCount, statsKeys.size());
        for (int i = 0; i < subOpCount; i++) {
            assertTrue(statsKeys.contains(String.format(""%s_%03d%sexecuted"",
                    ParallelSensorOperation.STATS_TAG, i, SensorStats.DELIMITER)));
        }
    }

    /**
     * Test that the {@link ParallelSensorOperation} functions correctly if there is a failure in
     * a child operation.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensoroperations.SensorOperationTest"	"testParallelSensorOperation_fail"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensoroperations/SensorOperationTest.java"	""	"public void testParallelSensorOperation_fail() throws Exception {
        final int subOpCount = 100;

        ParallelSensorOperation op = new ParallelSensorOperation();
        for (int i = 0; i < subOpCount; i++) {
            // Trigger failures in the 5th, 55th operations at t=5ms, t=55ms
            SensorOperation subOp = new FakeSensorOperation(i % 50 == 5, i, TimeUnit.MILLISECONDS);
            op.add(subOp);
        }

        Set<String> statsKeys = op.getStats().flatten().keySet();
        assertEquals(0, statsKeys.size());

        try {
            op.execute(mTestNode);
            fail(""AssertionError expected"");
        } catch (AssertionError e) {
            // Expected
            System.out.println(e.getMessage());
        }

        statsKeys = op.getStats().flatten().keySet();
        assertEquals(subOpCount + 3, statsKeys.size());
        for (int i = 0; i < subOpCount; i++) {
            assertTrue(statsKeys.contains(String.format(""%s_%03d%sexecuted"",
                    ParallelSensorOperation.STATS_TAG, i, SensorStats.DELIMITER)));
            if (i % 50 == 5) {
                assertTrue(statsKeys.contains(String.format(""%s_%03d%s%s"",
                        ParallelSensorOperation.STATS_TAG, i, SensorStats.DELIMITER,
                        SensorStats.ERROR)));
            }

        }
        assertTrue(statsKeys.contains(SensorStats.ERROR));
    }

    /**
     * Test that the {@link ParallelSensorOperation} functions correctly if a child exceeds the
     * timeout.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensoroperations.SensorOperationTest"	"testParallelSensorOperation_timeout"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensoroperations/SensorOperationTest.java"	""	"public void testParallelSensorOperation_timeout() throws Exception {
        final int subOpCount = 100;

        ParallelSensorOperation op = new ParallelSensorOperation(1, TimeUnit.SECONDS);
        for (int i = 0; i < subOpCount; i++) {
            // Trigger timeouts in the 5th, 55th operations (5 seconds vs 1 seconds)
            SensorOperation subOp = new FakeSensorOperation(i % 50 == 5 ? 5 : 0, TimeUnit.SECONDS);
            op.add(subOp);
        }

        Set<String> statsKeys = op.getStats().flatten().keySet();
        assertEquals(0, statsKeys.size());

        try {
            op.execute(mTestNode);
            fail(""AssertionError expected"");
        } catch (AssertionError e) {
            // Expected
            System.out.println(e.getMessage());
        }

        statsKeys = op.getStats().flatten().keySet();
        assertEquals(subOpCount - 2, statsKeys.size());
        for (int i = 0; i < subOpCount; i++) {
            if (i % 50 != 5) {
                assertTrue(statsKeys.contains(String.format(""%s_%03d%sexecuted"",
                        ParallelSensorOperation.STATS_TAG, i, SensorStats.DELIMITER)));
            }
        }
    }

    /**
     * Test that the {@link RepeatingSensorOperation} functions correctly.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensoroperations.SensorOperationTest"	"testRepeatingSensorOperation"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensoroperations/SensorOperationTest.java"	""	"public void testRepeatingSensorOperation() throws Exception {
        final int iterations = 10;
        final int subOpDurationMs = 100;

        SensorOperation subOp = new FakeSensorOperation(subOpDurationMs, TimeUnit.MILLISECONDS);
        SensorOperation op = new RepeatingSensorOperation(subOp, iterations);

        Set<String> statsKeys = op.getStats().flatten().keySet();
        assertEquals(0, statsKeys.size());

        long start = System.currentTimeMillis();
        op.execute(mTestNode);
        long duration = System.currentTimeMillis() - start;
        assertTrue(Math.abs(subOpDurationMs * iterations - duration) < TEST_DURATION_THRESHOLD_MS);

        statsKeys = op.getStats().flatten().keySet();
        assertEquals(iterations, statsKeys.size());
        for (int i = 0; i < iterations; i++) {
            assertTrue(statsKeys.contains(String.format(""%s_%03d%sexecuted"",
                    RepeatingSensorOperation.STATS_TAG, i, SensorStats.DELIMITER)));
        }
    }

    /**
     * Test that the {@link RepeatingSensorOperation} functions correctly if there is a failure in
     * a child operation.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensoroperations.SensorOperationTest"	"testRepeatingSensorOperation_fail"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensoroperations/SensorOperationTest.java"	""	"public void testRepeatingSensorOperation_fail() throws Exception {
        final int iterations = 100;
        final int failCount = 75;

        SensorOperation subOp = new FakeSensorOperation(0, TimeUnit.MILLISECONDS) {
            private int mExecutedCount = 0;
            private SensorStats mFakeStats = new SensorStats();

            @Override
            public void execute(ISensorTestNode parent) {
                super.execute(parent);
                mExecutedCount++;

                if (failCount == mExecutedCount) {
                    doFail();
                }
            }

            @Override
            public FakeSensorOperation clone() {
                // Don't clone
                mFakeStats = new SensorStats();
                return this;
            }

            @Override
            public SensorStats getStats() {
                return mFakeStats;
            }
        };
        SensorOperation op = new RepeatingSensorOperation(subOp, iterations);

        Set<String> statsKeys = op.getStats().flatten().keySet();
        assertEquals(0, statsKeys.size());

        try {
            op.execute(mTestNode);
            fail(""AssertionError expected"");
        } catch (AssertionError e) {
            // Expected
            System.out.println(e.getMessage());
        }

        statsKeys = op.getStats().flatten().keySet();
        assertEquals(failCount + 2, statsKeys.size());
        for (int i = 0; i < failCount; i++) {
            assertTrue(statsKeys.contains(String.format(""%s_%03d%sexecuted"",
                    RepeatingSensorOperation.STATS_TAG, i, SensorStats.DELIMITER)));
        }
        assertTrue(statsKeys.contains(String.format(""%s_%03d%s%s"",
                RepeatingSensorOperation.STATS_TAG, failCount - 1, SensorStats.DELIMITER,
                SensorStats.ERROR)));
        assertTrue(statsKeys.contains(SensorStats.ERROR));
    }

    /**
     * Test that the {@link SequentialSensorOperation} functions correctly.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensoroperations.SensorOperationTest"	"testSequentialSensorOperation"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensoroperations/SensorOperationTest.java"	""	"public void testSequentialSensorOperation() throws Exception {
        final int subOpCount = 10;
        final int subOpDurationMs = 100;

        SequentialSensorOperation op = new SequentialSensorOperation();
        for (int i = 0; i < subOpCount; i++) {
            SensorOperation subOp = new FakeSensorOperation(subOpDurationMs,
                    TimeUnit.MILLISECONDS);
            op.add(subOp);
        }

        Set<String> statsKeys = op.getStats().flatten().keySet();
        assertEquals(0, statsKeys.size());

        long start = System.currentTimeMillis();
        op.execute(mTestNode);
        long duration = System.currentTimeMillis() - start;
        assertTrue(Math.abs(subOpDurationMs * subOpCount - duration) < TEST_DURATION_THRESHOLD_MS);

        statsKeys = op.getStats().flatten().keySet();
        assertEquals(subOpCount, statsKeys.size());
        for (int i = 0; i < subOpCount; i++) {
            assertTrue(statsKeys.contains(String.format(""%s_%03d%sexecuted"",
                    SequentialSensorOperation.STATS_TAG, i, SensorStats.DELIMITER)));
        }
    }

    /**
     * Test that the {@link SequentialSensorOperation} functions correctly if there is a failure in
     * a child operation.
     */"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensoroperations.SensorOperationTest"	"testSequentialSensorOperation_fail"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensoroperations/SensorOperationTest.java"	""	"public void testSequentialSensorOperation_fail() throws Exception {
        final int subOpCount = 100;
        final int failCount = 75;

        SequentialSensorOperation op = new SequentialSensorOperation();
        for (int i = 0; i < subOpCount; i++) {
            // Trigger a failure in the 75th operation only
            SensorOperation subOp = new FakeSensorOperation(i + 1 == failCount, 0,
                    TimeUnit.MILLISECONDS);
            op.add(subOp);
        }

        Set<String> statsKeys = op.getStats().flatten().keySet();
        assertEquals(0, statsKeys.size());

        try {
            op.execute(mTestNode);
            fail(""AssertionError expected"");
        } catch (AssertionError e) {
            // Expected
            System.out.println(e.getMessage());
        }

        statsKeys = op.getStats().flatten().keySet();
        assertEquals(failCount + 2, statsKeys.size());
        for (int i = 0; i < failCount; i++) {
            assertTrue(statsKeys.contains(String.format(""%s_%03d%sexecuted"",
                    SequentialSensorOperation.STATS_TAG, i, SensorStats.DELIMITER)));
        }
        assertTrue(statsKeys.contains(String.format(""%s_%03d%s%s"",
                SequentialSensorOperation.STATS_TAG, failCount - 1, SensorStats.DELIMITER,
                SensorStats.ERROR)));
        assertTrue(statsKeys.contains(SensorStats.ERROR));
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.dumpsys.cts.BatteryStatsDumpsysTest"	"testBatterystatsOutput"	"CtsDumpsysHostTestCases"	"/home/gpoor/cts-12-source/cts/hostsidetests/dumpsys/src/android/dumpsys/cts/BatteryStatsDumpsysTest.java"	""	"public void testBatterystatsOutput() throws Exception {
        String batterystats = mDevice.executeShellCommand(""dumpsys batterystats --checkin"");
        assertNotNull(batterystats);
        assertTrue(batterystats.length() > 0);

        Set<String> seenTags = new HashSet<>();

        try (BufferedReader reader = new BufferedReader(
                new StringReader(batterystats))) {

            String line;
            while ((line = reader.readLine()) != null) {
                if (line.isEmpty()) {
                    continue;
                }


                try {
                    // With a default limit of 0, empty strings at the end are discarded.
                    // We still consider the empty string as a valid value in some cases.
                    // Using any negative number for the limit will preserve a trailing empty string.
                    // @see String#split(String, int)
                    String[] parts = line.split("","", -1);
                    assertInteger(parts[0]); // old version
                    assertInteger(parts[1]); // UID
                    switch (parts[2]) { // aggregation type
                        case ""i"":
                        case ""l"":
                        case ""c"":
                        case ""u"":
                            break;
                        default:
                            fail(""malformed stat: "" + parts[2]);
                    }
                    assertNotNull(parts[3]);
                    seenTags.add(parts[3]);

                    // Note the time fields are measured in milliseconds by default.
                    switch (parts[3]) {
                        case ""vers"":
                            checkVersion(parts);
                            break;
                        case ""uid"":
                            checkUid(parts);
                            break;
                        case ""apk"":
                            checkApk(parts);
                            break;
                        case ""pr"":
                            checkProcess(parts);
                            break;
                        case ""sr"":
                            checkSensor(parts);
                            break;
                        case ""vib"":
                            checkVibrator(parts);
                            break;
                        case ""fg"":
                            checkForegroundActivity(parts);
                            break;
                        case ""fgs"":
                            checkForegroundService(parts);
                            break;
                        case ""st"":
                            checkStateTime(parts);
                            break;
                        case ""wl"":
                            checkWakelock(parts);
                            break;
                        case ""awl"":
                            checkAggregatedWakelock(parts);
                            break;
                        case ""sy"":
                            checkSync(parts);
                            break;
                        case ""jb"":
                            checkJob(parts);
                            break;
                        case ""jbc"":
                            checkJobCompletion(parts);
                            break;
                        case ""jbd"":
                            checkJobsDeferred(parts);
                            break;
                        case ""kwl"":
                            checkKernelWakelock(parts);
                            break;
                        case ""wr"":
                            checkWakeupReason(parts);
                            break;
                        case ""nt"":
                            checkNetwork(parts);
                            break;
                        case ""ua"":
                            checkUserActivity(parts);
                            break;
                        case ""bt"":
                            checkBattery(parts);
                            break;
                        case ""dc"":
                            checkBatteryDischarge(parts);
                            break;
                        case ""lv"":
                            checkBatteryLevel(parts);
                            break;
                        case ""wfl"":
                            checkWifi(parts);
                            break;
                        case ""m"":
                            checkMisc(parts);
                            break;
                        case ""gn"":
                            checkGlobalNetwork(parts);
                            break;
                        case ""br"":
                            checkScreenBrightness(parts);
                            break;
                        case ""sgt"":
                        case ""sgc"":
                            checkSignalStrength(parts);
                            break;
                        case ""sst"":
                            checkSignalScanningTime(parts);
                            break;
                        case ""dct"":
                        case ""dcc"":
                            checkDataConnection(parts);
                            break;
                        case ""wst"":
                        case ""wsc"":
                            checkWifiState(parts);
                            break;
                        case ""wsst"":
                        case ""wssc"":
                            checkWifiSupplState(parts);
                            break;
                        case ""wsgt"":
                        case ""wsgc"":
                            checkWifiSignalStrength(parts);
                            break;
                        case ""bst"":
                        case ""bsc"":
                            checkBluetoothState(parts);
                            break;
                        case ""blem"":
                            checkBluetoothMisc(parts);
                            break;
                        case ""pws"":
                            checkPowerUseSummary(parts);
                            break;
                        case ""pwi"":
                            checkPowerUseItem(parts);
                            break;
                        case ""dsd"":
                        case ""csd"":
                            checkChargeDischargeStep(parts);
                            break;
                        case ""dtr"":
                            checkDischargeTimeRemain(parts);
                            break;
                        case ""ctr"":
                            checkChargeTimeRemain(parts);
                            break;
                        case ""cpu"":
                            checkUidCpuUsage(parts);
                            break;
                        default:
                            break;
                    }
                } catch (AssertionError e) {
                    CLog.e(""Assert fail for line <"" + line + "">"");
                    throw e;
                }
            }
        }

        // spot check a few tags
        assertSeenTag(seenTags, ""vers"");
        assertSeenTag(seenTags, ""bt"");
        assertSeenTag(seenTags, ""dc"");
        assertSeenTag(seenTags, ""m"");
    }

    private void checkVersion(String[] parts) {
        assertEquals(8, parts.length);
        assertInteger(parts[4]); // checkinVersion
        assertInteger(parts[5]); // parcelVersion
        assertNotNull(parts[6]); // startPlatformVersion
        assertNotNull(parts[7]); // endPlatformVersion
    }

    private void checkUid(String[] parts) {
        assertEquals(6, parts.length);
        assertInteger(parts[4]); // uid
        assertNotNull(parts[5]); // pkgName
    }

    private void checkApk(String[] parts) {
        assertEquals(10, parts.length);
        long wakeup_count = assertInteger(parts[4]); // wakeups
        assertNotNull(parts[5]); // apk
        assertNotNull(parts[6]); // service
        assertInteger(parts[7]); // startTime
        assertInteger(parts[8]); // starts
        assertInteger(parts[9]); // launches

        // Validation check.
        assertTrue(""wakeup count must be >= 0"", wakeup_count >= 0);
    }

    private void checkProcess(String[] parts) {
        assertTrue(parts.length >= 9);
        assertNotNull(parts[4]); // process
        assertInteger(parts[5]); // userMillis
        assertInteger(parts[6]); // systemMillis
        assertInteger(parts[7]); // foregroundMillis
        assertInteger(parts[8]); // starts
    }

    private void checkSensor(String[] parts) {
        assertEquals(10, parts.length);
        assertInteger(parts[4]); // sensorNumber
        assertInteger(parts[5]); // totalTime
        assertInteger(parts[6]); // count
        assertInteger(parts[7]); // backgroundCount
        assertInteger(parts[8]); // actualTime
        assertInteger(parts[9]); // backgroundActualTime
    }

    private void checkVibrator(String[] parts) {
        assertEquals(6, parts.length);
        assertInteger(parts[4]); // totalTime
        assertInteger(parts[5]); // count
    }

    private void checkForegroundActivity(String[] parts) {
        assertEquals(6, parts.length);
        assertInteger(parts[4]); // totalTime
        assertInteger(parts[5]); // count
    }

    private void checkForegroundService(String[] parts) {
        assertEquals(6, parts.length);
        assertInteger(parts[4]); // totalTime
        assertInteger(parts[5]); // count
    }

    private void checkStateTime(String[] parts) {
        assertEquals(11, parts.length);
        assertInteger(parts[4]);  // top
        assertInteger(parts[5]);  // foreground_service
        assertInteger(parts[6]);  // foreground
        assertInteger(parts[7]);  // background
        assertInteger(parts[8]);  // top_sleeping
        assertInteger(parts[9]);  // heavy_weight
        assertInteger(parts[10]); // cached
    }

    private void checkWakelock(String[] parts) {
        assertEquals(29, parts.length);
        assertNotNull(parts[4]);      // wakelock

        assertInteger(parts[5]);      // full totalTime
        assertEquals(""f"", parts[6]);  // full
        long full_count = assertInteger(parts[7]);      // full count
        assertInteger(parts[8]);      // current duration
        assertInteger(parts[9]);      // max duration
        assertInteger(parts[10]);     // total duration

        assertInteger(parts[11]);      // partial totalTime
        assertEquals(""p"", parts[12]);  // partial
        long partial_count = assertInteger(parts[13]);     // partial count
        assertInteger(parts[14]);      // current duration
        assertInteger(parts[15]);      // max duration
        assertInteger(parts[16]);      // total duration

        assertInteger(parts[17]);      // background partial totalTime
        assertEquals(""bp"", parts[18]); // background partial
        long bg_partial_count = assertInteger(parts[19]);     // background partial count
        assertInteger(parts[20]);      // current duration
        assertInteger(parts[21]);      // max duration
        assertInteger(parts[22]);      // total duration

        assertInteger(parts[23]);      // window totalTime
        assertEquals(""w"", parts[24]);  // window
        long window_count = assertInteger(parts[25]);     // window count
        assertInteger(parts[26]);      // current duration
        assertInteger(parts[27]);      // max duration
        assertInteger(parts[28]);      // total duration

        // Validation checks.
        assertTrue(""full wakelock count must be >= 0"", full_count >= 0);
        assertTrue(""partial wakelock count must be >= 0"", partial_count >= 0);
        assertTrue(""background partial wakelock count must be >= 0"", bg_partial_count >= 0);
        assertTrue(""window wakelock count must be >= 0"", window_count >= 0);
    }

    private void checkAggregatedWakelock(String[] parts) {
        assertEquals(6, parts.length);
        assertInteger(parts[4]); // total time
        assertInteger(parts[5]); // background time
    }

    private void checkSync(String[] parts) {
        assertEquals(9, parts.length);
        assertNotNull(parts[4]); // sync
        assertInteger(parts[5]); // totalTime
        assertInteger(parts[6]); // count
        assertInteger(parts[7]); // bgTime
        assertInteger(parts[8]); // bgCount
    }

    private void checkJob(String[] parts) {
        assertEquals(9, parts.length);
        assertNotNull(parts[4]); // job
        assertInteger(parts[5]); // totalTime
        assertInteger(parts[6]); // count
        assertInteger(parts[7]); // bgTime
        assertInteger(parts[8]); // bgCount
    }

    private void checkJobCompletion(String[] parts) {
        // This line contains a number for each job cancel reason.
        // (See JobParameters.JOB_STOP_REASON_CODES), and future mainline updates may introudce
        // more codes, so we have no upper bound for the number of columns.
        assertThat(parts.length).isAtLeast(11);
        assertNotNull(parts[4]); // job

        // Values for each of JOB_STOP_REASON_CODES.
        for (int i = 5; i < parts.length; i++) {
            assertInteger(parts[i]);
        }
    }

    private void checkJobsDeferred(String[] parts) {
        assertEquals(12, parts.length);
        assertInteger(parts[4]); // jobsDeferredEventCount
        assertInteger(parts[5]); // jobsDeferredCount
        assertInteger(parts[6]); // totalLatencyMillis
        assertInteger(parts[7]); // count at latency < 1 hr
        assertInteger(parts[8]); // count at latency 1-2 hrs
        assertInteger(parts[9]); // count at latency 2-4 hrs
        assertInteger(parts[10]); // count at latency 4-8 hrs
        assertInteger(parts[11]); // count at latency 8+ hrs
    }

    private void checkKernelWakelock(String[] parts) {
        assertTrue(parts.length >= 7);
 assertNotNull(parts[4]); // Kernel wakelock
 assertInteger(parts[parts.length-2]); // totalTime
        assertInteger(parts[parts.length-1]); // count
    }

    private void checkWakeupReason(String[] parts) {
        assertTrue(parts.length >= 7);
        for (int i = 4; i < parts.length-2; i++) {
            assertNotNull(parts[i]); // part of wakeup
        }
        assertInteger(parts[parts.length-2]); // totalTime
        assertInteger(parts[parts.length-1]); // count
    }

    private void checkNetwork(String[] parts) {
        assertEquals(26, parts.length);
        long mbRx = assertInteger(parts[4]);  // mobileBytesRx
        long mbTx = assertInteger(parts[5]);  // mobileBytesTx
        long wbRx = assertInteger(parts[6]);  // wifiBytesRx
        long wbTx = assertInteger(parts[7]);  // wifiBytesTx
        long mpRx = assertInteger(parts[8]);  // mobilePacketsRx
        long mpTx = assertInteger(parts[9]);  // mobilePacketsTx
        long wpRx = assertInteger(parts[10]); // wifiPacketsRx
        long wpTx = assertInteger(parts[11]); // wifiPacketsTx
        assertInteger(parts[12]); // mobileActiveTime (usec)
        assertInteger(parts[13]); // mobileActiveCount
        assertInteger(parts[14]); // btBytesRx
        assertInteger(parts[15]); // btBytesTx
        assertInteger(parts[16]); // mobileWakeup
        assertInteger(parts[17]); // wifiWakeup
        long mbBgRx = assertInteger(parts[18]);  // mobileBytesRx
        long mbBgTx = assertInteger(parts[19]);  // mobileBytesTx
        long wbBgRx = assertInteger(parts[20]);  // wifiBytesRx
        long wbBgTx = assertInteger(parts[21]);  // wifiBytesTx
        long mpBgRx = assertInteger(parts[22]);  // mobilePacketsRx
        long mpBgTx = assertInteger(parts[23]);  // mobilePacketsTx
        long wpBgRx = assertInteger(parts[24]); // wifiPacketsRx
        long wpBgTx = assertInteger(parts[25]); // wifiPacketsTx

        // Assuming each packet contains some bytes, bytes >= packets >= 0.
        assertTrue(""mobileBytesRx must be >= mobilePacketsRx"", mbRx >= mpRx);
        assertTrue(""mobilePacketsRx must be >= 0"", mpRx >= 0);
        assertTrue(""mobileBytesTx must be >= mobilePacketsTx"", mbTx >= mpTx);
        assertTrue(""mobilePacketsTx must be >= 0"", mpTx >= 0);
        assertTrue(""wifiBytesRx must be >= wifiPacketsRx"", wbRx >= wpRx);
        assertTrue(""wifiPacketsRx must be >= 0"", wpRx >= 0);
        assertTrue(""wifiBytesTx must be >= wifiPacketsTx"", wbTx >= wpTx);
        assertTrue(""wifiPacketsTx must be >= 0"", wpTx >= 0);
        // Totals should be greater than or equal to background data numbers
        assertTrue(""mobileBytesRx must be >= mobileBytesBgRx"", mbRx >= mbBgRx);
        assertTrue(""mobilePacketsRx must be >= mobilePacketsBgRx"", mpRx >= mpBgRx);
        assertTrue(""mobileBytesTx must be >= mobileBytesBgTx"", mbTx >= mbBgTx);
        assertTrue(""mobilePacketsTx must be >= mobilePacketsBgTx"", mpTx >= mpBgTx);
        assertTrue(""wifiBytesRx must be >= wifiBytesBgRx"", wbRx >= wbBgRx);
        assertTrue(""wifiPacketsRx must be >= wifiPacketsBgRx"", wpRx >= wpBgRx);
        assertTrue(""wifiBytesTx must be >= wifiBytesBgTx"", wbTx >= wbBgTx);
        assertTrue(""wifiPacketsTx must be >= wifiPacketsBgTx"", wpTx >= wpBgTx);
    }

    private void checkUserActivity(String[] parts) {
        assertEquals(9, parts.length);
        assertInteger(parts[4]); // other
        assertInteger(parts[5]); // button
        assertInteger(parts[6]); // touch
        assertInteger(parts[7]); // accessibility
        assertInteger(parts[8]); // attention
    }

    private void checkBattery(String[] parts) {
        assertEquals(16, parts.length);
        if (!parts[4].equals(""N/A"")) {
            assertInteger(parts[4]);  // startCount
        }
        long bReal = assertInteger(parts[5]);  // batteryRealtime
        long bUp = assertInteger(parts[6]);  // batteryUptime
        long tReal = assertInteger(parts[7]);  // totalRealtime
        long tUp = assertInteger(parts[8]);  // totalUptime
        assertInteger(parts[9]);  // startClockTime
        long bOffReal = assertInteger(parts[10]); // batteryScreenOffRealtime
        long bOffUp = assertInteger(parts[11]); // batteryScreenOffUptime
        long bEstCap = assertInteger(parts[12]); // batteryEstimatedCapacity
        assertInteger(parts[13]); // minLearnedBatteryCapacity
        assertInteger(parts[14]); // maxLearnedBatteryCapacity
        long bDoze = assertInteger(parts[15]); // screenDozeTime

        // The device cannot be up more than there are real-world seconds.
        assertTrue(""batteryRealtime must be >= batteryUptime"", bReal >= bUp);
        assertTrue(""totalRealtime must be >= totalUptime"", tReal >= tUp);
        assertTrue(""batteryScreenOffRealtime must be >= batteryScreenOffUptime"",
                bOffReal >= bOffUp);

        // total >= battery >= battery screen-off >= 0
        assertTrue(""totalRealtime must be >= batteryRealtime"", tReal >= bReal);
        assertTrue(""batteryRealtime must be >= batteryScreenOffRealtime"", bReal >= bOffReal);
        assertTrue(""batteryScreenOffRealtime must be >= 0"", bOffReal >= 0);
        assertTrue(""totalUptime must be >= batteryUptime"", tUp >= bUp);
        assertTrue(""batteryUptime must be >= batteryScreenOffUptime"", bUp >= bOffUp);
        assertTrue(""batteryScreenOffUptime must be >= 0"", bOffUp >= 0);
        assertTrue(""batteryEstimatedCapacity must be >= 0"", bEstCap >= 0);
        assertTrue(""screenDozeTime must be >= 0"", bDoze >= 0);
        assertTrue(""screenDozeTime must be <= batteryScreenOffRealtime"", bDoze <= bOffReal);
    }

    private void checkBatteryDischarge(String[] parts) {
        assertEquals(14, parts.length);
        assertInteger(parts[4]); // low
        assertInteger(parts[5]); // high
        assertInteger(parts[6]); // screenOn
        assertInteger(parts[7]); // screenOff
        assertInteger(parts[8]); // dischargeMah
        assertInteger(parts[9]); // dischargeScreenOffMah
        assertInteger(parts[10]); // dischargeDozeCount
        assertInteger(parts[11]); // dischargeDozeMah
        assertInteger(parts[12]); // dischargeLightDozeMah
        assertInteger(parts[13]); // dischargeDeepDozeMah
    }

    private void checkBatteryLevel(String[] parts) {
        assertEquals(6, parts.length);
        assertInteger(parts[4]); // startLevel
        assertInteger(parts[5]); // currentLevel
    }

    private void checkWifi(String[] parts) {
        assertEquals(14, parts.length);
        assertInteger(parts[4]); // fullWifiLockOnTime (usec)
        assertInteger(parts[5]); // wifiScanTime (usec)
        assertInteger(parts[6]); // uidWifiRunningTime (usec)
        assertInteger(parts[7]); // wifiScanCount
        // Fields for parts[8 and 9 and 10] are deprecated.
        assertInteger(parts[11]); // wifiScanCountBg
        assertInteger(parts[12]); // wifiScanActualTimeMs (msec)
        assertInteger(parts[13]); // wifiScanActualTimeMsBg (msec)
    }

    private void checkMisc(String[] parts) {
        assertTrue(parts.length >= 19);
        assertInteger(parts[4]);      // screenOnTime
        assertInteger(parts[5]);      // phoneOnTime
        assertInteger(parts[6]);      // fullWakeLockTimeTotal
        assertInteger(parts[7]);      // partialWakeLockTimeTotal
        assertInteger(parts[8]);      // mobileRadioActiveTime
        assertInteger(parts[9]);      // mobileRadioActiveAdjustedTime
        assertInteger(parts[10]);     // interactiveTime
        assertInteger(parts[11]);     // lowPowerModeEnabledTime
        assertInteger(parts[12]);     // connChanges
        assertInteger(parts[13]);     // deviceIdleModeEnabledTime
        assertInteger(parts[14]);     // deviceIdleModeEnabledCount
        assertInteger(parts[15]);     // deviceIdlingTime
        assertInteger(parts[16]);     // deviceIdlingCount
        assertInteger(parts[17]);     // mobileRadioActiveCount
        assertInteger(parts[18]);     // mobileRadioActiveUnknownTime
    }

    private void checkGlobalNetwork(String[] parts) {
        assertEquals(14, parts.length);
        assertInteger(parts[4]);  // mobileRxTotalBytes
        assertInteger(parts[5]);  // mobileTxTotalBytes
        assertInteger(parts[6]);  // wifiRxTotalBytes
        assertInteger(parts[7]);  // wifiTxTotalBytes
        assertInteger(parts[8]);  // mobileRxTotalPackets
        assertInteger(parts[9]);  // mobileTxTotalPackets
        assertInteger(parts[10]); // wifiRxTotalPackets
        assertInteger(parts[11]); // wifiTxTotalPackets
        assertInteger(parts[12]); // btRxTotalBytes
        assertInteger(parts[13]); // btTxTotalBytes
    }

    private void checkScreenBrightness(String[] parts) {
        assertEquals(9, parts.length);
        assertInteger(parts[4]); // dark
        assertInteger(parts[5]); // dim
        assertInteger(parts[6]); // medium
        assertInteger(parts[7]); // light
        assertInteger(parts[8]); // bright
    }

    private void checkSignalStrength(String[] parts) {
        assertTrue(parts.length >= 9);
        assertInteger(parts[4]); // none
        assertInteger(parts[5]); // poor
        assertInteger(parts[6]); // moderate
        assertInteger(parts[7]); // good
        assertInteger(parts[8]); // great
    }

    private void checkSignalScanningTime(String[] parts) {
        assertEquals(5, parts.length);
        assertInteger(parts[4]); // signalScanningTime
    }

    private void checkDataConnection(String[] parts) {
        assertEquals(27, parts.length);
        assertInteger(parts[4]);  // none
        assertInteger(parts[5]);  // gprs
        assertInteger(parts[6]);  // edge
        assertInteger(parts[7]);  // umts
        assertInteger(parts[8]);  // cdma
        assertInteger(parts[9]);  // evdo_0
        assertInteger(parts[10]); // evdo_A
        assertInteger(parts[11]); // 1xrtt
        assertInteger(parts[12]); // hsdpa
        assertInteger(parts[13]); // hsupa
        assertInteger(parts[14]); // hspa
        assertInteger(parts[15]); // iden
        assertInteger(parts[16]); // evdo_b
        assertInteger(parts[17]); // lte
        assertInteger(parts[18]); // ehrpd
        assertInteger(parts[19]); // hspap
        assertInteger(parts[20]); // gsm
        assertInteger(parts[21]); // td_scdma
        assertInteger(parts[22]); // iwlan
        assertInteger(parts[23]); // lte_ca
        assertInteger(parts[24]); // nr
        assertInteger(parts[25]); // emngcy
        assertInteger(parts[26]); // other
    }

    private void checkWifiState(String[] parts) {
        assertEquals(12, parts.length);
        assertInteger(parts[4]);  // off
        assertInteger(parts[5]);  // scanning
        assertInteger(parts[6]);  // no_net
        assertInteger(parts[7]);  // disconn
        assertInteger(parts[8]);  // sta
        assertInteger(parts[9]);  // p2p
        assertInteger(parts[10]); // sta_p2p
        assertInteger(parts[11]); // soft_ap
    }

    private void checkWifiSupplState(String[] parts) {
        assertEquals(17, parts.length);
        assertInteger(parts[4]);  // inv
        assertInteger(parts[5]);  // dsc
        assertInteger(parts[6]);  // dis
        assertInteger(parts[7]);  // inact
        assertInteger(parts[8]);  // scan
        assertInteger(parts[9]);  // auth
        assertInteger(parts[10]); // ascing
        assertInteger(parts[11]); // asced
        assertInteger(parts[12]); // 4-way
        assertInteger(parts[13]); // group
        assertInteger(parts[14]); // compl
        assertInteger(parts[15]); // dorm
        assertInteger(parts[16]); // uninit
    }

    private void checkWifiSignalStrength(String[] parts) {
        assertEquals(9, parts.length);
        assertInteger(parts[4]); // none
        assertInteger(parts[5]); // poor
        assertInteger(parts[6]); // moderate
        assertInteger(parts[7]); // good
        assertInteger(parts[8]); // great
    }

    private void checkBluetoothState(String[] parts) {
        assertEquals(8, parts.length);
        assertInteger(parts[4]); // inactive
        assertInteger(parts[5]); // low
        assertInteger(parts[6]); // med
        assertInteger(parts[7]); // high
    }

    private void checkPowerUseSummary(String[] parts) {
        assertEquals(8, parts.length);
        assertDouble(parts[4]); // batteryCapacity
        assertDouble(parts[5]); // computedPower
        assertDouble(parts[6]); // minDrainedPower
        assertDouble(parts[7]); // maxDrainedPower
    }

    private void checkPowerUseItem(String[] parts) {
        assertEquals(9, parts.length);
        assertNotNull(parts[4]); // label
        final double totalPowerMah = assertDouble(parts[5]);  // totalPowerMah
        final long shouldHide = assertInteger(parts[6]);  // shouldHide (0 or 1)
        final double screenPowerMah = assertDouble(parts[7]);  // screenPowerMah
        final double proportionalSmearMah = assertDouble(parts[8]);  // proportionalSmearMah

        assertTrue(""powerUseItem totalPowerMah must be >= 0"", totalPowerMah >= 0);
        assertTrue(""powerUseItem screenPowerMah must be >= 0"", screenPowerMah >= 0);
        assertTrue(""powerUseItem proportionalSmearMah must be >= 0"", proportionalSmearMah >= 0);
        assertTrue(""powerUseItem shouldHide must be 0 or 1"", shouldHide == 0 || shouldHide == 1);

        // Largest current Android battery is ~5K. 100K shouldn't get made for a while.
        assertTrue(""powerUseItem totalPowerMah is expected to be <= 100000"", totalPowerMah <= 100000);
    }

    private void checkChargeDischargeStep(String[] parts) {
        assertEquals(9, parts.length);
        assertInteger(parts[4]); // duration
        if (!parts[5].equals(""?"")) {
            assertInteger(parts[5]); // level
        }
        assertNotNull(parts[6]); // screen
        assertNotNull(parts[7]); // power-save
        assertNotNull(parts[8]); // device-idle
    }

    private void checkDischargeTimeRemain(String[] parts) {
        assertEquals(5, parts.length);
        assertInteger(parts[4]); // batteryTimeRemaining
    }

    private void checkChargeTimeRemain(String[] parts) {
        assertEquals(5, parts.length);
        assertInteger(parts[4]); // chargeTimeRemaining
    }

    private void checkUidCpuUsage(String[] parts) {
        assertTrue(parts.length >= 6);
        assertInteger(parts[4]); // user time
        assertInteger(parts[5]); // system time
    }

    private void checkBluetoothMisc(String[] parts) {
        assertEquals(15, parts.length);
        assertInteger(parts[4]); // totalTime
        assertInteger(parts[5]); // count
        assertInteger(parts[6]); // countBg
        assertInteger(parts[7]); // actualTime
        assertInteger(parts[8]); // actualTimeBg
        assertInteger(parts[9]); // resultsCount
        assertInteger(parts[10]); // resultsCountBg
        assertInteger(parts[11]); // unoptimizedScanTotalTime
        assertInteger(parts[12]); // unoptimizedScanTotalTimeBg
        assertInteger(parts[13]); // unoptimizedScanMaxTime
        assertInteger(parts[14]); // unoptimizedScanMaxTimeBg
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.cts.helpers.sensorverification.FrequencyVerification"	"isSensorSamplingRateOverloaded"	"CtsSensorTestCases"	"/home/gpoor/cts-12-source/cts/tests/sensor/src/android/hardware/cts/helpers/sensorverification/FrequencyVerification.java"	""	"public void test/*
 *.
 */

package android.hardware.cts.helpers.sensorverification;

import junit.framework.Assert;

import android.hardware.Sensor;
import android.hardware.cts.helpers.SensorCtsHelper;
import android.hardware.cts.helpers.SensorStats;
import android.hardware.cts.helpers.TestSensorEnvironment;
import android.hardware.cts.helpers.TestSensorEvent;
import android.util.Log;

import java.util.concurrent.TimeUnit;

/**
 * A {@link ISensorVerification} which verifies that the sensor frequency are within the expected
 * range.
 */
public class FrequencyVerification extends AbstractSensorVerification {
    public static final String PASSED_KEY = ""frequency_passed"";
    private static final String LOG_TAG = FrequencyVerification.class.getSimpleName();

    // Lowest acceptable frequency, as percentage of the requested one.
    private static final int DEFAULT_LOWER_THRESHOLD = 90;
    // Highest acceptable frequency, as percentage of the requested one.
    private static final int DEFAULT_UPPER_THRESHOLD = 220;

    private final double mLowerThresholdHz;
    private final double mUpperThresholdHz;

    private long mMinTimestamp = 0;
    private long mMaxTimestamp = 0;
    private int mCount = 0;

    /**
     * Construct a {@link FrequencyVerification}.
     *
     * @param lowerTheshold Lowest acceptable frequency Hz.
     * @param upperThreshold Highest acceptable frequency Hz.
     */
    public FrequencyVerification(double lowerTheshold, double upperThreshold) {
        mLowerThresholdHz = lowerTheshold;
        mUpperThresholdHz = upperThreshold;
    }

    /**
     * Get the default {@link FrequencyVerification} for a sensor.
     *
     * @param environment the test environment
     * @return the verification or null if the verification does not apply to the sensor.
     */
    public static FrequencyVerification getDefault(TestSensorEnvironment environment) {
        Sensor sensor = environment.getSensor();
        if (sensor.getReportingMode() != Sensor.REPORTING_MODE_CONTINUOUS) {
            return null;
        }

        Log.i(LOG_TAG, String.format(
                ""Preparing frequency test for \""%s\"" for which minDelay=%dus and maxDelay=%dus"",
                sensor.getName(),
                sensor.getMinDelay(),
                sensor.getMaxDelay()));

        double minDelayUs = sensor.getMinDelay();
        double maxDelayUs = sensor.getMaxDelay();

        if (maxDelayUs <= 0) {
            // This sensor didn't report its maxDelay.
            // It might be only capable of producing its max rate.
            // Do as if it reported its minDelay as its maxDelay.
            Log.w(LOG_TAG, ""This sensor ("" + sensor.getName() + "") didn't report its maxDelay.""
                    + ""Please update it in the sensor HAL to avoid failures in coming ""
                    + ""android releases."");
            maxDelayUs = minDelayUs;
        }

        if (environment.isSensorSamplingRateOverloaded()) {
            maxDelayUs = minDelayUs;
        }

        // Convert the rateUs parameter into a delay in microseconds and rate in Hz.
        double delayUs = environment.getRequestedSamplingPeriodUs();

        double lowerExpectedHz = 0;
        double upperExpectedHz = 0;

        // If sensor reports its maxDelay, then
        // lowerExpectedHz = upperExpectedHz and minRate <= expectedHz <= maxRate.
        // If sensor do not report its maxDelay, then
        // lowerExpectedHz is as per request (obviously <= maxRate) & upperExpectedHz = maxRate.
        if (sensor.getMaxDelay() > 0) {
            delayUs = SensorCtsHelper.clamp(delayUs, minDelayUs, maxDelayUs);
            double expectedHz = SensorCtsHelper.getFrequency(delayUs, TimeUnit.MICROSECONDS);
            lowerExpectedHz = upperExpectedHz = expectedHz;
        } else {
            delayUs = Math.max(minDelayUs, delayUs);
            lowerExpectedHz = SensorCtsHelper.getFrequency(delayUs, TimeUnit.MICROSECONDS);
            upperExpectedHz = SensorCtsHelper.getFrequency(minDelayUs, TimeUnit.MICROSECONDS);
        }

        // Set the pass thresholds based on default multipliers.
        double lowerThresholdHz = lowerExpectedHz * DEFAULT_LOWER_THRESHOLD / 100;
        double upperThresholdHz = upperExpectedHz * DEFAULT_UPPER_THRESHOLD / 100;

        return new FrequencyVerification(lowerThresholdHz, upperThresholdHz);
    }

    /**
     * Verify that the frequency is correct. Add {@value #PASSED_KEY} and
     * {@value SensorStats#FREQUENCY_KEY} keys to {@link SensorStats}.
     *
     * @throws AssertionError if the verification failed.
     */
    @Override
    public void verify(TestSensorEnvironment environment, SensorStats stats) {
        if (mCount < 2) {
            stats.addValue(PASSED_KEY, true);
            return;
        }

        double measuredFrequencyHz = SensorCtsHelper.getFrequency(
                ((double) (mMaxTimestamp - mMinTimestamp)) / (mCount - 1), TimeUnit.NANOSECONDS);
        boolean failed = (measuredFrequencyHz <= mLowerThresholdHz
                || measuredFrequencyHz >= mUpperThresholdHz);

        stats.addValue(SensorStats.FREQUENCY_KEY, measuredFrequencyHz);
        stats.addValue(PASSED_KEY, !failed);
        String resultString = String.format(
                ""Requested \""%s\"" at %s (expecting between %.2fHz and %.2fHz, measured %.2fHz)"",
                environment.getSensor().getName(),
                environment.getFrequencyString(),
                mLowerThresholdHz,
                mUpperThresholdHz,
                measuredFrequencyHz);

        if (failed) {
            Log.e(LOG_TAG, ""Frequency test FAIL: "" + resultString);
            Assert.fail(String.format(""Frequency out of range: "" + resultString));
        } else {
            Log.i(LOG_TAG, ""Frequency test pass: "" + resultString);
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public FrequencyVerification clone() {
        return new FrequencyVerification(mLowerThresholdHz, mUpperThresholdHz);
    }

    /**
     * {@inheritDoc}
     */
    @Override
    protected void addSensorEventInternal(TestSensorEvent event) {
        if (mCount == 0) {
            mMinTimestamp = event.timestamp;
            mMaxTimestamp = event.timestamp;
        } else {
            if (mMinTimestamp > event.timestamp) {
                mMinTimestamp = event.timestamp;
            }
            if (mMaxTimestamp < event.timestamp) {
                mMaxTimestamp = event.timestamp;
            }
        }
        mCount++;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Fragments.ComplexMovementFragment"	"OnClickListener"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Fragments/ComplexMovementFragment.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Fragments;

import com.android.cts.verifier.R;
import com.android.cts.verifier.sensors.sixdof.BuildConfig;
import com.android.cts.verifier.sensors.sixdof.Activities.StartActivity;
import com.android.cts.verifier.sensors.sixdof.Activities.TestActivity;
import com.android.cts.verifier.sensors.sixdof.Dialogs.ComplexMovementResultDialog;
import com.android.cts.verifier.sensors.sixdof.Interfaces.ComplexMovementListener;
import com.android.cts.verifier.sensors.sixdof.Renderer.ComplexMovementRenderer;
import com.android.cts.verifier.sensors.sixdof.Utils.Manager;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointAreaCoveredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointDistanceException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointRingNotEnteredException;
import com.android.cts.verifier.sensors.sixdof.Utils.Exceptions.WaypointStartPointException;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.ComplexMovementPath;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.PathUtilityClasses.Ring;
import com.android.cts.verifier.sensors.sixdof.Utils.ResultObjects.ResultObject;

import android.app.Activity;
import android.content.Intent;
import android.opengl.GLSurfaceView;
import android.os.Bundle;
import android.app.AlertDialog;
import android.util.Log;
import android.view.LayoutInflater;
import android.view.View;
import android.view.ViewGroup;
import android.widget.ImageButton;
import android.widget.LinearLayout;
import android.widget.TextView;
import android.widget.Toast;

import java.io.IOException;

/**
 * UI fragment for the third test.
 */
public class ComplexMovementFragment extends BaseUiFragment implements ComplexMovementListener {
    private static final String TAG = ""ComplexMovementFragment"";

    private TextView mTvObjective;
    private TextView mTvRings;

    /**
     * Standard practice to have a static newInstance constructor. Used to pass in arguments to the
     * fragment. We don't have any at the moment, but this is good structure for the future.
     *
     * @return a new Robustness test fragment.
     */
    public static ComplexMovementFragment newInstance() {
        return new ComplexMovementFragment();
    }

    /**
     * Called when the parent activity has been created. Adds the GLSurfaceView to the fragment
     * layout.
     */
    @Override
    public void onActivityCreated(Bundle savedInstanceState) {
        super.onActivityCreated(savedInstanceState);

        GLSurfaceView surfaceView = new GLSurfaceView(getActivity());
        surfaceView.setEGLContextClientVersion(2);
        mRenderer = new ComplexMovementRenderer(getActivity(), mActivity.getRings());
        surfaceView.setRenderer(mRenderer);
        mLLCameraLayout = (LinearLayout) getView().findViewById(R.id.llCamera);
        mLLCameraLayout.addView(surfaceView);
        Log.d(TAG, ""Camera Preview add to layout"");
    }

    /**
     * Initialises all of the UI elements
     */
    @Override
    public View onCreateView(LayoutInflater inflater, ViewGroup container,
                             Bundle savedInstanceState) {
        View view = inflater.inflate(R.layout.fragment_complex_movement, container, false);
        getActivity().setTitle(getResources().getStringArray(R.array.phase)[TestActivity.CTSTest.COMPLEX_MOVEMENT.ordinal()]);

        // Set up pass/info/fail buttons.
        setupButtons(view, TestActivity.CTSTest.COMPLEX_MOVEMENT);

        mPlaceWaypointButton = (ImageButton) view.findViewById(R.id.fabPlaceWaypoint);
        mPlaceWaypointButton.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                try {
                    mActivity.attemptWaypointPlacement();
                } catch (WaypointAreaCoveredException e) {
                    Toast.makeText(getActivity(),
                            getString(R.string.error_area), Toast.LENGTH_SHORT).show();
                } catch (WaypointDistanceException e) {
                    Toast.makeText(getActivity(),
                            getString(R.string.error_distance), Toast.LENGTH_SHORT).show();
                } catch (WaypointStartPointException e) {
                    Toast.makeText(getActivity(),
                            getString(R.string.error_start_point), Toast.LENGTH_SHORT).show();
                } catch (WaypointRingNotEnteredException e) {
                    Toast.makeText(getActivity(),
                            getString(R.string.error_rings_not_entered), Toast.LENGTH_SHORT).show();
                }
            }
        });

        mTvObjective = (TextView) view.findViewById(R.id.tvObjective);
        mTvRings = (TextView) view.findViewById(R.id.tvRings);

        return view;
    }

    /**
     * Called after onCreateView. Starts listening for 6DoF events.
     */
    @Override
    public void onViewCreated(View view, Bundle savedInstanceState) {
        super.onViewCreated(view, savedInstanceState);
        mActivity.listenFor6DofData(this);
    }

    @Override
    protected void setupUILoop() {
        Runnable runnable = new Runnable() {
            @Override
            public void run() {
                if (mActivity == null || getActivity() == null) {
                    return;
                }

                int waypointCount = mActivity.getUserGeneratedWaypoints(Manager.Lap.LAP_4).size();
                mTvObjective.setText(getObjectiveText(Manager.Lap.LAP_4, waypointCount));

                int ringCount = 0;
                for (Ring ring : mActivity.getRings()) {
                    if (ring.getPathNumber() == waypointCount && ring.isEntered()) {
                        ringCount++;
                    }
                }

                mTvRings.setText(String.format(getString(R.string.rings_entered),
                        ringCount, ComplexMovementPath.RINGS_PER_PATH));

                if (waypointCount < Manager.MAX_MARKER_NUMBER) {
                    mPlaceWaypointButton.setVisibility(View.VISIBLE);
                }

                // Update the UI again in x milliseconds.
                if (mHandler != null) {
                    mHandler.postDelayed(this, UI_UPDATE_DELAY);
                }
            }
        };

        super.initUIHandler(runnable);
    }

    /**
     * Shows initial instruction dialog
     */
    @Override
    protected void showInitialDialog() {
        AlertDialog.Builder builder = new AlertDialog.Builder(getActivity());

        builder.setMessage(R.string.phase3_initial_message)
                .setTitle(getResources().getStringArray(R.array.phase)[TestActivity.CTSTest.COMPLEX_MOVEMENT.ordinal()])
                .setPositiveButton(R.string.got_it, null);

        AlertDialog dialog = builder.create();
        dialog.show();
    }

    @Override
    public void onWaypointPlaced() {
        super.onWaypointPlaced();
        ((ComplexMovementRenderer) mRenderer).onWaypointPlaced(mActivity.getUserGeneratedWaypoints(Manager.Lap.LAP_4).size());
    }

    @Override
    public void onRingEntered(Ring ring) {
        ((ComplexMovementRenderer) mRenderer).onRingEntered(ring);
    }

    @Override
    public void onResult(ResultObject result) {
        ComplexMovementResultDialog dialog = ComplexMovementResultDialog.newInstance(result);
        dialog.setTargetFragment(ComplexMovementFragment.this, DIALOG_FRAGMENT);
        dialog.show(getActivity().getFragmentManager(), ""ResultDialogFragment"");
        mPlaceWaypointButton.setVisibility(View.INVISIBLE);

        if (result.hasPassed() || BuildConfig.DEBUG) {
            mBtnPass.setEnabled(true);
            mBtnPass.setOnClickListener(new View.OnClickListener() {
                @Override
                public void onClick(View view) {
                    finishTest();
                }
            });
        }
    }

    private void finishTest() {
        Intent resultIntent = getActivity().getIntent();
        String report = ""Couldn't create test report."";
        try {
            report = mActivity.getTestReport().getContents();
        } catch (IOException e) {
            Log.e(TAG, report);
        }
        resultIntent.putExtra(TestActivity.EXTRA_REPORT, report);
        resultIntent.putExtra(TestActivity.EXTRA_RESULT_ID, StartActivity.ResultCode.PASSED);
        getActivity().setResult(Activity.RESULT_OK, resultIntent);
        getActivity().finish();
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"android.hardware.camera2.cts.RecordingTest"	"testRecordingWithDifferentPreviewSizes"	"CtsCameraTestCases"	"/home/gpoor/cts-12-source/cts/tests/camera/src/android/hardware/camera2/cts/RecordingTest.java"	""	"public void testRecordingWithDifferentPreviewSizes() throws Exception {
        if (!MediaUtils.checkCodecForDomain(true /* encoder */, ""video"")) {
            return; // skipped
        }
        mPersistentSurface = MediaCodec.createPersistentInputSurface();
        assertNotNull(""Failed to create persistent input surface!"", mPersistentSurface);

        try {
            doRecordingWithDifferentPreviewSizes();
        } finally {
            mPersistentSurface.release();
            mPersistentSurface = null;
        }
    }

    public void doRecordingWithDifferentPreviewSizes() throws Exception {
        for (int i = 0; i < mCameraIdsUnderTest.length; i++) {
            try {
                Log.i(TAG, ""Testing recording with different preview sizes for camera "" +
                        mCameraIdsUnderTest[i]);
                StaticMetadata staticInfo = mAllStaticInfo.get(mCameraIdsUnderTest[i]);
                if (!staticInfo.isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support color outputs, skipping"");
                    continue;
                }
                if (staticInfo.isExternalCamera()) {
                    Log.i(TAG, ""Camera "" + mCameraIdsUnderTest[i] +
                            "" does not support CamcorderProfile, skipping"");
                    continue;
                }
                // Re-use the MediaRecorder object for the same camera device.
                mMediaRecorder = new MediaRecorder();
                openDevice(mCameraIdsUnderTest[i]);

                initSupportedVideoSize(mCameraIdsUnderTest[i]);

                Size maxPreviewSize = mOrderedPreviewSizes.get(0);
                List<Range<Integer> > fpsRanges = Arrays.asList(
                        mStaticInfo.getAeAvailableTargetFpsRangesChecked());
                int cameraId = Integer.valueOf(mCamera.getId());
                int maxVideoFrameRate = -1;
                for (int profileId : mCamcorderProfileList) {
                    if (!CamcorderProfile.hasProfile(cameraId, profileId)) {
                        continue;
                    }
                    CamcorderProfile profile = CamcorderProfile.get(cameraId, profileId);

                    Size videoSz = new Size(profile.videoFrameWidth, profile.videoFrameHeight);
                    Range<Integer> fpsRange = new Range(
                            profile.videoFrameRate, profile.videoFrameRate);
                    if (maxVideoFrameRate < profile.videoFrameRate) {
                        maxVideoFrameRate = profile.videoFrameRate;
                    }

                    if (allowedUnsupported(cameraId, profileId)) {
                        continue;
                    }

                    if (mStaticInfo.isHardwareLevelLegacy() &&
                            (videoSz.getWidth() > maxPreviewSize.getWidth() ||
                             videoSz.getHeight() > maxPreviewSize.getHeight())) {
                        // Skip. Legacy mode can only do recording up to max preview size
                        continue;
                    }
                    assertTrue(""Video size "" + videoSz.toString() + "" for profile ID "" + profileId +
                                    "" must be one of the camera device supported video size!"",
                                    mSupportedVideoSizes.contains(videoSz));
                    assertTrue(""Frame rate range "" + fpsRange + "" (for profile ID "" + profileId +
                            "") must be one of the camera device available FPS range!"",
                            fpsRanges.contains(fpsRange));

                    // Configure preview and recording surfaces.
                    mOutMediaFileName = mDebugFileNameBase + ""/test_video_surface_reconfig.mp4"";

                    // prepare preview surface by using video size.
                    List<Size> previewSizes = getPreviewSizesForVideo(videoSz,
                            profile.videoFrameRate);
                    if (previewSizes.size() <= 1) {
                        continue;
                    }

                    // 1. Do video recording using largest compatbile preview sizes
                    prepareRecordingWithProfile(profile);
                    updatePreviewSurface(previewSizes.get(0));
                    SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
                    startRecording(
                            /* useMediaRecorder */true, resultListener,
                            /*useVideoStab*/false, fpsRange, false);
                    SystemClock.sleep(RECORDING_DURATION_MS);
                    stopRecording(/* useMediaRecorder */true, /* useIntermediateSurface */false,
                            /* stopStreaming */false);

                    // 2. Reconfigure with the same recording surface, but switch to a smaller
                    // preview size.
                    prepareRecordingWithProfile(profile);
                    updatePreviewSurface(previewSizes.get(1));
                    SimpleCaptureCallback resultListener2 = new SimpleCaptureCallback();
                    startRecording(
                            /* useMediaRecorder */true, resultListener2,
                            /*useVideoStab*/false, fpsRange, false);
                    SystemClock.sleep(RECORDING_DURATION_MS);
                    stopRecording(/* useMediaRecorder */true);
                    break;
                }
            } finally {
                closeDevice();
                releaseRecorder();
            }
        }
    }

    /**
     * Test camera preview and video surface sharing for maximum supported size.
     */
    private void videoPreviewSurfaceSharingTestByCamera() throws Exception {
        for (Size sz : mOrderedPreviewSizes) {
            if (!isSupported(sz, VIDEO_FRAME_RATE, VIDEO_FRAME_RATE)) {
                continue;
            }

            if (VERBOSE) {
                Log.v(TAG, ""Testing camera recording with video size "" + sz.toString());
            }

            // Configure preview and recording surfaces.
            mOutMediaFileName = mDebugFileNameBase + ""/test_video_share.mp4"";
            if (DEBUG_DUMP) {
                mOutMediaFileName = mDebugFileNameBase + ""/test_video_share_"" + mCamera.getId() +
                    ""_"" + sz.toString() + "".mp4"";
            }

            // Allow external camera to use variable fps range
            Range<Integer> fpsRange = null;
            if (mStaticInfo.isExternalCamera()) {
                Range<Integer>[] availableFpsRange =
                        mStaticInfo.getAeAvailableTargetFpsRangesChecked();

                boolean foundRange = false;
                int minFps = 0;
                for (int i = 0; i < availableFpsRange.length; i += 1) {
                    if (minFps < availableFpsRange[i].getLower()
                            && VIDEO_FRAME_RATE == availableFpsRange[i].getUpper()) {
                        minFps = availableFpsRange[i].getLower();
                        foundRange = true;
                    }
                }
                assertTrue(""Cannot find FPS range for maxFps "" + VIDEO_FRAME_RATE, foundRange);
                fpsRange = Range.create(minFps, VIDEO_FRAME_RATE);
            }

            // Use AVC and AAC a/v compression format.
            prepareRecording(sz, VIDEO_FRAME_RATE, VIDEO_FRAME_RATE);

            // prepare preview surface by using video size.
            updatePreviewSurfaceWithVideo(sz, VIDEO_FRAME_RATE);

            // Start recording
            SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
            if (!startSharedRecording(/* useMediaRecorder */true, resultListener,
                    /*useVideoStab*/false, fpsRange)) {
                mMediaRecorder.reset();
                continue;
            }

            // Record certain duration.
            SystemClock.sleep(RECORDING_DURATION_MS);

            // Stop recording and preview
            stopRecording(/* useMediaRecorder */true);
            // Convert number of frames camera produced into the duration in unit of ms.
            float frameDurationMinMs = 1000.0f / VIDEO_FRAME_RATE;
            float durationMinMs = resultListener.getTotalNumFrames() * frameDurationMinMs;
            float durationMaxMs = durationMinMs;
            float frameDurationMaxMs = 0.f;
            if (fpsRange != null) {
                frameDurationMaxMs = 1000.0f / fpsRange.getLower();
                durationMaxMs = resultListener.getTotalNumFrames() * frameDurationMaxMs;
            }

            // Validation.
            validateRecording(sz, durationMinMs, durationMaxMs,
                    frameDurationMinMs, frameDurationMaxMs,
                    FRMDRP_RATE_TOLERANCE);

            break;
        }
    }

    /**
     * Test slow motion recording where capture rate (camera output) is different with
     * video (playback) frame rate for each camera if high speed recording is supported
     * by both camera and encoder.
     *
     * <p>
     * Normal recording use cases make the capture rate (camera output frame
     * rate) the same as the video (playback) frame rate. This guarantees that
     * the motions in the scene play at the normal speed. If the capture rate is
     * faster than video frame rate, for a given time duration, more number of
     * frames are captured than it can be played in the same time duration. This
     * generates ""slow motion"" effect during playback.
     * </p>
     */
    private void slowMotionRecording() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.i(TAG, ""Testing slow motion recording for camera "" + id);
                StaticMetadata staticInfo = mAllStaticInfo.get(id);
                if (!staticInfo.isColorOutputSupported()) {
                    Log.i(TAG, ""Camera "" + id +
                            "" does not support color outputs, skipping"");
                    continue;
                }
                if (!staticInfo.isHighSpeedVideoSupported()) {
                    continue;
                }

                // Re-use the MediaRecorder object for the same camera device.
                mMediaRecorder = new MediaRecorder();
                openDevice(id);

                StreamConfigurationMap config =
                        mStaticInfo.getValueFromKeyNonNull(
                                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
                Size[] highSpeedVideoSizes = config.getHighSpeedVideoSizes();
                for (Size size : highSpeedVideoSizes) {
                    Range<Integer> fpsRange = getHighestHighSpeedFixedFpsRangeForSize(config, size);
                    mCollector.expectNotNull(""Unable to find the fixed frame rate fps range for "" +
                            ""size "" + size, fpsRange);
                    if (fpsRange == null) {
                        continue;
                    }

                    int captureRate = fpsRange.getLower();
                    int videoFramerate = captureRate / SLOWMO_SLOW_FACTOR;
                    // Skip the test if the highest recording FPS supported by CamcorderProfile
                    if (fpsRange.getUpper() > getFpsFromHighSpeedProfileForSize(size)) {
                        Log.w(TAG, ""high speed recording "" + size + ""@"" + captureRate + ""fps""
                                + "" is not supported by CamcorderProfile"");
                        continue;
                    }

                    mOutMediaFileName = mDebugFileNameBase + ""/test_slowMo_video.mp4"";
                    if (DEBUG_DUMP) {
                        mOutMediaFileName = mDebugFileNameBase + ""/test_slowMo_video_"" + id + ""_""
                                + size.toString() + "".mp4"";
                    }

                    prepareRecording(size, videoFramerate, captureRate);

                    // prepare preview surface by using video size.
                    updatePreviewSurfaceWithVideo(size, captureRate);

                    // Start recording
                    SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
                    startSlowMotionRecording(/*useMediaRecorder*/true, videoFramerate, captureRate,
                            fpsRange, resultListener, /*useHighSpeedSession*/false);

                    // Record certain duration.
                    SystemClock.sleep(RECORDING_DURATION_MS);

                    // Stop recording and preview
                    stopRecording(/*useMediaRecorder*/true);
                    // Convert number of frames camera produced into the duration in unit of ms.
                    float frameDurationMs = 1000.0f / videoFramerate;
                    float durationMs = resultListener.getTotalNumFrames() * frameDurationMs;

                    // Validation.
                    validateRecording(size, durationMs, frameDurationMs, FRMDRP_RATE_TOLERANCE);
                }

            } finally {
                closeDevice();
                releaseRecorder();
            }
        }
    }

    private void constrainedHighSpeedRecording() throws Exception {
        for (String id : mCameraIdsUnderTest) {
            try {
                Log.i(TAG, ""Testing constrained high speed recording for camera "" + id);

                if (!mAllStaticInfo.get(id).isConstrainedHighSpeedVideoSupported()) {
                    Log.i(TAG, ""Camera "" + id + "" doesn't support high speed recording, skipping."");
                    continue;
                }

                // Re-use the MediaRecorder object for the same camera device.
                mMediaRecorder = new MediaRecorder();
                openDevice(id);

                StreamConfigurationMap config =
                        mStaticInfo.getValueFromKeyNonNull(
                                CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
                Size[] highSpeedVideoSizes = config.getHighSpeedVideoSizes();
                for (Size size : highSpeedVideoSizes) {
                    List<Range<Integer>> fixedFpsRanges =
                            getHighSpeedFixedFpsRangeForSize(config, size);
                    mCollector.expectTrue(""Unable to find the fixed frame rate fps range for "" +
                            ""size "" + size, fixedFpsRanges.size() > 0);
                    // Test recording for each FPS range
                    for (Range<Integer> fpsRange : fixedFpsRanges) {
                        int captureRate = fpsRange.getLower();
                        final int VIDEO_FRAME_RATE = 30;
                        // Skip the test if the highest recording FPS supported by CamcorderProfile
                        if (fpsRange.getUpper() > getFpsFromHighSpeedProfileForSize(size)) {
                            Log.w(TAG, ""high speed recording "" + size + ""@"" + captureRate + ""fps""
                                    + "" is not supported by CamcorderProfile"");
                            continue;
                        }

                        SimpleCaptureCallback previewResultListener = new SimpleCaptureCallback();

                        // prepare preview surface by using video size.
                        updatePreviewSurfaceWithVideo(size, captureRate);

                        startConstrainedPreview(fpsRange, previewResultListener);

                        mOutMediaFileName = mDebugFileNameBase + ""/test_cslowMo_video_"" +
                            captureRate + ""fps_"" + id + ""_"" + size.toString() + "".mp4"";

                        prepareRecording(size, VIDEO_FRAME_RATE, captureRate);

                        SystemClock.sleep(PREVIEW_DURATION_MS);

                        stopCameraStreaming();

                        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
                        // Start recording
                        startSlowMotionRecording(/*useMediaRecorder*/true, VIDEO_FRAME_RATE,
                                captureRate, fpsRange, resultListener,
                                /*useHighSpeedSession*/true);

                        // Record certain duration.
                        SystemClock.sleep(RECORDING_DURATION_MS);

                        // Stop recording and preview
                        stopRecording(/*useMediaRecorder*/true);

                        startConstrainedPreview(fpsRange, previewResultListener);

                        // Convert number of frames camera produced into the duration in unit of ms.
                        float frameDurationMs = 1000.0f / VIDEO_FRAME_RATE;
                        float durationMs = resultListener.getTotalNumFrames() * frameDurationMs;

                        // Validation.
                        validateRecording(size, durationMs, frameDurationMs, FRMDRP_RATE_TOLERANCE);

                        SystemClock.sleep(PREVIEW_DURATION_MS);

                        stopCameraStreaming();
                    }
                }

            } finally {
                closeDevice();
                releaseRecorder();
            }
        }
    }

    /**
     * Get high speed FPS from CamcorderProfiles for a given size.
     *
     * @param size The size used to search the CamcorderProfiles for the FPS.
     * @return high speed video FPS, 0 if the given size is not supported by the CamcorderProfiles.
     */
    private int getFpsFromHighSpeedProfileForSize(Size size) {
        for (int quality = CamcorderProfile.QUALITY_HIGH_SPEED_480P;
                quality <= CamcorderProfile.QUALITY_HIGH_SPEED_2160P; quality++) {
            if (CamcorderProfile.hasProfile(quality)) {
                CamcorderProfile profile = CamcorderProfile.get(quality);
                if (size.equals(new Size(profile.videoFrameWidth, profile.videoFrameHeight))){
                    return profile.videoFrameRate;
                }
            }
        }

        return 0;
    }

    private Range<Integer> getHighestHighSpeedFixedFpsRangeForSize(StreamConfigurationMap config,
            Size size) {
        Range<Integer>[] availableFpsRanges = config.getHighSpeedVideoFpsRangesFor(size);
        Range<Integer> maxRange = availableFpsRanges[0];
        boolean foundRange = false;
        for (Range<Integer> range : availableFpsRanges) {
            if (range.getLower().equals(range.getUpper()) && range.getLower() >= maxRange.getLower()) {
                foundRange = true;
                maxRange = range;
            }
        }

        if (!foundRange) {
            return null;
        }
        return maxRange;
    }

    private List<Range<Integer>> getHighSpeedFixedFpsRangeForSize(StreamConfigurationMap config,
            Size size) {
        Range<Integer>[] availableFpsRanges = config.getHighSpeedVideoFpsRangesFor(size);
        List<Range<Integer>> fixedRanges = new ArrayList<Range<Integer>>();
        for (Range<Integer> range : availableFpsRanges) {
            if (range.getLower().equals(range.getUpper())) {
                fixedRanges.add(range);
            }
        }
        return fixedRanges;
    }

    private void startConstrainedPreview(Range<Integer> fpsRange,
            CameraCaptureSession.CaptureCallback listener) throws Exception {
        List<Surface> outputSurfaces = new ArrayList<Surface>(1);
        assertTrue(""Preview surface should be valid"", mPreviewSurface.isValid());
        outputSurfaces.add(mPreviewSurface);
        mSessionListener = new BlockingSessionCallback();

        List<CaptureRequest> slowMoRequests = null;
        CaptureRequest.Builder requestBuilder =
            mCamera.createCaptureRequest(CameraDevice.TEMPLATE_RECORD);
        requestBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, fpsRange);
        requestBuilder.addTarget(mPreviewSurface);
        CaptureRequest initialRequest = requestBuilder.build();
        CameraTestUtils.checkSessionConfigurationWithSurfaces(mCamera, mHandler,
                outputSurfaces, /*inputConfig*/ null, SessionConfiguration.SESSION_HIGH_SPEED,
                /*defaultSupport*/ true, ""Constrained session configuration query failed"");
        mSession = buildConstrainedCameraSession(mCamera, outputSurfaces, mSessionListener,
                mHandler, initialRequest);
        slowMoRequests = ((CameraConstrainedHighSpeedCaptureSession) mSession).
            createHighSpeedRequestList(initialRequest);

        mSession.setRepeatingBurst(slowMoRequests, listener, mHandler);
    }

    private void startSlowMotionRecording(boolean useMediaRecorder, int videoFrameRate,
            int captureRate, Range<Integer> fpsRange,
            CameraCaptureSession.CaptureCallback listener, boolean useHighSpeedSession)
            throws Exception {
        List<Surface> outputSurfaces = new ArrayList<Surface>(2);
        assertTrue(""Both preview and recording surfaces should be valid"",
                mPreviewSurface.isValid() && mRecordingSurface.isValid());
        outputSurfaces.add(mPreviewSurface);
        outputSurfaces.add(mRecordingSurface);
        // Video snapshot surface
        if (mReaderSurface != null) {
            outputSurfaces.add(mReaderSurface);
        }
        mSessionListener = new BlockingSessionCallback();

        // Create slow motion request list
        List<CaptureRequest> slowMoRequests = null;
        if (useHighSpeedSession) {
            CaptureRequest.Builder requestBuilder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_RECORD);
            requestBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, fpsRange);
            requestBuilder.addTarget(mPreviewSurface);
            requestBuilder.addTarget(mRecordingSurface);
            CaptureRequest initialRequest = requestBuilder.build();
            mSession = buildConstrainedCameraSession(mCamera, outputSurfaces, mSessionListener,
                    mHandler, initialRequest);
            slowMoRequests = ((CameraConstrainedHighSpeedCaptureSession) mSession).
                    createHighSpeedRequestList(initialRequest);
        } else {
            CaptureRequest.Builder recordingRequestBuilder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_RECORD);
            recordingRequestBuilder.set(CaptureRequest.CONTROL_MODE,
                    CaptureRequest.CONTROL_MODE_USE_SCENE_MODE);
            recordingRequestBuilder.set(CaptureRequest.CONTROL_SCENE_MODE,
                    CaptureRequest.CONTROL_SCENE_MODE_HIGH_SPEED_VIDEO);

            CaptureRequest.Builder recordingOnlyBuilder =
                    mCamera.createCaptureRequest(CameraDevice.TEMPLATE_RECORD);
            recordingOnlyBuilder.set(CaptureRequest.CONTROL_MODE,
                    CaptureRequest.CONTROL_MODE_USE_SCENE_MODE);
            recordingOnlyBuilder.set(CaptureRequest.CONTROL_SCENE_MODE,
                    CaptureRequest.CONTROL_SCENE_MODE_HIGH_SPEED_VIDEO);
            int slowMotionFactor = captureRate / videoFrameRate;

            // Make sure camera output frame rate is set to correct value.
            recordingRequestBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, fpsRange);
            recordingRequestBuilder.addTarget(mRecordingSurface);
            recordingRequestBuilder.addTarget(mPreviewSurface);
            recordingOnlyBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, fpsRange);
            recordingOnlyBuilder.addTarget(mRecordingSurface);

            CaptureRequest initialRequest = recordingRequestBuilder.build();
            mSession = configureCameraSessionWithParameters(mCamera, outputSurfaces,
                    mSessionListener, mHandler, initialRequest);

            slowMoRequests = new ArrayList<CaptureRequest>();
            slowMoRequests.add(initialRequest);// Preview + recording.

            for (int i = 0; i < slowMotionFactor - 1; i++) {
                slowMoRequests.add(recordingOnlyBuilder.build()); // Recording only.
            }
        }

        mSession.setRepeatingBurst(slowMoRequests, listener, mHandler);

        if (useMediaRecorder) {
            mMediaRecorder.start();
        } else {
            // TODO: need implement MediaCodec path.
        }

    }

    private void basicRecordingTestByCamera(int[] camcorderProfileList, boolean useVideoStab)
            throws Exception {
        basicRecordingTestByCamera(camcorderProfileList, useVideoStab, false);
    }

    private void basicRecordingTestByCamera(int[] camcorderProfileList, boolean useVideoStab,
            boolean useIntermediateSurface) throws Exception {
        basicRecordingTestByCamera(camcorderProfileList, useVideoStab,
                useIntermediateSurface, false);
    }

    /**
     * Test camera recording by using each available CamcorderProfile for a
     * given camera. preview size is set to the video size.
     */
    private void basicRecordingTestByCamera(int[] camcorderProfileList, boolean useVideoStab,
            boolean useIntermediateSurface, boolean useEncoderProfiles) throws Exception {
        Size maxPreviewSize = mOrderedPreviewSizes.get(0);
        List<Range<Integer> > fpsRanges = Arrays.asList(
                mStaticInfo.getAeAvailableTargetFpsRangesChecked());
        int cameraId = Integer.valueOf(mCamera.getId());
        int maxVideoFrameRate = -1;

        // only validate recording for non-perf measurement runs
        boolean validateRecording = !isPerfMeasure();
        for (int profileId : camcorderProfileList) {
            if (!CamcorderProfile.hasProfile(cameraId, profileId)) {
                continue;
            }

            CamcorderProfile profile = CamcorderProfile.get(cameraId, profileId);
            Size videoSz = new Size(profile.videoFrameWidth, profile.videoFrameHeight);

            Range<Integer> fpsRange = new Range(profile.videoFrameRate, profile.videoFrameRate);
            if (maxVideoFrameRate < profile.videoFrameRate) {
                maxVideoFrameRate = profile.videoFrameRate;
            }

            if (allowedUnsupported(cameraId, profileId)) {
                continue;
            }

            if (mStaticInfo.isHardwareLevelLegacy() &&
                    (videoSz.getWidth() > maxPreviewSize.getWidth() ||
                     videoSz.getHeight() > maxPreviewSize.getHeight())) {
                // Skip. Legacy mode can only do recording up to max preview size
                continue;
            }
            assertTrue(""Video size "" + videoSz.toString() + "" for profile ID "" + profileId +
                            "" must be one of the camera device supported video size!"",
                            mSupportedVideoSizes.contains(videoSz));
            assertTrue(""Frame rate range "" + fpsRange + "" (for profile ID "" + profileId +
                    "") must be one of the camera device available FPS range!"",
                    fpsRanges.contains(fpsRange));


            if (useEncoderProfiles) {
                // Iterate through all video-audio codec combination
                EncoderProfiles profiles = CamcorderProfile.getAll(mCamera.getId(), profileId);
                for (EncoderProfiles.VideoProfile videoProfile : profiles.getVideoProfiles()) {
                    boolean hasAudioProfile = false;
                    for (EncoderProfiles.AudioProfile audioProfile : profiles.getAudioProfiles()) {
                        hasAudioProfile = true;
                        doBasicRecordingByProfile(profiles, videoProfile, audioProfile,
                                useVideoStab, useIntermediateSurface, validateRecording);
                        // Only measure the default video profile of the largest video
                        // recording size when measuring perf
                        if (isPerfMeasure()) {
                            break;
                        }
                    }
                    // Timelapse profiles do not have audio track
                    if (!hasAudioProfile) {
                        doBasicRecordingByProfile(profiles, videoProfile, /* audioProfile */null,
                                useVideoStab, useIntermediateSurface, validateRecording);
                    }
                }
            } else {
                doBasicRecordingByProfile(
                        profile, useVideoStab, useIntermediateSurface, validateRecording);
            }

            if (isPerfMeasure()) {
                // Only measure the largest video recording size when measuring perf
                break;
            }
        }
        if (maxVideoFrameRate != -1) {
            // At least one CamcorderProfile is present, check FPS
            assertTrue(""At least one CamcorderProfile must support >= 24 FPS"",
                    maxVideoFrameRate >= 24);
        }
    }

    private void doBasicRecordingByProfile(
            CamcorderProfile profile, boolean userVideoStab,
            boolean useIntermediateSurface, boolean validate) throws Exception {
        Size videoSz = new Size(profile.videoFrameWidth, profile.videoFrameHeight);
        int frameRate = profile.videoFrameRate;

        if (VERBOSE) {
            Log.v(TAG, ""Testing camera recording with video size "" + videoSz.toString());
        }

        // Configure preview and recording surfaces.
        mOutMediaFileName = mDebugFileNameBase + ""/test_video.mp4"";
        if (DEBUG_DUMP) {
            mOutMediaFileName = mDebugFileNameBase + ""/test_video_"" + mCamera.getId() + ""_""
                    + videoSz.toString() + "".mp4"";
        }

        setupMediaRecorder(profile);
        completeBasicRecording(videoSz, frameRate, userVideoStab, useIntermediateSurface, validate);
    }

    private void doBasicRecordingByProfile(
            EncoderProfiles profiles,
            EncoderProfiles.VideoProfile videoProfile, EncoderProfiles.AudioProfile audioProfile,
            boolean userVideoStab, boolean useIntermediateSurface, boolean validate)
                    throws Exception {
        Size videoSz = new Size(videoProfile.getWidth(), videoProfile.getHeight());
        int frameRate = videoProfile.getFrameRate();

        if (VERBOSE) {
            Log.v(TAG, ""Testing camera recording with video size "" + videoSz.toString() +
                  "", video codec "" + videoProfile.getMediaType() + "", and audio codec "" +
                  (audioProfile == null ? ""(null)"" : audioProfile.getMediaType()));
        }

        // Configure preview and recording surfaces.
        mOutMediaFileName = mDebugFileNameBase + ""/test_video.mp4"";
        if (DEBUG_DUMP) {
            mOutMediaFileName = mDebugFileNameBase + ""/test_video_"" + mCamera.getId() + ""_""
                    + videoSz.toString() + ""_"" + videoProfile.getCodec();
            if (audioProfile != null) {
                mOutMediaFileName += ""_"" + audioProfile.getCodec();
            }
            mOutMediaFileName += "".mp4"";
        }

        setupMediaRecorder(profiles, videoProfile, audioProfile);
        completeBasicRecording(videoSz, frameRate, userVideoStab, useIntermediateSurface, validate);
    }

    private void completeBasicRecording(
            Size videoSz, int frameRate, boolean useVideoStab,
            boolean useIntermediateSurface, boolean validate) throws Exception {
        prepareRecording(useIntermediateSurface);

        // prepare preview surface by using video size.
        updatePreviewSurfaceWithVideo(videoSz, frameRate);

        // Start recording
        SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
        startRecording(/* useMediaRecorder */true, resultListener, useVideoStab,
                useIntermediateSurface);

        // Record certain duration.
        SystemClock.sleep(RECORDING_DURATION_MS);

        // Stop recording and preview
        stopRecording(/* useMediaRecorder */true, useIntermediateSurface,
                /* stopCameraStreaming */true);
        // Convert number of frames camera produced into the duration in unit of ms.
        float frameDurationMs = 1000.0f / frameRate;
        float durationMs = 0.f;
        if (useIntermediateSurface) {
            durationMs = mQueuer.getQueuedCount() * frameDurationMs;
        } else {
            durationMs = resultListener.getTotalNumFrames() * frameDurationMs;
        }

        if (VERBOSE) {
            Log.v(TAG, ""video frame rate: "" + frameRate +
                            "", num of frames produced: "" + resultListener.getTotalNumFrames());
        }

        if (validate) {
            validateRecording(videoSz, durationMs, frameDurationMs, FRMDRP_RATE_TOLERANCE);
        }
    }

    /**
     * Test camera recording for each supported video size by camera, preview
     * size is set to the video size.
     */
    private void recordingSizeTestByCamera() throws Exception {
        for (Size sz : mSupportedVideoSizes) {
            if (!isSupported(sz, VIDEO_FRAME_RATE, VIDEO_FRAME_RATE)) {
                continue;
            }

            if (VERBOSE) {
                Log.v(TAG, ""Testing camera recording with video size "" + sz.toString());
            }

            // Configure preview and recording surfaces.
            mOutMediaFileName = mDebugFileNameBase + ""/test_video.mp4"";
            if (DEBUG_DUMP) {
                mOutMediaFileName = mDebugFileNameBase + ""/test_video_"" + mCamera.getId() + ""_""
                        + sz.toString() + "".mp4"";
            }

            // Allow external camera to use variable fps range
            Range<Integer> fpsRange = null;
            if (mStaticInfo.isExternalCamera()) {
                Range<Integer>[] availableFpsRange =
                        mStaticInfo.getAeAvailableTargetFpsRangesChecked();

                boolean foundRange = false;
                int minFps = 0;
                for (int i = 0; i < availableFpsRange.length; i += 1) {
                    if (minFps < availableFpsRange[i].getLower()
                            && VIDEO_FRAME_RATE == availableFpsRange[i].getUpper()) {
                        minFps = availableFpsRange[i].getLower();
                        foundRange = true;
                    }
                }
                assertTrue(""Cannot find FPS range for maxFps "" + VIDEO_FRAME_RATE, foundRange);
                fpsRange = Range.create(minFps, VIDEO_FRAME_RATE);
            }

            // Use AVC and AAC a/v compression format.
            prepareRecording(sz, VIDEO_FRAME_RATE, VIDEO_FRAME_RATE);

            // prepare preview surface by using video size.
            updatePreviewSurfaceWithVideo(sz, VIDEO_FRAME_RATE);

            // Start recording
            SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
            startRecording(
                    /* useMediaRecorder */true, resultListener,
                    /*useVideoStab*/false, fpsRange, false);

            // Record certain duration.
            SystemClock.sleep(RECORDING_DURATION_MS);

            // Stop recording and preview
            stopRecording(/* useMediaRecorder */true);
            // Convert number of frames camera produced into the duration in unit of ms.
            float frameDurationMinMs = 1000.0f / VIDEO_FRAME_RATE;
            float durationMinMs = resultListener.getTotalNumFrames() * frameDurationMinMs;
            float durationMaxMs = durationMinMs;
            float frameDurationMaxMs = 0.f;
            if (fpsRange != null) {
                frameDurationMaxMs = 1000.0f / fpsRange.getLower();
                durationMaxMs = resultListener.getTotalNumFrames() * frameDurationMaxMs;
            }

            // Validation.
            validateRecording(sz, durationMinMs, durationMaxMs,
                    frameDurationMinMs, frameDurationMaxMs,
                    FRMDRP_RATE_TOLERANCE);
        }
    }

    /**
     * Initialize the supported video sizes.
     */
    private void initSupportedVideoSize(String cameraId)  throws Exception {
        int id = Integer.valueOf(cameraId);
        Size maxVideoSize = SIZE_BOUND_720P;
        if (CamcorderProfile.hasProfile(id, CamcorderProfile.QUALITY_2160P)) {
            maxVideoSize = SIZE_BOUND_2160P;
        } else if (CamcorderProfile.hasProfile(id, CamcorderProfile.QUALITY_QHD)) {
            maxVideoSize = SIZE_BOUND_QHD;
        } else if (CamcorderProfile.hasProfile(id, CamcorderProfile.QUALITY_2K)) {
            maxVideoSize = SIZE_BOUND_2K;
        } else if (CamcorderProfile.hasProfile(id, CamcorderProfile.QUALITY_1080P)) {
            maxVideoSize = SIZE_BOUND_1080P;
        }

        mSupportedVideoSizes =
                getSupportedVideoSizes(cameraId, mCameraManager, maxVideoSize);
    }

    /**
     * Simple wrapper to wrap normal/burst video snapshot tests
     */
    private void videoSnapshotHelper(boolean burstTest) throws Exception {
            for (String id : mCameraIdsUnderTest) {
                try {
                    Log.i(TAG, ""Testing video snapshot for camera "" + id);

                    StaticMetadata staticInfo = mAllStaticInfo.get(id);
                    if (!staticInfo.isColorOutputSupported()) {
                        Log.i(TAG, ""Camera "" + id +
                                "" does not support color outputs, skipping"");
                        continue;
                    }

                    if (staticInfo.isExternalCamera()) {
                        Log.i(TAG, ""Camera "" + id +
                                "" does not support CamcorderProfile, skipping"");
                        continue;
                    }

                    // Re-use the MediaRecorder object for the same camera device.
                    mMediaRecorder = new MediaRecorder();

                    openDevice(id);

                    initSupportedVideoSize(id);

                    videoSnapshotTestByCamera(burstTest);
                } finally {
                    closeDevice();
                    releaseRecorder();
                }
            }
    }

    /**
     * Returns {@code true} if the {@link CamcorderProfile} ID is allowed to be unsupported.
     *
     * <p>This only allows unsupported profiles when using the LEGACY mode of the Camera API.</p>
     *
     * @param profileId a {@link CamcorderProfile} ID to check.
     * @return {@code true} if supported.
     */
    private boolean allowedUnsupported(int cameraId, int profileId) {
        if (!mStaticInfo.isHardwareLevelLegacy()) {
            return false;
        }

        switch(profileId) {
            case CamcorderProfile.QUALITY_2160P:
            case CamcorderProfile.QUALITY_1080P:
            case CamcorderProfile.QUALITY_HIGH:
                return !CamcorderProfile.hasProfile(cameraId, profileId) ||
                        CamcorderProfile.get(cameraId, profileId).videoFrameWidth >= 1080;
        }
        return false;
    }

    /**
     * Test video snapshot for each  available CamcorderProfile for a given camera.
     *
     * <p>
     * Preview size is set to the video size. For the burst test, frame drop and jittering
     * is not checked.
     * </p>
     *
     * @param burstTest Perform burst capture or single capture. For burst capture
     *                  {@value #BURST_VIDEO_SNAPSHOT_NUM} capture requests will be sent.
     */
    private void videoSnapshotTestByCamera(boolean burstTest)
            throws Exception {
        final int NUM_SINGLE_SHOT_TEST = 5;
        final int FRAMEDROP_TOLERANCE = 8;
        final int FRAME_SIZE_15M = 15000000;
        final float FRAME_DROP_TOLERENCE_FACTOR = 1.5f;
        int kFrameDrop_Tolerence = FRAMEDROP_TOLERANCE;

        for (int profileId : mCamcorderProfileList) {
            int cameraId = Integer.valueOf(mCamera.getId());
            if (!CamcorderProfile.hasProfile(cameraId, profileId) ||
                    allowedUnsupported(cameraId, profileId)) {
                continue;
            }

            CamcorderProfile profile = CamcorderProfile.get(cameraId, profileId);
            Size QCIF = new Size(176, 144);
            Size FULL_HD = new Size(1920, 1080);
            Size videoSz = new Size(profile.videoFrameWidth, profile.videoFrameHeight);
            Size maxPreviewSize = mOrderedPreviewSizes.get(0);

            if (mStaticInfo.isHardwareLevelLegacy() &&
                    (videoSz.getWidth() > maxPreviewSize.getWidth() ||
                     videoSz.getHeight() > maxPreviewSize.getHeight())) {
                // Skip. Legacy mode can only do recording up to max preview size
                continue;
            }

            if (!mSupportedVideoSizes.contains(videoSz)) {
                mCollector.addMessage(""Video size "" + videoSz.toString() + "" for profile ID "" +
                        profileId + "" must be one of the camera device supported video size!"");
                continue;
            }

            // For LEGACY, find closest supported smaller or equal JPEG size to the current video
            // size; if no size is smaller than the video, pick the smallest JPEG size.  The assert
            // for video size above guarantees that for LIMITED or FULL, we select videoSz here.
            // Also check for minFrameDuration here to make sure jpeg stream won't slow down
            // video capture
            Size videoSnapshotSz = mOrderedStillSizes.get(mOrderedStillSizes.size() - 1);
            // Allow a bit tolerance so we don't fail for a few nano seconds of difference
            final float FRAME_DURATION_TOLERANCE = 0.01f;
            long videoFrameDuration = (long) (1e9 / profile.videoFrameRate *
                    (1.0 + FRAME_DURATION_TOLERANCE));
            HashMap<Size, Long> minFrameDurationMap = mStaticInfo.
                    getAvailableMinFrameDurationsForFormatChecked(ImageFormat.JPEG);
            for (int i = mOrderedStillSizes.size() - 2; i >= 0; i--) {
                Size candidateSize = mOrderedStillSizes.get(i);
                if (mStaticInfo.isHardwareLevelLegacy()) {
                    // Legacy level doesn't report min frame duration
                    if (candidateSize.getWidth() <= videoSz.getWidth() &&
                            candidateSize.getHeight() <= videoSz.getHeight()) {
                        videoSnapshotSz = candidateSize;
                    }
                } else {
                    Long jpegFrameDuration = minFrameDurationMap.get(candidateSize);
                    assertTrue(""Cannot find minimum frame duration for jpeg size "" + candidateSize,
                            jpegFrameDuration != null);
                    if (candidateSize.getWidth() <= videoSz.getWidth() &&
                            candidateSize.getHeight() <= videoSz.getHeight() &&
                            jpegFrameDuration <= videoFrameDuration) {
                        videoSnapshotSz = candidateSize;
                    }
                }
            }
            Size defaultvideoSnapshotSz = videoSnapshotSz;

            /**
             * Only test full res snapshot when below conditions are all true.
             * 1. Camera is at least a LIMITED device.
             * 2. video size is up to max preview size, which will be bounded by 1080p.
             * 3. Full resolution jpeg stream can keep up to video stream speed.
             *    When full res jpeg stream cannot keep up to video stream speed, search
             *    the largest jpeg size that can susptain video speed instead.
             */
            if (mStaticInfo.isHardwareLevelAtLeastLimited() &&
                    videoSz.getWidth() <= maxPreviewSize.getWidth() &&
                    videoSz.getHeight() <= maxPreviewSize.getHeight()) {
                for (Size jpegSize : mOrderedStillSizes) {
                    Long jpegFrameDuration = minFrameDurationMap.get(jpegSize);
                    assertTrue(""Cannot find minimum frame duration for jpeg size "" + jpegSize,
                            jpegFrameDuration != null);
                    if (jpegFrameDuration <= videoFrameDuration) {
                        videoSnapshotSz = jpegSize;
                        break;
                    }
                    if (jpegSize.equals(videoSz)) {
                        throw new AssertionFailedError(
                                ""Cannot find adequate video snapshot size for video size"" +
                                        videoSz);
                    }
                }
            }

            if (videoSnapshotSz.getWidth() * videoSnapshotSz.getHeight() > FRAME_SIZE_15M)
                kFrameDrop_Tolerence = (int)(FRAMEDROP_TOLERANCE * FRAME_DROP_TOLERENCE_FACTOR);

            createImageReader(
                    videoSnapshotSz, ImageFormat.JPEG,
                    MAX_VIDEO_SNAPSHOT_IMAGES, /*listener*/null);

            // Full or better devices should support whatever video snapshot size calculated above.
            // Limited devices may only be able to support the default one.
            if (mStaticInfo.isHardwareLevelLimited()) {
                List<Surface> outputs = new ArrayList<Surface>();
                outputs.add(mPreviewSurface);
                outputs.add(mRecordingSurface);
                outputs.add(mReaderSurface);
                boolean isSupported = isStreamConfigurationSupported(
                        mCamera, outputs, mSessionListener, mHandler);
                if (!isSupported) {
                    videoSnapshotSz = defaultvideoSnapshotSz;
                    createImageReader(
                            videoSnapshotSz, ImageFormat.JPEG,
                            MAX_VIDEO_SNAPSHOT_IMAGES, /*listener*/null);
                }
            }

            if (videoSz.equals(QCIF) &&
                    ((videoSnapshotSz.getWidth() > FULL_HD.getWidth()) ||
                     (videoSnapshotSz.getHeight() > FULL_HD.getHeight()))) {
                List<Surface> outputs = new ArrayList<Surface>();
                outputs.add(mPreviewSurface);
                outputs.add(mRecordingSurface);
                outputs.add(mReaderSurface);
                boolean isSupported = isStreamConfigurationSupported(
                        mCamera, outputs, mSessionListener, mHandler);
                if (!isSupported) {
                    videoSnapshotSz = defaultvideoSnapshotSz;
                    createImageReader(
                            videoSnapshotSz, ImageFormat.JPEG,
                            MAX_VIDEO_SNAPSHOT_IMAGES, /*listener*/null);
                }
            }

            Log.i(TAG, ""Testing video snapshot size "" + videoSnapshotSz +
                    "" for video size "" + videoSz);

            if (VERBOSE) {
                Log.v(TAG, ""Testing camera recording with video size "" + videoSz.toString());
            }

            // Configure preview and recording surfaces.
            mOutMediaFileName = mDebugFileNameBase + ""/test_video.mp4"";
            if (DEBUG_DUMP) {
                mOutMediaFileName = mDebugFileNameBase + ""/test_video_"" + cameraId + ""_""
                        + videoSz.toString() + "".mp4"";
            }

            int numTestIterations = burstTest ? 1 : NUM_SINGLE_SHOT_TEST;
            int totalDroppedFrames = 0;

            for (int numTested = 0; numTested < numTestIterations; numTested++) {
                prepareRecordingWithProfile(profile);

                // prepare video snapshot
                SimpleCaptureCallback resultListener = new SimpleCaptureCallback();
                SimpleImageReaderListener imageListener = new SimpleImageReaderListener();
                CaptureRequest.Builder videoSnapshotRequestBuilder =
                        mCamera.createCaptureRequest((mStaticInfo.isHardwareLevelLegacy()) ?
                                CameraDevice.TEMPLATE_RECORD :
                                CameraDevice.TEMPLATE_VIDEO_SNAPSHOT);

                // prepare preview surface by using video size.
                updatePreviewSurfaceWithVideo(videoSz, profile.videoFrameRate);

                prepareVideoSnapshot(videoSnapshotRequestBuilder, imageListener);
                Range<Integer> fpsRange = Range.create(profile.videoFrameRate,
                        profile.videoFrameRate);
                videoSnapshotRequestBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE,
                        fpsRange);
                if (mStaticInfo.isVideoStabilizationSupported()) {
                    videoSnapshotRequestBuilder.set(CaptureRequest.CONTROL_VIDEO_STABILIZATION_MODE,
                            CaptureRequest.CONTROL_VIDEO_STABILIZATION_MODE_ON);
                }
                CaptureRequest request = videoSnapshotRequestBuilder.build();

                // Start recording
                startRecording(/* useMediaRecorder */true, resultListener,
                        /*useVideoStab*/mStaticInfo.isVideoStabilizationSupported());
                long startTime = SystemClock.elapsedRealtime();

                // Record certain duration.
                SystemClock.sleep(RECORDING_DURATION_MS / 2);

                // take video snapshot
                if (burstTest) {
                    List<CaptureRequest> requests =
                            new ArrayList<CaptureRequest>(BURST_VIDEO_SNAPSHOT_NUM);
                    for (int i = 0; i < BURST_VIDEO_SNAPSHOT_NUM; i++) {
                        requests.add(request);
                    }
                    mSession.captureBurst(requests, resultListener, mHandler);
                } else {
                    mSession.capture(request, resultListener, mHandler);
                }

                // make sure recording is still going after video snapshot
                SystemClock.sleep(RECORDING_DURATION_MS / 2);

                // Stop recording and preview
                float durationMs = (float) stopRecording(/* useMediaRecorder */true);
                // For non-burst test, use number of frames to also double check video frame rate.
                // Burst video snapshot is allowed to cause frame rate drop, so do not use number
                // of frames to estimate duration
                if (!burstTest) {
                    durationMs = resultListener.getTotalNumFrames() * 1000.0f /
                        profile.videoFrameRate;
                }

                float frameDurationMs = 1000.0f / profile.videoFrameRate;
                // Validation recorded video
                validateRecording(videoSz, durationMs,
                        frameDurationMs, VID_SNPSHT_FRMDRP_RATE_TOLERANCE);

                if (burstTest) {
                    for (int i = 0; i < BURST_VIDEO_SNAPSHOT_NUM; i++) {
                        Image image = imageListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
                        validateVideoSnapshotCapture(image, videoSnapshotSz);
                        image.close();
                    }
                } else {
                    // validate video snapshot image
                    Image image = imageListener.getImage(CAPTURE_IMAGE_TIMEOUT_MS);
                    validateVideoSnapshotCapture(image, videoSnapshotSz);

                    // validate if there is framedrop around video snapshot
                    totalDroppedFrames +=  validateFrameDropAroundVideoSnapshot(
                            resultListener, image.getTimestamp());

                    //TODO: validate jittering. Should move to PTS
                    //validateJittering(resultListener);

                    image.close();
                }
            }

            if (!burstTest) {
                Log.w(TAG, String.format(""Camera %d Video size %s: Number of dropped frames "" +
                        ""detected in %d trials is %d frames."", cameraId, videoSz.toString(),
                        numTestIterations, totalDroppedFrames));
                mCollector.expectLessOrEqual(
                        String.format(
                                ""Camera %d Video size %s: Number of dropped frames %d must not""
                                + "" be larger than %d"",
                                cameraId, videoSz.toString(), totalDroppedFrames,
                                kFrameDrop_Tolerence),
                        kFrameDrop_Tolerence, totalDroppedFrames);
            }
            closeImageReader();
        }
    }

    /**
     * Configure video snapshot request according to the still capture size
     */
    private void prepareVideoSnapshot(
            CaptureRequest.Builder requestBuilder,
            ImageReader.OnImageAvailableListener imageListener)
            throws Exception {
        mReader.setOnImageAvailableListener(imageListener, mHandler);
        assertNotNull(""Recording surface must be non-null!"", mRecordingSurface);
        requestBuilder.addTarget(mRecordingSurface);
        assertNotNull(""Preview surface must be non-null!"", mPreviewSurface);
        requestBuilder.addTarget(mPreviewSurface);
        assertNotNull(""Reader surface must be non-null!"", mReaderSurface);
        requestBuilder.addTarget(mReaderSurface);
    }

    /**
     * Find compatible preview sizes for video size and framerate.
     *
     * <p>Preview size will be capped with max preview size.</p>
     *
     * @param videoSize The video size used for preview.
     * @param videoFrameRate The video frame rate
     */
    private List<Size> getPreviewSizesForVideo(Size videoSize, int videoFrameRate) {
        if (mOrderedPreviewSizes == null) {
            throw new IllegalStateException(""supported preview size list is not initialized yet"");
        }
        final float FRAME_DURATION_TOLERANCE = 0.01f;
        long videoFrameDuration = (long) (1e9 / videoFrameRate *
                (1.0 + FRAME_DURATION_TOLERANCE));
        HashMap<Size, Long> minFrameDurationMap = mStaticInfo.
                getAvailableMinFrameDurationsForFormatChecked(ImageFormat.PRIVATE);
        Size maxPreviewSize = mOrderedPreviewSizes.get(0);
        ArrayList<Size> previewSizes = new ArrayList<>();
        if (videoSize.getWidth() > maxPreviewSize.getWidth() ||
                videoSize.getHeight() > maxPreviewSize.getHeight()) {
            for (Size s : mOrderedPreviewSizes) {
                Long frameDuration = minFrameDurationMap.get(s);
                if (mStaticInfo.isHardwareLevelLegacy()) {
                    // Legacy doesn't report min frame duration
                    frameDuration = new Long(0);
                }
                assertTrue(""Cannot find minimum frame duration for private size"" + s,
                        frameDuration != null);
                if (frameDuration <= videoFrameDuration &&
                        s.getWidth() <= videoSize.getWidth() &&
                        s.getHeight() <= videoSize.getHeight()) {
                    Log.v(TAG, ""Add preview size "" + s.toString() + "" for video size "" +
                            videoSize.toString());
                    previewSizes.add(s);
                }
            }
        }

        if (previewSizes.isEmpty()) {
            previewSizes.add(videoSize);
        }

        return previewSizes;
    }

    /**
     * Update preview size with video size.
     *
     * <p>Preview size will be capped with max preview size.</p>
     *
     * @param videoSize The video size used for preview.
     * @param videoFrameRate The video frame rate
     *
     */
    private void updatePreviewSurfaceWithVideo(Size videoSize, int videoFrameRate) {
        List<Size> previewSizes = getPreviewSizesForVideo(videoSize, videoFrameRate);
        updatePreviewSurface(previewSizes.get(0));
    }

    private void prepareRecordingWithProfile(CamcorderProfile profile) throws Exception {
        prepareRecordingWithProfile(profile, false);
    }

    /**
     * Configure MediaRecorder recording session with CamcorderProfile, prepare
     * the recording surface.
     */
    private void prepareRecordingWithProfile(CamcorderProfile profile,
            boolean useIntermediateSurface) throws Exception {
        // Prepare MediaRecorder.
        setupMediaRecorder(profile);
        prepareRecording(useIntermediateSurface);
    }

    private void setupMediaRecorder(CamcorderProfile profile) throws Exception {
        // Set-up MediaRecorder.
        mMediaRecorder.setAudioSource(MediaRecorder.AudioSource.CAMCORDER);
        mMediaRecorder.setVideoSource(MediaRecorder.VideoSource.SURFACE);
        mMediaRecorder.setProfile(profile);

        mVideoFrameRate = profile.videoFrameRate;
        mVideoSize = new Size(profile.videoFrameWidth, profile.videoFrameHeight);
    }

    private void setupMediaRecorder(
            EncoderProfiles profiles,
            EncoderProfiles.VideoProfile videoProfile,
            EncoderProfiles.AudioProfile audioProfile) throws Exception {
        // Set-up MediaRecorder.
        mMediaRecorder.setAudioSource(MediaRecorder.AudioSource.CAMCORDER);
        mMediaRecorder.setVideoSource(MediaRecorder.VideoSource.SURFACE);
        mMediaRecorder.setOutputFormat(profiles.getRecommendedFileFormat());
        mMediaRecorder.setVideoProfile(videoProfile);
        if (audioProfile != null) {
            mMediaRecorder.setAudioProfile(audioProfile);
        }

        mVideoFrameRate = videoProfile.getFrameRate();
        mVideoSize = new Size(videoProfile.getWidth(), videoProfile.getHeight());
    }

    private void prepareRecording(boolean useIntermediateSurface) throws Exception {
        // Continue preparing MediaRecorder
        mMediaRecorder.setOutputFile(mOutMediaFileName);
        if (mPersistentSurface != null) {
            mMediaRecorder.setInputSurface(mPersistentSurface);
            mRecordingSurface = mPersistentSurface;
        }
        mMediaRecorder.prepare();
        if (mPersistentSurface == null) {
            mRecordingSurface = mMediaRecorder.getSurface();
        }
        assertNotNull(""Recording surface must be non-null!"", mRecordingSurface);

        if (useIntermediateSurface) {
            mIntermediateReader = ImageReader.newInstance(
                    mVideoSize.getWidth(), mVideoSize.getHeight(),
                    ImageFormat.PRIVATE, /*maxImages*/3, HardwareBuffer.USAGE_VIDEO_ENCODE);

            mIntermediateSurface = mIntermediateReader.getSurface();
            mIntermediateWriter = ImageWriter.newInstance(mRecordingSurface, /*maxImages*/3,
                    ImageFormat.PRIVATE);
            mQueuer = new ImageWriterQueuer(mIntermediateWriter);

            mIntermediateThread = new HandlerThread(TAG);
            mIntermediateThread.start();
            mIntermediateHandler = new Handler(mIntermediateThread.getLooper());
            mIntermediateReader.setOnImageAvailableListener(mQueuer, mIntermediateHandler);
        }
    }

    /**
     * Configure MediaRecorder recording session with CamcorderProfile, prepare
     * the recording surface. Use AVC for video compression, AAC for audio compression.
     * Both are required for android devices by android CDD.
     */
    private void prepareRecording(Size sz, int videoFrameRate, int captureRate)
            throws Exception {
        // Prepare MediaRecorder.
        mMediaRecorder.setAudioSource(MediaRecorder.AudioSource.CAMCORDER);
        mMediaRecorder.setVideoSource(MediaRecorder.VideoSource.SURFACE);
        mMediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP);
        mMediaRecorder.setOutputFile(mOutMediaFileName);
        mMediaRecorder.setVideoEncodingBitRate(getVideoBitRate(sz));
        mMediaRecorder.setVideoFrameRate(videoFrameRate);
        mMediaRecorder.setCaptureRate(captureRate);
        mMediaRecorder.setVideoSize(sz.getWidth(), sz.getHeight());
        mMediaRecorder.setVideoEncoder(MediaRecorder.VideoEncoder.H264);
        mMediaRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AAC);
        if (mPersistentSurface != null) {
            mMediaRecorder.setInputSurface(mPersistentSurface);
            mRecordingSurface = mPersistentSurface;
        }
        mMediaRecorder.prepare();
        if (mPersistentSurface == null) {
            mRecordingSurface = mMediaRecorder.getSurface();
        }
        assertNotNull(""Recording surface must be non-null!"", mRecordingSurface);
        mVideoFrameRate = videoFrameRate;
        mVideoSize = sz;
    }

    private void startRecording(boolean useMediaRecorder,
            CameraCaptureSession.CaptureCallback listener, boolean useVideoStab) throws Exception {
        startRecording(useMediaRecorder, listener, useVideoStab, /*variableFpsRange*/null,
                /*useIntermediateSurface*/false);
    }

    private void startRecording(boolean useMediaRecorder,
            CameraCaptureSession.CaptureCallback listener, boolean useVideoStab,
            boolean useIntermediateSurface) throws Exception {
        startRecording(useMediaRecorder, listener, useVideoStab, /*variableFpsRange*/null,
                useIntermediateSurface);
    }

    private void startRecording(boolean useMediaRecorder,
            CameraCaptureSession.CaptureCallback listener, boolean useVideoStab,
            Range<Integer> variableFpsRange, boolean useIntermediateSurface) throws Exception {
        if (!mStaticInfo.isVideoStabilizationSupported() && useVideoStab) {
            throw new IllegalArgumentException(""Video stabilization is not supported"");
        }

        List<Surface> outputSurfaces = new ArrayList<Surface>(2);
        assertTrue(""Both preview and recording surfaces should be valid"",
                mPreviewSurface.isValid() && mRecordingSurface.isValid());
        outputSurfaces.add(mPreviewSurface);
        if (useIntermediateSurface) {
            outputSurfaces.add(mIntermediateSurface);
        } else {
            outputSurfaces.add(mRecordingSurface);
        }

        // Video snapshot surface
        if (mReaderSurface != null) {
            outputSurfaces.add(mReaderSurface);
        }
        mSessionListener = new BlockingSessionCallback();

        CaptureRequest.Builder recordingRequestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_RECORD);
        // Make sure camera output frame rate is set to correct value.
        Range<Integer> fpsRange = (variableFpsRange == null) ?
                Range.create(mVideoFrameRate, mVideoFrameRate) : variableFpsRange;

        recordingRequestBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, fpsRange);
        if (useVideoStab) {
            recordingRequestBuilder.set(CaptureRequest.CONTROL_VIDEO_STABILIZATION_MODE,
                    CaptureRequest.CONTROL_VIDEO_STABILIZATION_MODE_ON);
        }
        if (useIntermediateSurface) {
            recordingRequestBuilder.addTarget(mIntermediateSurface);
            if (mQueuer != null) {
                mQueuer.resetInvalidSurfaceFlag();
            }
        } else {
            recordingRequestBuilder.addTarget(mRecordingSurface);
        }
        recordingRequestBuilder.addTarget(mPreviewSurface);
        CaptureRequest recordingRequest = recordingRequestBuilder.build();
        mSession = configureCameraSessionWithParameters(mCamera, outputSurfaces, mSessionListener,
                mHandler, recordingRequest);
        mSession.setRepeatingRequest(recordingRequest, listener, mHandler);

        if (useMediaRecorder) {
            mMediaRecorder.start();
        } else {
            // TODO: need implement MediaCodec path.
        }
        mRecordingStartTime = SystemClock.elapsedRealtime();
    }

    /**
     * Start video recording with preview and video surfaces sharing the same
     * camera stream.
     *
     * @return true if success, false if sharing is not supported.
     */
    private boolean startSharedRecording(boolean useMediaRecorder,
            CameraCaptureSession.CaptureCallback listener, boolean useVideoStab,
            Range<Integer> variableFpsRange) throws Exception {
        if (!mStaticInfo.isVideoStabilizationSupported() && useVideoStab) {
            throw new IllegalArgumentException(""Video stabilization is not supported"");
        }

        List<OutputConfiguration> outputConfigs = new ArrayList<OutputConfiguration>(2);
        assertTrue(""Both preview and recording surfaces should be valid"",
                mPreviewSurface.isValid() && mRecordingSurface.isValid());
        OutputConfiguration sharedConfig = new OutputConfiguration(mPreviewSurface);
        sharedConfig.enableSurfaceSharing();
        sharedConfig.addSurface(mRecordingSurface);
        outputConfigs.add(sharedConfig);

        CaptureRequest.Builder recordingRequestBuilder =
                mCamera.createCaptureRequest(CameraDevice.TEMPLATE_RECORD);
        // Make sure camera output frame rate is set to correct value.
        Range<Integer> fpsRange = (variableFpsRange == null) ?
                Range.create(mVideoFrameRate, mVideoFrameRate) : variableFpsRange;
        recordingRequestBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, fpsRange);
        if (useVideoStab) {
            recordingRequestBuilder.set(CaptureRequest.CONTROL_VIDEO_STABILIZATION_MODE,
                    CaptureRequest.CONTROL_VIDEO_STABILIZATION_MODE_ON);
        }
        CaptureRequest recordingRequest = recordingRequestBuilder.build();

        mSessionListener = new BlockingSessionCallback();
        mSession = tryConfigureCameraSessionWithConfig(mCamera, outputConfigs, recordingRequest,
                mSessionListener, mHandler);

        if (mSession == null) {
            Log.i(TAG, ""Sharing between preview and video is not supported"");
            return false;
        }

        recordingRequestBuilder.addTarget(mRecordingSurface);
        recordingRequestBuilder.addTarget(mPreviewSurface);
        mSession.setRepeatingRequest(recordingRequestBuilder.build(), listener, mHandler);

        if (useMediaRecorder) {
            mMediaRecorder.start();
        } else {
            // TODO: need implement MediaCodec path.
        }
        mRecordingStartTime = SystemClock.elapsedRealtime();
        return true;
    }


    private void stopCameraStreaming() throws Exception {
        if (VERBOSE) {
            Log.v(TAG, ""Stopping camera streaming and waiting for idle"");
        }
        // Stop repeating, wait for captures to complete, and disconnect from
        // surfaces
        mSession.close();
        mSessionListener.getStateWaiter().waitForState(SESSION_CLOSED, SESSION_CLOSE_TIMEOUT_MS);
    }

    private int stopRecording(boolean useMediaRecorder) throws Exception {
        return stopRecording(useMediaRecorder, /*useIntermediateSurface*/false,
                /*stopStreaming*/true);
    }

    // Stop recording and return the estimated video duration in milliseconds.
    private int stopRecording(boolean useMediaRecorder, boolean useIntermediateSurface,
            boolean stopStreaming) throws Exception {
        long stopRecordingTime = SystemClock.elapsedRealtime();
        if (useMediaRecorder) {
            if (stopStreaming) {
                stopCameraStreaming();
            }
            if (useIntermediateSurface) {
                mIntermediateReader.setOnImageAvailableListener(null, null);
                mQueuer.expectInvalidSurface();
            }

            mMediaRecorder.stop();
            // Can reuse the MediaRecorder object after reset.
            mMediaRecorder.reset();
        } else {
            // TODO: need implement MediaCodec path.
        }

        if (useIntermediateSurface) {
            mIntermediateReader.close();
            mQueuer.close();
            mIntermediateWriter.close();
            mIntermediateSurface.release();
            mIntermediateReader = null;
            mIntermediateSurface = null;
            mIntermediateWriter = null;
            mIntermediateThread.quitSafely();
            mIntermediateHandler = null;
        }

        if (mPersistentSurface == null && mRecordingSurface != null) {
            mRecordingSurface.release();
            mRecordingSurface = null;
        }
        return (int) (stopRecordingTime - mRecordingStartTime);
    }

    private void releaseRecorder() {
        if (mMediaRecorder != null) {
            mMediaRecorder.release();
            mMediaRecorder = null;
        }
    }

    private void validateRecording(
            Size sz, float expectedDurationMs, float expectedFrameDurationMs,
            float frameDropTolerance) throws Exception {
        validateRecording(sz,
                expectedDurationMs,  /*fixed FPS recording*/0.f,
                expectedFrameDurationMs, /*fixed FPS recording*/0.f,
                frameDropTolerance);
    }

    private void validateRecording(
            Size sz,
            float expectedDurationMinMs,      // Min duration (maxFps)
            float expectedDurationMaxMs,      // Max duration (minFps). 0.f for fixed fps recording
            float expectedFrameDurationMinMs, // maxFps
            float expectedFrameDurationMaxMs, // minFps. 0.f for fixed fps recording
            float frameDropTolerance) throws Exception {
        File outFile = new File(mOutMediaFileName);
        assertTrue(""No video is recorded"", outFile.exists());
        float maxFrameDuration = expectedFrameDurationMinMs * (1.0f + FRAMEDURATION_MARGIN);
        if (expectedFrameDurationMaxMs > 0.f) {
            maxFrameDuration = expectedFrameDurationMaxMs * (1.0f + FRAMEDURATION_MARGIN);
        }

        if (expectedDurationMaxMs == 0.f) {
            expectedDurationMaxMs = expectedDurationMinMs;
        }

        MediaExtractor extractor = new MediaExtractor();
        try {
            extractor.setDataSource(mOutMediaFileName);
            long durationUs = 0;
            int width = -1, height = -1;
            int numTracks = extractor.getTrackCount();
            int selectedTrack = -1;
            final String VIDEO_MIME_TYPE = ""video"";
            for (int i = 0; i < numTracks; i++) {
                MediaFormat format = extractor.getTrackFormat(i);
                String mime = format.getString(MediaFormat.KEY_MIME);
                if (mime.contains(VIDEO_MIME_TYPE)) {
                    Log.i(TAG, ""video format is: "" + format.toString());
                    durationUs = format.getLong(MediaFormat.KEY_DURATION);
                    width = format.getInteger(MediaFormat.KEY_WIDTH);
                    height = format.getInteger(MediaFormat.KEY_HEIGHT);
                    selectedTrack = i;
                    extractor.selectTrack(i);
                    break;
                }
            }
            if (selectedTrack < 0) {
                throw new AssertionFailedError(
                        ""Cannot find video track!"");
            }

            Size videoSz = new Size(width, height);
            assertTrue(""Video size doesn't match, expected "" + sz.toString() +
                    "" got "" + videoSz.toString(), videoSz.equals(sz));
            float duration = (float) (durationUs / 1000);
            if (VERBOSE) {
                Log.v(TAG, String.format(""Video duration: recorded %fms, expected [%f,%f]ms"",
                                         duration, expectedDurationMinMs, expectedDurationMaxMs));
            }

            // Do rest of validation only for better-than-LEGACY devices
            if (mStaticInfo.isHardwareLevelLegacy()) return;

            // TODO: Don't skip this one for video snapshot on LEGACY
            assertTrue(String.format(
                    ""Camera %s: Video duration doesn't match: recorded %fms, expected [%f,%f]ms."",
                    mCamera.getId(), duration,
                    expectedDurationMinMs * (1.f - DURATION_MARGIN),
                    expectedDurationMaxMs * (1.f + DURATION_MARGIN)),
                    duration > expectedDurationMinMs * (1.f - DURATION_MARGIN) &&
                            duration < expectedDurationMaxMs * (1.f + DURATION_MARGIN));

            // Check for framedrop
            long lastSampleUs = 0;
            int frameDropCount = 0;
            int expectedFrameCount = (int) (expectedDurationMinMs / expectedFrameDurationMinMs);
            ArrayList<Long> timestamps = new ArrayList<Long>(expectedFrameCount);
            while (true) {
                timestamps.add(extractor.getSampleTime());
                if (!extractor.advance()) {
                    break;
                }
            }
            Collections.sort(timestamps);
            long prevSampleUs = timestamps.get(0);
            for (int i = 1; i < timestamps.size(); i++) {
                long currentSampleUs = timestamps.get(i);
                float frameDurationMs = (float) (currentSampleUs - prevSampleUs) / 1000;
                if (frameDurationMs > maxFrameDuration) {
                    Log.w(TAG, String.format(
                        ""Frame drop at %d: expectation %f, observed %f"",
                        i, expectedFrameDurationMinMs, frameDurationMs));
                    frameDropCount++;
                }
                prevSampleUs = currentSampleUs;
            }
            float frameDropRate = 100.f * frameDropCount / timestamps.size();
            Log.i(TAG, String.format(""Frame drop rate %d/%d (%f%%)"",
                frameDropCount, timestamps.size(), frameDropRate));
            assertTrue(String.format(
                    ""Camera %s: Video frame drop rate too high: %f%%, tolerance %f%%. "" +
                    ""Video size: %s, expectedDuration [%f,%f], expectedFrameDuration %f, "" +
                    ""frameDropCnt %d, frameCount %d"",
                    mCamera.getId(), frameDropRate, frameDropTolerance,
                    sz.toString(), expectedDurationMinMs, expectedDurationMaxMs,
                    expectedFrameDurationMinMs, frameDropCount, timestamps.size()),
                    frameDropRate < frameDropTolerance);
        } finally {
            extractor.release();
            if (!DEBUG_DUMP) {
                outFile.delete();
            }
        }
    }

    /**
     * Validate video snapshot capture image object validity and test.
     *
     * <p> Check for size, format and jpeg decoding</p>
     *
     * @param image The JPEG image to be verified.
     * @param size The JPEG capture size to be verified against.
     */
    private void validateVideoSnapshotCapture(Image image, Size size) {
        CameraTestUtils.validateImage(image, size.getWidth(), size.getHeight(),
                ImageFormat.JPEG, /*filePath*/null);
    }

    /**
     * Validate if video snapshot causes frame drop.
     * Here frame drop is defined as frame duration >= 2 * expected frame duration.
     * Return the estimated number of frames dropped during video snapshot
     */
    private int validateFrameDropAroundVideoSnapshot(
            SimpleCaptureCallback resultListener, long imageTimeStamp) {
        double expectedDurationMs = 1000.0 / mVideoFrameRate;
        CaptureResult prevResult = resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
        long prevTS = getValueNotNull(prevResult, CaptureResult.SENSOR_TIMESTAMP);
        while (resultListener.hasMoreResults()) {
            CaptureResult currentResult =
                    resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
            long currentTS = getValueNotNull(currentResult, CaptureResult.SENSOR_TIMESTAMP);
            if (currentTS == imageTimeStamp) {
                // validate the timestamp before and after, then return
                CaptureResult nextResult =
                        resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
                long nextTS = getValueNotNull(nextResult, CaptureResult.SENSOR_TIMESTAMP);
                double durationMs = (currentTS - prevTS) / 1000000.0;
                int totalFramesDropped = 0;

                // Snapshots in legacy mode pause the preview briefly.  Skip the duration
                // requirements for legacy mode unless this is fixed.
                if (!mStaticInfo.isHardwareLevelLegacy()) {
                    mCollector.expectTrue(
                            String.format(
                                    ""Video %dx%d Frame drop detected before video snapshot: "" +
                                            ""duration %.2fms (expected %.2fms)"",
                                    mVideoSize.getWidth(), mVideoSize.getHeight(),
                                    durationMs, expectedDurationMs
                            ),
                            durationMs <= (expectedDurationMs * MAX_NUM_FRAME_DROP_INTERVAL_ALLOWED)
                    );
                    // Log a warning is there is any frame drop detected.
                    if (durationMs >= expectedDurationMs * 2) {
                        Log.w(TAG, String.format(
                                ""Video %dx%d Frame drop detected before video snapshot: "" +
                                        ""duration %.2fms (expected %.2fms)"",
                                mVideoSize.getWidth(), mVideoSize.getHeight(),
                                durationMs, expectedDurationMs
                        ));
                    }

                    durationMs = (nextTS - currentTS) / 1000000.0;
                    mCollector.expectTrue(
                            String.format(
                                    ""Video %dx%d Frame drop detected after video snapshot: "" +
                                            ""duration %.2fms (expected %.2fms)"",
                                    mVideoSize.getWidth(), mVideoSize.getHeight(),
                                    durationMs, expectedDurationMs
                            ),
                            durationMs <= (expectedDurationMs * MAX_NUM_FRAME_DROP_INTERVAL_ALLOWED)
                    );
                    // Log a warning is there is any frame drop detected.
                    if (durationMs >= expectedDurationMs * 2) {
                        Log.w(TAG, String.format(
                                ""Video %dx%d Frame drop detected after video snapshot: "" +
                                        ""duration %fms (expected %fms)"",
                                mVideoSize.getWidth(), mVideoSize.getHeight(),
                                durationMs, expectedDurationMs
                        ));
                    }

                    double totalDurationMs = (nextTS - prevTS) / 1000000.0;
                    // Minus 2 for the expected 2 frames interval
                    totalFramesDropped = (int) (totalDurationMs / expectedDurationMs) - 2;
                    if (totalFramesDropped < 0) {
                        Log.w(TAG, ""totalFrameDropped is "" + totalFramesDropped +
                                "". Video frame rate might be too fast."");
                    }
                    totalFramesDropped = Math.max(0, totalFramesDropped);
                }
                return totalFramesDropped;
            }
            prevTS = currentTS;
        }
        throw new AssertionFailedError(
                ""Video snapshot timestamp does not match any of capture results!"");
    }

    /**
     * Validate frame jittering from the input simple listener's buffered results
     */
    private void validateJittering(SimpleCaptureCallback resultListener) {
        double expectedDurationMs = 1000.0 / mVideoFrameRate;
        CaptureResult prevResult = resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
        long prevTS = getValueNotNull(prevResult, CaptureResult.SENSOR_TIMESTAMP);
        while (resultListener.hasMoreResults()) {
            CaptureResult currentResult =
                    resultListener.getCaptureResult(WAIT_FOR_RESULT_TIMEOUT_MS);
            long currentTS = getValueNotNull(currentResult, CaptureResult.SENSOR_TIMESTAMP);
            double durationMs = (currentTS - prevTS) / 1000000.0;
            double durationError = Math.abs(durationMs - expectedDurationMs);
            long frameNumber = currentResult.getFrameNumber();
            mCollector.expectTrue(
                    String.format(
                            ""Resolution %dx%d Frame %d: jittering (%.2fms) exceeds bound [%.2fms,%.2fms]"",
                            mVideoSize.getWidth(), mVideoSize.getHeight(),
                            frameNumber, durationMs,
                            expectedDurationMs - FRAME_DURATION_ERROR_TOLERANCE_MS,
                            expectedDurationMs + FRAME_DURATION_ERROR_TOLERANCE_MS),
                    durationError <= FRAME_DURATION_ERROR_TOLERANCE_MS);
            prevTS = currentTS;
        }
    }

    /**
     * Calculate a video bit rate based on the size. The bit rate is scaled
     * based on ratio of video size to 1080p size.
     */
    private int getVideoBitRate(Size sz) {
        int rate = BIT_RATE_1080P;
        float scaleFactor = sz.getHeight() * sz.getWidth() / (float)(1920 * 1080);
        rate = (int)(rate * scaleFactor);

        // Clamp to the MIN, MAX range.
        return Math.max(BIT_RATE_MIN, Math.min(BIT_RATE_MAX, rate));
    }

    /**
     * Check if the encoder and camera are able to support this size and frame rate.
     * Assume the video compression format is AVC.
     */
    private boolean isSupported(Size sz, int captureRate, int encodingRate) throws Exception {
        // Check camera capability.
        if (!isSupportedByCamera(sz, captureRate)) {
            return false;
        }

        // Check encode capability.
        if (!isSupportedByAVCEncoder(sz, encodingRate)){
            return false;
        }

        if(VERBOSE) {
            Log.v(TAG, ""Both encoder and camera support "" + sz.toString() + ""@"" + encodingRate + ""@""
                    + getVideoBitRate(sz) / 1000 + ""Kbps"");
        }

        return true;
    }

    private boolean isSupportedByCamera(Size sz, int frameRate) {
        // Check if camera can support this sz and frame rate combination.
        StreamConfigurationMap config = mStaticInfo.
                getValueFromKeyNonNull(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);

        long minDuration = config.getOutputMinFrameDuration(MediaRecorder.class, sz);
        if (minDuration == 0) {
            return false;
        }

        int maxFrameRate = (int) (1e9f / minDuration);
        return maxFrameRate >= frameRate;
    }

    /**
     * Check if encoder can support this size and frame rate combination by querying
     * MediaCodec capability. Check is based on size and frame rate. Ignore the bit rate
     * as the bit rates targeted in this test are well below the bit rate max value specified
     * by AVC specification for certain level.
     */
    private static boolean isSupportedByAVCEncoder(Size sz, int frameRate) {
        MediaFormat format = MediaFormat.createVideoFormat(
                MediaFormat.MIMETYPE_VIDEO_AVC, sz.getWidth(), sz.getHeight());
        format.setInteger(MediaFormat.KEY_FRAME_RATE, frameRate);
        MediaCodecList mcl = new MediaCodecList(MediaCodecList.REGULAR_CODECS);
        return mcl.findEncoderForFormat(format) != null;
    }

    private static class ImageWriterQueuer implements ImageReader.OnImageAvailableListener {
        public ImageWriterQueuer(ImageWriter writer) {
            mWriter = writer;
        }

        public void resetInvalidSurfaceFlag() {
            synchronized (mLock) {
                mExpectInvalidSurface = false;
            }
        }

        // Indicate that the writer surface is about to get released
        // and become invalid.
        public void expectInvalidSurface() {
            // If we sync on 'mLock', we risk a possible deadlock
            // during 'mWriter.queueInputImage(image)' which is
            // called while the lock is held.
            mExpectInvalidSurface = true;
        }

        @Override
        public void onImageAvailable(ImageReader reader) {
            Image image = null;
            try {
                image = reader.acquireNextImage();
            } finally {
                synchronized (mLock) {
                    if (image != null && mWriter != null) {
                        try {
                            mWriter.queueInputImage(image);
                            mQueuedCount++;
                        } catch (IllegalStateException e) {
                            // Per API documentation ISE are possible
                            // in case the writer surface is not valid.
                            // Re-throw in case we have some other
                            // unexpected ISE.
                            if (mExpectInvalidSurface) {
                                Log.d(TAG, ""Invalid writer surface"");
                                image.close();
                            } else {
                                throw e;
                            }
                        }
                    } else if (image != null) {
                        image.close();
                    }
                }
            }
        }

        public int getQueuedCount() {
            synchronized (mLock) {
                return mQueuedCount;
            }
        }

        public void close() {
            synchronized (mLock) {
                mWriter = null;
            }
        }

        private Object      mLock = new Object();
        private ImageWriter mWriter = null;
        private int         mQueuedCount = 0;
        private boolean     mExpectInvalidSurface = false;
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
"7.3.8  . Proximity Sensor"	"7.3.8"	"C-1-3"	"7.3.8/C-1-3"	"07030800.670103"	"""C-1-3] MUST use 0 centimeters as the near reading and 5 centimeters as the far reading."""	""	""	"proximity sensor"	""	""	""	""	""	""	""	""	"com.android.cts.verifier.sensors.sixdof.Utils.TestPhase.AccuracyTest"	"getPathMarkersSize"	""	"/home/gpoor/cts-12-source/cts/apps/CtsVerifier/src/com/android/cts/verifier/sensors/sixdof/Utils/TestPhase/AccuracyTest.java"	""	"public void test/*
 *.
 */
package com.android.cts.verifier.sensors.sixdof.Utils.TestPhase;

import com.android.cts.verifier.sensors.sixdof.Utils.Manager;
import com.android.cts.verifier.sensors.sixdof.Utils.TestReport;
import com.android.cts.verifier.sensors.sixdof.Utils.Path.ReferencePath;

import android.util.Log;

/**
 * Class to handle accuracy test specific operations.
 */
public class AccuracyTest extends Test {
    private boolean resultsGiven = false;

    /**
     * Calls the constructor of the super class.
     *
     * @param referencePath Reference the the reference path.
     * @param testReport    The test report object to record the tests.
     * @param manager       The manager to call when the test is done.
     */
    public AccuracyTest(ReferencePath referencePath, TestReport testReport, Manager manager) {
        super(referencePath, testReport, manager, ""Accuracy Test"");
    }

    /**
     * Accuracy test specific checks. Checks to see if the test is done.
     */
    @Override
    protected void runAdditionalMethods() {
        if (mTestPath.getPathMarkersSize() == MAX_MARKER_NUMBER && !resultsGiven) {
            Log.e(""testPhase addPoseData:"", ""giving the results"");
            resultsGiven = true;
            mManager.onAccuracyTestCompleted(super.executeTests(true, true));
        }
    }
}"	""	""	"sensor"	""	""	""	""	""	""	""	""	""	""
